{
    "/home/zhang/Packages/torch/torch1.11.0/utils/model_dump/__init__.py": [
        {
            "torch.utils.model_dump.__init__.get_info_and_burn_skeleton": 344,
            "get_model_info": [
                345,
                "[175]"
            ]
        }
    ],
    "/home/zhang/Packages/torch/torch1.11.0/utils/tensorboard/_caffe2_graph.py": [
        {
            "torch.utils.tensorboard._caffe2_graph.protos_to_graph_def": 766,
            "_operators_to_graph_def": [
                784,
                "[601]"
            ]
        }
    ],
    "/home/zhang/Packages/torch/torch1.11.0/fx/experimental/unification/multipledispatch/dispatcher.py": [
        {
            "torch.fx.experimental.unification.multipledispatch.dispatcher.Dispatcher.register": 114,
            "add": [
                135,
                "[165]"
            ]
        }
    ],
    "/home/zhang/Packages/torch/torch1.11.0/testing/_internal/common_utils.py": [
        {
            "torch.testing._internal.common_utils.TestCase.compare_with_numpy": 1780,
            "assertEqual": [
                1809,
                "[1814]"
            ]
        },
        {
            "torch.testing._internal.common_utils.TestCase.assertEqualIgnoreType": 1811,
            "assertEqual": [
                1812,
                "[1814]"
            ]
        },
        {
            "torch.testing._internal.common_utils.TestCase.assertNotEqual": 1880,
            "assertEqual": [
                1883,
                "[1814]"
            ]
        }
    ],
    "/home/zhang/Packages/torch/torch1.11.0/testing/_internal/common_methods_invocations.py": [
        {
            "torch.testing._internal.common_methods_invocations.sample_inputs_argsort": 2853,
            "sample_inputs_sort": [
                2854,
                "[2806]"
            ]
        },
        {
            "torch.testing._internal.common_methods_invocations.sample_inputs_unique_consecutive": 2882,
            "sample_inputs_unique": [
                2883,
                "[2856]"
            ]
        },
        {
            "torch.testing._internal.common_methods_invocations.sample_inputs_reduction_count_nonzero": 3554,
            "sample_inputs_reduction": [
                3556,
                "[602]"
            ]
        }
    ],
    "/home/zhang/Packages/torch/torch1.11.0/onnx/symbolic_opset9.py": [
        {
            "torch.onnx.symbolic_opset9.div": 72,
            "_div_rounding_mode": [
                76,
                "[80]"
            ]
        },
        {
            "torch.onnx.symbolic_opset9.lstm": 2134,
            "_lstm_packed": [
                2136,
                "[2128]"
            ]
        },
        {
            "torch.onnx.symbolic_opset9.lstm": 2134,
            "_lstm_full": [
                2138,
                "[2121]"
            ]
        },
        {
            "torch.onnx.symbolic_opset9.var_mean": 2507,
            "_var_mean": [
                2511,
                "[2472]"
            ]
        }
    ],
    "/home/zhang/Packages/torch/torch1.11.0/onnx/symbolic_opset10.py": [
        {
            "torch.onnx.symbolic_opset10.div": 16,
            "_div_rounding_mode": [
                20,
                "[24]"
            ]
        }
    ],
    "/home/zhang/Packages/torch/torch1.11.0/distributed/fsdp/fully_sharded_data_parallel.py": [
        {
            "torch.distributed.fsdp.fully_sharded_data_parallel.FullyShardedDataParallel.forward": 528,
            "module": [
                538,
                "[250]"
            ]
        }
    ],
    "/home/zhang/Packages/torch/torch1.11.0/distributed/fsdp/flatten_params_wrapper.py": [
        {
            "torch.distributed.fsdp.flatten_params_wrapper.FlattenParamsWrapper.forward": 194,
            "module": [
                197,
                "[70]"
            ]
        }
    ],
    "/home/zhang/Packages/torch/torch1.11.0/distributed/pipeline/sync/pipe.py": [
        {
            "torch.distributed.pipeline.sync.pipe.PipeSequential.forward": 119,
            "module": [
                122,
                "[162]"
            ]
        }
    ]
}