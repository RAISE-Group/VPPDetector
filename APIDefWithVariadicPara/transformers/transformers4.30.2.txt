{
    "/home/zhang/Packages/transformers/transformers4.30.2/integrations.py": [
        {
            "transformers.integrations.run_hp_search_optuna": 189
        },
        {
            "transformers.integrations.run_hp_search_ray": 240
        },
        {
            "transformers.integrations.dynamic_modules_import_trainable": 340
        },
        {
            "transformers.integrations.run_hp_search_sigopt": 376
        },
        {
            "transformers.integrations.run_hp_search_wandb": 476
        },
        {
            "transformers.integrations.TensorBoardCallback.on_train_begin": 621
        },
        {
            "transformers.integrations.TensorBoardCallback.on_log": 643
        },
        {
            "transformers.integrations.TensorBoardCallback.on_train_end": 664
        },
        {
            "transformers.integrations.WandbCallback.setup": 695
        },
        {
            "transformers.integrations.WandbCallback.on_train_begin": 762
        },
        {
            "transformers.integrations.WandbCallback.on_train_end": 773
        },
        {
            "transformers.integrations.WandbCallback.on_log": 807
        },
        {
            "transformers.integrations.WandbCallback.on_save": 816
        },
        {
            "transformers.integrations.CometCallback.on_train_begin": 890
        },
        {
            "transformers.integrations.CometCallback.on_log": 894
        },
        {
            "transformers.integrations.CometCallback.on_train_end": 902
        },
        {
            "transformers.integrations.AzureMLCallback.on_init_end": 924
        },
        {
            "transformers.integrations.AzureMLCallback.on_log": 930
        },
        {
            "transformers.integrations.MLflowCallback.on_train_begin": 1026
        },
        {
            "transformers.integrations.MLflowCallback.on_log": 1030
        },
        {
            "transformers.integrations.MLflowCallback.on_train_end": 1045
        },
        {
            "transformers.integrations.MLflowCallback.on_save": 1050
        },
        {
            "transformers.integrations.DagsHubCallback.setup": 1086
        },
        {
            "transformers.integrations.DagsHubCallback.on_train_end": 1113
        },
        {
            "transformers.integrations.NeptuneCallback.__init__": 1168
        },
        {
            "transformers.integrations.NeptuneCallback._initialize_run": 1229
        },
        {
            "transformers.integrations.NeptuneCallback.on_init_end": 1330
        },
        {
            "transformers.integrations.NeptuneCallback.on_train_begin": 1338
        },
        {
            "transformers.integrations.NeptuneCallback.on_train_end": 1353
        },
        {
            "transformers.integrations.NeptuneCallback.on_save": 1362
        },
        {
            "transformers.integrations.NeptuneCallback.on_evaluate": 1366
        },
        {
            "transformers.integrations.NeptuneCallback.on_log": 1386
        },
        {
            "transformers.integrations.CodeCarbonCallback.on_init_end": 1414
        },
        {
            "transformers.integrations.CodeCarbonCallback.on_train_begin": 1419
        },
        {
            "transformers.integrations.CodeCarbonCallback.on_train_end": 1423
        },
        {
            "transformers.integrations.ClearMLCallback.setup": 1454
        },
        {
            "transformers.integrations.ClearMLCallback.on_train_begin": 1482
        },
        {
            "transformers.integrations.ClearMLCallback.on_train_end": 1490
        },
        {
            "transformers.integrations.ClearMLCallback.on_log": 1497
        },
        {
            "transformers.integrations.ClearMLCallback.on_save": 1539
        },
        {
            "transformers.integrations.FlyteCallback.on_save": 1592
        },
        {
            "transformers.integrations.FlyteCallback.on_train_end": 1600
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/tokenization_utils_base.py": [
        {
            "transformers.tokenization_utils_base.SpecialTokensMixin.__init__": 816
        },
        {
            "transformers.tokenization_utils_base.PreTrainedTokenizerBase.__init__": 1514
        },
        {
            "transformers.tokenization_utils_base.PreTrainedTokenizerBase.from_pretrained": 1618
        },
        {
            "transformers.tokenization_utils_base.PreTrainedTokenizerBase._from_pretrained": 1839
        },
        {
            "transformers.tokenization_utils_base.PreTrainedTokenizerBase.save_pretrained": 2078
        },
        {
            "transformers.tokenization_utils_base.PreTrainedTokenizerBase.tokenize": 2275
        },
        {
            "transformers.tokenization_utils_base.PreTrainedTokenizerBase.encode": 2305
        },
        {
            "transformers.tokenization_utils_base.PreTrainedTokenizerBase._get_padding_truncation_strategies": 2349
        },
        {
            "transformers.tokenization_utils_base.PreTrainedTokenizerBase.__call__": 2488
        },
        {
            "transformers.tokenization_utils_base.PreTrainedTokenizerBase._call_one": 2576
        },
        {
            "transformers.tokenization_utils_base.PreTrainedTokenizerBase.encode_plus": 2689
        },
        {
            "transformers.tokenization_utils_base.PreTrainedTokenizerBase._encode_plus": 2761
        },
        {
            "transformers.tokenization_utils_base.PreTrainedTokenizerBase.batch_encode_plus": 2785
        },
        {
            "transformers.tokenization_utils_base.PreTrainedTokenizerBase._batch_encode_plus": 2858
        },
        {
            "transformers.tokenization_utils_base.PreTrainedTokenizerBase.prepare_for_model": 3101
        },
        {
            "transformers.tokenization_utils_base.PreTrainedTokenizerBase.batch_decode": 3445
        },
        {
            "transformers.tokenization_utils_base.PreTrainedTokenizerBase.decode": 3479
        },
        {
            "transformers.tokenization_utils_base.PreTrainedTokenizerBase._decode": 3516
        },
        {
            "transformers.tokenization_utils_base.PreTrainedTokenizerBase.prepare_seq2seq_batch": 3656
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/optimization_tf.py": [
        {
            "transformers.optimization_tf.AdamWeightDecay.__init__": 211
        },
        {
            "transformers.optimization_tf.AdamWeightDecay.apply_gradients": 250
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/tokenization_utils.py": [
        {
            "transformers.tokenization_utils.PreTrainedTokenizer.__init__": 346
        },
        {
            "transformers.tokenization_utils.PreTrainedTokenizer.tokenize": 481
        },
        {
            "transformers.tokenization_utils.PreTrainedTokenizer._tokenize": 551
        },
        {
            "transformers.tokenization_utils.PreTrainedTokenizer._encode_plus": 593
        },
        {
            "transformers.tokenization_utils.PreTrainedTokenizer._batch_encode_plus": 671
        },
        {
            "transformers.tokenization_utils.PreTrainedTokenizer.prepare_for_tokenization": 821
        },
        {
            "transformers.tokenization_utils.PreTrainedTokenizer._decode": 921
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/pytorch_utils.py": [
        {
            "transformers.pytorch_utils.apply_chunking_to_forward": 165
        },
        {
            "transformers.pytorch_utils.meshgrid": 267
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/modelcard.py": [
        {
            "transformers.modelcard.ModelCard.__init__": 91
        },
        {
            "transformers.modelcard.ModelCard.from_pretrained": 126
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/image_processing_utils.py": [
        {
            "transformers.image_processing_utils.ImageProcessingMixin.__init__": 67
        },
        {
            "transformers.image_processing_utils.ImageProcessingMixin.from_pretrained": 84
        },
        {
            "transformers.image_processing_utils.ImageProcessingMixin.save_pretrained": 169
        },
        {
            "transformers.image_processing_utils.ImageProcessingMixin.get_image_processor_dict": 218
        },
        {
            "transformers.image_processing_utils.ImageProcessingMixin.from_dict": 321
        },
        {
            "transformers.image_processing_utils.BaseImageProcessor.__init__": 459
        },
        {
            "transformers.image_processing_utils.BaseImageProcessor.__call__": 462
        },
        {
            "transformers.image_processing_utils.BaseImageProcessor.preprocess": 466
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/processing_utils.py": [
        {
            "transformers.processing_utils.ProcessorMixin.__init__": 52
        },
        {
            "transformers.processing_utils.ProcessorMixin.save_pretrained": 91
        },
        {
            "transformers.processing_utils.ProcessorMixin.from_pretrained": 154
        },
        {
            "transformers.processing_utils.ProcessorMixin._get_arguments_from_pretrained": 214
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/modeling_utils.py": [
        {
            "transformers.modeling_utils.Identity.__init__": 150
        },
        {
            "transformers.modeling_utils.ModuleUtilsMixin._hook_rss_memory_pre_forward": 750
        },
        {
            "transformers.modeling_utils.ModuleUtilsMixin._hook_rss_memory_post_forward": 762
        },
        {
            "transformers.modeling_utils.PreTrainedModel.__init__": 1090
        },
        {
            "transformers.modeling_utils.PreTrainedModel._from_config": 1119
        },
        {
            "transformers.modeling_utils.PreTrainedModel.save_pretrained": 1654
        },
        {
            "transformers.modeling_utils.PreTrainedModel.to": 1894
        },
        {
            "transformers.modeling_utils.PreTrainedModel.half": 1904
        },
        {
            "transformers.modeling_utils.PreTrainedModel.float": 1914
        },
        {
            "transformers.modeling_utils.PreTrainedModel.from_pretrained": 1925
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/trainer_callback.py": [
        {
            "transformers.trainer_callback.TrainerCallback.on_init_end": 209
        },
        {
            "transformers.trainer_callback.TrainerCallback.on_train_begin": 215
        },
        {
            "transformers.trainer_callback.TrainerCallback.on_train_end": 221
        },
        {
            "transformers.trainer_callback.TrainerCallback.on_epoch_begin": 227
        },
        {
            "transformers.trainer_callback.TrainerCallback.on_epoch_end": 233
        },
        {
            "transformers.trainer_callback.TrainerCallback.on_step_begin": 239
        },
        {
            "transformers.trainer_callback.TrainerCallback.on_substep_end": 246
        },
        {
            "transformers.trainer_callback.TrainerCallback.on_step_end": 252
        },
        {
            "transformers.trainer_callback.TrainerCallback.on_evaluate": 259
        },
        {
            "transformers.trainer_callback.TrainerCallback.on_predict": 265
        },
        {
            "transformers.trainer_callback.TrainerCallback.on_save": 271
        },
        {
            "transformers.trainer_callback.TrainerCallback.on_log": 277
        },
        {
            "transformers.trainer_callback.TrainerCallback.on_prediction_step": 283
        },
        {
            "transformers.trainer_callback.CallbackHandler.call_event": 395
        },
        {
            "transformers.trainer_callback.DefaultFlowCallback.on_step_end": 420
        },
        {
            "transformers.trainer_callback.DefaultFlowCallback.on_epoch_end": 449
        },
        {
            "transformers.trainer_callback.ProgressCallback.on_train_begin": 474
        },
        {
            "transformers.trainer_callback.ProgressCallback.on_step_end": 479
        },
        {
            "transformers.trainer_callback.ProgressCallback.on_prediction_step": 484
        },
        {
            "transformers.trainer_callback.ProgressCallback.on_evaluate": 490
        },
        {
            "transformers.trainer_callback.ProgressCallback.on_predict": 496
        },
        {
            "transformers.trainer_callback.ProgressCallback.on_log": 502
        },
        {
            "transformers.trainer_callback.ProgressCallback.on_train_end": 507
        },
        {
            "transformers.trainer_callback.PrinterCallback.on_log": 518
        },
        {
            "transformers.trainer_callback.EarlyStoppingCallback.on_train_begin": 558
        },
        {
            "transformers.trainer_callback.EarlyStoppingCallback.on_evaluate": 567
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/time_series_utils.py": [
        {
            "transformers.time_series_utils.ParameterProjection.__init__": 64
        },
        {
            "transformers.time_series_utils.LambdaLayer.forward": 83
        },
        {
            "transformers.time_series_utils.DistributionOutput.domain_map": 147
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/trainer.py": [
        {
            "transformers.trainer.Trainer.auto_wrapper_callable": 1522
        },
        {
            "transformers.trainer.Trainer.train": 1566
        },
        {
            "transformers.trainer.Trainer.hyperparameter_search": 2561
        },
        {
            "transformers.trainer.Trainer.push_to_hub": 3697
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/hf_argparser.py": [
        {
            "transformers.hf_argparser.HfArg": 70
        },
        {
            "transformers.hf_argparser.HfArgumentParser.__init__": 128
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/keras_callbacks.py": [
        {
            "transformers.keras_callbacks.PushToHubCallback.__init__": 315
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/testing_utils.py": [
        {
            "transformers.testing_utils.CaptureStd.__exit__": 935
        },
        {
            "transformers.testing_utils.CaptureLogger.__exit__": 1014
        },
        {
            "transformers.testing_utils.mockenv": 1348
        },
        {
            "transformers.testing_utils.mockenv_context": 1361
        },
        {
            "transformers.testing_utils.RequestCounter.__exit__": 1749
        },
        {
            "transformers.testing_utils.RequestCounter.new_request": 1752
        },
        {
            "transformers.testing_utils.wrapper": 1779
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/configuration_utils.py": [
        {
            "transformers.configuration_utils.PretrainedConfig.__init__": 263
        },
        {
            "transformers.configuration_utils.PretrainedConfig.save_pretrained": 423
        },
        {
            "transformers.configuration_utils.PretrainedConfig.from_pretrained": 470
        },
        {
            "transformers.configuration_utils.PretrainedConfig.get_config_dict": 557
        },
        {
            "transformers.configuration_utils.PretrainedConfig._get_config_dict": 588
        },
        {
            "transformers.configuration_utils.PretrainedConfig.from_dict": 678
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/dynamic_module_utils.py": [
        {
            "transformers.dynamic_module_utils.get_class_from_dynamic_module": 333
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/feature_extraction_sequence_utils.py": [
        {
            "transformers.feature_extraction_sequence_utils.SequenceFeatureExtractor.__init__": 42
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/convert_graph_to_onnx.py": [
        {
            "transformers.convert_graph_to_onnx.load_graph_from_args": 226
        },
        {
            "transformers.convert_graph_to_onnx.convert": 352
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/trainer_seq2seq.py": [
        {
            "transformers.trainer_seq2seq.Seq2SeqTrainer.evaluate": 112
        },
        {
            "transformers.trainer_seq2seq.Seq2SeqTrainer.predict": 161
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/tokenization_utils_fast.py": [
        {
            "transformers.tokenization_utils_fast.PreTrainedTokenizerFast.__init__": 95
        },
        {
            "transformers.tokenization_utils_fast.PreTrainedTokenizerFast.tokenize": 316
        },
        {
            "transformers.tokenization_utils_fast.PreTrainedTokenizerFast._encode_plus": 475
        },
        {
            "transformers.tokenization_utils_fast.PreTrainedTokenizerFast._decode": 535
        },
        {
            "transformers.tokenization_utils_fast.PreTrainedTokenizerFast.train_new_from_iterator": 607
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/convert_slow_tokenizer.py": [
        {
            "transformers.convert_slow_tokenizer.SpmConverter.__init__": 440
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/feature_extraction_utils.py": [
        {
            "transformers.feature_extraction_utils.BatchFeature.to": 187
        },
        {
            "transformers.feature_extraction_utils.FeatureExtractionMixin.__init__": 240
        },
        {
            "transformers.feature_extraction_utils.FeatureExtractionMixin.from_pretrained": 257
        },
        {
            "transformers.feature_extraction_utils.FeatureExtractionMixin.save_pretrained": 342
        },
        {
            "transformers.feature_extraction_utils.FeatureExtractionMixin.get_feature_extractor_dict": 391
        },
        {
            "transformers.feature_extraction_utils.FeatureExtractionMixin.from_dict": 489
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/trainer_pt_utils.py": [
        {
            "transformers.trainer_pt_utils.DistributedSamplerWithLoop.__init__": 264
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/modeling_flax_utils.py": [
        {
            "transformers.modeling_flax_utils.FlaxPreTrainedModel._from_config": 237
        },
        {
            "transformers.modeling_flax_utils.FlaxPreTrainedModel.from_pretrained": 482
        },
        {
            "transformers.modeling_flax_utils.FlaxPreTrainedModel.save_pretrained": 1008
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/modeling_tf_utils.py": [
        {
            "transformers.modeling_tf_utils.wrapped_init": 171
        },
        {
            "transformers.modeling_tf_utils.booleans_processing": 375
        },
        {
            "transformers.modeling_tf_utils.run_call_with_unpacked_inputs": 426
        },
        {
            "transformers.modeling_tf_utils.input_processing": 452
        },
        {
            "transformers.modeling_tf_utils.TFPreTrainedModel.__init__": 1162
        },
        {
            "transformers.modeling_tf_utils.TFPreTrainedModel.from_config": 1185
        },
        {
            "transformers.modeling_tf_utils.TFPreTrainedModel._from_config": 1191
        },
        {
            "transformers.modeling_tf_utils.TFPreTrainedModel.compile": 1517
        },
        {
            "transformers.modeling_tf_utils.TFPreTrainedModel.compute_loss": 1571
        },
        {
            "transformers.modeling_tf_utils.TFPreTrainedModel.save_pretrained": 2344
        },
        {
            "transformers.modeling_tf_utils.TFPreTrainedModel.from_pretrained": 2501
        },
        {
            "transformers.modeling_tf_utils.TFPreTrainedModel.push_to_hub": 3029
        },
        {
            "transformers.modeling_tf_utils.TFConv1D.__init__": 3169
        },
        {
            "transformers.modeling_tf_utils.TFSharedEmbeddings.__init__": 3212
        },
        {
            "transformers.modeling_tf_utils.TFSequenceSummary.__init__": 3325
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/generation/tf_logits_process.py": [
        {
            "transformers.generation.tf_logits_process.TFLogitsProcessorList.__call__": 83
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/generation/utils.py": [
        {
            "transformers.generation.utils.GenerationMixin.prepare_inputs_for_generation": 493
        },
        {
            "transformers.generation.utils.GenerationMixin.adjust_logits_during_generation": 562
        },
        {
            "transformers.generation.utils.GenerationMixin._expand_inputs_for_generation": 708
        },
        {
            "transformers.generation.utils.GenerationMixin.generate": 1150
        },
        {
            "transformers.generation.utils.GenerationMixin.contrastive_search": 1798
        },
        {
            "transformers.generation.utils.GenerationMixin.greedy_search": 2171
        },
        {
            "transformers.generation.utils.GenerationMixin.sample": 2430
        },
        {
            "transformers.generation.utils.GenerationMixin.beam_search": 2712
        },
        {
            "transformers.generation.utils.GenerationMixin.beam_sample": 3035
        },
        {
            "transformers.generation.utils.GenerationMixin.group_beam_search": 3368
        },
        {
            "transformers.generation.utils.GenerationMixin.constrained_beam_search": 3748
        },
        {
            "transformers.generation.utils.GenerationMixin.assisted_decoding": 4073
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/generation/flax_utils.py": [
        {
            "transformers.generation.flax_utils.FlaxGenerationMixin.prepare_inputs_for_generation": 146
        },
        {
            "transformers.generation.flax_utils.FlaxGenerationMixin.generate": 267
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/generation/beam_search.py": [
        {
            "transformers.generation.beam_search.BeamScorer.process": 95
        },
        {
            "transformers.generation.beam_search.BeamScorer.finalize": 107
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/generation/configuration_utils.py": [
        {
            "transformers.generation.configuration_utils.GenerationConfig.__init__": 224
        },
        {
            "transformers.generation.configuration_utils.GenerationConfig.save_pretrained": 325
        },
        {
            "transformers.generation.configuration_utils.GenerationConfig.from_pretrained": 376
        },
        {
            "transformers.generation.configuration_utils.GenerationConfig.from_dict": 550
        },
        {
            "transformers.generation.configuration_utils.GenerationConfig.update": 696
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/generation/tf_utils.py": [
        {
            "transformers.generation.tf_utils.TFGenerationMixin.prepare_inputs_for_generation": 472
        },
        {
            "transformers.generation.tf_utils.TFGenerationMixin.adjust_logits_during_generation": 477
        },
        {
            "transformers.generation.tf_utils.TFGenerationMixin.generate": 666
        },
        {
            "transformers.generation.tf_utils.TFGenerationMixin._expand_inputs_for_generation": 1152
        },
        {
            "transformers.generation.tf_utils.TFGenerationMixin.greedy_search": 1536
        },
        {
            "transformers.generation.tf_utils.TFGenerationMixin.sample": 1798
        },
        {
            "transformers.generation.tf_utils.TFGenerationMixin.beam_search": 2109
        },
        {
            "transformers.generation.tf_utils.TFGenerationMixin.contrastive_search": 2672
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/generation/streamers.py": [
        {
            "transformers.generation.streamers.TextStreamer.__init__": 72
        },
        {
            "transformers.generation.streamers.TextIteratorStreamer.__init__": 205
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/generation/logits_process.py": [
        {
            "transformers.generation.logits_process.LogitsProcessorList.__call__": 81
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/generation/stopping_criteria.py": [
        {
            "transformers.generation.stopping_criteria.StoppingCriteria.__call__": 37
        },
        {
            "transformers.generation.stopping_criteria.MaxLengthCriteria.__call__": 55
        },
        {
            "transformers.generation.stopping_criteria.MaxNewTokensCriteria.__call__": 84
        },
        {
            "transformers.generation.stopping_criteria.MaxTimeCriteria.__call__": 106
        },
        {
            "transformers.generation.stopping_criteria.StoppingCriteriaList.__call__": 112
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/generation/flax_logits_process.py": [
        {
            "transformers.generation.flax_logits_process.FlaxLogitsProcessorList.__call__": 80
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/pipelines/text_classification.py": [
        {
            "transformers.pipelines.text_classification.TextClassificationPipeline.__init__": 82
        },
        {
            "transformers.pipelines.text_classification.TextClassificationPipeline._sanitize_parameters": 91
        },
        {
            "transformers.pipelines.text_classification.TextClassificationPipeline.__call__": 121
        },
        {
            "transformers.pipelines.text_classification.TextClassificationPipeline.preprocess": 164
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/pipelines/question_answering.py": [
        {
            "transformers.pipelines.question_answering.QuestionAnsweringArgumentHandler.__call__": 173
        },
        {
            "transformers.pipelines.question_answering.QuestionAnsweringPipeline.__init__": 252
        },
        {
            "transformers.pipelines.question_answering.QuestionAnsweringPipeline._sanitize_parameters": 297
        },
        {
            "transformers.pipelines.question_answering.QuestionAnsweringPipeline.__call__": 340
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/pipelines/text2text_generation.py": [
        {
            "transformers.pipelines.text2text_generation.Text2TextGenerationPipeline.__init__": 64
        },
        {
            "transformers.pipelines.text2text_generation.Text2TextGenerationPipeline._sanitize_parameters": 73
        },
        {
            "transformers.pipelines.text2text_generation.Text2TextGenerationPipeline._parse_and_tokenize": 115
        },
        {
            "transformers.pipelines.text2text_generation.Text2TextGenerationPipeline.__call__": 136
        },
        {
            "transformers.pipelines.text2text_generation.Text2TextGenerationPipeline.preprocess": 174
        },
        {
            "transformers.pipelines.text2text_generation.Text2TextGenerationPipeline._forward": 178
        },
        {
            "transformers.pipelines.text2text_generation.SummarizationPipeline.__call__": 241
        },
        {
            "transformers.pipelines.text2text_generation.TranslationPipeline.preprocess": 313
        },
        {
            "transformers.pipelines.text2text_generation.TranslationPipeline._sanitize_parameters": 321
        },
        {
            "transformers.pipelines.text2text_generation.TranslationPipeline.__call__": 337
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/pipelines/token_classification.py": [
        {
            "transformers.pipelines.token_classification.TokenClassificationArgumentHandler.__call__": 30
        },
        {
            "transformers.pipelines.token_classification.TokenClassificationPipeline.__init__": 135
        },
        {
            "transformers.pipelines.token_classification.TokenClassificationPipeline.__call__": 219
        },
        {
            "transformers.pipelines.token_classification.TokenClassificationPipeline.preprocess": 251
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/pipelines/automatic_speech_recognition.py": [
        {
            "transformers.pipelines.automatic_speech_recognition.AutomaticSpeechRecognitionPipeline.__init__": 196
        },
        {
            "transformers.pipelines.automatic_speech_recognition.AutomaticSpeechRecognitionPipeline.__call__": 225
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/pipelines/image_classification.py": [
        {
            "transformers.pipelines.image_classification.ImageClassificationPipeline.__init__": 56
        },
        {
            "transformers.pipelines.image_classification.ImageClassificationPipeline.__call__": 71
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/pipelines/visual_question_answering.py": [
        {
            "transformers.pipelines.visual_question_answering.VisualQuestionAnsweringPipeline.__init__": 54
        },
        {
            "transformers.pipelines.visual_question_answering.VisualQuestionAnsweringPipeline._sanitize_parameters": 58
        },
        {
            "transformers.pipelines.visual_question_answering.VisualQuestionAnsweringPipeline.__call__": 68
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/pipelines/zero_shot_object_detection.py": [
        {
            "transformers.pipelines.zero_shot_object_detection.ZeroShotObjectDetectionPipeline.__init__": 56
        },
        {
            "transformers.pipelines.zero_shot_object_detection.ZeroShotObjectDetectionPipeline.__call__": 65
        },
        {
            "transformers.pipelines.zero_shot_object_detection.ZeroShotObjectDetectionPipeline._sanitize_parameters": 134
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/pipelines/zero_shot_image_classification.py": [
        {
            "transformers.pipelines.zero_shot_image_classification.ZeroShotImageClassificationPipeline.__init__": 64
        },
        {
            "transformers.pipelines.zero_shot_image_classification.ZeroShotImageClassificationPipeline.__call__": 74
        },
        {
            "transformers.pipelines.zero_shot_image_classification.ZeroShotImageClassificationPipeline._sanitize_parameters": 103
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/pipelines/zero_shot_audio_classification.py": [
        {
            "transformers.pipelines.zero_shot_audio_classification.ZeroShotAudioClassificationPipeline.__init__": 57
        },
        {
            "transformers.pipelines.zero_shot_audio_classification.ZeroShotAudioClassificationPipeline.__call__": 64
        },
        {
            "transformers.pipelines.zero_shot_audio_classification.ZeroShotAudioClassificationPipeline._sanitize_parameters": 88
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/pipelines/audio_classification.py": [
        {
            "transformers.pipelines.audio_classification.AudioClassificationPipeline.__init__": 93
        },
        {
            "transformers.pipelines.audio_classification.AudioClassificationPipeline.__call__": 103
        },
        {
            "transformers.pipelines.audio_classification.AudioClassificationPipeline._sanitize_parameters": 132
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/pipelines/conversational.py": [
        {
            "transformers.pipelines.conversational.ConversationalPipeline.__init__": 195
        },
        {
            "transformers.pipelines.conversational.ConversationalPipeline._sanitize_parameters": 200
        },
        {
            "transformers.pipelines.conversational.ConversationalPipeline.__call__": 222
        },
        {
            "transformers.pipelines.conversational.ConversationalPipeline._forward": 268
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/pipelines/table_question_answering.py": [
        {
            "transformers.pipelines.table_question_answering.TableQuestionAnsweringArgumentHandler.__call__": 39
        },
        {
            "transformers.pipelines.table_question_answering.TableQuestionAnsweringPipeline.__init__": 121
        },
        {
            "transformers.pipelines.table_question_answering.TableQuestionAnsweringPipeline.batch_inference": 141
        },
        {
            "transformers.pipelines.table_question_answering.TableQuestionAnsweringPipeline.sequential_inference": 144
        },
        {
            "transformers.pipelines.table_question_answering.TableQuestionAnsweringPipeline.__call__": 273
        },
        {
            "transformers.pipelines.table_question_answering.TableQuestionAnsweringPipeline._sanitize_parameters": 355
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/pipelines/base.py": [
        {
            "transformers.pipelines.base.infer_framework_load_model": 187
        },
        {
            "transformers.pipelines.base.infer_framework_from_model": 284
        },
        {
            "transformers.pipelines.base.ArgumentHandler.__call__": 424
        },
        {
            "transformers.pipelines.base.Pipeline.__init__": 753
        },
        {
            "transformers.pipelines.base.Pipeline.ensure_tensor_on_device": 909
        },
        {
            "transformers.pipelines.base.Pipeline._sanitize_parameters": 967
        },
        {
            "transformers.pipelines.base.Pipeline.preprocess": 980
        },
        {
            "transformers.pipelines.base.Pipeline._forward": 988
        },
        {
            "transformers.pipelines.base.Pipeline.postprocess": 1001
        },
        {
            "transformers.pipelines.base.Pipeline.forward": 1017
        },
        {
            "transformers.pipelines.base.Pipeline.__call__": 1057
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/pipelines/mask_generation.py": [
        {
            "transformers.pipelines.mask_generation.MaskGenerationPipeline.__init__": 91
        },
        {
            "transformers.pipelines.mask_generation.MaskGenerationPipeline._sanitize_parameters": 101
        },
        {
            "transformers.pipelines.mask_generation.MaskGenerationPipeline.__call__": 133
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/pipelines/image_to_text.py": [
        {
            "transformers.pipelines.image_to_text.ImageToTextPipeline.__init__": 54
        },
        {
            "transformers.pipelines.image_to_text.ImageToTextPipeline.__call__": 81
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/pipelines/feature_extraction.py": [
        {
            "transformers.pipelines.feature_extraction.FeatureExtractionPipeline._sanitize_parameters": 60
        },
        {
            "transformers.pipelines.feature_extraction.FeatureExtractionPipeline.preprocess": 79
        },
        {
            "transformers.pipelines.feature_extraction.FeatureExtractionPipeline.__call__": 97
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/pipelines/zero_shot_classification.py": [
        {
            "transformers.pipelines.zero_shot_classification.ZeroShotClassificationPipeline.__init__": 86
        },
        {
            "transformers.pipelines.zero_shot_classification.ZeroShotClassificationPipeline._parse_and_tokenize": 102
        },
        {
            "transformers.pipelines.zero_shot_classification.ZeroShotClassificationPipeline._sanitize_parameters": 144
        },
        {
            "transformers.pipelines.zero_shot_classification.ZeroShotClassificationPipeline.__call__": 162
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/pipelines/depth_estimation.py": [
        {
            "transformers.pipelines.depth_estimation.DepthEstimationPipeline.__init__": 48
        },
        {
            "transformers.pipelines.depth_estimation.DepthEstimationPipeline.__call__": 53
        },
        {
            "transformers.pipelines.depth_estimation.DepthEstimationPipeline._sanitize_parameters": 84
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/pipelines/document_question_answering.py": [
        {
            "transformers.pipelines.document_question_answering.DocumentQuestionAnsweringPipeline.__init__": 132
        },
        {
            "transformers.pipelines.document_question_answering.DocumentQuestionAnsweringPipeline._sanitize_parameters": 151
        },
        {
            "transformers.pipelines.document_question_answering.DocumentQuestionAnsweringPipeline.__call__": 191
        },
        {
            "transformers.pipelines.document_question_answering.DocumentQuestionAnsweringPipeline.postprocess": 434
        },
        {
            "transformers.pipelines.document_question_answering.DocumentQuestionAnsweringPipeline.postprocess_encoder_decoder_single": 443
        },
        {
            "transformers.pipelines.document_question_answering.DocumentQuestionAnsweringPipeline.postprocess_extractive_qa": 459
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/pipelines/fill_mask.py": [
        {
            "transformers.pipelines.fill_mask.FillMaskPipeline.preprocess": 93
        },
        {
            "transformers.pipelines.fill_mask.FillMaskPipeline.__call__": 217
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/pipelines/__init__.py": [
        {
            "transformers.pipelines.__init__.pipeline": 506
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/pipelines/image_segmentation.py": [
        {
            "transformers.pipelines.image_segmentation.ImageSegmentationPipeline.__init__": 67
        },
        {
            "transformers.pipelines.image_segmentation.ImageSegmentationPipeline._sanitize_parameters": 83
        },
        {
            "transformers.pipelines.image_segmentation.ImageSegmentationPipeline.__call__": 98
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/pipelines/object_detection.py": [
        {
            "transformers.pipelines.object_detection.ObjectDetectionPipeline.__init__": 49
        },
        {
            "transformers.pipelines.object_detection.ObjectDetectionPipeline._sanitize_parameters": 60
        },
        {
            "transformers.pipelines.object_detection.ObjectDetectionPipeline.__call__": 66
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/pipelines/text_generation.py": [
        {
            "transformers.pipelines.text_generation.TextGenerationPipeline.__init__": 63
        },
        {
            "transformers.pipelines.text_generation.TextGenerationPipeline._sanitize_parameters": 90
        },
        {
            "transformers.pipelines.text_generation.TextGenerationPipeline._parse_and_tokenize": 150
        },
        {
            "transformers.pipelines.text_generation.TextGenerationPipeline.__call__": 160
        },
        {
            "transformers.pipelines.text_generation.TextGenerationPipeline.preprocess": 203
        },
        {
            "transformers.pipelines.text_generation.TextGenerationPipeline._forward": 231
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/pipelines/video_classification.py": [
        {
            "transformers.pipelines.video_classification.VideoClassificationPipeline.__init__": 34
        },
        {
            "transformers.pipelines.video_classification.VideoClassificationPipeline.__call__": 51
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/utils/dummy_keras_nlp_objects.py": [
        {
            "transformers.utils.dummy_keras_nlp_objects.TFGPT2Tokenizer.__init__": 8
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/utils/dummy_sentencepiece_and_tokenizers_objects.py": [
        {
            "transformers.utils.dummy_sentencepiece_and_tokenizers_objects.convert_slow_tokenizer": 8
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/utils/doc.py": [
        {
            "transformers.utils.doc.add_start_docstrings": 23
        },
        {
            "transformers.utils.doc.add_start_docstrings_to_model_forward": 31
        },
        {
            "transformers.utils.doc.add_end_docstrings": 53
        },
        {
            "transformers.utils.doc.filter_outputs_from_example": 1045
        },
        {
            "transformers.utils.doc.add_code_sample_docstrings": 1059
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/utils/dummy_sentencepiece_objects.py": [
        {
            "transformers.utils.dummy_sentencepiece_objects.AlbertTokenizer.__init__": 8
        },
        {
            "transformers.utils.dummy_sentencepiece_objects.BarthezTokenizer.__init__": 15
        },
        {
            "transformers.utils.dummy_sentencepiece_objects.BartphoTokenizer.__init__": 22
        },
        {
            "transformers.utils.dummy_sentencepiece_objects.BertGenerationTokenizer.__init__": 29
        },
        {
            "transformers.utils.dummy_sentencepiece_objects.BigBirdTokenizer.__init__": 36
        },
        {
            "transformers.utils.dummy_sentencepiece_objects.CamembertTokenizer.__init__": 43
        },
        {
            "transformers.utils.dummy_sentencepiece_objects.CpmTokenizer.__init__": 50
        },
        {
            "transformers.utils.dummy_sentencepiece_objects.DebertaV2Tokenizer.__init__": 57
        },
        {
            "transformers.utils.dummy_sentencepiece_objects.ErnieMTokenizer.__init__": 64
        },
        {
            "transformers.utils.dummy_sentencepiece_objects.FNetTokenizer.__init__": 71
        },
        {
            "transformers.utils.dummy_sentencepiece_objects.GPTSw3Tokenizer.__init__": 78
        },
        {
            "transformers.utils.dummy_sentencepiece_objects.LayoutXLMTokenizer.__init__": 85
        },
        {
            "transformers.utils.dummy_sentencepiece_objects.LlamaTokenizer.__init__": 92
        },
        {
            "transformers.utils.dummy_sentencepiece_objects.M2M100Tokenizer.__init__": 99
        },
        {
            "transformers.utils.dummy_sentencepiece_objects.MarianTokenizer.__init__": 106
        },
        {
            "transformers.utils.dummy_sentencepiece_objects.MBart50Tokenizer.__init__": 113
        },
        {
            "transformers.utils.dummy_sentencepiece_objects.MBartTokenizer.__init__": 120
        },
        {
            "transformers.utils.dummy_sentencepiece_objects.MLukeTokenizer.__init__": 127
        },
        {
            "transformers.utils.dummy_sentencepiece_objects.MT5Tokenizer.__init__": 134
        },
        {
            "transformers.utils.dummy_sentencepiece_objects.NllbTokenizer.__init__": 141
        },
        {
            "transformers.utils.dummy_sentencepiece_objects.PegasusTokenizer.__init__": 148
        },
        {
            "transformers.utils.dummy_sentencepiece_objects.PLBartTokenizer.__init__": 155
        },
        {
            "transformers.utils.dummy_sentencepiece_objects.ReformerTokenizer.__init__": 162
        },
        {
            "transformers.utils.dummy_sentencepiece_objects.RemBertTokenizer.__init__": 169
        },
        {
            "transformers.utils.dummy_sentencepiece_objects.Speech2TextTokenizer.__init__": 176
        },
        {
            "transformers.utils.dummy_sentencepiece_objects.SpeechT5Tokenizer.__init__": 183
        },
        {
            "transformers.utils.dummy_sentencepiece_objects.T5Tokenizer.__init__": 190
        },
        {
            "transformers.utils.dummy_sentencepiece_objects.XGLMTokenizer.__init__": 197
        },
        {
            "transformers.utils.dummy_sentencepiece_objects.XLMProphetNetTokenizer.__init__": 204
        },
        {
            "transformers.utils.dummy_sentencepiece_objects.XLMRobertaTokenizer.__init__": 211
        },
        {
            "transformers.utils.dummy_sentencepiece_objects.XLNetTokenizer.__init__": 218
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/utils/notebook.py": [
        {
            "transformers.utils.notebook.NotebookProgressCallback.on_train_begin": 278
        },
        {
            "transformers.utils.notebook.NotebookProgressCallback.on_step_end": 287
        },
        {
            "transformers.utils.notebook.NotebookProgressCallback.on_prediction_step": 296
        },
        {
            "transformers.utils.notebook.NotebookProgressCallback.on_predict": 308
        },
        {
            "transformers.utils.notebook.NotebookProgressCallback.on_log": 313
        },
        {
            "transformers.utils.notebook.NotebookProgressCallback.on_evaluate": 321
        },
        {
            "transformers.utils.notebook.NotebookProgressCallback.on_train_end": 356
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/utils/logging.py": [
        {
            "transformers.utils.logging.warning_advice": 272
        },
        {
            "transformers.utils.logging.warning_once": 287
        },
        {
            "transformers.utils.logging.EmptyTqdm.__init__": 304
        },
        {
            "transformers.utils.logging.EmptyTqdm.empty_fn": 313
        },
        {
            "transformers.utils.logging._tqdm_cls.__call__": 326
        },
        {
            "transformers.utils.logging._tqdm_cls.set_lock": 332
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/utils/dummy_tensorflow_text_objects.py": [
        {
            "transformers.utils.dummy_tensorflow_text_objects.TFBertTokenizer.__init__": 8
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/utils/dummy_speech_objects.py": [
        {
            "transformers.utils.dummy_speech_objects.ASTFeatureExtractor.__init__": 8
        },
        {
            "transformers.utils.dummy_speech_objects.MCTCTFeatureExtractor.__init__": 15
        },
        {
            "transformers.utils.dummy_speech_objects.Speech2TextFeatureExtractor.__init__": 22
        },
        {
            "transformers.utils.dummy_speech_objects.SpeechT5FeatureExtractor.__init__": 29
        },
        {
            "transformers.utils.dummy_speech_objects.TvltFeatureExtractor.__init__": 36
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/utils/fx.py": [
        {
            "transformers.utils.fx.torch_arange": 232
        },
        {
            "transformers.utils.fx.torch_full": 253
        },
        {
            "transformers.utils.fx.torch_einsum": 364
        },
        {
            "transformers.utils.fx.torch_tensor_repeat": 370
        },
        {
            "transformers.utils.fx.torch_repeat_interleave": 377
        },
        {
            "transformers.utils.fx.torch_unique_consecutive": 501
        },
        {
            "transformers.utils.fx.HFAttribute.__call__": 668
        },
        {
            "transformers.utils.fx.wrapper": 689
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/utils/dummy_flax_objects.py": [
        {
            "transformers.utils.dummy_flax_objects.FlaxForcedBOSTokenLogitsProcessor.__init__": 8
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxForcedEOSTokenLogitsProcessor.__init__": 15
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxGenerationMixin.__init__": 22
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxLogitsProcessor.__init__": 29
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxLogitsProcessorList.__init__": 36
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxLogitsWarper.__init__": 43
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxMinLengthLogitsProcessor.__init__": 50
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxTemperatureLogitsWarper.__init__": 57
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxTopKLogitsWarper.__init__": 64
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxTopPLogitsWarper.__init__": 71
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxPreTrainedModel.__init__": 78
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxAlbertForMaskedLM.__init__": 85
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxAlbertForMultipleChoice.__init__": 92
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxAlbertForPreTraining.__init__": 99
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxAlbertForQuestionAnswering.__init__": 106
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxAlbertForSequenceClassification.__init__": 113
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxAlbertForTokenClassification.__init__": 120
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxAlbertModel.__init__": 127
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxAlbertPreTrainedModel.__init__": 134
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxAutoModel.__init__": 180
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxAutoModelForCausalLM.__init__": 187
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxAutoModelForImageClassification.__init__": 194
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxAutoModelForMaskedLM.__init__": 201
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxAutoModelForMultipleChoice.__init__": 208
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxAutoModelForNextSentencePrediction.__init__": 215
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxAutoModelForPreTraining.__init__": 222
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxAutoModelForQuestionAnswering.__init__": 229
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxAutoModelForSeq2SeqLM.__init__": 236
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxAutoModelForSequenceClassification.__init__": 243
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxAutoModelForSpeechSeq2Seq.__init__": 250
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxAutoModelForTokenClassification.__init__": 257
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxAutoModelForVision2Seq.__init__": 264
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxBartDecoderPreTrainedModel.__init__": 271
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxBartForCausalLM.__init__": 278
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxBartForConditionalGeneration.__init__": 285
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxBartForQuestionAnswering.__init__": 292
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxBartForSequenceClassification.__init__": 299
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxBartModel.__init__": 306
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxBartPreTrainedModel.__init__": 313
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxBeitForImageClassification.__init__": 320
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxBeitForMaskedImageModeling.__init__": 327
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxBeitModel.__init__": 334
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxBeitPreTrainedModel.__init__": 341
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxBertForCausalLM.__init__": 348
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxBertForMaskedLM.__init__": 355
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxBertForMultipleChoice.__init__": 362
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxBertForNextSentencePrediction.__init__": 369
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxBertForPreTraining.__init__": 376
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxBertForQuestionAnswering.__init__": 383
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxBertForSequenceClassification.__init__": 390
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxBertForTokenClassification.__init__": 397
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxBertModel.__init__": 404
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxBertPreTrainedModel.__init__": 411
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxBigBirdForCausalLM.__init__": 418
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxBigBirdForMaskedLM.__init__": 425
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxBigBirdForMultipleChoice.__init__": 432
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxBigBirdForPreTraining.__init__": 439
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxBigBirdForQuestionAnswering.__init__": 446
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxBigBirdForSequenceClassification.__init__": 453
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxBigBirdForTokenClassification.__init__": 460
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxBigBirdModel.__init__": 467
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxBigBirdPreTrainedModel.__init__": 474
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxBlenderbotForConditionalGeneration.__init__": 481
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxBlenderbotModel.__init__": 488
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxBlenderbotPreTrainedModel.__init__": 495
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxBlenderbotSmallForConditionalGeneration.__init__": 502
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxBlenderbotSmallModel.__init__": 509
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxBlenderbotSmallPreTrainedModel.__init__": 516
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxCLIPModel.__init__": 523
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxCLIPPreTrainedModel.__init__": 530
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxCLIPTextModel.__init__": 537
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxCLIPTextPreTrainedModel.__init__": 544
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxCLIPVisionModel.__init__": 551
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxCLIPVisionPreTrainedModel.__init__": 558
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxDistilBertForMaskedLM.__init__": 565
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxDistilBertForMultipleChoice.__init__": 572
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxDistilBertForQuestionAnswering.__init__": 579
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxDistilBertForSequenceClassification.__init__": 586
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxDistilBertForTokenClassification.__init__": 593
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxDistilBertModel.__init__": 600
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxDistilBertPreTrainedModel.__init__": 607
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxElectraForCausalLM.__init__": 614
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxElectraForMaskedLM.__init__": 621
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxElectraForMultipleChoice.__init__": 628
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxElectraForPreTraining.__init__": 635
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxElectraForQuestionAnswering.__init__": 642
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxElectraForSequenceClassification.__init__": 649
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxElectraForTokenClassification.__init__": 656
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxElectraModel.__init__": 663
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxElectraPreTrainedModel.__init__": 670
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxEncoderDecoderModel.__init__": 677
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxGPT2LMHeadModel.__init__": 684
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxGPT2Model.__init__": 691
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxGPT2PreTrainedModel.__init__": 698
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxGPTNeoForCausalLM.__init__": 705
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxGPTNeoModel.__init__": 712
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxGPTNeoPreTrainedModel.__init__": 719
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxGPTJForCausalLM.__init__": 726
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxGPTJModel.__init__": 733
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxGPTJPreTrainedModel.__init__": 740
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxLongT5ForConditionalGeneration.__init__": 747
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxLongT5Model.__init__": 754
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxLongT5PreTrainedModel.__init__": 761
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxMarianModel.__init__": 768
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxMarianMTModel.__init__": 775
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxMarianPreTrainedModel.__init__": 782
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxMBartForConditionalGeneration.__init__": 789
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxMBartForQuestionAnswering.__init__": 796
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxMBartForSequenceClassification.__init__": 803
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxMBartModel.__init__": 810
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxMBartPreTrainedModel.__init__": 817
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxMT5EncoderModel.__init__": 824
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxMT5ForConditionalGeneration.__init__": 831
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxMT5Model.__init__": 838
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxOPTForCausalLM.__init__": 845
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxOPTModel.__init__": 852
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxOPTPreTrainedModel.__init__": 859
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxPegasusForConditionalGeneration.__init__": 866
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxPegasusModel.__init__": 873
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxPegasusPreTrainedModel.__init__": 880
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxRegNetForImageClassification.__init__": 887
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxRegNetModel.__init__": 894
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxRegNetPreTrainedModel.__init__": 901
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxResNetForImageClassification.__init__": 908
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxResNetModel.__init__": 915
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxResNetPreTrainedModel.__init__": 922
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxRobertaForCausalLM.__init__": 929
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxRobertaForMaskedLM.__init__": 936
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxRobertaForMultipleChoice.__init__": 943
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxRobertaForQuestionAnswering.__init__": 950
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxRobertaForSequenceClassification.__init__": 957
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxRobertaForTokenClassification.__init__": 964
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxRobertaModel.__init__": 971
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxRobertaPreTrainedModel.__init__": 978
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxRobertaPreLayerNormForCausalLM.__init__": 985
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxRobertaPreLayerNormForMaskedLM.__init__": 992
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxRobertaPreLayerNormForMultipleChoice.__init__": 999
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxRobertaPreLayerNormForQuestionAnswering.__init__": 1006
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxRobertaPreLayerNormForSequenceClassification.__init__": 1013
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxRobertaPreLayerNormForTokenClassification.__init__": 1020
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxRobertaPreLayerNormModel.__init__": 1027
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxRobertaPreLayerNormPreTrainedModel.__init__": 1034
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxRoFormerForMaskedLM.__init__": 1041
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxRoFormerForMultipleChoice.__init__": 1048
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxRoFormerForQuestionAnswering.__init__": 1055
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxRoFormerForSequenceClassification.__init__": 1062
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxRoFormerForTokenClassification.__init__": 1069
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxRoFormerModel.__init__": 1076
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxRoFormerPreTrainedModel.__init__": 1083
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxSpeechEncoderDecoderModel.__init__": 1090
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxT5EncoderModel.__init__": 1097
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxT5ForConditionalGeneration.__init__": 1104
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxT5Model.__init__": 1111
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxT5PreTrainedModel.__init__": 1118
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxVisionEncoderDecoderModel.__init__": 1125
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxVisionTextDualEncoderModel.__init__": 1132
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxViTForImageClassification.__init__": 1139
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxViTModel.__init__": 1146
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxViTPreTrainedModel.__init__": 1153
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxWav2Vec2ForCTC.__init__": 1160
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxWav2Vec2ForPreTraining.__init__": 1167
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxWav2Vec2Model.__init__": 1174
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxWav2Vec2PreTrainedModel.__init__": 1181
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxWhisperForAudioClassification.__init__": 1188
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxWhisperForConditionalGeneration.__init__": 1195
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxWhisperModel.__init__": 1202
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxWhisperPreTrainedModel.__init__": 1209
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxXGLMForCausalLM.__init__": 1216
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxXGLMModel.__init__": 1223
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxXGLMPreTrainedModel.__init__": 1230
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxXLMRobertaForCausalLM.__init__": 1240
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxXLMRobertaForMaskedLM.__init__": 1247
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxXLMRobertaForMultipleChoice.__init__": 1254
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxXLMRobertaForQuestionAnswering.__init__": 1261
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxXLMRobertaForSequenceClassification.__init__": 1268
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxXLMRobertaForTokenClassification.__init__": 1275
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxXLMRobertaModel.__init__": 1282
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxXLMRobertaPreTrainedModel.__init__": 1289
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/utils/bitsandbytes.py": [
        {
            "transformers.utils.bitsandbytes.replace_8bit_linear": 212
        },
        {
            "transformers.utils.bitsandbytes.set_module_8bit_tensor_to_device": 221
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/utils/dummy_detectron2_objects.py": [
        {
            "transformers.utils.dummy_detectron2_objects.LayoutLMv2Model.__init__": 9
        },
        {
            "transformers.utils.dummy_detectron2_objects.LayoutLMv2Model.from_pretrained": 13
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/utils/dummy_pt_objects.py": [
        {
            "transformers.utils.dummy_pt_objects.PyTorchBenchmark.__init__": 8
        },
        {
            "transformers.utils.dummy_pt_objects.PyTorchBenchmarkArguments.__init__": 15
        },
        {
            "transformers.utils.dummy_pt_objects.GlueDataset.__init__": 22
        },
        {
            "transformers.utils.dummy_pt_objects.GlueDataTrainingArguments.__init__": 29
        },
        {
            "transformers.utils.dummy_pt_objects.LineByLineTextDataset.__init__": 36
        },
        {
            "transformers.utils.dummy_pt_objects.LineByLineWithRefDataset.__init__": 43
        },
        {
            "transformers.utils.dummy_pt_objects.LineByLineWithSOPTextDataset.__init__": 50
        },
        {
            "transformers.utils.dummy_pt_objects.SquadDataset.__init__": 57
        },
        {
            "transformers.utils.dummy_pt_objects.SquadDataTrainingArguments.__init__": 64
        },
        {
            "transformers.utils.dummy_pt_objects.TextDataset.__init__": 71
        },
        {
            "transformers.utils.dummy_pt_objects.TextDatasetForNextSentencePrediction.__init__": 78
        },
        {
            "transformers.utils.dummy_pt_objects.BeamScorer.__init__": 85
        },
        {
            "transformers.utils.dummy_pt_objects.BeamSearchScorer.__init__": 92
        },
        {
            "transformers.utils.dummy_pt_objects.ConstrainedBeamSearchScorer.__init__": 99
        },
        {
            "transformers.utils.dummy_pt_objects.Constraint.__init__": 106
        },
        {
            "transformers.utils.dummy_pt_objects.ConstraintListState.__init__": 113
        },
        {
            "transformers.utils.dummy_pt_objects.DisjunctiveConstraint.__init__": 120
        },
        {
            "transformers.utils.dummy_pt_objects.ForcedBOSTokenLogitsProcessor.__init__": 127
        },
        {
            "transformers.utils.dummy_pt_objects.ForcedEOSTokenLogitsProcessor.__init__": 134
        },
        {
            "transformers.utils.dummy_pt_objects.GenerationMixin.__init__": 141
        },
        {
            "transformers.utils.dummy_pt_objects.HammingDiversityLogitsProcessor.__init__": 148
        },
        {
            "transformers.utils.dummy_pt_objects.InfNanRemoveLogitsProcessor.__init__": 155
        },
        {
            "transformers.utils.dummy_pt_objects.LogitsProcessor.__init__": 162
        },
        {
            "transformers.utils.dummy_pt_objects.LogitsProcessorList.__init__": 169
        },
        {
            "transformers.utils.dummy_pt_objects.LogitsWarper.__init__": 176
        },
        {
            "transformers.utils.dummy_pt_objects.MaxLengthCriteria.__init__": 183
        },
        {
            "transformers.utils.dummy_pt_objects.MaxTimeCriteria.__init__": 190
        },
        {
            "transformers.utils.dummy_pt_objects.MinLengthLogitsProcessor.__init__": 197
        },
        {
            "transformers.utils.dummy_pt_objects.MinNewTokensLengthLogitsProcessor.__init__": 204
        },
        {
            "transformers.utils.dummy_pt_objects.NoBadWordsLogitsProcessor.__init__": 211
        },
        {
            "transformers.utils.dummy_pt_objects.NoRepeatNGramLogitsProcessor.__init__": 218
        },
        {
            "transformers.utils.dummy_pt_objects.PhrasalConstraint.__init__": 225
        },
        {
            "transformers.utils.dummy_pt_objects.PrefixConstrainedLogitsProcessor.__init__": 232
        },
        {
            "transformers.utils.dummy_pt_objects.RepetitionPenaltyLogitsProcessor.__init__": 239
        },
        {
            "transformers.utils.dummy_pt_objects.StoppingCriteria.__init__": 246
        },
        {
            "transformers.utils.dummy_pt_objects.StoppingCriteriaList.__init__": 253
        },
        {
            "transformers.utils.dummy_pt_objects.TemperatureLogitsWarper.__init__": 260
        },
        {
            "transformers.utils.dummy_pt_objects.TopKLogitsWarper.__init__": 267
        },
        {
            "transformers.utils.dummy_pt_objects.TopPLogitsWarper.__init__": 274
        },
        {
            "transformers.utils.dummy_pt_objects.TypicalLogitsWarper.__init__": 281
        },
        {
            "transformers.utils.dummy_pt_objects.top_k_top_p_filtering": 285
        },
        {
            "transformers.utils.dummy_pt_objects.PreTrainedModel.__init__": 292
        },
        {
            "transformers.utils.dummy_pt_objects.AlbertForMaskedLM.__init__": 302
        },
        {
            "transformers.utils.dummy_pt_objects.AlbertForMultipleChoice.__init__": 309
        },
        {
            "transformers.utils.dummy_pt_objects.AlbertForPreTraining.__init__": 316
        },
        {
            "transformers.utils.dummy_pt_objects.AlbertForQuestionAnswering.__init__": 323
        },
        {
            "transformers.utils.dummy_pt_objects.AlbertForSequenceClassification.__init__": 330
        },
        {
            "transformers.utils.dummy_pt_objects.AlbertForTokenClassification.__init__": 337
        },
        {
            "transformers.utils.dummy_pt_objects.AlbertModel.__init__": 344
        },
        {
            "transformers.utils.dummy_pt_objects.AlbertPreTrainedModel.__init__": 351
        },
        {
            "transformers.utils.dummy_pt_objects.load_tf_weights_in_albert": 355
        },
        {
            "transformers.utils.dummy_pt_objects.AlignModel.__init__": 365
        },
        {
            "transformers.utils.dummy_pt_objects.AlignPreTrainedModel.__init__": 372
        },
        {
            "transformers.utils.dummy_pt_objects.AlignTextModel.__init__": 379
        },
        {
            "transformers.utils.dummy_pt_objects.AlignVisionModel.__init__": 386
        },
        {
            "transformers.utils.dummy_pt_objects.AltCLIPModel.__init__": 396
        },
        {
            "transformers.utils.dummy_pt_objects.AltCLIPPreTrainedModel.__init__": 403
        },
        {
            "transformers.utils.dummy_pt_objects.AltCLIPTextModel.__init__": 410
        },
        {
            "transformers.utils.dummy_pt_objects.AltCLIPVisionModel.__init__": 417
        },
        {
            "transformers.utils.dummy_pt_objects.ASTForAudioClassification.__init__": 427
        },
        {
            "transformers.utils.dummy_pt_objects.ASTModel.__init__": 434
        },
        {
            "transformers.utils.dummy_pt_objects.ASTPreTrainedModel.__init__": 441
        },
        {
            "transformers.utils.dummy_pt_objects.AutoBackbone.__init__": 547
        },
        {
            "transformers.utils.dummy_pt_objects.AutoModel.__init__": 554
        },
        {
            "transformers.utils.dummy_pt_objects.AutoModelForAudioClassification.__init__": 561
        },
        {
            "transformers.utils.dummy_pt_objects.AutoModelForAudioFrameClassification.__init__": 568
        },
        {
            "transformers.utils.dummy_pt_objects.AutoModelForAudioXVector.__init__": 575
        },
        {
            "transformers.utils.dummy_pt_objects.AutoModelForCausalLM.__init__": 582
        },
        {
            "transformers.utils.dummy_pt_objects.AutoModelForCTC.__init__": 589
        },
        {
            "transformers.utils.dummy_pt_objects.AutoModelForDepthEstimation.__init__": 596
        },
        {
            "transformers.utils.dummy_pt_objects.AutoModelForDocumentQuestionAnswering.__init__": 603
        },
        {
            "transformers.utils.dummy_pt_objects.AutoModelForImageClassification.__init__": 610
        },
        {
            "transformers.utils.dummy_pt_objects.AutoModelForImageSegmentation.__init__": 617
        },
        {
            "transformers.utils.dummy_pt_objects.AutoModelForInstanceSegmentation.__init__": 624
        },
        {
            "transformers.utils.dummy_pt_objects.AutoModelForMaskedImageModeling.__init__": 631
        },
        {
            "transformers.utils.dummy_pt_objects.AutoModelForMaskedLM.__init__": 638
        },
        {
            "transformers.utils.dummy_pt_objects.AutoModelForMaskGeneration.__init__": 645
        },
        {
            "transformers.utils.dummy_pt_objects.AutoModelForMultipleChoice.__init__": 652
        },
        {
            "transformers.utils.dummy_pt_objects.AutoModelForNextSentencePrediction.__init__": 659
        },
        {
            "transformers.utils.dummy_pt_objects.AutoModelForObjectDetection.__init__": 666
        },
        {
            "transformers.utils.dummy_pt_objects.AutoModelForPreTraining.__init__": 673
        },
        {
            "transformers.utils.dummy_pt_objects.AutoModelForQuestionAnswering.__init__": 680
        },
        {
            "transformers.utils.dummy_pt_objects.AutoModelForSemanticSegmentation.__init__": 687
        },
        {
            "transformers.utils.dummy_pt_objects.AutoModelForSeq2SeqLM.__init__": 694
        },
        {
            "transformers.utils.dummy_pt_objects.AutoModelForSequenceClassification.__init__": 701
        },
        {
            "transformers.utils.dummy_pt_objects.AutoModelForSpeechSeq2Seq.__init__": 708
        },
        {
            "transformers.utils.dummy_pt_objects.AutoModelForTableQuestionAnswering.__init__": 715
        },
        {
            "transformers.utils.dummy_pt_objects.AutoModelForTokenClassification.__init__": 722
        },
        {
            "transformers.utils.dummy_pt_objects.AutoModelForUniversalSegmentation.__init__": 729
        },
        {
            "transformers.utils.dummy_pt_objects.AutoModelForVideoClassification.__init__": 736
        },
        {
            "transformers.utils.dummy_pt_objects.AutoModelForVision2Seq.__init__": 743
        },
        {
            "transformers.utils.dummy_pt_objects.AutoModelForVisualQuestionAnswering.__init__": 750
        },
        {
            "transformers.utils.dummy_pt_objects.AutoModelForZeroShotImageClassification.__init__": 757
        },
        {
            "transformers.utils.dummy_pt_objects.AutoModelForZeroShotObjectDetection.__init__": 764
        },
        {
            "transformers.utils.dummy_pt_objects.AutoModelWithLMHead.__init__": 771
        },
        {
            "transformers.utils.dummy_pt_objects.AutoformerForPrediction.__init__": 781
        },
        {
            "transformers.utils.dummy_pt_objects.AutoformerModel.__init__": 788
        },
        {
            "transformers.utils.dummy_pt_objects.AutoformerPreTrainedModel.__init__": 795
        },
        {
            "transformers.utils.dummy_pt_objects.BartForCausalLM.__init__": 805
        },
        {
            "transformers.utils.dummy_pt_objects.BartForConditionalGeneration.__init__": 812
        },
        {
            "transformers.utils.dummy_pt_objects.BartForQuestionAnswering.__init__": 819
        },
        {
            "transformers.utils.dummy_pt_objects.BartForSequenceClassification.__init__": 826
        },
        {
            "transformers.utils.dummy_pt_objects.BartModel.__init__": 833
        },
        {
            "transformers.utils.dummy_pt_objects.BartPretrainedModel.__init__": 840
        },
        {
            "transformers.utils.dummy_pt_objects.PretrainedBartModel.__init__": 847
        },
        {
            "transformers.utils.dummy_pt_objects.BeitForImageClassification.__init__": 857
        },
        {
            "transformers.utils.dummy_pt_objects.BeitForMaskedImageModeling.__init__": 864
        },
        {
            "transformers.utils.dummy_pt_objects.BeitForSemanticSegmentation.__init__": 871
        },
        {
            "transformers.utils.dummy_pt_objects.BeitModel.__init__": 878
        },
        {
            "transformers.utils.dummy_pt_objects.BeitPreTrainedModel.__init__": 885
        },
        {
            "transformers.utils.dummy_pt_objects.BertForMaskedLM.__init__": 895
        },
        {
            "transformers.utils.dummy_pt_objects.BertForMultipleChoice.__init__": 902
        },
        {
            "transformers.utils.dummy_pt_objects.BertForNextSentencePrediction.__init__": 909
        },
        {
            "transformers.utils.dummy_pt_objects.BertForPreTraining.__init__": 916
        },
        {
            "transformers.utils.dummy_pt_objects.BertForQuestionAnswering.__init__": 923
        },
        {
            "transformers.utils.dummy_pt_objects.BertForSequenceClassification.__init__": 930
        },
        {
            "transformers.utils.dummy_pt_objects.BertForTokenClassification.__init__": 937
        },
        {
            "transformers.utils.dummy_pt_objects.BertLayer.__init__": 944
        },
        {
            "transformers.utils.dummy_pt_objects.BertLMHeadModel.__init__": 951
        },
        {
            "transformers.utils.dummy_pt_objects.BertModel.__init__": 958
        },
        {
            "transformers.utils.dummy_pt_objects.BertPreTrainedModel.__init__": 965
        },
        {
            "transformers.utils.dummy_pt_objects.load_tf_weights_in_bert": 969
        },
        {
            "transformers.utils.dummy_pt_objects.BertGenerationDecoder.__init__": 976
        },
        {
            "transformers.utils.dummy_pt_objects.BertGenerationEncoder.__init__": 983
        },
        {
            "transformers.utils.dummy_pt_objects.BertGenerationPreTrainedModel.__init__": 990
        },
        {
            "transformers.utils.dummy_pt_objects.load_tf_weights_in_bert_generation": 994
        },
        {
            "transformers.utils.dummy_pt_objects.BigBirdForCausalLM.__init__": 1004
        },
        {
            "transformers.utils.dummy_pt_objects.BigBirdForMaskedLM.__init__": 1011
        },
        {
            "transformers.utils.dummy_pt_objects.BigBirdForMultipleChoice.__init__": 1018
        },
        {
            "transformers.utils.dummy_pt_objects.BigBirdForPreTraining.__init__": 1025
        },
        {
            "transformers.utils.dummy_pt_objects.BigBirdForQuestionAnswering.__init__": 1032
        },
        {
            "transformers.utils.dummy_pt_objects.BigBirdForSequenceClassification.__init__": 1039
        },
        {
            "transformers.utils.dummy_pt_objects.BigBirdForTokenClassification.__init__": 1046
        },
        {
            "transformers.utils.dummy_pt_objects.BigBirdLayer.__init__": 1053
        },
        {
            "transformers.utils.dummy_pt_objects.BigBirdModel.__init__": 1060
        },
        {
            "transformers.utils.dummy_pt_objects.BigBirdPreTrainedModel.__init__": 1067
        },
        {
            "transformers.utils.dummy_pt_objects.load_tf_weights_in_big_bird": 1071
        },
        {
            "transformers.utils.dummy_pt_objects.BigBirdPegasusForCausalLM.__init__": 1081
        },
        {
            "transformers.utils.dummy_pt_objects.BigBirdPegasusForConditionalGeneration.__init__": 1088
        },
        {
            "transformers.utils.dummy_pt_objects.BigBirdPegasusForQuestionAnswering.__init__": 1095
        },
        {
            "transformers.utils.dummy_pt_objects.BigBirdPegasusForSequenceClassification.__init__": 1102
        },
        {
            "transformers.utils.dummy_pt_objects.BigBirdPegasusModel.__init__": 1109
        },
        {
            "transformers.utils.dummy_pt_objects.BigBirdPegasusPreTrainedModel.__init__": 1116
        },
        {
            "transformers.utils.dummy_pt_objects.BioGptForCausalLM.__init__": 1126
        },
        {
            "transformers.utils.dummy_pt_objects.BioGptForSequenceClassification.__init__": 1133
        },
        {
            "transformers.utils.dummy_pt_objects.BioGptForTokenClassification.__init__": 1140
        },
        {
            "transformers.utils.dummy_pt_objects.BioGptModel.__init__": 1147
        },
        {
            "transformers.utils.dummy_pt_objects.BioGptPreTrainedModel.__init__": 1154
        },
        {
            "transformers.utils.dummy_pt_objects.BitBackbone.__init__": 1164
        },
        {
            "transformers.utils.dummy_pt_objects.BitForImageClassification.__init__": 1171
        },
        {
            "transformers.utils.dummy_pt_objects.BitModel.__init__": 1178
        },
        {
            "transformers.utils.dummy_pt_objects.BitPreTrainedModel.__init__": 1185
        },
        {
            "transformers.utils.dummy_pt_objects.BlenderbotForCausalLM.__init__": 1195
        },
        {
            "transformers.utils.dummy_pt_objects.BlenderbotForConditionalGeneration.__init__": 1202
        },
        {
            "transformers.utils.dummy_pt_objects.BlenderbotModel.__init__": 1209
        },
        {
            "transformers.utils.dummy_pt_objects.BlenderbotPreTrainedModel.__init__": 1216
        },
        {
            "transformers.utils.dummy_pt_objects.BlenderbotSmallForCausalLM.__init__": 1226
        },
        {
            "transformers.utils.dummy_pt_objects.BlenderbotSmallForConditionalGeneration.__init__": 1233
        },
        {
            "transformers.utils.dummy_pt_objects.BlenderbotSmallModel.__init__": 1240
        },
        {
            "transformers.utils.dummy_pt_objects.BlenderbotSmallPreTrainedModel.__init__": 1247
        },
        {
            "transformers.utils.dummy_pt_objects.BlipForConditionalGeneration.__init__": 1257
        },
        {
            "transformers.utils.dummy_pt_objects.BlipForImageTextRetrieval.__init__": 1264
        },
        {
            "transformers.utils.dummy_pt_objects.BlipForQuestionAnswering.__init__": 1271
        },
        {
            "transformers.utils.dummy_pt_objects.BlipModel.__init__": 1278
        },
        {
            "transformers.utils.dummy_pt_objects.BlipPreTrainedModel.__init__": 1285
        },
        {
            "transformers.utils.dummy_pt_objects.BlipTextModel.__init__": 1292
        },
        {
            "transformers.utils.dummy_pt_objects.BlipVisionModel.__init__": 1299
        },
        {
            "transformers.utils.dummy_pt_objects.Blip2ForConditionalGeneration.__init__": 1309
        },
        {
            "transformers.utils.dummy_pt_objects.Blip2Model.__init__": 1316
        },
        {
            "transformers.utils.dummy_pt_objects.Blip2PreTrainedModel.__init__": 1323
        },
        {
            "transformers.utils.dummy_pt_objects.Blip2QFormerModel.__init__": 1330
        },
        {
            "transformers.utils.dummy_pt_objects.Blip2VisionModel.__init__": 1337
        },
        {
            "transformers.utils.dummy_pt_objects.BloomForCausalLM.__init__": 1347
        },
        {
            "transformers.utils.dummy_pt_objects.BloomForQuestionAnswering.__init__": 1354
        },
        {
            "transformers.utils.dummy_pt_objects.BloomForSequenceClassification.__init__": 1361
        },
        {
            "transformers.utils.dummy_pt_objects.BloomForTokenClassification.__init__": 1368
        },
        {
            "transformers.utils.dummy_pt_objects.BloomModel.__init__": 1375
        },
        {
            "transformers.utils.dummy_pt_objects.BloomPreTrainedModel.__init__": 1382
        },
        {
            "transformers.utils.dummy_pt_objects.BridgeTowerForContrastiveLearning.__init__": 1392
        },
        {
            "transformers.utils.dummy_pt_objects.BridgeTowerForImageAndTextRetrieval.__init__": 1399
        },
        {
            "transformers.utils.dummy_pt_objects.BridgeTowerForMaskedLM.__init__": 1406
        },
        {
            "transformers.utils.dummy_pt_objects.BridgeTowerModel.__init__": 1413
        },
        {
            "transformers.utils.dummy_pt_objects.BridgeTowerPreTrainedModel.__init__": 1420
        },
        {
            "transformers.utils.dummy_pt_objects.CamembertForCausalLM.__init__": 1430
        },
        {
            "transformers.utils.dummy_pt_objects.CamembertForMaskedLM.__init__": 1437
        },
        {
            "transformers.utils.dummy_pt_objects.CamembertForMultipleChoice.__init__": 1444
        },
        {
            "transformers.utils.dummy_pt_objects.CamembertForQuestionAnswering.__init__": 1451
        },
        {
            "transformers.utils.dummy_pt_objects.CamembertForSequenceClassification.__init__": 1458
        },
        {
            "transformers.utils.dummy_pt_objects.CamembertForTokenClassification.__init__": 1465
        },
        {
            "transformers.utils.dummy_pt_objects.CamembertModel.__init__": 1472
        },
        {
            "transformers.utils.dummy_pt_objects.CamembertPreTrainedModel.__init__": 1479
        },
        {
            "transformers.utils.dummy_pt_objects.CanineForMultipleChoice.__init__": 1489
        },
        {
            "transformers.utils.dummy_pt_objects.CanineForQuestionAnswering.__init__": 1496
        },
        {
            "transformers.utils.dummy_pt_objects.CanineForSequenceClassification.__init__": 1503
        },
        {
            "transformers.utils.dummy_pt_objects.CanineForTokenClassification.__init__": 1510
        },
        {
            "transformers.utils.dummy_pt_objects.CanineLayer.__init__": 1517
        },
        {
            "transformers.utils.dummy_pt_objects.CanineModel.__init__": 1524
        },
        {
            "transformers.utils.dummy_pt_objects.CaninePreTrainedModel.__init__": 1531
        },
        {
            "transformers.utils.dummy_pt_objects.load_tf_weights_in_canine": 1535
        },
        {
            "transformers.utils.dummy_pt_objects.ChineseCLIPModel.__init__": 1545
        },
        {
            "transformers.utils.dummy_pt_objects.ChineseCLIPPreTrainedModel.__init__": 1552
        },
        {
            "transformers.utils.dummy_pt_objects.ChineseCLIPTextModel.__init__": 1559
        },
        {
            "transformers.utils.dummy_pt_objects.ChineseCLIPVisionModel.__init__": 1566
        },
        {
            "transformers.utils.dummy_pt_objects.ClapAudioModel.__init__": 1576
        },
        {
            "transformers.utils.dummy_pt_objects.ClapAudioModelWithProjection.__init__": 1583
        },
        {
            "transformers.utils.dummy_pt_objects.ClapFeatureExtractor.__init__": 1590
        },
        {
            "transformers.utils.dummy_pt_objects.ClapModel.__init__": 1597
        },
        {
            "transformers.utils.dummy_pt_objects.ClapPreTrainedModel.__init__": 1604
        },
        {
            "transformers.utils.dummy_pt_objects.ClapTextModel.__init__": 1611
        },
        {
            "transformers.utils.dummy_pt_objects.ClapTextModelWithProjection.__init__": 1618
        },
        {
            "transformers.utils.dummy_pt_objects.CLIPModel.__init__": 1628
        },
        {
            "transformers.utils.dummy_pt_objects.CLIPPreTrainedModel.__init__": 1635
        },
        {
            "transformers.utils.dummy_pt_objects.CLIPTextModel.__init__": 1642
        },
        {
            "transformers.utils.dummy_pt_objects.CLIPTextModelWithProjection.__init__": 1649
        },
        {
            "transformers.utils.dummy_pt_objects.CLIPVisionModel.__init__": 1656
        },
        {
            "transformers.utils.dummy_pt_objects.CLIPVisionModelWithProjection.__init__": 1663
        },
        {
            "transformers.utils.dummy_pt_objects.CLIPSegForImageSegmentation.__init__": 1673
        },
        {
            "transformers.utils.dummy_pt_objects.CLIPSegModel.__init__": 1680
        },
        {
            "transformers.utils.dummy_pt_objects.CLIPSegPreTrainedModel.__init__": 1687
        },
        {
            "transformers.utils.dummy_pt_objects.CLIPSegTextModel.__init__": 1694
        },
        {
            "transformers.utils.dummy_pt_objects.CLIPSegVisionModel.__init__": 1701
        },
        {
            "transformers.utils.dummy_pt_objects.CodeGenForCausalLM.__init__": 1711
        },
        {
            "transformers.utils.dummy_pt_objects.CodeGenModel.__init__": 1718
        },
        {
            "transformers.utils.dummy_pt_objects.CodeGenPreTrainedModel.__init__": 1725
        },
        {
            "transformers.utils.dummy_pt_objects.ConditionalDetrForObjectDetection.__init__": 1735
        },
        {
            "transformers.utils.dummy_pt_objects.ConditionalDetrForSegmentation.__init__": 1742
        },
        {
            "transformers.utils.dummy_pt_objects.ConditionalDetrModel.__init__": 1749
        },
        {
            "transformers.utils.dummy_pt_objects.ConditionalDetrPreTrainedModel.__init__": 1756
        },
        {
            "transformers.utils.dummy_pt_objects.ConvBertForMaskedLM.__init__": 1766
        },
        {
            "transformers.utils.dummy_pt_objects.ConvBertForMultipleChoice.__init__": 1773
        },
        {
            "transformers.utils.dummy_pt_objects.ConvBertForQuestionAnswering.__init__": 1780
        },
        {
            "transformers.utils.dummy_pt_objects.ConvBertForSequenceClassification.__init__": 1787
        },
        {
            "transformers.utils.dummy_pt_objects.ConvBertForTokenClassification.__init__": 1794
        },
        {
            "transformers.utils.dummy_pt_objects.ConvBertLayer.__init__": 1801
        },
        {
            "transformers.utils.dummy_pt_objects.ConvBertModel.__init__": 1808
        },
        {
            "transformers.utils.dummy_pt_objects.ConvBertPreTrainedModel.__init__": 1815
        },
        {
            "transformers.utils.dummy_pt_objects.load_tf_weights_in_convbert": 1819
        },
        {
            "transformers.utils.dummy_pt_objects.ConvNextBackbone.__init__": 1829
        },
        {
            "transformers.utils.dummy_pt_objects.ConvNextForImageClassification.__init__": 1836
        },
        {
            "transformers.utils.dummy_pt_objects.ConvNextModel.__init__": 1843
        },
        {
            "transformers.utils.dummy_pt_objects.ConvNextPreTrainedModel.__init__": 1850
        },
        {
            "transformers.utils.dummy_pt_objects.ConvNextV2Backbone.__init__": 1860
        },
        {
            "transformers.utils.dummy_pt_objects.ConvNextV2ForImageClassification.__init__": 1867
        },
        {
            "transformers.utils.dummy_pt_objects.ConvNextV2Model.__init__": 1874
        },
        {
            "transformers.utils.dummy_pt_objects.ConvNextV2PreTrainedModel.__init__": 1881
        },
        {
            "transformers.utils.dummy_pt_objects.CpmAntForCausalLM.__init__": 1891
        },
        {
            "transformers.utils.dummy_pt_objects.CpmAntModel.__init__": 1898
        },
        {
            "transformers.utils.dummy_pt_objects.CpmAntPreTrainedModel.__init__": 1905
        },
        {
            "transformers.utils.dummy_pt_objects.CTRLForSequenceClassification.__init__": 1915
        },
        {
            "transformers.utils.dummy_pt_objects.CTRLLMHeadModel.__init__": 1922
        },
        {
            "transformers.utils.dummy_pt_objects.CTRLModel.__init__": 1929
        },
        {
            "transformers.utils.dummy_pt_objects.CTRLPreTrainedModel.__init__": 1936
        },
        {
            "transformers.utils.dummy_pt_objects.CvtForImageClassification.__init__": 1946
        },
        {
            "transformers.utils.dummy_pt_objects.CvtModel.__init__": 1953
        },
        {
            "transformers.utils.dummy_pt_objects.CvtPreTrainedModel.__init__": 1960
        },
        {
            "transformers.utils.dummy_pt_objects.Data2VecAudioForAudioFrameClassification.__init__": 1976
        },
        {
            "transformers.utils.dummy_pt_objects.Data2VecAudioForCTC.__init__": 1983
        },
        {
            "transformers.utils.dummy_pt_objects.Data2VecAudioForSequenceClassification.__init__": 1990
        },
        {
            "transformers.utils.dummy_pt_objects.Data2VecAudioForXVector.__init__": 1997
        },
        {
            "transformers.utils.dummy_pt_objects.Data2VecAudioModel.__init__": 2004
        },
        {
            "transformers.utils.dummy_pt_objects.Data2VecAudioPreTrainedModel.__init__": 2011
        },
        {
            "transformers.utils.dummy_pt_objects.Data2VecTextForCausalLM.__init__": 2018
        },
        {
            "transformers.utils.dummy_pt_objects.Data2VecTextForMaskedLM.__init__": 2025
        },
        {
            "transformers.utils.dummy_pt_objects.Data2VecTextForMultipleChoice.__init__": 2032
        },
        {
            "transformers.utils.dummy_pt_objects.Data2VecTextForQuestionAnswering.__init__": 2039
        },
        {
            "transformers.utils.dummy_pt_objects.Data2VecTextForSequenceClassification.__init__": 2046
        },
        {
            "transformers.utils.dummy_pt_objects.Data2VecTextForTokenClassification.__init__": 2053
        },
        {
            "transformers.utils.dummy_pt_objects.Data2VecTextModel.__init__": 2060
        },
        {
            "transformers.utils.dummy_pt_objects.Data2VecTextPreTrainedModel.__init__": 2067
        },
        {
            "transformers.utils.dummy_pt_objects.Data2VecVisionForImageClassification.__init__": 2074
        },
        {
            "transformers.utils.dummy_pt_objects.Data2VecVisionForSemanticSegmentation.__init__": 2081
        },
        {
            "transformers.utils.dummy_pt_objects.Data2VecVisionModel.__init__": 2088
        },
        {
            "transformers.utils.dummy_pt_objects.Data2VecVisionPreTrainedModel.__init__": 2095
        },
        {
            "transformers.utils.dummy_pt_objects.DebertaForMaskedLM.__init__": 2105
        },
        {
            "transformers.utils.dummy_pt_objects.DebertaForQuestionAnswering.__init__": 2112
        },
        {
            "transformers.utils.dummy_pt_objects.DebertaForSequenceClassification.__init__": 2119
        },
        {
            "transformers.utils.dummy_pt_objects.DebertaForTokenClassification.__init__": 2126
        },
        {
            "transformers.utils.dummy_pt_objects.DebertaModel.__init__": 2133
        },
        {
            "transformers.utils.dummy_pt_objects.DebertaPreTrainedModel.__init__": 2140
        },
        {
            "transformers.utils.dummy_pt_objects.DebertaV2ForMaskedLM.__init__": 2150
        },
        {
            "transformers.utils.dummy_pt_objects.DebertaV2ForMultipleChoice.__init__": 2157
        },
        {
            "transformers.utils.dummy_pt_objects.DebertaV2ForQuestionAnswering.__init__": 2164
        },
        {
            "transformers.utils.dummy_pt_objects.DebertaV2ForSequenceClassification.__init__": 2171
        },
        {
            "transformers.utils.dummy_pt_objects.DebertaV2ForTokenClassification.__init__": 2178
        },
        {
            "transformers.utils.dummy_pt_objects.DebertaV2Model.__init__": 2185
        },
        {
            "transformers.utils.dummy_pt_objects.DebertaV2PreTrainedModel.__init__": 2192
        },
        {
            "transformers.utils.dummy_pt_objects.DecisionTransformerGPT2Model.__init__": 2202
        },
        {
            "transformers.utils.dummy_pt_objects.DecisionTransformerGPT2PreTrainedModel.__init__": 2209
        },
        {
            "transformers.utils.dummy_pt_objects.DecisionTransformerModel.__init__": 2216
        },
        {
            "transformers.utils.dummy_pt_objects.DecisionTransformerPreTrainedModel.__init__": 2223
        },
        {
            "transformers.utils.dummy_pt_objects.DeformableDetrForObjectDetection.__init__": 2233
        },
        {
            "transformers.utils.dummy_pt_objects.DeformableDetrModel.__init__": 2240
        },
        {
            "transformers.utils.dummy_pt_objects.DeformableDetrPreTrainedModel.__init__": 2247
        },
        {
            "transformers.utils.dummy_pt_objects.DeiTForImageClassification.__init__": 2257
        },
        {
            "transformers.utils.dummy_pt_objects.DeiTForImageClassificationWithTeacher.__init__": 2264
        },
        {
            "transformers.utils.dummy_pt_objects.DeiTForMaskedImageModeling.__init__": 2271
        },
        {
            "transformers.utils.dummy_pt_objects.DeiTModel.__init__": 2278
        },
        {
            "transformers.utils.dummy_pt_objects.DeiTPreTrainedModel.__init__": 2285
        },
        {
            "transformers.utils.dummy_pt_objects.DetaForObjectDetection.__init__": 2295
        },
        {
            "transformers.utils.dummy_pt_objects.DetaModel.__init__": 2302
        },
        {
            "transformers.utils.dummy_pt_objects.DetaPreTrainedModel.__init__": 2309
        },
        {
            "transformers.utils.dummy_pt_objects.DetrForObjectDetection.__init__": 2319
        },
        {
            "transformers.utils.dummy_pt_objects.DetrForSegmentation.__init__": 2326
        },
        {
            "transformers.utils.dummy_pt_objects.DetrModel.__init__": 2333
        },
        {
            "transformers.utils.dummy_pt_objects.DetrPreTrainedModel.__init__": 2340
        },
        {
            "transformers.utils.dummy_pt_objects.DinatBackbone.__init__": 2350
        },
        {
            "transformers.utils.dummy_pt_objects.DinatForImageClassification.__init__": 2357
        },
        {
            "transformers.utils.dummy_pt_objects.DinatModel.__init__": 2364
        },
        {
            "transformers.utils.dummy_pt_objects.DinatPreTrainedModel.__init__": 2371
        },
        {
            "transformers.utils.dummy_pt_objects.DistilBertForMaskedLM.__init__": 2381
        },
        {
            "transformers.utils.dummy_pt_objects.DistilBertForMultipleChoice.__init__": 2388
        },
        {
            "transformers.utils.dummy_pt_objects.DistilBertForQuestionAnswering.__init__": 2395
        },
        {
            "transformers.utils.dummy_pt_objects.DistilBertForSequenceClassification.__init__": 2402
        },
        {
            "transformers.utils.dummy_pt_objects.DistilBertForTokenClassification.__init__": 2409
        },
        {
            "transformers.utils.dummy_pt_objects.DistilBertModel.__init__": 2416
        },
        {
            "transformers.utils.dummy_pt_objects.DistilBertPreTrainedModel.__init__": 2423
        },
        {
            "transformers.utils.dummy_pt_objects.DonutSwinModel.__init__": 2433
        },
        {
            "transformers.utils.dummy_pt_objects.DonutSwinPreTrainedModel.__init__": 2440
        },
        {
            "transformers.utils.dummy_pt_objects.DPRContextEncoder.__init__": 2456
        },
        {
            "transformers.utils.dummy_pt_objects.DPRPretrainedContextEncoder.__init__": 2463
        },
        {
            "transformers.utils.dummy_pt_objects.DPRPreTrainedModel.__init__": 2470
        },
        {
            "transformers.utils.dummy_pt_objects.DPRPretrainedQuestionEncoder.__init__": 2477
        },
        {
            "transformers.utils.dummy_pt_objects.DPRPretrainedReader.__init__": 2484
        },
        {
            "transformers.utils.dummy_pt_objects.DPRQuestionEncoder.__init__": 2491
        },
        {
            "transformers.utils.dummy_pt_objects.DPRReader.__init__": 2498
        },
        {
            "transformers.utils.dummy_pt_objects.DPTForDepthEstimation.__init__": 2508
        },
        {
            "transformers.utils.dummy_pt_objects.DPTForSemanticSegmentation.__init__": 2515
        },
        {
            "transformers.utils.dummy_pt_objects.DPTModel.__init__": 2522
        },
        {
            "transformers.utils.dummy_pt_objects.DPTPreTrainedModel.__init__": 2529
        },
        {
            "transformers.utils.dummy_pt_objects.EfficientFormerForImageClassification.__init__": 2539
        },
        {
            "transformers.utils.dummy_pt_objects.EfficientFormerForImageClassificationWithTeacher.__init__": 2546
        },
        {
            "transformers.utils.dummy_pt_objects.EfficientFormerModel.__init__": 2553
        },
        {
            "transformers.utils.dummy_pt_objects.EfficientFormerPreTrainedModel.__init__": 2560
        },
        {
            "transformers.utils.dummy_pt_objects.EfficientNetForImageClassification.__init__": 2570
        },
        {
            "transformers.utils.dummy_pt_objects.EfficientNetModel.__init__": 2577
        },
        {
            "transformers.utils.dummy_pt_objects.EfficientNetPreTrainedModel.__init__": 2584
        },
        {
            "transformers.utils.dummy_pt_objects.ElectraForCausalLM.__init__": 2594
        },
        {
            "transformers.utils.dummy_pt_objects.ElectraForMaskedLM.__init__": 2601
        },
        {
            "transformers.utils.dummy_pt_objects.ElectraForMultipleChoice.__init__": 2608
        },
        {
            "transformers.utils.dummy_pt_objects.ElectraForPreTraining.__init__": 2615
        },
        {
            "transformers.utils.dummy_pt_objects.ElectraForQuestionAnswering.__init__": 2622
        },
        {
            "transformers.utils.dummy_pt_objects.ElectraForSequenceClassification.__init__": 2629
        },
        {
            "transformers.utils.dummy_pt_objects.ElectraForTokenClassification.__init__": 2636
        },
        {
            "transformers.utils.dummy_pt_objects.ElectraModel.__init__": 2643
        },
        {
            "transformers.utils.dummy_pt_objects.ElectraPreTrainedModel.__init__": 2650
        },
        {
            "transformers.utils.dummy_pt_objects.load_tf_weights_in_electra": 2654
        },
        {
            "transformers.utils.dummy_pt_objects.EncoderDecoderModel.__init__": 2661
        },
        {
            "transformers.utils.dummy_pt_objects.ErnieForCausalLM.__init__": 2671
        },
        {
            "transformers.utils.dummy_pt_objects.ErnieForMaskedLM.__init__": 2678
        },
        {
            "transformers.utils.dummy_pt_objects.ErnieForMultipleChoice.__init__": 2685
        },
        {
            "transformers.utils.dummy_pt_objects.ErnieForNextSentencePrediction.__init__": 2692
        },
        {
            "transformers.utils.dummy_pt_objects.ErnieForPreTraining.__init__": 2699
        },
        {
            "transformers.utils.dummy_pt_objects.ErnieForQuestionAnswering.__init__": 2706
        },
        {
            "transformers.utils.dummy_pt_objects.ErnieForSequenceClassification.__init__": 2713
        },
        {
            "transformers.utils.dummy_pt_objects.ErnieForTokenClassification.__init__": 2720
        },
        {
            "transformers.utils.dummy_pt_objects.ErnieModel.__init__": 2727
        },
        {
            "transformers.utils.dummy_pt_objects.ErniePreTrainedModel.__init__": 2734
        },
        {
            "transformers.utils.dummy_pt_objects.ErnieMForInformationExtraction.__init__": 2744
        },
        {
            "transformers.utils.dummy_pt_objects.ErnieMForMultipleChoice.__init__": 2751
        },
        {
            "transformers.utils.dummy_pt_objects.ErnieMForQuestionAnswering.__init__": 2758
        },
        {
            "transformers.utils.dummy_pt_objects.ErnieMForSequenceClassification.__init__": 2765
        },
        {
            "transformers.utils.dummy_pt_objects.ErnieMForTokenClassification.__init__": 2772
        },
        {
            "transformers.utils.dummy_pt_objects.ErnieMModel.__init__": 2779
        },
        {
            "transformers.utils.dummy_pt_objects.ErnieMPreTrainedModel.__init__": 2786
        },
        {
            "transformers.utils.dummy_pt_objects.EsmFoldPreTrainedModel.__init__": 2796
        },
        {
            "transformers.utils.dummy_pt_objects.EsmForMaskedLM.__init__": 2803
        },
        {
            "transformers.utils.dummy_pt_objects.EsmForProteinFolding.__init__": 2810
        },
        {
            "transformers.utils.dummy_pt_objects.EsmForSequenceClassification.__init__": 2817
        },
        {
            "transformers.utils.dummy_pt_objects.EsmForTokenClassification.__init__": 2824
        },
        {
            "transformers.utils.dummy_pt_objects.EsmModel.__init__": 2831
        },
        {
            "transformers.utils.dummy_pt_objects.EsmPreTrainedModel.__init__": 2838
        },
        {
            "transformers.utils.dummy_pt_objects.FlaubertForMultipleChoice.__init__": 2848
        },
        {
            "transformers.utils.dummy_pt_objects.FlaubertForQuestionAnswering.__init__": 2855
        },
        {
            "transformers.utils.dummy_pt_objects.FlaubertForQuestionAnsweringSimple.__init__": 2862
        },
        {
            "transformers.utils.dummy_pt_objects.FlaubertForSequenceClassification.__init__": 2869
        },
        {
            "transformers.utils.dummy_pt_objects.FlaubertForTokenClassification.__init__": 2876
        },
        {
            "transformers.utils.dummy_pt_objects.FlaubertModel.__init__": 2883
        },
        {
            "transformers.utils.dummy_pt_objects.FlaubertPreTrainedModel.__init__": 2890
        },
        {
            "transformers.utils.dummy_pt_objects.FlaubertWithLMHeadModel.__init__": 2897
        },
        {
            "transformers.utils.dummy_pt_objects.FlavaForPreTraining.__init__": 2907
        },
        {
            "transformers.utils.dummy_pt_objects.FlavaImageCodebook.__init__": 2914
        },
        {
            "transformers.utils.dummy_pt_objects.FlavaImageModel.__init__": 2921
        },
        {
            "transformers.utils.dummy_pt_objects.FlavaModel.__init__": 2928
        },
        {
            "transformers.utils.dummy_pt_objects.FlavaMultimodalModel.__init__": 2935
        },
        {
            "transformers.utils.dummy_pt_objects.FlavaPreTrainedModel.__init__": 2942
        },
        {
            "transformers.utils.dummy_pt_objects.FlavaTextModel.__init__": 2949
        },
        {
            "transformers.utils.dummy_pt_objects.FNetForMaskedLM.__init__": 2959
        },
        {
            "transformers.utils.dummy_pt_objects.FNetForMultipleChoice.__init__": 2966
        },
        {
            "transformers.utils.dummy_pt_objects.FNetForNextSentencePrediction.__init__": 2973
        },
        {
            "transformers.utils.dummy_pt_objects.FNetForPreTraining.__init__": 2980
        },
        {
            "transformers.utils.dummy_pt_objects.FNetForQuestionAnswering.__init__": 2987
        },
        {
            "transformers.utils.dummy_pt_objects.FNetForSequenceClassification.__init__": 2994
        },
        {
            "transformers.utils.dummy_pt_objects.FNetForTokenClassification.__init__": 3001
        },
        {
            "transformers.utils.dummy_pt_objects.FNetLayer.__init__": 3008
        },
        {
            "transformers.utils.dummy_pt_objects.FNetModel.__init__": 3015
        },
        {
            "transformers.utils.dummy_pt_objects.FNetPreTrainedModel.__init__": 3022
        },
        {
            "transformers.utils.dummy_pt_objects.FocalNetBackbone.__init__": 3032
        },
        {
            "transformers.utils.dummy_pt_objects.FocalNetForImageClassification.__init__": 3039
        },
        {
            "transformers.utils.dummy_pt_objects.FocalNetForMaskedImageModeling.__init__": 3046
        },
        {
            "transformers.utils.dummy_pt_objects.FocalNetModel.__init__": 3053
        },
        {
            "transformers.utils.dummy_pt_objects.FocalNetPreTrainedModel.__init__": 3060
        },
        {
            "transformers.utils.dummy_pt_objects.FSMTForConditionalGeneration.__init__": 3067
        },
        {
            "transformers.utils.dummy_pt_objects.FSMTModel.__init__": 3074
        },
        {
            "transformers.utils.dummy_pt_objects.PretrainedFSMTModel.__init__": 3081
        },
        {
            "transformers.utils.dummy_pt_objects.FunnelBaseModel.__init__": 3091
        },
        {
            "transformers.utils.dummy_pt_objects.FunnelForMaskedLM.__init__": 3098
        },
        {
            "transformers.utils.dummy_pt_objects.FunnelForMultipleChoice.__init__": 3105
        },
        {
            "transformers.utils.dummy_pt_objects.FunnelForPreTraining.__init__": 3112
        },
        {
            "transformers.utils.dummy_pt_objects.FunnelForQuestionAnswering.__init__": 3119
        },
        {
            "transformers.utils.dummy_pt_objects.FunnelForSequenceClassification.__init__": 3126
        },
        {
            "transformers.utils.dummy_pt_objects.FunnelForTokenClassification.__init__": 3133
        },
        {
            "transformers.utils.dummy_pt_objects.FunnelModel.__init__": 3140
        },
        {
            "transformers.utils.dummy_pt_objects.FunnelPreTrainedModel.__init__": 3147
        },
        {
            "transformers.utils.dummy_pt_objects.load_tf_weights_in_funnel": 3151
        },
        {
            "transformers.utils.dummy_pt_objects.GitForCausalLM.__init__": 3161
        },
        {
            "transformers.utils.dummy_pt_objects.GitModel.__init__": 3168
        },
        {
            "transformers.utils.dummy_pt_objects.GitPreTrainedModel.__init__": 3175
        },
        {
            "transformers.utils.dummy_pt_objects.GitVisionModel.__init__": 3182
        },
        {
            "transformers.utils.dummy_pt_objects.GLPNForDepthEstimation.__init__": 3192
        },
        {
            "transformers.utils.dummy_pt_objects.GLPNModel.__init__": 3199
        },
        {
            "transformers.utils.dummy_pt_objects.GLPNPreTrainedModel.__init__": 3206
        },
        {
            "transformers.utils.dummy_pt_objects.GPT2DoubleHeadsModel.__init__": 3216
        },
        {
            "transformers.utils.dummy_pt_objects.GPT2ForQuestionAnswering.__init__": 3223
        },
        {
            "transformers.utils.dummy_pt_objects.GPT2ForSequenceClassification.__init__": 3230
        },
        {
            "transformers.utils.dummy_pt_objects.GPT2ForTokenClassification.__init__": 3237
        },
        {
            "transformers.utils.dummy_pt_objects.GPT2LMHeadModel.__init__": 3244
        },
        {
            "transformers.utils.dummy_pt_objects.GPT2Model.__init__": 3251
        },
        {
            "transformers.utils.dummy_pt_objects.GPT2PreTrainedModel.__init__": 3258
        },
        {
            "transformers.utils.dummy_pt_objects.load_tf_weights_in_gpt2": 3262
        },
        {
            "transformers.utils.dummy_pt_objects.GPTBigCodeForCausalLM.__init__": 3272
        },
        {
            "transformers.utils.dummy_pt_objects.GPTBigCodeForSequenceClassification.__init__": 3279
        },
        {
            "transformers.utils.dummy_pt_objects.GPTBigCodeForTokenClassification.__init__": 3286
        },
        {
            "transformers.utils.dummy_pt_objects.GPTBigCodeModel.__init__": 3293
        },
        {
            "transformers.utils.dummy_pt_objects.GPTBigCodePreTrainedModel.__init__": 3300
        },
        {
            "transformers.utils.dummy_pt_objects.GPTNeoForCausalLM.__init__": 3310
        },
        {
            "transformers.utils.dummy_pt_objects.GPTNeoForQuestionAnswering.__init__": 3317
        },
        {
            "transformers.utils.dummy_pt_objects.GPTNeoForSequenceClassification.__init__": 3324
        },
        {
            "transformers.utils.dummy_pt_objects.GPTNeoForTokenClassification.__init__": 3331
        },
        {
            "transformers.utils.dummy_pt_objects.GPTNeoModel.__init__": 3338
        },
        {
            "transformers.utils.dummy_pt_objects.GPTNeoPreTrainedModel.__init__": 3345
        },
        {
            "transformers.utils.dummy_pt_objects.load_tf_weights_in_gpt_neo": 3349
        },
        {
            "transformers.utils.dummy_pt_objects.GPTNeoXForCausalLM.__init__": 3359
        },
        {
            "transformers.utils.dummy_pt_objects.GPTNeoXForQuestionAnswering.__init__": 3366
        },
        {
            "transformers.utils.dummy_pt_objects.GPTNeoXForSequenceClassification.__init__": 3373
        },
        {
            "transformers.utils.dummy_pt_objects.GPTNeoXForTokenClassification.__init__": 3380
        },
        {
            "transformers.utils.dummy_pt_objects.GPTNeoXLayer.__init__": 3387
        },
        {
            "transformers.utils.dummy_pt_objects.GPTNeoXModel.__init__": 3394
        },
        {
            "transformers.utils.dummy_pt_objects.GPTNeoXPreTrainedModel.__init__": 3401
        },
        {
            "transformers.utils.dummy_pt_objects.GPTNeoXJapaneseForCausalLM.__init__": 3411
        },
        {
            "transformers.utils.dummy_pt_objects.GPTNeoXJapaneseLayer.__init__": 3418
        },
        {
            "transformers.utils.dummy_pt_objects.GPTNeoXJapaneseModel.__init__": 3425
        },
        {
            "transformers.utils.dummy_pt_objects.GPTNeoXJapanesePreTrainedModel.__init__": 3432
        },
        {
            "transformers.utils.dummy_pt_objects.GPTJForCausalLM.__init__": 3442
        },
        {
            "transformers.utils.dummy_pt_objects.GPTJForQuestionAnswering.__init__": 3449
        },
        {
            "transformers.utils.dummy_pt_objects.GPTJForSequenceClassification.__init__": 3456
        },
        {
            "transformers.utils.dummy_pt_objects.GPTJModel.__init__": 3463
        },
        {
            "transformers.utils.dummy_pt_objects.GPTJPreTrainedModel.__init__": 3470
        },
        {
            "transformers.utils.dummy_pt_objects.GPTSanJapaneseForConditionalGeneration.__init__": 3480
        },
        {
            "transformers.utils.dummy_pt_objects.GPTSanJapaneseModel.__init__": 3487
        },
        {
            "transformers.utils.dummy_pt_objects.GPTSanJapanesePreTrainedModel.__init__": 3494
        },
        {
            "transformers.utils.dummy_pt_objects.GraphormerForGraphClassification.__init__": 3504
        },
        {
            "transformers.utils.dummy_pt_objects.GraphormerModel.__init__": 3511
        },
        {
            "transformers.utils.dummy_pt_objects.GraphormerPreTrainedModel.__init__": 3518
        },
        {
            "transformers.utils.dummy_pt_objects.GroupViTModel.__init__": 3528
        },
        {
            "transformers.utils.dummy_pt_objects.GroupViTPreTrainedModel.__init__": 3535
        },
        {
            "transformers.utils.dummy_pt_objects.GroupViTTextModel.__init__": 3542
        },
        {
            "transformers.utils.dummy_pt_objects.GroupViTVisionModel.__init__": 3549
        },
        {
            "transformers.utils.dummy_pt_objects.HubertForCTC.__init__": 3559
        },
        {
            "transformers.utils.dummy_pt_objects.HubertForSequenceClassification.__init__": 3566
        },
        {
            "transformers.utils.dummy_pt_objects.HubertModel.__init__": 3573
        },
        {
            "transformers.utils.dummy_pt_objects.HubertPreTrainedModel.__init__": 3580
        },
        {
            "transformers.utils.dummy_pt_objects.IBertForMaskedLM.__init__": 3590
        },
        {
            "transformers.utils.dummy_pt_objects.IBertForMultipleChoice.__init__": 3597
        },
        {
            "transformers.utils.dummy_pt_objects.IBertForQuestionAnswering.__init__": 3604
        },
        {
            "transformers.utils.dummy_pt_objects.IBertForSequenceClassification.__init__": 3611
        },
        {
            "transformers.utils.dummy_pt_objects.IBertForTokenClassification.__init__": 3618
        },
        {
            "transformers.utils.dummy_pt_objects.IBertModel.__init__": 3625
        },
        {
            "transformers.utils.dummy_pt_objects.IBertPreTrainedModel.__init__": 3632
        },
        {
            "transformers.utils.dummy_pt_objects.ImageGPTForCausalImageModeling.__init__": 3642
        },
        {
            "transformers.utils.dummy_pt_objects.ImageGPTForImageClassification.__init__": 3649
        },
        {
            "transformers.utils.dummy_pt_objects.ImageGPTModel.__init__": 3656
        },
        {
            "transformers.utils.dummy_pt_objects.ImageGPTPreTrainedModel.__init__": 3663
        },
        {
            "transformers.utils.dummy_pt_objects.load_tf_weights_in_imagegpt": 3667
        },
        {
            "transformers.utils.dummy_pt_objects.InformerForPrediction.__init__": 3677
        },
        {
            "transformers.utils.dummy_pt_objects.InformerModel.__init__": 3684
        },
        {
            "transformers.utils.dummy_pt_objects.InformerPreTrainedModel.__init__": 3691
        },
        {
            "transformers.utils.dummy_pt_objects.JukeboxModel.__init__": 3701
        },
        {
            "transformers.utils.dummy_pt_objects.JukeboxPreTrainedModel.__init__": 3708
        },
        {
            "transformers.utils.dummy_pt_objects.JukeboxPrior.__init__": 3715
        },
        {
            "transformers.utils.dummy_pt_objects.JukeboxVQVAE.__init__": 3722
        },
        {
            "transformers.utils.dummy_pt_objects.LayoutLMForMaskedLM.__init__": 3732
        },
        {
            "transformers.utils.dummy_pt_objects.LayoutLMForQuestionAnswering.__init__": 3739
        },
        {
            "transformers.utils.dummy_pt_objects.LayoutLMForSequenceClassification.__init__": 3746
        },
        {
            "transformers.utils.dummy_pt_objects.LayoutLMForTokenClassification.__init__": 3753
        },
        {
            "transformers.utils.dummy_pt_objects.LayoutLMModel.__init__": 3760
        },
        {
            "transformers.utils.dummy_pt_objects.LayoutLMPreTrainedModel.__init__": 3767
        },
        {
            "transformers.utils.dummy_pt_objects.LayoutLMv2ForQuestionAnswering.__init__": 3777
        },
        {
            "transformers.utils.dummy_pt_objects.LayoutLMv2ForSequenceClassification.__init__": 3784
        },
        {
            "transformers.utils.dummy_pt_objects.LayoutLMv2ForTokenClassification.__init__": 3791
        },
        {
            "transformers.utils.dummy_pt_objects.LayoutLMv2Model.__init__": 3798
        },
        {
            "transformers.utils.dummy_pt_objects.LayoutLMv2PreTrainedModel.__init__": 3805
        },
        {
            "transformers.utils.dummy_pt_objects.LayoutLMv3ForQuestionAnswering.__init__": 3815
        },
        {
            "transformers.utils.dummy_pt_objects.LayoutLMv3ForSequenceClassification.__init__": 3822
        },
        {
            "transformers.utils.dummy_pt_objects.LayoutLMv3ForTokenClassification.__init__": 3829
        },
        {
            "transformers.utils.dummy_pt_objects.LayoutLMv3Model.__init__": 3836
        },
        {
            "transformers.utils.dummy_pt_objects.LayoutLMv3PreTrainedModel.__init__": 3843
        },
        {
            "transformers.utils.dummy_pt_objects.LEDForConditionalGeneration.__init__": 3853
        },
        {
            "transformers.utils.dummy_pt_objects.LEDForQuestionAnswering.__init__": 3860
        },
        {
            "transformers.utils.dummy_pt_objects.LEDForSequenceClassification.__init__": 3867
        },
        {
            "transformers.utils.dummy_pt_objects.LEDModel.__init__": 3874
        },
        {
            "transformers.utils.dummy_pt_objects.LEDPreTrainedModel.__init__": 3881
        },
        {
            "transformers.utils.dummy_pt_objects.LevitForImageClassification.__init__": 3891
        },
        {
            "transformers.utils.dummy_pt_objects.LevitForImageClassificationWithTeacher.__init__": 3898
        },
        {
            "transformers.utils.dummy_pt_objects.LevitModel.__init__": 3905
        },
        {
            "transformers.utils.dummy_pt_objects.LevitPreTrainedModel.__init__": 3912
        },
        {
            "transformers.utils.dummy_pt_objects.LiltForQuestionAnswering.__init__": 3922
        },
        {
            "transformers.utils.dummy_pt_objects.LiltForSequenceClassification.__init__": 3929
        },
        {
            "transformers.utils.dummy_pt_objects.LiltForTokenClassification.__init__": 3936
        },
        {
            "transformers.utils.dummy_pt_objects.LiltModel.__init__": 3943
        },
        {
            "transformers.utils.dummy_pt_objects.LiltPreTrainedModel.__init__": 3950
        },
        {
            "transformers.utils.dummy_pt_objects.LlamaForCausalLM.__init__": 3957
        },
        {
            "transformers.utils.dummy_pt_objects.LlamaForSequenceClassification.__init__": 3964
        },
        {
            "transformers.utils.dummy_pt_objects.LlamaModel.__init__": 3971
        },
        {
            "transformers.utils.dummy_pt_objects.LlamaPreTrainedModel.__init__": 3978
        },
        {
            "transformers.utils.dummy_pt_objects.LongformerForMaskedLM.__init__": 3988
        },
        {
            "transformers.utils.dummy_pt_objects.LongformerForMultipleChoice.__init__": 3995
        },
        {
            "transformers.utils.dummy_pt_objects.LongformerForQuestionAnswering.__init__": 4002
        },
        {
            "transformers.utils.dummy_pt_objects.LongformerForSequenceClassification.__init__": 4009
        },
        {
            "transformers.utils.dummy_pt_objects.LongformerForTokenClassification.__init__": 4016
        },
        {
            "transformers.utils.dummy_pt_objects.LongformerModel.__init__": 4023
        },
        {
            "transformers.utils.dummy_pt_objects.LongformerPreTrainedModel.__init__": 4030
        },
        {
            "transformers.utils.dummy_pt_objects.LongformerSelfAttention.__init__": 4037
        },
        {
            "transformers.utils.dummy_pt_objects.LongT5EncoderModel.__init__": 4047
        },
        {
            "transformers.utils.dummy_pt_objects.LongT5ForConditionalGeneration.__init__": 4054
        },
        {
            "transformers.utils.dummy_pt_objects.LongT5Model.__init__": 4061
        },
        {
            "transformers.utils.dummy_pt_objects.LongT5PreTrainedModel.__init__": 4068
        },
        {
            "transformers.utils.dummy_pt_objects.LukeForEntityClassification.__init__": 4078
        },
        {
            "transformers.utils.dummy_pt_objects.LukeForEntityPairClassification.__init__": 4085
        },
        {
            "transformers.utils.dummy_pt_objects.LukeForEntitySpanClassification.__init__": 4092
        },
        {
            "transformers.utils.dummy_pt_objects.LukeForMaskedLM.__init__": 4099
        },
        {
            "transformers.utils.dummy_pt_objects.LukeForMultipleChoice.__init__": 4106
        },
        {
            "transformers.utils.dummy_pt_objects.LukeForQuestionAnswering.__init__": 4113
        },
        {
            "transformers.utils.dummy_pt_objects.LukeForSequenceClassification.__init__": 4120
        },
        {
            "transformers.utils.dummy_pt_objects.LukeForTokenClassification.__init__": 4127
        },
        {
            "transformers.utils.dummy_pt_objects.LukeModel.__init__": 4134
        },
        {
            "transformers.utils.dummy_pt_objects.LukePreTrainedModel.__init__": 4141
        },
        {
            "transformers.utils.dummy_pt_objects.LxmertEncoder.__init__": 4148
        },
        {
            "transformers.utils.dummy_pt_objects.LxmertForPreTraining.__init__": 4155
        },
        {
            "transformers.utils.dummy_pt_objects.LxmertForQuestionAnswering.__init__": 4162
        },
        {
            "transformers.utils.dummy_pt_objects.LxmertModel.__init__": 4169
        },
        {
            "transformers.utils.dummy_pt_objects.LxmertPreTrainedModel.__init__": 4176
        },
        {
            "transformers.utils.dummy_pt_objects.LxmertVisualFeatureEncoder.__init__": 4183
        },
        {
            "transformers.utils.dummy_pt_objects.LxmertXLayer.__init__": 4190
        },
        {
            "transformers.utils.dummy_pt_objects.M2M100ForConditionalGeneration.__init__": 4200
        },
        {
            "transformers.utils.dummy_pt_objects.M2M100Model.__init__": 4207
        },
        {
            "transformers.utils.dummy_pt_objects.M2M100PreTrainedModel.__init__": 4214
        },
        {
            "transformers.utils.dummy_pt_objects.MarianForCausalLM.__init__": 4221
        },
        {
            "transformers.utils.dummy_pt_objects.MarianModel.__init__": 4228
        },
        {
            "transformers.utils.dummy_pt_objects.MarianMTModel.__init__": 4235
        },
        {
            "transformers.utils.dummy_pt_objects.MarkupLMForQuestionAnswering.__init__": 4245
        },
        {
            "transformers.utils.dummy_pt_objects.MarkupLMForSequenceClassification.__init__": 4252
        },
        {
            "transformers.utils.dummy_pt_objects.MarkupLMForTokenClassification.__init__": 4259
        },
        {
            "transformers.utils.dummy_pt_objects.MarkupLMModel.__init__": 4266
        },
        {
            "transformers.utils.dummy_pt_objects.MarkupLMPreTrainedModel.__init__": 4273
        },
        {
            "transformers.utils.dummy_pt_objects.Mask2FormerForUniversalSegmentation.__init__": 4283
        },
        {
            "transformers.utils.dummy_pt_objects.Mask2FormerModel.__init__": 4290
        },
        {
            "transformers.utils.dummy_pt_objects.Mask2FormerPreTrainedModel.__init__": 4297
        },
        {
            "transformers.utils.dummy_pt_objects.MaskFormerForInstanceSegmentation.__init__": 4307
        },
        {
            "transformers.utils.dummy_pt_objects.MaskFormerModel.__init__": 4314
        },
        {
            "transformers.utils.dummy_pt_objects.MaskFormerPreTrainedModel.__init__": 4321
        },
        {
            "transformers.utils.dummy_pt_objects.MaskFormerSwinBackbone.__init__": 4328
        },
        {
            "transformers.utils.dummy_pt_objects.MBartForCausalLM.__init__": 4335
        },
        {
            "transformers.utils.dummy_pt_objects.MBartForConditionalGeneration.__init__": 4342
        },
        {
            "transformers.utils.dummy_pt_objects.MBartForQuestionAnswering.__init__": 4349
        },
        {
            "transformers.utils.dummy_pt_objects.MBartForSequenceClassification.__init__": 4356
        },
        {
            "transformers.utils.dummy_pt_objects.MBartModel.__init__": 4363
        },
        {
            "transformers.utils.dummy_pt_objects.MBartPreTrainedModel.__init__": 4370
        },
        {
            "transformers.utils.dummy_pt_objects.MCTCTForCTC.__init__": 4380
        },
        {
            "transformers.utils.dummy_pt_objects.MCTCTModel.__init__": 4387
        },
        {
            "transformers.utils.dummy_pt_objects.MCTCTPreTrainedModel.__init__": 4394
        },
        {
            "transformers.utils.dummy_pt_objects.MegaForCausalLM.__init__": 4404
        },
        {
            "transformers.utils.dummy_pt_objects.MegaForMaskedLM.__init__": 4411
        },
        {
            "transformers.utils.dummy_pt_objects.MegaForMultipleChoice.__init__": 4418
        },
        {
            "transformers.utils.dummy_pt_objects.MegaForQuestionAnswering.__init__": 4425
        },
        {
            "transformers.utils.dummy_pt_objects.MegaForSequenceClassification.__init__": 4432
        },
        {
            "transformers.utils.dummy_pt_objects.MegaForTokenClassification.__init__": 4439
        },
        {
            "transformers.utils.dummy_pt_objects.MegaModel.__init__": 4446
        },
        {
            "transformers.utils.dummy_pt_objects.MegaPreTrainedModel.__init__": 4453
        },
        {
            "transformers.utils.dummy_pt_objects.MegatronBertForCausalLM.__init__": 4463
        },
        {
            "transformers.utils.dummy_pt_objects.MegatronBertForMaskedLM.__init__": 4470
        },
        {
            "transformers.utils.dummy_pt_objects.MegatronBertForMultipleChoice.__init__": 4477
        },
        {
            "transformers.utils.dummy_pt_objects.MegatronBertForNextSentencePrediction.__init__": 4484
        },
        {
            "transformers.utils.dummy_pt_objects.MegatronBertForPreTraining.__init__": 4491
        },
        {
            "transformers.utils.dummy_pt_objects.MegatronBertForQuestionAnswering.__init__": 4498
        },
        {
            "transformers.utils.dummy_pt_objects.MegatronBertForSequenceClassification.__init__": 4505
        },
        {
            "transformers.utils.dummy_pt_objects.MegatronBertForTokenClassification.__init__": 4512
        },
        {
            "transformers.utils.dummy_pt_objects.MegatronBertModel.__init__": 4519
        },
        {
            "transformers.utils.dummy_pt_objects.MegatronBertPreTrainedModel.__init__": 4526
        },
        {
            "transformers.utils.dummy_pt_objects.MgpstrForSceneTextRecognition.__init__": 4536
        },
        {
            "transformers.utils.dummy_pt_objects.MgpstrModel.__init__": 4543
        },
        {
            "transformers.utils.dummy_pt_objects.MgpstrPreTrainedModel.__init__": 4550
        },
        {
            "transformers.utils.dummy_pt_objects.MMBTForClassification.__init__": 4557
        },
        {
            "transformers.utils.dummy_pt_objects.MMBTModel.__init__": 4564
        },
        {
            "transformers.utils.dummy_pt_objects.ModalEmbeddings.__init__": 4571
        },
        {
            "transformers.utils.dummy_pt_objects.MobileBertForMaskedLM.__init__": 4581
        },
        {
            "transformers.utils.dummy_pt_objects.MobileBertForMultipleChoice.__init__": 4588
        },
        {
            "transformers.utils.dummy_pt_objects.MobileBertForNextSentencePrediction.__init__": 4595
        },
        {
            "transformers.utils.dummy_pt_objects.MobileBertForPreTraining.__init__": 4602
        },
        {
            "transformers.utils.dummy_pt_objects.MobileBertForQuestionAnswering.__init__": 4609
        },
        {
            "transformers.utils.dummy_pt_objects.MobileBertForSequenceClassification.__init__": 4616
        },
        {
            "transformers.utils.dummy_pt_objects.MobileBertForTokenClassification.__init__": 4623
        },
        {
            "transformers.utils.dummy_pt_objects.MobileBertLayer.__init__": 4630
        },
        {
            "transformers.utils.dummy_pt_objects.MobileBertModel.__init__": 4637
        },
        {
            "transformers.utils.dummy_pt_objects.MobileBertPreTrainedModel.__init__": 4644
        },
        {
            "transformers.utils.dummy_pt_objects.load_tf_weights_in_mobilebert": 4648
        },
        {
            "transformers.utils.dummy_pt_objects.MobileNetV1ForImageClassification.__init__": 4658
        },
        {
            "transformers.utils.dummy_pt_objects.MobileNetV1Model.__init__": 4665
        },
        {
            "transformers.utils.dummy_pt_objects.MobileNetV1PreTrainedModel.__init__": 4672
        },
        {
            "transformers.utils.dummy_pt_objects.load_tf_weights_in_mobilenet_v1": 4676
        },
        {
            "transformers.utils.dummy_pt_objects.MobileNetV2ForImageClassification.__init__": 4686
        },
        {
            "transformers.utils.dummy_pt_objects.MobileNetV2ForSemanticSegmentation.__init__": 4693
        },
        {
            "transformers.utils.dummy_pt_objects.MobileNetV2Model.__init__": 4700
        },
        {
            "transformers.utils.dummy_pt_objects.MobileNetV2PreTrainedModel.__init__": 4707
        },
        {
            "transformers.utils.dummy_pt_objects.load_tf_weights_in_mobilenet_v2": 4711
        },
        {
            "transformers.utils.dummy_pt_objects.MobileViTForImageClassification.__init__": 4721
        },
        {
            "transformers.utils.dummy_pt_objects.MobileViTForSemanticSegmentation.__init__": 4728
        },
        {
            "transformers.utils.dummy_pt_objects.MobileViTModel.__init__": 4735
        },
        {
            "transformers.utils.dummy_pt_objects.MobileViTPreTrainedModel.__init__": 4742
        },
        {
            "transformers.utils.dummy_pt_objects.MobileViTV2ForImageClassification.__init__": 4752
        },
        {
            "transformers.utils.dummy_pt_objects.MobileViTV2ForSemanticSegmentation.__init__": 4759
        },
        {
            "transformers.utils.dummy_pt_objects.MobileViTV2Model.__init__": 4766
        },
        {
            "transformers.utils.dummy_pt_objects.MobileViTV2PreTrainedModel.__init__": 4773
        },
        {
            "transformers.utils.dummy_pt_objects.MPNetForMaskedLM.__init__": 4783
        },
        {
            "transformers.utils.dummy_pt_objects.MPNetForMultipleChoice.__init__": 4790
        },
        {
            "transformers.utils.dummy_pt_objects.MPNetForQuestionAnswering.__init__": 4797
        },
        {
            "transformers.utils.dummy_pt_objects.MPNetForSequenceClassification.__init__": 4804
        },
        {
            "transformers.utils.dummy_pt_objects.MPNetForTokenClassification.__init__": 4811
        },
        {
            "transformers.utils.dummy_pt_objects.MPNetLayer.__init__": 4818
        },
        {
            "transformers.utils.dummy_pt_objects.MPNetModel.__init__": 4825
        },
        {
            "transformers.utils.dummy_pt_objects.MPNetPreTrainedModel.__init__": 4832
        },
        {
            "transformers.utils.dummy_pt_objects.MT5EncoderModel.__init__": 4839
        },
        {
            "transformers.utils.dummy_pt_objects.MT5ForConditionalGeneration.__init__": 4846
        },
        {
            "transformers.utils.dummy_pt_objects.MT5Model.__init__": 4853
        },
        {
            "transformers.utils.dummy_pt_objects.MT5PreTrainedModel.__init__": 4860
        },
        {
            "transformers.utils.dummy_pt_objects.MvpForCausalLM.__init__": 4870
        },
        {
            "transformers.utils.dummy_pt_objects.MvpForConditionalGeneration.__init__": 4877
        },
        {
            "transformers.utils.dummy_pt_objects.MvpForQuestionAnswering.__init__": 4884
        },
        {
            "transformers.utils.dummy_pt_objects.MvpForSequenceClassification.__init__": 4891
        },
        {
            "transformers.utils.dummy_pt_objects.MvpModel.__init__": 4898
        },
        {
            "transformers.utils.dummy_pt_objects.MvpPreTrainedModel.__init__": 4905
        },
        {
            "transformers.utils.dummy_pt_objects.NatBackbone.__init__": 4915
        },
        {
            "transformers.utils.dummy_pt_objects.NatForImageClassification.__init__": 4922
        },
        {
            "transformers.utils.dummy_pt_objects.NatModel.__init__": 4929
        },
        {
            "transformers.utils.dummy_pt_objects.NatPreTrainedModel.__init__": 4936
        },
        {
            "transformers.utils.dummy_pt_objects.NezhaForMaskedLM.__init__": 4946
        },
        {
            "transformers.utils.dummy_pt_objects.NezhaForMultipleChoice.__init__": 4953
        },
        {
            "transformers.utils.dummy_pt_objects.NezhaForNextSentencePrediction.__init__": 4960
        },
        {
            "transformers.utils.dummy_pt_objects.NezhaForPreTraining.__init__": 4967
        },
        {
            "transformers.utils.dummy_pt_objects.NezhaForQuestionAnswering.__init__": 4974
        },
        {
            "transformers.utils.dummy_pt_objects.NezhaForSequenceClassification.__init__": 4981
        },
        {
            "transformers.utils.dummy_pt_objects.NezhaForTokenClassification.__init__": 4988
        },
        {
            "transformers.utils.dummy_pt_objects.NezhaModel.__init__": 4995
        },
        {
            "transformers.utils.dummy_pt_objects.NezhaPreTrainedModel.__init__": 5002
        },
        {
            "transformers.utils.dummy_pt_objects.NllbMoeForConditionalGeneration.__init__": 5012
        },
        {
            "transformers.utils.dummy_pt_objects.NllbMoeModel.__init__": 5019
        },
        {
            "transformers.utils.dummy_pt_objects.NllbMoePreTrainedModel.__init__": 5026
        },
        {
            "transformers.utils.dummy_pt_objects.NllbMoeSparseMLP.__init__": 5033
        },
        {
            "transformers.utils.dummy_pt_objects.NllbMoeTop2Router.__init__": 5040
        },
        {
            "transformers.utils.dummy_pt_objects.NystromformerForMaskedLM.__init__": 5050
        },
        {
            "transformers.utils.dummy_pt_objects.NystromformerForMultipleChoice.__init__": 5057
        },
        {
            "transformers.utils.dummy_pt_objects.NystromformerForQuestionAnswering.__init__": 5064
        },
        {
            "transformers.utils.dummy_pt_objects.NystromformerForSequenceClassification.__init__": 5071
        },
        {
            "transformers.utils.dummy_pt_objects.NystromformerForTokenClassification.__init__": 5078
        },
        {
            "transformers.utils.dummy_pt_objects.NystromformerLayer.__init__": 5085
        },
        {
            "transformers.utils.dummy_pt_objects.NystromformerModel.__init__": 5092
        },
        {
            "transformers.utils.dummy_pt_objects.NystromformerPreTrainedModel.__init__": 5099
        },
        {
            "transformers.utils.dummy_pt_objects.OneFormerForUniversalSegmentation.__init__": 5109
        },
        {
            "transformers.utils.dummy_pt_objects.OneFormerModel.__init__": 5116
        },
        {
            "transformers.utils.dummy_pt_objects.OneFormerPreTrainedModel.__init__": 5123
        },
        {
            "transformers.utils.dummy_pt_objects.OpenLlamaForCausalLM.__init__": 5130
        },
        {
            "transformers.utils.dummy_pt_objects.OpenLlamaForSequenceClassification.__init__": 5137
        },
        {
            "transformers.utils.dummy_pt_objects.OpenLlamaModel.__init__": 5144
        },
        {
            "transformers.utils.dummy_pt_objects.OpenLlamaPreTrainedModel.__init__": 5151
        },
        {
            "transformers.utils.dummy_pt_objects.OpenAIGPTDoubleHeadsModel.__init__": 5161
        },
        {
            "transformers.utils.dummy_pt_objects.OpenAIGPTForSequenceClassification.__init__": 5168
        },
        {
            "transformers.utils.dummy_pt_objects.OpenAIGPTLMHeadModel.__init__": 5175
        },
        {
            "transformers.utils.dummy_pt_objects.OpenAIGPTModel.__init__": 5182
        },
        {
            "transformers.utils.dummy_pt_objects.OpenAIGPTPreTrainedModel.__init__": 5189
        },
        {
            "transformers.utils.dummy_pt_objects.load_tf_weights_in_openai_gpt": 5193
        },
        {
            "transformers.utils.dummy_pt_objects.OPTForCausalLM.__init__": 5203
        },
        {
            "transformers.utils.dummy_pt_objects.OPTForQuestionAnswering.__init__": 5210
        },
        {
            "transformers.utils.dummy_pt_objects.OPTForSequenceClassification.__init__": 5217
        },
        {
            "transformers.utils.dummy_pt_objects.OPTModel.__init__": 5224
        },
        {
            "transformers.utils.dummy_pt_objects.OPTPreTrainedModel.__init__": 5231
        },
        {
            "transformers.utils.dummy_pt_objects.OwlViTForObjectDetection.__init__": 5241
        },
        {
            "transformers.utils.dummy_pt_objects.OwlViTModel.__init__": 5248
        },
        {
            "transformers.utils.dummy_pt_objects.OwlViTPreTrainedModel.__init__": 5255
        },
        {
            "transformers.utils.dummy_pt_objects.OwlViTTextModel.__init__": 5262
        },
        {
            "transformers.utils.dummy_pt_objects.OwlViTVisionModel.__init__": 5269
        },
        {
            "transformers.utils.dummy_pt_objects.PegasusForCausalLM.__init__": 5276
        },
        {
            "transformers.utils.dummy_pt_objects.PegasusForConditionalGeneration.__init__": 5283
        },
        {
            "transformers.utils.dummy_pt_objects.PegasusModel.__init__": 5290
        },
        {
            "transformers.utils.dummy_pt_objects.PegasusPreTrainedModel.__init__": 5297
        },
        {
            "transformers.utils.dummy_pt_objects.PegasusXForConditionalGeneration.__init__": 5307
        },
        {
            "transformers.utils.dummy_pt_objects.PegasusXModel.__init__": 5314
        },
        {
            "transformers.utils.dummy_pt_objects.PegasusXPreTrainedModel.__init__": 5321
        },
        {
            "transformers.utils.dummy_pt_objects.PerceiverForImageClassificationConvProcessing.__init__": 5331
        },
        {
            "transformers.utils.dummy_pt_objects.PerceiverForImageClassificationFourier.__init__": 5338
        },
        {
            "transformers.utils.dummy_pt_objects.PerceiverForImageClassificationLearned.__init__": 5345
        },
        {
            "transformers.utils.dummy_pt_objects.PerceiverForMaskedLM.__init__": 5352
        },
        {
            "transformers.utils.dummy_pt_objects.PerceiverForMultimodalAutoencoding.__init__": 5359
        },
        {
            "transformers.utils.dummy_pt_objects.PerceiverForOpticalFlow.__init__": 5366
        },
        {
            "transformers.utils.dummy_pt_objects.PerceiverForSequenceClassification.__init__": 5373
        },
        {
            "transformers.utils.dummy_pt_objects.PerceiverLayer.__init__": 5380
        },
        {
            "transformers.utils.dummy_pt_objects.PerceiverModel.__init__": 5387
        },
        {
            "transformers.utils.dummy_pt_objects.PerceiverPreTrainedModel.__init__": 5394
        },
        {
            "transformers.utils.dummy_pt_objects.Pix2StructForConditionalGeneration.__init__": 5404
        },
        {
            "transformers.utils.dummy_pt_objects.Pix2StructPreTrainedModel.__init__": 5411
        },
        {
            "transformers.utils.dummy_pt_objects.Pix2StructTextModel.__init__": 5418
        },
        {
            "transformers.utils.dummy_pt_objects.Pix2StructVisionModel.__init__": 5425
        },
        {
            "transformers.utils.dummy_pt_objects.PLBartForCausalLM.__init__": 5435
        },
        {
            "transformers.utils.dummy_pt_objects.PLBartForConditionalGeneration.__init__": 5442
        },
        {
            "transformers.utils.dummy_pt_objects.PLBartForSequenceClassification.__init__": 5449
        },
        {
            "transformers.utils.dummy_pt_objects.PLBartModel.__init__": 5456
        },
        {
            "transformers.utils.dummy_pt_objects.PLBartPreTrainedModel.__init__": 5463
        },
        {
            "transformers.utils.dummy_pt_objects.PoolFormerForImageClassification.__init__": 5473
        },
        {
            "transformers.utils.dummy_pt_objects.PoolFormerModel.__init__": 5480
        },
        {
            "transformers.utils.dummy_pt_objects.PoolFormerPreTrainedModel.__init__": 5487
        },
        {
            "transformers.utils.dummy_pt_objects.ProphetNetDecoder.__init__": 5497
        },
        {
            "transformers.utils.dummy_pt_objects.ProphetNetEncoder.__init__": 5504
        },
        {
            "transformers.utils.dummy_pt_objects.ProphetNetForCausalLM.__init__": 5511
        },
        {
            "transformers.utils.dummy_pt_objects.ProphetNetForConditionalGeneration.__init__": 5518
        },
        {
            "transformers.utils.dummy_pt_objects.ProphetNetModel.__init__": 5525
        },
        {
            "transformers.utils.dummy_pt_objects.ProphetNetPreTrainedModel.__init__": 5532
        },
        {
            "transformers.utils.dummy_pt_objects.QDQBertForMaskedLM.__init__": 5542
        },
        {
            "transformers.utils.dummy_pt_objects.QDQBertForMultipleChoice.__init__": 5549
        },
        {
            "transformers.utils.dummy_pt_objects.QDQBertForNextSentencePrediction.__init__": 5556
        },
        {
            "transformers.utils.dummy_pt_objects.QDQBertForQuestionAnswering.__init__": 5563
        },
        {
            "transformers.utils.dummy_pt_objects.QDQBertForSequenceClassification.__init__": 5570
        },
        {
            "transformers.utils.dummy_pt_objects.QDQBertForTokenClassification.__init__": 5577
        },
        {
            "transformers.utils.dummy_pt_objects.QDQBertLayer.__init__": 5584
        },
        {
            "transformers.utils.dummy_pt_objects.QDQBertLMHeadModel.__init__": 5591
        },
        {
            "transformers.utils.dummy_pt_objects.QDQBertModel.__init__": 5598
        },
        {
            "transformers.utils.dummy_pt_objects.QDQBertPreTrainedModel.__init__": 5605
        },
        {
            "transformers.utils.dummy_pt_objects.load_tf_weights_in_qdqbert": 5609
        },
        {
            "transformers.utils.dummy_pt_objects.RagModel.__init__": 5616
        },
        {
            "transformers.utils.dummy_pt_objects.RagPreTrainedModel.__init__": 5623
        },
        {
            "transformers.utils.dummy_pt_objects.RagSequenceForGeneration.__init__": 5630
        },
        {
            "transformers.utils.dummy_pt_objects.RagTokenForGeneration.__init__": 5637
        },
        {
            "transformers.utils.dummy_pt_objects.RealmEmbedder.__init__": 5647
        },
        {
            "transformers.utils.dummy_pt_objects.RealmForOpenQA.__init__": 5654
        },
        {
            "transformers.utils.dummy_pt_objects.RealmKnowledgeAugEncoder.__init__": 5661
        },
        {
            "transformers.utils.dummy_pt_objects.RealmPreTrainedModel.__init__": 5668
        },
        {
            "transformers.utils.dummy_pt_objects.RealmReader.__init__": 5675
        },
        {
            "transformers.utils.dummy_pt_objects.RealmRetriever.__init__": 5682
        },
        {
            "transformers.utils.dummy_pt_objects.RealmScorer.__init__": 5689
        },
        {
            "transformers.utils.dummy_pt_objects.load_tf_weights_in_realm": 5693
        },
        {
            "transformers.utils.dummy_pt_objects.ReformerAttention.__init__": 5703
        },
        {
            "transformers.utils.dummy_pt_objects.ReformerForMaskedLM.__init__": 5710
        },
        {
            "transformers.utils.dummy_pt_objects.ReformerForQuestionAnswering.__init__": 5717
        },
        {
            "transformers.utils.dummy_pt_objects.ReformerForSequenceClassification.__init__": 5724
        },
        {
            "transformers.utils.dummy_pt_objects.ReformerLayer.__init__": 5731
        },
        {
            "transformers.utils.dummy_pt_objects.ReformerModel.__init__": 5738
        },
        {
            "transformers.utils.dummy_pt_objects.ReformerModelWithLMHead.__init__": 5745
        },
        {
            "transformers.utils.dummy_pt_objects.ReformerPreTrainedModel.__init__": 5752
        },
        {
            "transformers.utils.dummy_pt_objects.RegNetForImageClassification.__init__": 5762
        },
        {
            "transformers.utils.dummy_pt_objects.RegNetModel.__init__": 5769
        },
        {
            "transformers.utils.dummy_pt_objects.RegNetPreTrainedModel.__init__": 5776
        },
        {
            "transformers.utils.dummy_pt_objects.RemBertForCausalLM.__init__": 5786
        },
        {
            "transformers.utils.dummy_pt_objects.RemBertForMaskedLM.__init__": 5793
        },
        {
            "transformers.utils.dummy_pt_objects.RemBertForMultipleChoice.__init__": 5800
        },
        {
            "transformers.utils.dummy_pt_objects.RemBertForQuestionAnswering.__init__": 5807
        },
        {
            "transformers.utils.dummy_pt_objects.RemBertForSequenceClassification.__init__": 5814
        },
        {
            "transformers.utils.dummy_pt_objects.RemBertForTokenClassification.__init__": 5821
        },
        {
            "transformers.utils.dummy_pt_objects.RemBertLayer.__init__": 5828
        },
        {
            "transformers.utils.dummy_pt_objects.RemBertModel.__init__": 5835
        },
        {
            "transformers.utils.dummy_pt_objects.RemBertPreTrainedModel.__init__": 5842
        },
        {
            "transformers.utils.dummy_pt_objects.load_tf_weights_in_rembert": 5846
        },
        {
            "transformers.utils.dummy_pt_objects.ResNetBackbone.__init__": 5856
        },
        {
            "transformers.utils.dummy_pt_objects.ResNetForImageClassification.__init__": 5863
        },
        {
            "transformers.utils.dummy_pt_objects.ResNetModel.__init__": 5870
        },
        {
            "transformers.utils.dummy_pt_objects.ResNetPreTrainedModel.__init__": 5877
        },
        {
            "transformers.utils.dummy_pt_objects.RetriBertModel.__init__": 5887
        },
        {
            "transformers.utils.dummy_pt_objects.RetriBertPreTrainedModel.__init__": 5894
        },
        {
            "transformers.utils.dummy_pt_objects.RobertaForCausalLM.__init__": 5904
        },
        {
            "transformers.utils.dummy_pt_objects.RobertaForMaskedLM.__init__": 5911
        },
        {
            "transformers.utils.dummy_pt_objects.RobertaForMultipleChoice.__init__": 5918
        },
        {
            "transformers.utils.dummy_pt_objects.RobertaForQuestionAnswering.__init__": 5925
        },
        {
            "transformers.utils.dummy_pt_objects.RobertaForSequenceClassification.__init__": 5932
        },
        {
            "transformers.utils.dummy_pt_objects.RobertaForTokenClassification.__init__": 5939
        },
        {
            "transformers.utils.dummy_pt_objects.RobertaModel.__init__": 5946
        },
        {
            "transformers.utils.dummy_pt_objects.RobertaPreTrainedModel.__init__": 5953
        },
        {
            "transformers.utils.dummy_pt_objects.RobertaPreLayerNormForCausalLM.__init__": 5963
        },
        {
            "transformers.utils.dummy_pt_objects.RobertaPreLayerNormForMaskedLM.__init__": 5970
        },
        {
            "transformers.utils.dummy_pt_objects.RobertaPreLayerNormForMultipleChoice.__init__": 5977
        },
        {
            "transformers.utils.dummy_pt_objects.RobertaPreLayerNormForQuestionAnswering.__init__": 5984
        },
        {
            "transformers.utils.dummy_pt_objects.RobertaPreLayerNormForSequenceClassification.__init__": 5991
        },
        {
            "transformers.utils.dummy_pt_objects.RobertaPreLayerNormForTokenClassification.__init__": 5998
        },
        {
            "transformers.utils.dummy_pt_objects.RobertaPreLayerNormModel.__init__": 6005
        },
        {
            "transformers.utils.dummy_pt_objects.RobertaPreLayerNormPreTrainedModel.__init__": 6012
        },
        {
            "transformers.utils.dummy_pt_objects.RoCBertForCausalLM.__init__": 6022
        },
        {
            "transformers.utils.dummy_pt_objects.RoCBertForMaskedLM.__init__": 6029
        },
        {
            "transformers.utils.dummy_pt_objects.RoCBertForMultipleChoice.__init__": 6036
        },
        {
            "transformers.utils.dummy_pt_objects.RoCBertForPreTraining.__init__": 6043
        },
        {
            "transformers.utils.dummy_pt_objects.RoCBertForQuestionAnswering.__init__": 6050
        },
        {
            "transformers.utils.dummy_pt_objects.RoCBertForSequenceClassification.__init__": 6057
        },
        {
            "transformers.utils.dummy_pt_objects.RoCBertForTokenClassification.__init__": 6064
        },
        {
            "transformers.utils.dummy_pt_objects.RoCBertLayer.__init__": 6071
        },
        {
            "transformers.utils.dummy_pt_objects.RoCBertModel.__init__": 6078
        },
        {
            "transformers.utils.dummy_pt_objects.RoCBertPreTrainedModel.__init__": 6085
        },
        {
            "transformers.utils.dummy_pt_objects.load_tf_weights_in_roc_bert": 6089
        },
        {
            "transformers.utils.dummy_pt_objects.RoFormerForCausalLM.__init__": 6099
        },
        {
            "transformers.utils.dummy_pt_objects.RoFormerForMaskedLM.__init__": 6106
        },
        {
            "transformers.utils.dummy_pt_objects.RoFormerForMultipleChoice.__init__": 6113
        },
        {
            "transformers.utils.dummy_pt_objects.RoFormerForQuestionAnswering.__init__": 6120
        },
        {
            "transformers.utils.dummy_pt_objects.RoFormerForSequenceClassification.__init__": 6127
        },
        {
            "transformers.utils.dummy_pt_objects.RoFormerForTokenClassification.__init__": 6134
        },
        {
            "transformers.utils.dummy_pt_objects.RoFormerLayer.__init__": 6141
        },
        {
            "transformers.utils.dummy_pt_objects.RoFormerModel.__init__": 6148
        },
        {
            "transformers.utils.dummy_pt_objects.RoFormerPreTrainedModel.__init__": 6155
        },
        {
            "transformers.utils.dummy_pt_objects.load_tf_weights_in_roformer": 6159
        },
        {
            "transformers.utils.dummy_pt_objects.RwkvForCausalLM.__init__": 6169
        },
        {
            "transformers.utils.dummy_pt_objects.RwkvModel.__init__": 6176
        },
        {
            "transformers.utils.dummy_pt_objects.RwkvPreTrainedModel.__init__": 6183
        },
        {
            "transformers.utils.dummy_pt_objects.SamModel.__init__": 6193
        },
        {
            "transformers.utils.dummy_pt_objects.SamPreTrainedModel.__init__": 6200
        },
        {
            "transformers.utils.dummy_pt_objects.SegformerDecodeHead.__init__": 6210
        },
        {
            "transformers.utils.dummy_pt_objects.SegformerForImageClassification.__init__": 6217
        },
        {
            "transformers.utils.dummy_pt_objects.SegformerForSemanticSegmentation.__init__": 6224
        },
        {
            "transformers.utils.dummy_pt_objects.SegformerLayer.__init__": 6231
        },
        {
            "transformers.utils.dummy_pt_objects.SegformerModel.__init__": 6238
        },
        {
            "transformers.utils.dummy_pt_objects.SegformerPreTrainedModel.__init__": 6245
        },
        {
            "transformers.utils.dummy_pt_objects.SEWForCTC.__init__": 6255
        },
        {
            "transformers.utils.dummy_pt_objects.SEWForSequenceClassification.__init__": 6262
        },
        {
            "transformers.utils.dummy_pt_objects.SEWModel.__init__": 6269
        },
        {
            "transformers.utils.dummy_pt_objects.SEWPreTrainedModel.__init__": 6276
        },
        {
            "transformers.utils.dummy_pt_objects.SEWDForCTC.__init__": 6286
        },
        {
            "transformers.utils.dummy_pt_objects.SEWDForSequenceClassification.__init__": 6293
        },
        {
            "transformers.utils.dummy_pt_objects.SEWDModel.__init__": 6300
        },
        {
            "transformers.utils.dummy_pt_objects.SEWDPreTrainedModel.__init__": 6307
        },
        {
            "transformers.utils.dummy_pt_objects.SpeechEncoderDecoderModel.__init__": 6314
        },
        {
            "transformers.utils.dummy_pt_objects.Speech2TextForConditionalGeneration.__init__": 6324
        },
        {
            "transformers.utils.dummy_pt_objects.Speech2TextModel.__init__": 6331
        },
        {
            "transformers.utils.dummy_pt_objects.Speech2TextPreTrainedModel.__init__": 6338
        },
        {
            "transformers.utils.dummy_pt_objects.Speech2Text2ForCausalLM.__init__": 6345
        },
        {
            "transformers.utils.dummy_pt_objects.Speech2Text2PreTrainedModel.__init__": 6352
        },
        {
            "transformers.utils.dummy_pt_objects.SpeechT5ForSpeechToSpeech.__init__": 6362
        },
        {
            "transformers.utils.dummy_pt_objects.SpeechT5ForSpeechToText.__init__": 6369
        },
        {
            "transformers.utils.dummy_pt_objects.SpeechT5ForTextToSpeech.__init__": 6376
        },
        {
            "transformers.utils.dummy_pt_objects.SpeechT5HifiGan.__init__": 6383
        },
        {
            "transformers.utils.dummy_pt_objects.SpeechT5Model.__init__": 6390
        },
        {
            "transformers.utils.dummy_pt_objects.SpeechT5PreTrainedModel.__init__": 6397
        },
        {
            "transformers.utils.dummy_pt_objects.SplinterForPreTraining.__init__": 6407
        },
        {
            "transformers.utils.dummy_pt_objects.SplinterForQuestionAnswering.__init__": 6414
        },
        {
            "transformers.utils.dummy_pt_objects.SplinterLayer.__init__": 6421
        },
        {
            "transformers.utils.dummy_pt_objects.SplinterModel.__init__": 6428
        },
        {
            "transformers.utils.dummy_pt_objects.SplinterPreTrainedModel.__init__": 6435
        },
        {
            "transformers.utils.dummy_pt_objects.SqueezeBertForMaskedLM.__init__": 6445
        },
        {
            "transformers.utils.dummy_pt_objects.SqueezeBertForMultipleChoice.__init__": 6452
        },
        {
            "transformers.utils.dummy_pt_objects.SqueezeBertForQuestionAnswering.__init__": 6459
        },
        {
            "transformers.utils.dummy_pt_objects.SqueezeBertForSequenceClassification.__init__": 6466
        },
        {
            "transformers.utils.dummy_pt_objects.SqueezeBertForTokenClassification.__init__": 6473
        },
        {
            "transformers.utils.dummy_pt_objects.SqueezeBertModel.__init__": 6480
        },
        {
            "transformers.utils.dummy_pt_objects.SqueezeBertModule.__init__": 6487
        },
        {
            "transformers.utils.dummy_pt_objects.SqueezeBertPreTrainedModel.__init__": 6494
        },
        {
            "transformers.utils.dummy_pt_objects.SwiftFormerForImageClassification.__init__": 6504
        },
        {
            "transformers.utils.dummy_pt_objects.SwiftFormerModel.__init__": 6511
        },
        {
            "transformers.utils.dummy_pt_objects.SwiftFormerPreTrainedModel.__init__": 6518
        },
        {
            "transformers.utils.dummy_pt_objects.SwinBackbone.__init__": 6528
        },
        {
            "transformers.utils.dummy_pt_objects.SwinForImageClassification.__init__": 6535
        },
        {
            "transformers.utils.dummy_pt_objects.SwinForMaskedImageModeling.__init__": 6542
        },
        {
            "transformers.utils.dummy_pt_objects.SwinModel.__init__": 6549
        },
        {
            "transformers.utils.dummy_pt_objects.SwinPreTrainedModel.__init__": 6556
        },
        {
            "transformers.utils.dummy_pt_objects.Swin2SRForImageSuperResolution.__init__": 6566
        },
        {
            "transformers.utils.dummy_pt_objects.Swin2SRModel.__init__": 6573
        },
        {
            "transformers.utils.dummy_pt_objects.Swin2SRPreTrainedModel.__init__": 6580
        },
        {
            "transformers.utils.dummy_pt_objects.Swinv2ForImageClassification.__init__": 6590
        },
        {
            "transformers.utils.dummy_pt_objects.Swinv2ForMaskedImageModeling.__init__": 6597
        },
        {
            "transformers.utils.dummy_pt_objects.Swinv2Model.__init__": 6604
        },
        {
            "transformers.utils.dummy_pt_objects.Swinv2PreTrainedModel.__init__": 6611
        },
        {
            "transformers.utils.dummy_pt_objects.SwitchTransformersEncoderModel.__init__": 6621
        },
        {
            "transformers.utils.dummy_pt_objects.SwitchTransformersForConditionalGeneration.__init__": 6628
        },
        {
            "transformers.utils.dummy_pt_objects.SwitchTransformersModel.__init__": 6635
        },
        {
            "transformers.utils.dummy_pt_objects.SwitchTransformersPreTrainedModel.__init__": 6642
        },
        {
            "transformers.utils.dummy_pt_objects.SwitchTransformersSparseMLP.__init__": 6649
        },
        {
            "transformers.utils.dummy_pt_objects.SwitchTransformersTop1Router.__init__": 6656
        },
        {
            "transformers.utils.dummy_pt_objects.T5EncoderModel.__init__": 6666
        },
        {
            "transformers.utils.dummy_pt_objects.T5ForConditionalGeneration.__init__": 6673
        },
        {
            "transformers.utils.dummy_pt_objects.T5Model.__init__": 6680
        },
        {
            "transformers.utils.dummy_pt_objects.T5PreTrainedModel.__init__": 6687
        },
        {
            "transformers.utils.dummy_pt_objects.load_tf_weights_in_t5": 6691
        },
        {
            "transformers.utils.dummy_pt_objects.TableTransformerForObjectDetection.__init__": 6701
        },
        {
            "transformers.utils.dummy_pt_objects.TableTransformerModel.__init__": 6708
        },
        {
            "transformers.utils.dummy_pt_objects.TableTransformerPreTrainedModel.__init__": 6715
        },
        {
            "transformers.utils.dummy_pt_objects.TapasForMaskedLM.__init__": 6725
        },
        {
            "transformers.utils.dummy_pt_objects.TapasForQuestionAnswering.__init__": 6732
        },
        {
            "transformers.utils.dummy_pt_objects.TapasForSequenceClassification.__init__": 6739
        },
        {
            "transformers.utils.dummy_pt_objects.TapasModel.__init__": 6746
        },
        {
            "transformers.utils.dummy_pt_objects.TapasPreTrainedModel.__init__": 6753
        },
        {
            "transformers.utils.dummy_pt_objects.load_tf_weights_in_tapas": 6757
        },
        {
            "transformers.utils.dummy_pt_objects.TimeSeriesTransformerForPrediction.__init__": 6767
        },
        {
            "transformers.utils.dummy_pt_objects.TimeSeriesTransformerModel.__init__": 6774
        },
        {
            "transformers.utils.dummy_pt_objects.TimeSeriesTransformerPreTrainedModel.__init__": 6781
        },
        {
            "transformers.utils.dummy_pt_objects.TimesformerForVideoClassification.__init__": 6791
        },
        {
            "transformers.utils.dummy_pt_objects.TimesformerModel.__init__": 6798
        },
        {
            "transformers.utils.dummy_pt_objects.TimesformerPreTrainedModel.__init__": 6805
        },
        {
            "transformers.utils.dummy_pt_objects.TimmBackbone.__init__": 6812
        },
        {
            "transformers.utils.dummy_pt_objects.TrajectoryTransformerModel.__init__": 6822
        },
        {
            "transformers.utils.dummy_pt_objects.TrajectoryTransformerPreTrainedModel.__init__": 6829
        },
        {
            "transformers.utils.dummy_pt_objects.AdaptiveEmbedding.__init__": 6839
        },
        {
            "transformers.utils.dummy_pt_objects.TransfoXLForSequenceClassification.__init__": 6846
        },
        {
            "transformers.utils.dummy_pt_objects.TransfoXLLMHeadModel.__init__": 6853
        },
        {
            "transformers.utils.dummy_pt_objects.TransfoXLModel.__init__": 6860
        },
        {
            "transformers.utils.dummy_pt_objects.TransfoXLPreTrainedModel.__init__": 6867
        },
        {
            "transformers.utils.dummy_pt_objects.load_tf_weights_in_transfo_xl": 6871
        },
        {
            "transformers.utils.dummy_pt_objects.TrOCRForCausalLM.__init__": 6881
        },
        {
            "transformers.utils.dummy_pt_objects.TrOCRPreTrainedModel.__init__": 6888
        },
        {
            "transformers.utils.dummy_pt_objects.TvltForAudioVisualClassification.__init__": 6898
        },
        {
            "transformers.utils.dummy_pt_objects.TvltForPreTraining.__init__": 6905
        },
        {
            "transformers.utils.dummy_pt_objects.TvltModel.__init__": 6912
        },
        {
            "transformers.utils.dummy_pt_objects.TvltPreTrainedModel.__init__": 6919
        },
        {
            "transformers.utils.dummy_pt_objects.UniSpeechForCTC.__init__": 6929
        },
        {
            "transformers.utils.dummy_pt_objects.UniSpeechForPreTraining.__init__": 6936
        },
        {
            "transformers.utils.dummy_pt_objects.UniSpeechForSequenceClassification.__init__": 6943
        },
        {
            "transformers.utils.dummy_pt_objects.UniSpeechModel.__init__": 6950
        },
        {
            "transformers.utils.dummy_pt_objects.UniSpeechPreTrainedModel.__init__": 6957
        },
        {
            "transformers.utils.dummy_pt_objects.UniSpeechSatForAudioFrameClassification.__init__": 6967
        },
        {
            "transformers.utils.dummy_pt_objects.UniSpeechSatForCTC.__init__": 6974
        },
        {
            "transformers.utils.dummy_pt_objects.UniSpeechSatForPreTraining.__init__": 6981
        },
        {
            "transformers.utils.dummy_pt_objects.UniSpeechSatForSequenceClassification.__init__": 6988
        },
        {
            "transformers.utils.dummy_pt_objects.UniSpeechSatForXVector.__init__": 6995
        },
        {
            "transformers.utils.dummy_pt_objects.UniSpeechSatModel.__init__": 7002
        },
        {
            "transformers.utils.dummy_pt_objects.UniSpeechSatPreTrainedModel.__init__": 7009
        },
        {
            "transformers.utils.dummy_pt_objects.UperNetForSemanticSegmentation.__init__": 7016
        },
        {
            "transformers.utils.dummy_pt_objects.UperNetPreTrainedModel.__init__": 7023
        },
        {
            "transformers.utils.dummy_pt_objects.VanForImageClassification.__init__": 7033
        },
        {
            "transformers.utils.dummy_pt_objects.VanModel.__init__": 7040
        },
        {
            "transformers.utils.dummy_pt_objects.VanPreTrainedModel.__init__": 7047
        },
        {
            "transformers.utils.dummy_pt_objects.VideoMAEForPreTraining.__init__": 7057
        },
        {
            "transformers.utils.dummy_pt_objects.VideoMAEForVideoClassification.__init__": 7064
        },
        {
            "transformers.utils.dummy_pt_objects.VideoMAEModel.__init__": 7071
        },
        {
            "transformers.utils.dummy_pt_objects.VideoMAEPreTrainedModel.__init__": 7078
        },
        {
            "transformers.utils.dummy_pt_objects.ViltForImageAndTextRetrieval.__init__": 7088
        },
        {
            "transformers.utils.dummy_pt_objects.ViltForImagesAndTextClassification.__init__": 7095
        },
        {
            "transformers.utils.dummy_pt_objects.ViltForMaskedLM.__init__": 7102
        },
        {
            "transformers.utils.dummy_pt_objects.ViltForQuestionAnswering.__init__": 7109
        },
        {
            "transformers.utils.dummy_pt_objects.ViltForTokenClassification.__init__": 7116
        },
        {
            "transformers.utils.dummy_pt_objects.ViltLayer.__init__": 7123
        },
        {
            "transformers.utils.dummy_pt_objects.ViltModel.__init__": 7130
        },
        {
            "transformers.utils.dummy_pt_objects.ViltPreTrainedModel.__init__": 7137
        },
        {
            "transformers.utils.dummy_pt_objects.VisionEncoderDecoderModel.__init__": 7144
        },
        {
            "transformers.utils.dummy_pt_objects.VisionTextDualEncoderModel.__init__": 7151
        },
        {
            "transformers.utils.dummy_pt_objects.VisualBertForMultipleChoice.__init__": 7161
        },
        {
            "transformers.utils.dummy_pt_objects.VisualBertForPreTraining.__init__": 7168
        },
        {
            "transformers.utils.dummy_pt_objects.VisualBertForQuestionAnswering.__init__": 7175
        },
        {
            "transformers.utils.dummy_pt_objects.VisualBertForRegionToPhraseAlignment.__init__": 7182
        },
        {
            "transformers.utils.dummy_pt_objects.VisualBertForVisualReasoning.__init__": 7189
        },
        {
            "transformers.utils.dummy_pt_objects.VisualBertLayer.__init__": 7196
        },
        {
            "transformers.utils.dummy_pt_objects.VisualBertModel.__init__": 7203
        },
        {
            "transformers.utils.dummy_pt_objects.VisualBertPreTrainedModel.__init__": 7210
        },
        {
            "transformers.utils.dummy_pt_objects.ViTForImageClassification.__init__": 7220
        },
        {
            "transformers.utils.dummy_pt_objects.ViTForMaskedImageModeling.__init__": 7227
        },
        {
            "transformers.utils.dummy_pt_objects.ViTModel.__init__": 7234
        },
        {
            "transformers.utils.dummy_pt_objects.ViTPreTrainedModel.__init__": 7241
        },
        {
            "transformers.utils.dummy_pt_objects.ViTHybridForImageClassification.__init__": 7251
        },
        {
            "transformers.utils.dummy_pt_objects.ViTHybridModel.__init__": 7258
        },
        {
            "transformers.utils.dummy_pt_objects.ViTHybridPreTrainedModel.__init__": 7265
        },
        {
            "transformers.utils.dummy_pt_objects.ViTMAEForPreTraining.__init__": 7275
        },
        {
            "transformers.utils.dummy_pt_objects.ViTMAELayer.__init__": 7282
        },
        {
            "transformers.utils.dummy_pt_objects.ViTMAEModel.__init__": 7289
        },
        {
            "transformers.utils.dummy_pt_objects.ViTMAEPreTrainedModel.__init__": 7296
        },
        {
            "transformers.utils.dummy_pt_objects.ViTMSNForImageClassification.__init__": 7306
        },
        {
            "transformers.utils.dummy_pt_objects.ViTMSNModel.__init__": 7313
        },
        {
            "transformers.utils.dummy_pt_objects.ViTMSNPreTrainedModel.__init__": 7320
        },
        {
            "transformers.utils.dummy_pt_objects.Wav2Vec2ForAudioFrameClassification.__init__": 7330
        },
        {
            "transformers.utils.dummy_pt_objects.Wav2Vec2ForCTC.__init__": 7337
        },
        {
            "transformers.utils.dummy_pt_objects.Wav2Vec2ForMaskedLM.__init__": 7344
        },
        {
            "transformers.utils.dummy_pt_objects.Wav2Vec2ForPreTraining.__init__": 7351
        },
        {
            "transformers.utils.dummy_pt_objects.Wav2Vec2ForSequenceClassification.__init__": 7358
        },
        {
            "transformers.utils.dummy_pt_objects.Wav2Vec2ForXVector.__init__": 7365
        },
        {
            "transformers.utils.dummy_pt_objects.Wav2Vec2Model.__init__": 7372
        },
        {
            "transformers.utils.dummy_pt_objects.Wav2Vec2PreTrainedModel.__init__": 7379
        },
        {
            "transformers.utils.dummy_pt_objects.Wav2Vec2ConformerForAudioFrameClassification.__init__": 7389
        },
        {
            "transformers.utils.dummy_pt_objects.Wav2Vec2ConformerForCTC.__init__": 7396
        },
        {
            "transformers.utils.dummy_pt_objects.Wav2Vec2ConformerForPreTraining.__init__": 7403
        },
        {
            "transformers.utils.dummy_pt_objects.Wav2Vec2ConformerForSequenceClassification.__init__": 7410
        },
        {
            "transformers.utils.dummy_pt_objects.Wav2Vec2ConformerForXVector.__init__": 7417
        },
        {
            "transformers.utils.dummy_pt_objects.Wav2Vec2ConformerModel.__init__": 7424
        },
        {
            "transformers.utils.dummy_pt_objects.Wav2Vec2ConformerPreTrainedModel.__init__": 7431
        },
        {
            "transformers.utils.dummy_pt_objects.WavLMForAudioFrameClassification.__init__": 7441
        },
        {
            "transformers.utils.dummy_pt_objects.WavLMForCTC.__init__": 7448
        },
        {
            "transformers.utils.dummy_pt_objects.WavLMForSequenceClassification.__init__": 7455
        },
        {
            "transformers.utils.dummy_pt_objects.WavLMForXVector.__init__": 7462
        },
        {
            "transformers.utils.dummy_pt_objects.WavLMModel.__init__": 7469
        },
        {
            "transformers.utils.dummy_pt_objects.WavLMPreTrainedModel.__init__": 7476
        },
        {
            "transformers.utils.dummy_pt_objects.WhisperForAudioClassification.__init__": 7486
        },
        {
            "transformers.utils.dummy_pt_objects.WhisperForConditionalGeneration.__init__": 7493
        },
        {
            "transformers.utils.dummy_pt_objects.WhisperModel.__init__": 7500
        },
        {
            "transformers.utils.dummy_pt_objects.WhisperPreTrainedModel.__init__": 7507
        },
        {
            "transformers.utils.dummy_pt_objects.XCLIPModel.__init__": 7517
        },
        {
            "transformers.utils.dummy_pt_objects.XCLIPPreTrainedModel.__init__": 7524
        },
        {
            "transformers.utils.dummy_pt_objects.XCLIPTextModel.__init__": 7531
        },
        {
            "transformers.utils.dummy_pt_objects.XCLIPVisionModel.__init__": 7538
        },
        {
            "transformers.utils.dummy_pt_objects.XGLMForCausalLM.__init__": 7548
        },
        {
            "transformers.utils.dummy_pt_objects.XGLMModel.__init__": 7555
        },
        {
            "transformers.utils.dummy_pt_objects.XGLMPreTrainedModel.__init__": 7562
        },
        {
            "transformers.utils.dummy_pt_objects.XLMForMultipleChoice.__init__": 7572
        },
        {
            "transformers.utils.dummy_pt_objects.XLMForQuestionAnswering.__init__": 7579
        },
        {
            "transformers.utils.dummy_pt_objects.XLMForQuestionAnsweringSimple.__init__": 7586
        },
        {
            "transformers.utils.dummy_pt_objects.XLMForSequenceClassification.__init__": 7593
        },
        {
            "transformers.utils.dummy_pt_objects.XLMForTokenClassification.__init__": 7600
        },
        {
            "transformers.utils.dummy_pt_objects.XLMModel.__init__": 7607
        },
        {
            "transformers.utils.dummy_pt_objects.XLMPreTrainedModel.__init__": 7614
        },
        {
            "transformers.utils.dummy_pt_objects.XLMWithLMHeadModel.__init__": 7621
        },
        {
            "transformers.utils.dummy_pt_objects.XLMProphetNetDecoder.__init__": 7631
        },
        {
            "transformers.utils.dummy_pt_objects.XLMProphetNetEncoder.__init__": 7638
        },
        {
            "transformers.utils.dummy_pt_objects.XLMProphetNetForCausalLM.__init__": 7645
        },
        {
            "transformers.utils.dummy_pt_objects.XLMProphetNetForConditionalGeneration.__init__": 7652
        },
        {
            "transformers.utils.dummy_pt_objects.XLMProphetNetModel.__init__": 7659
        },
        {
            "transformers.utils.dummy_pt_objects.XLMProphetNetPreTrainedModel.__init__": 7666
        },
        {
            "transformers.utils.dummy_pt_objects.XLMRobertaForCausalLM.__init__": 7676
        },
        {
            "transformers.utils.dummy_pt_objects.XLMRobertaForMaskedLM.__init__": 7683
        },
        {
            "transformers.utils.dummy_pt_objects.XLMRobertaForMultipleChoice.__init__": 7690
        },
        {
            "transformers.utils.dummy_pt_objects.XLMRobertaForQuestionAnswering.__init__": 7697
        },
        {
            "transformers.utils.dummy_pt_objects.XLMRobertaForSequenceClassification.__init__": 7704
        },
        {
            "transformers.utils.dummy_pt_objects.XLMRobertaForTokenClassification.__init__": 7711
        },
        {
            "transformers.utils.dummy_pt_objects.XLMRobertaModel.__init__": 7718
        },
        {
            "transformers.utils.dummy_pt_objects.XLMRobertaPreTrainedModel.__init__": 7725
        },
        {
            "transformers.utils.dummy_pt_objects.XLMRobertaXLForCausalLM.__init__": 7735
        },
        {
            "transformers.utils.dummy_pt_objects.XLMRobertaXLForMaskedLM.__init__": 7742
        },
        {
            "transformers.utils.dummy_pt_objects.XLMRobertaXLForMultipleChoice.__init__": 7749
        },
        {
            "transformers.utils.dummy_pt_objects.XLMRobertaXLForQuestionAnswering.__init__": 7756
        },
        {
            "transformers.utils.dummy_pt_objects.XLMRobertaXLForSequenceClassification.__init__": 7763
        },
        {
            "transformers.utils.dummy_pt_objects.XLMRobertaXLForTokenClassification.__init__": 7770
        },
        {
            "transformers.utils.dummy_pt_objects.XLMRobertaXLModel.__init__": 7777
        },
        {
            "transformers.utils.dummy_pt_objects.XLMRobertaXLPreTrainedModel.__init__": 7784
        },
        {
            "transformers.utils.dummy_pt_objects.XLNetForMultipleChoice.__init__": 7794
        },
        {
            "transformers.utils.dummy_pt_objects.XLNetForQuestionAnswering.__init__": 7801
        },
        {
            "transformers.utils.dummy_pt_objects.XLNetForQuestionAnsweringSimple.__init__": 7808
        },
        {
            "transformers.utils.dummy_pt_objects.XLNetForSequenceClassification.__init__": 7815
        },
        {
            "transformers.utils.dummy_pt_objects.XLNetForTokenClassification.__init__": 7822
        },
        {
            "transformers.utils.dummy_pt_objects.XLNetLMHeadModel.__init__": 7829
        },
        {
            "transformers.utils.dummy_pt_objects.XLNetModel.__init__": 7836
        },
        {
            "transformers.utils.dummy_pt_objects.XLNetPreTrainedModel.__init__": 7843
        },
        {
            "transformers.utils.dummy_pt_objects.load_tf_weights_in_xlnet": 7847
        },
        {
            "transformers.utils.dummy_pt_objects.XmodForCausalLM.__init__": 7857
        },
        {
            "transformers.utils.dummy_pt_objects.XmodForMaskedLM.__init__": 7864
        },
        {
            "transformers.utils.dummy_pt_objects.XmodForMultipleChoice.__init__": 7871
        },
        {
            "transformers.utils.dummy_pt_objects.XmodForQuestionAnswering.__init__": 7878
        },
        {
            "transformers.utils.dummy_pt_objects.XmodForSequenceClassification.__init__": 7885
        },
        {
            "transformers.utils.dummy_pt_objects.XmodForTokenClassification.__init__": 7892
        },
        {
            "transformers.utils.dummy_pt_objects.XmodModel.__init__": 7899
        },
        {
            "transformers.utils.dummy_pt_objects.XmodPreTrainedModel.__init__": 7906
        },
        {
            "transformers.utils.dummy_pt_objects.YolosForObjectDetection.__init__": 7916
        },
        {
            "transformers.utils.dummy_pt_objects.YolosModel.__init__": 7923
        },
        {
            "transformers.utils.dummy_pt_objects.YolosPreTrainedModel.__init__": 7930
        },
        {
            "transformers.utils.dummy_pt_objects.YosoForMaskedLM.__init__": 7940
        },
        {
            "transformers.utils.dummy_pt_objects.YosoForMultipleChoice.__init__": 7947
        },
        {
            "transformers.utils.dummy_pt_objects.YosoForQuestionAnswering.__init__": 7954
        },
        {
            "transformers.utils.dummy_pt_objects.YosoForSequenceClassification.__init__": 7961
        },
        {
            "transformers.utils.dummy_pt_objects.YosoForTokenClassification.__init__": 7968
        },
        {
            "transformers.utils.dummy_pt_objects.YosoLayer.__init__": 7975
        },
        {
            "transformers.utils.dummy_pt_objects.YosoModel.__init__": 7982
        },
        {
            "transformers.utils.dummy_pt_objects.YosoPreTrainedModel.__init__": 7989
        },
        {
            "transformers.utils.dummy_pt_objects.Adafactor.__init__": 7996
        },
        {
            "transformers.utils.dummy_pt_objects.AdamW.__init__": 8003
        },
        {
            "transformers.utils.dummy_pt_objects.get_constant_schedule": 8007
        },
        {
            "transformers.utils.dummy_pt_objects.get_constant_schedule_with_warmup": 8011
        },
        {
            "transformers.utils.dummy_pt_objects.get_cosine_schedule_with_warmup": 8015
        },
        {
            "transformers.utils.dummy_pt_objects.get_cosine_with_hard_restarts_schedule_with_warmup": 8019
        },
        {
            "transformers.utils.dummy_pt_objects.get_inverse_sqrt_schedule": 8023
        },
        {
            "transformers.utils.dummy_pt_objects.get_linear_schedule_with_warmup": 8027
        },
        {
            "transformers.utils.dummy_pt_objects.get_polynomial_decay_schedule_with_warmup": 8031
        },
        {
            "transformers.utils.dummy_pt_objects.get_scheduler": 8035
        },
        {
            "transformers.utils.dummy_pt_objects.Conv1D.__init__": 8042
        },
        {
            "transformers.utils.dummy_pt_objects.apply_chunking_to_forward": 8046
        },
        {
            "transformers.utils.dummy_pt_objects.prune_layer": 8050
        },
        {
            "transformers.utils.dummy_pt_objects.Trainer.__init__": 8057
        },
        {
            "transformers.utils.dummy_pt_objects.torch_distributed_zero_first": 8061
        },
        {
            "transformers.utils.dummy_pt_objects.Seq2SeqTrainer.__init__": 8068
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/utils/import_utils.py": [
        {
            "transformers.utils.import_utils.wrapper": 662
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/utils/generic.py": [
        {
            "transformers.utils.generic.ModelOutput.__delitem__": 303
        },
        {
            "transformers.utils.generic.ModelOutput.setdefault": 306
        },
        {
            "transformers.utils.generic.ModelOutput.pop": 309
        },
        {
            "transformers.utils.generic.ModelOutput.update": 312
        },
        {
            "transformers.utils.generic.ContextManagers.__exit__": 390
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/utils/dummy_vision_objects.py": [
        {
            "transformers.utils.dummy_vision_objects.ImageProcessingMixin.__init__": 8
        },
        {
            "transformers.utils.dummy_vision_objects.ImageFeatureExtractionMixin.__init__": 15
        },
        {
            "transformers.utils.dummy_vision_objects.BeitFeatureExtractor.__init__": 22
        },
        {
            "transformers.utils.dummy_vision_objects.BeitImageProcessor.__init__": 29
        },
        {
            "transformers.utils.dummy_vision_objects.BitImageProcessor.__init__": 36
        },
        {
            "transformers.utils.dummy_vision_objects.BlipImageProcessor.__init__": 43
        },
        {
            "transformers.utils.dummy_vision_objects.BridgeTowerImageProcessor.__init__": 50
        },
        {
            "transformers.utils.dummy_vision_objects.ChineseCLIPFeatureExtractor.__init__": 57
        },
        {
            "transformers.utils.dummy_vision_objects.ChineseCLIPImageProcessor.__init__": 64
        },
        {
            "transformers.utils.dummy_vision_objects.CLIPFeatureExtractor.__init__": 71
        },
        {
            "transformers.utils.dummy_vision_objects.CLIPImageProcessor.__init__": 78
        },
        {
            "transformers.utils.dummy_vision_objects.ConditionalDetrFeatureExtractor.__init__": 85
        },
        {
            "transformers.utils.dummy_vision_objects.ConditionalDetrImageProcessor.__init__": 92
        },
        {
            "transformers.utils.dummy_vision_objects.ConvNextFeatureExtractor.__init__": 99
        },
        {
            "transformers.utils.dummy_vision_objects.ConvNextImageProcessor.__init__": 106
        },
        {
            "transformers.utils.dummy_vision_objects.DeformableDetrFeatureExtractor.__init__": 113
        },
        {
            "transformers.utils.dummy_vision_objects.DeformableDetrImageProcessor.__init__": 120
        },
        {
            "transformers.utils.dummy_vision_objects.DeiTFeatureExtractor.__init__": 127
        },
        {
            "transformers.utils.dummy_vision_objects.DeiTImageProcessor.__init__": 134
        },
        {
            "transformers.utils.dummy_vision_objects.DetaImageProcessor.__init__": 141
        },
        {
            "transformers.utils.dummy_vision_objects.DetrFeatureExtractor.__init__": 148
        },
        {
            "transformers.utils.dummy_vision_objects.DetrImageProcessor.__init__": 155
        },
        {
            "transformers.utils.dummy_vision_objects.DonutFeatureExtractor.__init__": 162
        },
        {
            "transformers.utils.dummy_vision_objects.DonutImageProcessor.__init__": 169
        },
        {
            "transformers.utils.dummy_vision_objects.DPTFeatureExtractor.__init__": 176
        },
        {
            "transformers.utils.dummy_vision_objects.DPTImageProcessor.__init__": 183
        },
        {
            "transformers.utils.dummy_vision_objects.EfficientFormerImageProcessor.__init__": 190
        },
        {
            "transformers.utils.dummy_vision_objects.EfficientNetImageProcessor.__init__": 197
        },
        {
            "transformers.utils.dummy_vision_objects.FlavaFeatureExtractor.__init__": 204
        },
        {
            "transformers.utils.dummy_vision_objects.FlavaImageProcessor.__init__": 211
        },
        {
            "transformers.utils.dummy_vision_objects.FlavaProcessor.__init__": 218
        },
        {
            "transformers.utils.dummy_vision_objects.GLPNFeatureExtractor.__init__": 225
        },
        {
            "transformers.utils.dummy_vision_objects.GLPNImageProcessor.__init__": 232
        },
        {
            "transformers.utils.dummy_vision_objects.ImageGPTFeatureExtractor.__init__": 239
        },
        {
            "transformers.utils.dummy_vision_objects.ImageGPTImageProcessor.__init__": 246
        },
        {
            "transformers.utils.dummy_vision_objects.LayoutLMv2FeatureExtractor.__init__": 253
        },
        {
            "transformers.utils.dummy_vision_objects.LayoutLMv2ImageProcessor.__init__": 260
        },
        {
            "transformers.utils.dummy_vision_objects.LayoutLMv3FeatureExtractor.__init__": 267
        },
        {
            "transformers.utils.dummy_vision_objects.LayoutLMv3ImageProcessor.__init__": 274
        },
        {
            "transformers.utils.dummy_vision_objects.LevitFeatureExtractor.__init__": 281
        },
        {
            "transformers.utils.dummy_vision_objects.LevitImageProcessor.__init__": 288
        },
        {
            "transformers.utils.dummy_vision_objects.Mask2FormerImageProcessor.__init__": 295
        },
        {
            "transformers.utils.dummy_vision_objects.MaskFormerFeatureExtractor.__init__": 302
        },
        {
            "transformers.utils.dummy_vision_objects.MaskFormerImageProcessor.__init__": 309
        },
        {
            "transformers.utils.dummy_vision_objects.MobileNetV1FeatureExtractor.__init__": 316
        },
        {
            "transformers.utils.dummy_vision_objects.MobileNetV1ImageProcessor.__init__": 323
        },
        {
            "transformers.utils.dummy_vision_objects.MobileNetV2FeatureExtractor.__init__": 330
        },
        {
            "transformers.utils.dummy_vision_objects.MobileNetV2ImageProcessor.__init__": 337
        },
        {
            "transformers.utils.dummy_vision_objects.MobileViTFeatureExtractor.__init__": 344
        },
        {
            "transformers.utils.dummy_vision_objects.MobileViTImageProcessor.__init__": 351
        },
        {
            "transformers.utils.dummy_vision_objects.OneFormerImageProcessor.__init__": 358
        },
        {
            "transformers.utils.dummy_vision_objects.OwlViTFeatureExtractor.__init__": 365
        },
        {
            "transformers.utils.dummy_vision_objects.OwlViTImageProcessor.__init__": 372
        },
        {
            "transformers.utils.dummy_vision_objects.PerceiverFeatureExtractor.__init__": 379
        },
        {
            "transformers.utils.dummy_vision_objects.PerceiverImageProcessor.__init__": 386
        },
        {
            "transformers.utils.dummy_vision_objects.Pix2StructImageProcessor.__init__": 393
        },
        {
            "transformers.utils.dummy_vision_objects.PoolFormerFeatureExtractor.__init__": 400
        },
        {
            "transformers.utils.dummy_vision_objects.PoolFormerImageProcessor.__init__": 407
        },
        {
            "transformers.utils.dummy_vision_objects.SamImageProcessor.__init__": 414
        },
        {
            "transformers.utils.dummy_vision_objects.SegformerFeatureExtractor.__init__": 421
        },
        {
            "transformers.utils.dummy_vision_objects.SegformerImageProcessor.__init__": 428
        },
        {
            "transformers.utils.dummy_vision_objects.Swin2SRImageProcessor.__init__": 435
        },
        {
            "transformers.utils.dummy_vision_objects.TvltImageProcessor.__init__": 442
        },
        {
            "transformers.utils.dummy_vision_objects.VideoMAEFeatureExtractor.__init__": 449
        },
        {
            "transformers.utils.dummy_vision_objects.VideoMAEImageProcessor.__init__": 456
        },
        {
            "transformers.utils.dummy_vision_objects.ViltFeatureExtractor.__init__": 463
        },
        {
            "transformers.utils.dummy_vision_objects.ViltImageProcessor.__init__": 470
        },
        {
            "transformers.utils.dummy_vision_objects.ViltProcessor.__init__": 477
        },
        {
            "transformers.utils.dummy_vision_objects.ViTFeatureExtractor.__init__": 484
        },
        {
            "transformers.utils.dummy_vision_objects.ViTImageProcessor.__init__": 491
        },
        {
            "transformers.utils.dummy_vision_objects.ViTHybridImageProcessor.__init__": 498
        },
        {
            "transformers.utils.dummy_vision_objects.YolosFeatureExtractor.__init__": 505
        },
        {
            "transformers.utils.dummy_vision_objects.YolosImageProcessor.__init__": 512
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/utils/backbone_utils.py": [
        {
            "transformers.utils.backbone_utils.BackboneMixin.forward_with_filtered_kwargs": 207
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/utils/quantization_config.py": [
        {
            "transformers.utils.quantization_config.BitsAndBytesConfig.__init__": 87
        },
        {
            "transformers.utils.quantization_config.BitsAndBytesConfig.from_dict": 172
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/utils/dummy_tf_objects.py": [
        {
            "transformers.utils.dummy_tf_objects.TensorFlowBenchmarkArguments.__init__": 8
        },
        {
            "transformers.utils.dummy_tf_objects.TensorFlowBenchmark.__init__": 15
        },
        {
            "transformers.utils.dummy_tf_objects.TFForcedBOSTokenLogitsProcessor.__init__": 22
        },
        {
            "transformers.utils.dummy_tf_objects.TFForcedEOSTokenLogitsProcessor.__init__": 29
        },
        {
            "transformers.utils.dummy_tf_objects.TFGenerationMixin.__init__": 36
        },
        {
            "transformers.utils.dummy_tf_objects.TFLogitsProcessor.__init__": 43
        },
        {
            "transformers.utils.dummy_tf_objects.TFLogitsProcessorList.__init__": 50
        },
        {
            "transformers.utils.dummy_tf_objects.TFLogitsWarper.__init__": 57
        },
        {
            "transformers.utils.dummy_tf_objects.TFMinLengthLogitsProcessor.__init__": 64
        },
        {
            "transformers.utils.dummy_tf_objects.TFNoBadWordsLogitsProcessor.__init__": 71
        },
        {
            "transformers.utils.dummy_tf_objects.TFNoRepeatNGramLogitsProcessor.__init__": 78
        },
        {
            "transformers.utils.dummy_tf_objects.TFRepetitionPenaltyLogitsProcessor.__init__": 85
        },
        {
            "transformers.utils.dummy_tf_objects.TFTemperatureLogitsWarper.__init__": 92
        },
        {
            "transformers.utils.dummy_tf_objects.TFTopKLogitsWarper.__init__": 99
        },
        {
            "transformers.utils.dummy_tf_objects.TFTopPLogitsWarper.__init__": 106
        },
        {
            "transformers.utils.dummy_tf_objects.tf_top_k_top_p_filtering": 110
        },
        {
            "transformers.utils.dummy_tf_objects.KerasMetricCallback.__init__": 117
        },
        {
            "transformers.utils.dummy_tf_objects.PushToHubCallback.__init__": 124
        },
        {
            "transformers.utils.dummy_tf_objects.TFPreTrainedModel.__init__": 131
        },
        {
            "transformers.utils.dummy_tf_objects.TFSequenceSummary.__init__": 138
        },
        {
            "transformers.utils.dummy_tf_objects.TFSharedEmbeddings.__init__": 145
        },
        {
            "transformers.utils.dummy_tf_objects.shape_list": 149
        },
        {
            "transformers.utils.dummy_tf_objects.TFAlbertForMaskedLM.__init__": 159
        },
        {
            "transformers.utils.dummy_tf_objects.TFAlbertForMultipleChoice.__init__": 166
        },
        {
            "transformers.utils.dummy_tf_objects.TFAlbertForPreTraining.__init__": 173
        },
        {
            "transformers.utils.dummy_tf_objects.TFAlbertForQuestionAnswering.__init__": 180
        },
        {
            "transformers.utils.dummy_tf_objects.TFAlbertForSequenceClassification.__init__": 187
        },
        {
            "transformers.utils.dummy_tf_objects.TFAlbertForTokenClassification.__init__": 194
        },
        {
            "transformers.utils.dummy_tf_objects.TFAlbertMainLayer.__init__": 201
        },
        {
            "transformers.utils.dummy_tf_objects.TFAlbertModel.__init__": 208
        },
        {
            "transformers.utils.dummy_tf_objects.TFAlbertPreTrainedModel.__init__": 215
        },
        {
            "transformers.utils.dummy_tf_objects.TFAutoModel.__init__": 279
        },
        {
            "transformers.utils.dummy_tf_objects.TFAutoModelForCausalLM.__init__": 286
        },
        {
            "transformers.utils.dummy_tf_objects.TFAutoModelForDocumentQuestionAnswering.__init__": 293
        },
        {
            "transformers.utils.dummy_tf_objects.TFAutoModelForImageClassification.__init__": 300
        },
        {
            "transformers.utils.dummy_tf_objects.TFAutoModelForMaskedLM.__init__": 307
        },
        {
            "transformers.utils.dummy_tf_objects.TFAutoModelForMultipleChoice.__init__": 314
        },
        {
            "transformers.utils.dummy_tf_objects.TFAutoModelForNextSentencePrediction.__init__": 321
        },
        {
            "transformers.utils.dummy_tf_objects.TFAutoModelForPreTraining.__init__": 328
        },
        {
            "transformers.utils.dummy_tf_objects.TFAutoModelForQuestionAnswering.__init__": 335
        },
        {
            "transformers.utils.dummy_tf_objects.TFAutoModelForSemanticSegmentation.__init__": 342
        },
        {
            "transformers.utils.dummy_tf_objects.TFAutoModelForSeq2SeqLM.__init__": 349
        },
        {
            "transformers.utils.dummy_tf_objects.TFAutoModelForSequenceClassification.__init__": 356
        },
        {
            "transformers.utils.dummy_tf_objects.TFAutoModelForSpeechSeq2Seq.__init__": 363
        },
        {
            "transformers.utils.dummy_tf_objects.TFAutoModelForTableQuestionAnswering.__init__": 370
        },
        {
            "transformers.utils.dummy_tf_objects.TFAutoModelForTokenClassification.__init__": 377
        },
        {
            "transformers.utils.dummy_tf_objects.TFAutoModelForVision2Seq.__init__": 384
        },
        {
            "transformers.utils.dummy_tf_objects.TFAutoModelForZeroShotImageClassification.__init__": 391
        },
        {
            "transformers.utils.dummy_tf_objects.TFAutoModelWithLMHead.__init__": 398
        },
        {
            "transformers.utils.dummy_tf_objects.TFBartForConditionalGeneration.__init__": 405
        },
        {
            "transformers.utils.dummy_tf_objects.TFBartForSequenceClassification.__init__": 412
        },
        {
            "transformers.utils.dummy_tf_objects.TFBartModel.__init__": 419
        },
        {
            "transformers.utils.dummy_tf_objects.TFBartPretrainedModel.__init__": 426
        },
        {
            "transformers.utils.dummy_tf_objects.TFBertEmbeddings.__init__": 436
        },
        {
            "transformers.utils.dummy_tf_objects.TFBertForMaskedLM.__init__": 443
        },
        {
            "transformers.utils.dummy_tf_objects.TFBertForMultipleChoice.__init__": 450
        },
        {
            "transformers.utils.dummy_tf_objects.TFBertForNextSentencePrediction.__init__": 457
        },
        {
            "transformers.utils.dummy_tf_objects.TFBertForPreTraining.__init__": 464
        },
        {
            "transformers.utils.dummy_tf_objects.TFBertForQuestionAnswering.__init__": 471
        },
        {
            "transformers.utils.dummy_tf_objects.TFBertForSequenceClassification.__init__": 478
        },
        {
            "transformers.utils.dummy_tf_objects.TFBertForTokenClassification.__init__": 485
        },
        {
            "transformers.utils.dummy_tf_objects.TFBertLMHeadModel.__init__": 492
        },
        {
            "transformers.utils.dummy_tf_objects.TFBertMainLayer.__init__": 499
        },
        {
            "transformers.utils.dummy_tf_objects.TFBertModel.__init__": 506
        },
        {
            "transformers.utils.dummy_tf_objects.TFBertPreTrainedModel.__init__": 513
        },
        {
            "transformers.utils.dummy_tf_objects.TFBlenderbotForConditionalGeneration.__init__": 520
        },
        {
            "transformers.utils.dummy_tf_objects.TFBlenderbotModel.__init__": 527
        },
        {
            "transformers.utils.dummy_tf_objects.TFBlenderbotPreTrainedModel.__init__": 534
        },
        {
            "transformers.utils.dummy_tf_objects.TFBlenderbotSmallForConditionalGeneration.__init__": 541
        },
        {
            "transformers.utils.dummy_tf_objects.TFBlenderbotSmallModel.__init__": 548
        },
        {
            "transformers.utils.dummy_tf_objects.TFBlenderbotSmallPreTrainedModel.__init__": 555
        },
        {
            "transformers.utils.dummy_tf_objects.TFBlipForConditionalGeneration.__init__": 565
        },
        {
            "transformers.utils.dummy_tf_objects.TFBlipForImageTextRetrieval.__init__": 572
        },
        {
            "transformers.utils.dummy_tf_objects.TFBlipForQuestionAnswering.__init__": 579
        },
        {
            "transformers.utils.dummy_tf_objects.TFBlipModel.__init__": 586
        },
        {
            "transformers.utils.dummy_tf_objects.TFBlipPreTrainedModel.__init__": 593
        },
        {
            "transformers.utils.dummy_tf_objects.TFBlipTextModel.__init__": 600
        },
        {
            "transformers.utils.dummy_tf_objects.TFBlipVisionModel.__init__": 607
        },
        {
            "transformers.utils.dummy_tf_objects.TFCamembertForCausalLM.__init__": 617
        },
        {
            "transformers.utils.dummy_tf_objects.TFCamembertForMaskedLM.__init__": 624
        },
        {
            "transformers.utils.dummy_tf_objects.TFCamembertForMultipleChoice.__init__": 631
        },
        {
            "transformers.utils.dummy_tf_objects.TFCamembertForQuestionAnswering.__init__": 638
        },
        {
            "transformers.utils.dummy_tf_objects.TFCamembertForSequenceClassification.__init__": 645
        },
        {
            "transformers.utils.dummy_tf_objects.TFCamembertForTokenClassification.__init__": 652
        },
        {
            "transformers.utils.dummy_tf_objects.TFCamembertModel.__init__": 659
        },
        {
            "transformers.utils.dummy_tf_objects.TFCamembertPreTrainedModel.__init__": 666
        },
        {
            "transformers.utils.dummy_tf_objects.TFCLIPModel.__init__": 676
        },
        {
            "transformers.utils.dummy_tf_objects.TFCLIPPreTrainedModel.__init__": 683
        },
        {
            "transformers.utils.dummy_tf_objects.TFCLIPTextModel.__init__": 690
        },
        {
            "transformers.utils.dummy_tf_objects.TFCLIPVisionModel.__init__": 697
        },
        {
            "transformers.utils.dummy_tf_objects.TFConvBertForMaskedLM.__init__": 707
        },
        {
            "transformers.utils.dummy_tf_objects.TFConvBertForMultipleChoice.__init__": 714
        },
        {
            "transformers.utils.dummy_tf_objects.TFConvBertForQuestionAnswering.__init__": 721
        },
        {
            "transformers.utils.dummy_tf_objects.TFConvBertForSequenceClassification.__init__": 728
        },
        {
            "transformers.utils.dummy_tf_objects.TFConvBertForTokenClassification.__init__": 735
        },
        {
            "transformers.utils.dummy_tf_objects.TFConvBertLayer.__init__": 742
        },
        {
            "transformers.utils.dummy_tf_objects.TFConvBertModel.__init__": 749
        },
        {
            "transformers.utils.dummy_tf_objects.TFConvBertPreTrainedModel.__init__": 756
        },
        {
            "transformers.utils.dummy_tf_objects.TFConvNextForImageClassification.__init__": 763
        },
        {
            "transformers.utils.dummy_tf_objects.TFConvNextModel.__init__": 770
        },
        {
            "transformers.utils.dummy_tf_objects.TFConvNextPreTrainedModel.__init__": 777
        },
        {
            "transformers.utils.dummy_tf_objects.TFCTRLForSequenceClassification.__init__": 787
        },
        {
            "transformers.utils.dummy_tf_objects.TFCTRLLMHeadModel.__init__": 794
        },
        {
            "transformers.utils.dummy_tf_objects.TFCTRLModel.__init__": 801
        },
        {
            "transformers.utils.dummy_tf_objects.TFCTRLPreTrainedModel.__init__": 808
        },
        {
            "transformers.utils.dummy_tf_objects.TFCvtForImageClassification.__init__": 818
        },
        {
            "transformers.utils.dummy_tf_objects.TFCvtModel.__init__": 825
        },
        {
            "transformers.utils.dummy_tf_objects.TFCvtPreTrainedModel.__init__": 832
        },
        {
            "transformers.utils.dummy_tf_objects.TFData2VecVisionForImageClassification.__init__": 839
        },
        {
            "transformers.utils.dummy_tf_objects.TFData2VecVisionForSemanticSegmentation.__init__": 846
        },
        {
            "transformers.utils.dummy_tf_objects.TFData2VecVisionModel.__init__": 853
        },
        {
            "transformers.utils.dummy_tf_objects.TFData2VecVisionPreTrainedModel.__init__": 860
        },
        {
            "transformers.utils.dummy_tf_objects.TFDebertaForMaskedLM.__init__": 870
        },
        {
            "transformers.utils.dummy_tf_objects.TFDebertaForQuestionAnswering.__init__": 877
        },
        {
            "transformers.utils.dummy_tf_objects.TFDebertaForSequenceClassification.__init__": 884
        },
        {
            "transformers.utils.dummy_tf_objects.TFDebertaForTokenClassification.__init__": 891
        },
        {
            "transformers.utils.dummy_tf_objects.TFDebertaModel.__init__": 898
        },
        {
            "transformers.utils.dummy_tf_objects.TFDebertaPreTrainedModel.__init__": 905
        },
        {
            "transformers.utils.dummy_tf_objects.TFDebertaV2ForMaskedLM.__init__": 915
        },
        {
            "transformers.utils.dummy_tf_objects.TFDebertaV2ForQuestionAnswering.__init__": 922
        },
        {
            "transformers.utils.dummy_tf_objects.TFDebertaV2ForSequenceClassification.__init__": 929
        },
        {
            "transformers.utils.dummy_tf_objects.TFDebertaV2ForTokenClassification.__init__": 936
        },
        {
            "transformers.utils.dummy_tf_objects.TFDebertaV2Model.__init__": 943
        },
        {
            "transformers.utils.dummy_tf_objects.TFDebertaV2PreTrainedModel.__init__": 950
        },
        {
            "transformers.utils.dummy_tf_objects.TFDeiTForImageClassification.__init__": 960
        },
        {
            "transformers.utils.dummy_tf_objects.TFDeiTForImageClassificationWithTeacher.__init__": 967
        },
        {
            "transformers.utils.dummy_tf_objects.TFDeiTForMaskedImageModeling.__init__": 974
        },
        {
            "transformers.utils.dummy_tf_objects.TFDeiTModel.__init__": 981
        },
        {
            "transformers.utils.dummy_tf_objects.TFDeiTPreTrainedModel.__init__": 988
        },
        {
            "transformers.utils.dummy_tf_objects.TFDistilBertForMaskedLM.__init__": 998
        },
        {
            "transformers.utils.dummy_tf_objects.TFDistilBertForMultipleChoice.__init__": 1005
        },
        {
            "transformers.utils.dummy_tf_objects.TFDistilBertForQuestionAnswering.__init__": 1012
        },
        {
            "transformers.utils.dummy_tf_objects.TFDistilBertForSequenceClassification.__init__": 1019
        },
        {
            "transformers.utils.dummy_tf_objects.TFDistilBertForTokenClassification.__init__": 1026
        },
        {
            "transformers.utils.dummy_tf_objects.TFDistilBertMainLayer.__init__": 1033
        },
        {
            "transformers.utils.dummy_tf_objects.TFDistilBertModel.__init__": 1040
        },
        {
            "transformers.utils.dummy_tf_objects.TFDistilBertPreTrainedModel.__init__": 1047
        },
        {
            "transformers.utils.dummy_tf_objects.TFDPRContextEncoder.__init__": 1063
        },
        {
            "transformers.utils.dummy_tf_objects.TFDPRPretrainedContextEncoder.__init__": 1070
        },
        {
            "transformers.utils.dummy_tf_objects.TFDPRPretrainedQuestionEncoder.__init__": 1077
        },
        {
            "transformers.utils.dummy_tf_objects.TFDPRPretrainedReader.__init__": 1084
        },
        {
            "transformers.utils.dummy_tf_objects.TFDPRQuestionEncoder.__init__": 1091
        },
        {
            "transformers.utils.dummy_tf_objects.TFDPRReader.__init__": 1098
        },
        {
            "transformers.utils.dummy_tf_objects.TFEfficientFormerForImageClassification.__init__": 1108
        },
        {
            "transformers.utils.dummy_tf_objects.TFEfficientFormerForImageClassificationWithTeacher.__init__": 1115
        },
        {
            "transformers.utils.dummy_tf_objects.TFEfficientFormerModel.__init__": 1122
        },
        {
            "transformers.utils.dummy_tf_objects.TFEfficientFormerPreTrainedModel.__init__": 1129
        },
        {
            "transformers.utils.dummy_tf_objects.TFElectraForMaskedLM.__init__": 1139
        },
        {
            "transformers.utils.dummy_tf_objects.TFElectraForMultipleChoice.__init__": 1146
        },
        {
            "transformers.utils.dummy_tf_objects.TFElectraForPreTraining.__init__": 1153
        },
        {
            "transformers.utils.dummy_tf_objects.TFElectraForQuestionAnswering.__init__": 1160
        },
        {
            "transformers.utils.dummy_tf_objects.TFElectraForSequenceClassification.__init__": 1167
        },
        {
            "transformers.utils.dummy_tf_objects.TFElectraForTokenClassification.__init__": 1174
        },
        {
            "transformers.utils.dummy_tf_objects.TFElectraModel.__init__": 1181
        },
        {
            "transformers.utils.dummy_tf_objects.TFElectraPreTrainedModel.__init__": 1188
        },
        {
            "transformers.utils.dummy_tf_objects.TFEncoderDecoderModel.__init__": 1195
        },
        {
            "transformers.utils.dummy_tf_objects.TFEsmForMaskedLM.__init__": 1205
        },
        {
            "transformers.utils.dummy_tf_objects.TFEsmForSequenceClassification.__init__": 1212
        },
        {
            "transformers.utils.dummy_tf_objects.TFEsmForTokenClassification.__init__": 1219
        },
        {
            "transformers.utils.dummy_tf_objects.TFEsmModel.__init__": 1226
        },
        {
            "transformers.utils.dummy_tf_objects.TFEsmPreTrainedModel.__init__": 1233
        },
        {
            "transformers.utils.dummy_tf_objects.TFFlaubertForMultipleChoice.__init__": 1243
        },
        {
            "transformers.utils.dummy_tf_objects.TFFlaubertForQuestionAnsweringSimple.__init__": 1250
        },
        {
            "transformers.utils.dummy_tf_objects.TFFlaubertForSequenceClassification.__init__": 1257
        },
        {
            "transformers.utils.dummy_tf_objects.TFFlaubertForTokenClassification.__init__": 1264
        },
        {
            "transformers.utils.dummy_tf_objects.TFFlaubertModel.__init__": 1271
        },
        {
            "transformers.utils.dummy_tf_objects.TFFlaubertPreTrainedModel.__init__": 1278
        },
        {
            "transformers.utils.dummy_tf_objects.TFFlaubertWithLMHeadModel.__init__": 1285
        },
        {
            "transformers.utils.dummy_tf_objects.TFFunnelBaseModel.__init__": 1295
        },
        {
            "transformers.utils.dummy_tf_objects.TFFunnelForMaskedLM.__init__": 1302
        },
        {
            "transformers.utils.dummy_tf_objects.TFFunnelForMultipleChoice.__init__": 1309
        },
        {
            "transformers.utils.dummy_tf_objects.TFFunnelForPreTraining.__init__": 1316
        },
        {
            "transformers.utils.dummy_tf_objects.TFFunnelForQuestionAnswering.__init__": 1323
        },
        {
            "transformers.utils.dummy_tf_objects.TFFunnelForSequenceClassification.__init__": 1330
        },
        {
            "transformers.utils.dummy_tf_objects.TFFunnelForTokenClassification.__init__": 1337
        },
        {
            "transformers.utils.dummy_tf_objects.TFFunnelModel.__init__": 1344
        },
        {
            "transformers.utils.dummy_tf_objects.TFFunnelPreTrainedModel.__init__": 1351
        },
        {
            "transformers.utils.dummy_tf_objects.TFGPT2DoubleHeadsModel.__init__": 1361
        },
        {
            "transformers.utils.dummy_tf_objects.TFGPT2ForSequenceClassification.__init__": 1368
        },
        {
            "transformers.utils.dummy_tf_objects.TFGPT2LMHeadModel.__init__": 1375
        },
        {
            "transformers.utils.dummy_tf_objects.TFGPT2MainLayer.__init__": 1382
        },
        {
            "transformers.utils.dummy_tf_objects.TFGPT2Model.__init__": 1389
        },
        {
            "transformers.utils.dummy_tf_objects.TFGPT2PreTrainedModel.__init__": 1396
        },
        {
            "transformers.utils.dummy_tf_objects.TFGPTJForCausalLM.__init__": 1403
        },
        {
            "transformers.utils.dummy_tf_objects.TFGPTJForQuestionAnswering.__init__": 1410
        },
        {
            "transformers.utils.dummy_tf_objects.TFGPTJForSequenceClassification.__init__": 1417
        },
        {
            "transformers.utils.dummy_tf_objects.TFGPTJModel.__init__": 1424
        },
        {
            "transformers.utils.dummy_tf_objects.TFGPTJPreTrainedModel.__init__": 1431
        },
        {
            "transformers.utils.dummy_tf_objects.TFGroupViTModel.__init__": 1441
        },
        {
            "transformers.utils.dummy_tf_objects.TFGroupViTPreTrainedModel.__init__": 1448
        },
        {
            "transformers.utils.dummy_tf_objects.TFGroupViTTextModel.__init__": 1455
        },
        {
            "transformers.utils.dummy_tf_objects.TFGroupViTVisionModel.__init__": 1462
        },
        {
            "transformers.utils.dummy_tf_objects.TFHubertForCTC.__init__": 1472
        },
        {
            "transformers.utils.dummy_tf_objects.TFHubertModel.__init__": 1479
        },
        {
            "transformers.utils.dummy_tf_objects.TFHubertPreTrainedModel.__init__": 1486
        },
        {
            "transformers.utils.dummy_tf_objects.TFLayoutLMForMaskedLM.__init__": 1496
        },
        {
            "transformers.utils.dummy_tf_objects.TFLayoutLMForQuestionAnswering.__init__": 1503
        },
        {
            "transformers.utils.dummy_tf_objects.TFLayoutLMForSequenceClassification.__init__": 1510
        },
        {
            "transformers.utils.dummy_tf_objects.TFLayoutLMForTokenClassification.__init__": 1517
        },
        {
            "transformers.utils.dummy_tf_objects.TFLayoutLMMainLayer.__init__": 1524
        },
        {
            "transformers.utils.dummy_tf_objects.TFLayoutLMModel.__init__": 1531
        },
        {
            "transformers.utils.dummy_tf_objects.TFLayoutLMPreTrainedModel.__init__": 1538
        },
        {
            "transformers.utils.dummy_tf_objects.TFLayoutLMv3ForQuestionAnswering.__init__": 1548
        },
        {
            "transformers.utils.dummy_tf_objects.TFLayoutLMv3ForSequenceClassification.__init__": 1555
        },
        {
            "transformers.utils.dummy_tf_objects.TFLayoutLMv3ForTokenClassification.__init__": 1562
        },
        {
            "transformers.utils.dummy_tf_objects.TFLayoutLMv3Model.__init__": 1569
        },
        {
            "transformers.utils.dummy_tf_objects.TFLayoutLMv3PreTrainedModel.__init__": 1576
        },
        {
            "transformers.utils.dummy_tf_objects.TFLEDForConditionalGeneration.__init__": 1583
        },
        {
            "transformers.utils.dummy_tf_objects.TFLEDModel.__init__": 1590
        },
        {
            "transformers.utils.dummy_tf_objects.TFLEDPreTrainedModel.__init__": 1597
        },
        {
            "transformers.utils.dummy_tf_objects.TFLongformerForMaskedLM.__init__": 1607
        },
        {
            "transformers.utils.dummy_tf_objects.TFLongformerForMultipleChoice.__init__": 1614
        },
        {
            "transformers.utils.dummy_tf_objects.TFLongformerForQuestionAnswering.__init__": 1621
        },
        {
            "transformers.utils.dummy_tf_objects.TFLongformerForSequenceClassification.__init__": 1628
        },
        {
            "transformers.utils.dummy_tf_objects.TFLongformerForTokenClassification.__init__": 1635
        },
        {
            "transformers.utils.dummy_tf_objects.TFLongformerModel.__init__": 1642
        },
        {
            "transformers.utils.dummy_tf_objects.TFLongformerPreTrainedModel.__init__": 1649
        },
        {
            "transformers.utils.dummy_tf_objects.TFLongformerSelfAttention.__init__": 1656
        },
        {
            "transformers.utils.dummy_tf_objects.TFLxmertForPreTraining.__init__": 1666
        },
        {
            "transformers.utils.dummy_tf_objects.TFLxmertMainLayer.__init__": 1673
        },
        {
            "transformers.utils.dummy_tf_objects.TFLxmertModel.__init__": 1680
        },
        {
            "transformers.utils.dummy_tf_objects.TFLxmertPreTrainedModel.__init__": 1687
        },
        {
            "transformers.utils.dummy_tf_objects.TFLxmertVisualFeatureEncoder.__init__": 1694
        },
        {
            "transformers.utils.dummy_tf_objects.TFMarianModel.__init__": 1701
        },
        {
            "transformers.utils.dummy_tf_objects.TFMarianMTModel.__init__": 1708
        },
        {
            "transformers.utils.dummy_tf_objects.TFMarianPreTrainedModel.__init__": 1715
        },
        {
            "transformers.utils.dummy_tf_objects.TFMBartForConditionalGeneration.__init__": 1722
        },
        {
            "transformers.utils.dummy_tf_objects.TFMBartModel.__init__": 1729
        },
        {
            "transformers.utils.dummy_tf_objects.TFMBartPreTrainedModel.__init__": 1736
        },
        {
            "transformers.utils.dummy_tf_objects.TFMobileBertForMaskedLM.__init__": 1746
        },
        {
            "transformers.utils.dummy_tf_objects.TFMobileBertForMultipleChoice.__init__": 1753
        },
        {
            "transformers.utils.dummy_tf_objects.TFMobileBertForNextSentencePrediction.__init__": 1760
        },
        {
            "transformers.utils.dummy_tf_objects.TFMobileBertForPreTraining.__init__": 1767
        },
        {
            "transformers.utils.dummy_tf_objects.TFMobileBertForQuestionAnswering.__init__": 1774
        },
        {
            "transformers.utils.dummy_tf_objects.TFMobileBertForSequenceClassification.__init__": 1781
        },
        {
            "transformers.utils.dummy_tf_objects.TFMobileBertForTokenClassification.__init__": 1788
        },
        {
            "transformers.utils.dummy_tf_objects.TFMobileBertMainLayer.__init__": 1795
        },
        {
            "transformers.utils.dummy_tf_objects.TFMobileBertModel.__init__": 1802
        },
        {
            "transformers.utils.dummy_tf_objects.TFMobileBertPreTrainedModel.__init__": 1809
        },
        {
            "transformers.utils.dummy_tf_objects.TFMobileViTForImageClassification.__init__": 1819
        },
        {
            "transformers.utils.dummy_tf_objects.TFMobileViTForSemanticSegmentation.__init__": 1826
        },
        {
            "transformers.utils.dummy_tf_objects.TFMobileViTModel.__init__": 1833
        },
        {
            "transformers.utils.dummy_tf_objects.TFMobileViTPreTrainedModel.__init__": 1840
        },
        {
            "transformers.utils.dummy_tf_objects.TFMPNetForMaskedLM.__init__": 1850
        },
        {
            "transformers.utils.dummy_tf_objects.TFMPNetForMultipleChoice.__init__": 1857
        },
        {
            "transformers.utils.dummy_tf_objects.TFMPNetForQuestionAnswering.__init__": 1864
        },
        {
            "transformers.utils.dummy_tf_objects.TFMPNetForSequenceClassification.__init__": 1871
        },
        {
            "transformers.utils.dummy_tf_objects.TFMPNetForTokenClassification.__init__": 1878
        },
        {
            "transformers.utils.dummy_tf_objects.TFMPNetMainLayer.__init__": 1885
        },
        {
            "transformers.utils.dummy_tf_objects.TFMPNetModel.__init__": 1892
        },
        {
            "transformers.utils.dummy_tf_objects.TFMPNetPreTrainedModel.__init__": 1899
        },
        {
            "transformers.utils.dummy_tf_objects.TFMT5EncoderModel.__init__": 1906
        },
        {
            "transformers.utils.dummy_tf_objects.TFMT5ForConditionalGeneration.__init__": 1913
        },
        {
            "transformers.utils.dummy_tf_objects.TFMT5Model.__init__": 1920
        },
        {
            "transformers.utils.dummy_tf_objects.TFOpenAIGPTDoubleHeadsModel.__init__": 1930
        },
        {
            "transformers.utils.dummy_tf_objects.TFOpenAIGPTForSequenceClassification.__init__": 1937
        },
        {
            "transformers.utils.dummy_tf_objects.TFOpenAIGPTLMHeadModel.__init__": 1944
        },
        {
            "transformers.utils.dummy_tf_objects.TFOpenAIGPTMainLayer.__init__": 1951
        },
        {
            "transformers.utils.dummy_tf_objects.TFOpenAIGPTModel.__init__": 1958
        },
        {
            "transformers.utils.dummy_tf_objects.TFOpenAIGPTPreTrainedModel.__init__": 1965
        },
        {
            "transformers.utils.dummy_tf_objects.TFOPTForCausalLM.__init__": 1972
        },
        {
            "transformers.utils.dummy_tf_objects.TFOPTModel.__init__": 1979
        },
        {
            "transformers.utils.dummy_tf_objects.TFOPTPreTrainedModel.__init__": 1986
        },
        {
            "transformers.utils.dummy_tf_objects.TFPegasusForConditionalGeneration.__init__": 1993
        },
        {
            "transformers.utils.dummy_tf_objects.TFPegasusModel.__init__": 2000
        },
        {
            "transformers.utils.dummy_tf_objects.TFPegasusPreTrainedModel.__init__": 2007
        },
        {
            "transformers.utils.dummy_tf_objects.TFRagModel.__init__": 2014
        },
        {
            "transformers.utils.dummy_tf_objects.TFRagPreTrainedModel.__init__": 2021
        },
        {
            "transformers.utils.dummy_tf_objects.TFRagSequenceForGeneration.__init__": 2028
        },
        {
            "transformers.utils.dummy_tf_objects.TFRagTokenForGeneration.__init__": 2035
        },
        {
            "transformers.utils.dummy_tf_objects.TFRegNetForImageClassification.__init__": 2045
        },
        {
            "transformers.utils.dummy_tf_objects.TFRegNetModel.__init__": 2052
        },
        {
            "transformers.utils.dummy_tf_objects.TFRegNetPreTrainedModel.__init__": 2059
        },
        {
            "transformers.utils.dummy_tf_objects.TFRemBertForCausalLM.__init__": 2069
        },
        {
            "transformers.utils.dummy_tf_objects.TFRemBertForMaskedLM.__init__": 2076
        },
        {
            "transformers.utils.dummy_tf_objects.TFRemBertForMultipleChoice.__init__": 2083
        },
        {
            "transformers.utils.dummy_tf_objects.TFRemBertForQuestionAnswering.__init__": 2090
        },
        {
            "transformers.utils.dummy_tf_objects.TFRemBertForSequenceClassification.__init__": 2097
        },
        {
            "transformers.utils.dummy_tf_objects.TFRemBertForTokenClassification.__init__": 2104
        },
        {
            "transformers.utils.dummy_tf_objects.TFRemBertLayer.__init__": 2111
        },
        {
            "transformers.utils.dummy_tf_objects.TFRemBertModel.__init__": 2118
        },
        {
            "transformers.utils.dummy_tf_objects.TFRemBertPreTrainedModel.__init__": 2125
        },
        {
            "transformers.utils.dummy_tf_objects.TFResNetForImageClassification.__init__": 2135
        },
        {
            "transformers.utils.dummy_tf_objects.TFResNetModel.__init__": 2142
        },
        {
            "transformers.utils.dummy_tf_objects.TFResNetPreTrainedModel.__init__": 2149
        },
        {
            "transformers.utils.dummy_tf_objects.TFRobertaForCausalLM.__init__": 2159
        },
        {
            "transformers.utils.dummy_tf_objects.TFRobertaForMaskedLM.__init__": 2166
        },
        {
            "transformers.utils.dummy_tf_objects.TFRobertaForMultipleChoice.__init__": 2173
        },
        {
            "transformers.utils.dummy_tf_objects.TFRobertaForQuestionAnswering.__init__": 2180
        },
        {
            "transformers.utils.dummy_tf_objects.TFRobertaForSequenceClassification.__init__": 2187
        },
        {
            "transformers.utils.dummy_tf_objects.TFRobertaForTokenClassification.__init__": 2194
        },
        {
            "transformers.utils.dummy_tf_objects.TFRobertaMainLayer.__init__": 2201
        },
        {
            "transformers.utils.dummy_tf_objects.TFRobertaModel.__init__": 2208
        },
        {
            "transformers.utils.dummy_tf_objects.TFRobertaPreTrainedModel.__init__": 2215
        },
        {
            "transformers.utils.dummy_tf_objects.TFRobertaPreLayerNormForCausalLM.__init__": 2225
        },
        {
            "transformers.utils.dummy_tf_objects.TFRobertaPreLayerNormForMaskedLM.__init__": 2232
        },
        {
            "transformers.utils.dummy_tf_objects.TFRobertaPreLayerNormForMultipleChoice.__init__": 2239
        },
        {
            "transformers.utils.dummy_tf_objects.TFRobertaPreLayerNormForQuestionAnswering.__init__": 2246
        },
        {
            "transformers.utils.dummy_tf_objects.TFRobertaPreLayerNormForSequenceClassification.__init__": 2253
        },
        {
            "transformers.utils.dummy_tf_objects.TFRobertaPreLayerNormForTokenClassification.__init__": 2260
        },
        {
            "transformers.utils.dummy_tf_objects.TFRobertaPreLayerNormMainLayer.__init__": 2267
        },
        {
            "transformers.utils.dummy_tf_objects.TFRobertaPreLayerNormModel.__init__": 2274
        },
        {
            "transformers.utils.dummy_tf_objects.TFRobertaPreLayerNormPreTrainedModel.__init__": 2281
        },
        {
            "transformers.utils.dummy_tf_objects.TFRoFormerForCausalLM.__init__": 2291
        },
        {
            "transformers.utils.dummy_tf_objects.TFRoFormerForMaskedLM.__init__": 2298
        },
        {
            "transformers.utils.dummy_tf_objects.TFRoFormerForMultipleChoice.__init__": 2305
        },
        {
            "transformers.utils.dummy_tf_objects.TFRoFormerForQuestionAnswering.__init__": 2312
        },
        {
            "transformers.utils.dummy_tf_objects.TFRoFormerForSequenceClassification.__init__": 2319
        },
        {
            "transformers.utils.dummy_tf_objects.TFRoFormerForTokenClassification.__init__": 2326
        },
        {
            "transformers.utils.dummy_tf_objects.TFRoFormerLayer.__init__": 2333
        },
        {
            "transformers.utils.dummy_tf_objects.TFRoFormerModel.__init__": 2340
        },
        {
            "transformers.utils.dummy_tf_objects.TFRoFormerPreTrainedModel.__init__": 2347
        },
        {
            "transformers.utils.dummy_tf_objects.TFSamModel.__init__": 2357
        },
        {
            "transformers.utils.dummy_tf_objects.TFSamPreTrainedModel.__init__": 2364
        },
        {
            "transformers.utils.dummy_tf_objects.TFSegformerDecodeHead.__init__": 2374
        },
        {
            "transformers.utils.dummy_tf_objects.TFSegformerForImageClassification.__init__": 2381
        },
        {
            "transformers.utils.dummy_tf_objects.TFSegformerForSemanticSegmentation.__init__": 2388
        },
        {
            "transformers.utils.dummy_tf_objects.TFSegformerModel.__init__": 2395
        },
        {
            "transformers.utils.dummy_tf_objects.TFSegformerPreTrainedModel.__init__": 2402
        },
        {
            "transformers.utils.dummy_tf_objects.TFSpeech2TextForConditionalGeneration.__init__": 2412
        },
        {
            "transformers.utils.dummy_tf_objects.TFSpeech2TextModel.__init__": 2419
        },
        {
            "transformers.utils.dummy_tf_objects.TFSpeech2TextPreTrainedModel.__init__": 2426
        },
        {
            "transformers.utils.dummy_tf_objects.TFSwinForImageClassification.__init__": 2436
        },
        {
            "transformers.utils.dummy_tf_objects.TFSwinForMaskedImageModeling.__init__": 2443
        },
        {
            "transformers.utils.dummy_tf_objects.TFSwinModel.__init__": 2450
        },
        {
            "transformers.utils.dummy_tf_objects.TFSwinPreTrainedModel.__init__": 2457
        },
        {
            "transformers.utils.dummy_tf_objects.TFT5EncoderModel.__init__": 2467
        },
        {
            "transformers.utils.dummy_tf_objects.TFT5ForConditionalGeneration.__init__": 2474
        },
        {
            "transformers.utils.dummy_tf_objects.TFT5Model.__init__": 2481
        },
        {
            "transformers.utils.dummy_tf_objects.TFT5PreTrainedModel.__init__": 2488
        },
        {
            "transformers.utils.dummy_tf_objects.TFTapasForMaskedLM.__init__": 2498
        },
        {
            "transformers.utils.dummy_tf_objects.TFTapasForQuestionAnswering.__init__": 2505
        },
        {
            "transformers.utils.dummy_tf_objects.TFTapasForSequenceClassification.__init__": 2512
        },
        {
            "transformers.utils.dummy_tf_objects.TFTapasModel.__init__": 2519
        },
        {
            "transformers.utils.dummy_tf_objects.TFTapasPreTrainedModel.__init__": 2526
        },
        {
            "transformers.utils.dummy_tf_objects.TFAdaptiveEmbedding.__init__": 2536
        },
        {
            "transformers.utils.dummy_tf_objects.TFTransfoXLForSequenceClassification.__init__": 2543
        },
        {
            "transformers.utils.dummy_tf_objects.TFTransfoXLLMHeadModel.__init__": 2550
        },
        {
            "transformers.utils.dummy_tf_objects.TFTransfoXLMainLayer.__init__": 2557
        },
        {
            "transformers.utils.dummy_tf_objects.TFTransfoXLModel.__init__": 2564
        },
        {
            "transformers.utils.dummy_tf_objects.TFTransfoXLPreTrainedModel.__init__": 2571
        },
        {
            "transformers.utils.dummy_tf_objects.TFVisionEncoderDecoderModel.__init__": 2578
        },
        {
            "transformers.utils.dummy_tf_objects.TFVisionTextDualEncoderModel.__init__": 2585
        },
        {
            "transformers.utils.dummy_tf_objects.TFViTForImageClassification.__init__": 2592
        },
        {
            "transformers.utils.dummy_tf_objects.TFViTModel.__init__": 2599
        },
        {
            "transformers.utils.dummy_tf_objects.TFViTPreTrainedModel.__init__": 2606
        },
        {
            "transformers.utils.dummy_tf_objects.TFViTMAEForPreTraining.__init__": 2613
        },
        {
            "transformers.utils.dummy_tf_objects.TFViTMAEModel.__init__": 2620
        },
        {
            "transformers.utils.dummy_tf_objects.TFViTMAEPreTrainedModel.__init__": 2627
        },
        {
            "transformers.utils.dummy_tf_objects.TFWav2Vec2ForCTC.__init__": 2637
        },
        {
            "transformers.utils.dummy_tf_objects.TFWav2Vec2ForSequenceClassification.__init__": 2644
        },
        {
            "transformers.utils.dummy_tf_objects.TFWav2Vec2Model.__init__": 2651
        },
        {
            "transformers.utils.dummy_tf_objects.TFWav2Vec2PreTrainedModel.__init__": 2658
        },
        {
            "transformers.utils.dummy_tf_objects.TFWhisperForConditionalGeneration.__init__": 2668
        },
        {
            "transformers.utils.dummy_tf_objects.TFWhisperModel.__init__": 2675
        },
        {
            "transformers.utils.dummy_tf_objects.TFWhisperPreTrainedModel.__init__": 2682
        },
        {
            "transformers.utils.dummy_tf_objects.TFXGLMForCausalLM.__init__": 2692
        },
        {
            "transformers.utils.dummy_tf_objects.TFXGLMModel.__init__": 2699
        },
        {
            "transformers.utils.dummy_tf_objects.TFXGLMPreTrainedModel.__init__": 2706
        },
        {
            "transformers.utils.dummy_tf_objects.TFXLMForMultipleChoice.__init__": 2716
        },
        {
            "transformers.utils.dummy_tf_objects.TFXLMForQuestionAnsweringSimple.__init__": 2723
        },
        {
            "transformers.utils.dummy_tf_objects.TFXLMForSequenceClassification.__init__": 2730
        },
        {
            "transformers.utils.dummy_tf_objects.TFXLMForTokenClassification.__init__": 2737
        },
        {
            "transformers.utils.dummy_tf_objects.TFXLMMainLayer.__init__": 2744
        },
        {
            "transformers.utils.dummy_tf_objects.TFXLMModel.__init__": 2751
        },
        {
            "transformers.utils.dummy_tf_objects.TFXLMPreTrainedModel.__init__": 2758
        },
        {
            "transformers.utils.dummy_tf_objects.TFXLMWithLMHeadModel.__init__": 2765
        },
        {
            "transformers.utils.dummy_tf_objects.TFXLMRobertaForCausalLM.__init__": 2775
        },
        {
            "transformers.utils.dummy_tf_objects.TFXLMRobertaForMaskedLM.__init__": 2782
        },
        {
            "transformers.utils.dummy_tf_objects.TFXLMRobertaForMultipleChoice.__init__": 2789
        },
        {
            "transformers.utils.dummy_tf_objects.TFXLMRobertaForQuestionAnswering.__init__": 2796
        },
        {
            "transformers.utils.dummy_tf_objects.TFXLMRobertaForSequenceClassification.__init__": 2803
        },
        {
            "transformers.utils.dummy_tf_objects.TFXLMRobertaForTokenClassification.__init__": 2810
        },
        {
            "transformers.utils.dummy_tf_objects.TFXLMRobertaModel.__init__": 2817
        },
        {
            "transformers.utils.dummy_tf_objects.TFXLMRobertaPreTrainedModel.__init__": 2824
        },
        {
            "transformers.utils.dummy_tf_objects.TFXLNetForMultipleChoice.__init__": 2834
        },
        {
            "transformers.utils.dummy_tf_objects.TFXLNetForQuestionAnsweringSimple.__init__": 2841
        },
        {
            "transformers.utils.dummy_tf_objects.TFXLNetForSequenceClassification.__init__": 2848
        },
        {
            "transformers.utils.dummy_tf_objects.TFXLNetForTokenClassification.__init__": 2855
        },
        {
            "transformers.utils.dummy_tf_objects.TFXLNetLMHeadModel.__init__": 2862
        },
        {
            "transformers.utils.dummy_tf_objects.TFXLNetMainLayer.__init__": 2869
        },
        {
            "transformers.utils.dummy_tf_objects.TFXLNetModel.__init__": 2876
        },
        {
            "transformers.utils.dummy_tf_objects.TFXLNetPreTrainedModel.__init__": 2883
        },
        {
            "transformers.utils.dummy_tf_objects.AdamWeightDecay.__init__": 2890
        },
        {
            "transformers.utils.dummy_tf_objects.GradientAccumulator.__init__": 2897
        },
        {
            "transformers.utils.dummy_tf_objects.WarmUp.__init__": 2904
        },
        {
            "transformers.utils.dummy_tf_objects.create_optimizer": 2908
        },
        {
            "transformers.utils.dummy_tf_objects.TFTrainer.__init__": 2915
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/utils/hub.py": [
        {
            "transformers.utils.hub.PushToHubMixin.push_to_hub": 733
        },
        {
            "transformers.utils.hub.send_example_telemetry": 834
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/utils/dummy_tokenizers_objects.py": [
        {
            "transformers.utils.dummy_tokenizers_objects.AlbertTokenizerFast.__init__": 8
        },
        {
            "transformers.utils.dummy_tokenizers_objects.BartTokenizerFast.__init__": 15
        },
        {
            "transformers.utils.dummy_tokenizers_objects.BarthezTokenizerFast.__init__": 22
        },
        {
            "transformers.utils.dummy_tokenizers_objects.BertTokenizerFast.__init__": 29
        },
        {
            "transformers.utils.dummy_tokenizers_objects.BigBirdTokenizerFast.__init__": 36
        },
        {
            "transformers.utils.dummy_tokenizers_objects.BlenderbotTokenizerFast.__init__": 43
        },
        {
            "transformers.utils.dummy_tokenizers_objects.BlenderbotSmallTokenizerFast.__init__": 50
        },
        {
            "transformers.utils.dummy_tokenizers_objects.BloomTokenizerFast.__init__": 57
        },
        {
            "transformers.utils.dummy_tokenizers_objects.CamembertTokenizerFast.__init__": 64
        },
        {
            "transformers.utils.dummy_tokenizers_objects.CLIPTokenizerFast.__init__": 71
        },
        {
            "transformers.utils.dummy_tokenizers_objects.CodeGenTokenizerFast.__init__": 78
        },
        {
            "transformers.utils.dummy_tokenizers_objects.ConvBertTokenizerFast.__init__": 85
        },
        {
            "transformers.utils.dummy_tokenizers_objects.CpmTokenizerFast.__init__": 92
        },
        {
            "transformers.utils.dummy_tokenizers_objects.DebertaTokenizerFast.__init__": 99
        },
        {
            "transformers.utils.dummy_tokenizers_objects.DebertaV2TokenizerFast.__init__": 106
        },
        {
            "transformers.utils.dummy_tokenizers_objects.DistilBertTokenizerFast.__init__": 113
        },
        {
            "transformers.utils.dummy_tokenizers_objects.DPRContextEncoderTokenizerFast.__init__": 120
        },
        {
            "transformers.utils.dummy_tokenizers_objects.DPRQuestionEncoderTokenizerFast.__init__": 127
        },
        {
            "transformers.utils.dummy_tokenizers_objects.DPRReaderTokenizerFast.__init__": 134
        },
        {
            "transformers.utils.dummy_tokenizers_objects.ElectraTokenizerFast.__init__": 141
        },
        {
            "transformers.utils.dummy_tokenizers_objects.FNetTokenizerFast.__init__": 148
        },
        {
            "transformers.utils.dummy_tokenizers_objects.FunnelTokenizerFast.__init__": 155
        },
        {
            "transformers.utils.dummy_tokenizers_objects.GPT2TokenizerFast.__init__": 162
        },
        {
            "transformers.utils.dummy_tokenizers_objects.GPTNeoXTokenizerFast.__init__": 169
        },
        {
            "transformers.utils.dummy_tokenizers_objects.GPTNeoXJapaneseTokenizer.__init__": 176
        },
        {
            "transformers.utils.dummy_tokenizers_objects.HerbertTokenizerFast.__init__": 183
        },
        {
            "transformers.utils.dummy_tokenizers_objects.LayoutLMTokenizerFast.__init__": 190
        },
        {
            "transformers.utils.dummy_tokenizers_objects.LayoutLMv2TokenizerFast.__init__": 197
        },
        {
            "transformers.utils.dummy_tokenizers_objects.LayoutLMv3TokenizerFast.__init__": 204
        },
        {
            "transformers.utils.dummy_tokenizers_objects.LayoutXLMTokenizerFast.__init__": 211
        },
        {
            "transformers.utils.dummy_tokenizers_objects.LEDTokenizerFast.__init__": 218
        },
        {
            "transformers.utils.dummy_tokenizers_objects.LlamaTokenizerFast.__init__": 225
        },
        {
            "transformers.utils.dummy_tokenizers_objects.LongformerTokenizerFast.__init__": 232
        },
        {
            "transformers.utils.dummy_tokenizers_objects.LxmertTokenizerFast.__init__": 239
        },
        {
            "transformers.utils.dummy_tokenizers_objects.MarkupLMTokenizerFast.__init__": 246
        },
        {
            "transformers.utils.dummy_tokenizers_objects.MBartTokenizerFast.__init__": 253
        },
        {
            "transformers.utils.dummy_tokenizers_objects.MBart50TokenizerFast.__init__": 260
        },
        {
            "transformers.utils.dummy_tokenizers_objects.MobileBertTokenizerFast.__init__": 267
        },
        {
            "transformers.utils.dummy_tokenizers_objects.MPNetTokenizerFast.__init__": 274
        },
        {
            "transformers.utils.dummy_tokenizers_objects.MT5TokenizerFast.__init__": 281
        },
        {
            "transformers.utils.dummy_tokenizers_objects.MvpTokenizerFast.__init__": 288
        },
        {
            "transformers.utils.dummy_tokenizers_objects.NllbTokenizerFast.__init__": 295
        },
        {
            "transformers.utils.dummy_tokenizers_objects.OpenAIGPTTokenizerFast.__init__": 302
        },
        {
            "transformers.utils.dummy_tokenizers_objects.PegasusTokenizerFast.__init__": 309
        },
        {
            "transformers.utils.dummy_tokenizers_objects.RealmTokenizerFast.__init__": 316
        },
        {
            "transformers.utils.dummy_tokenizers_objects.ReformerTokenizerFast.__init__": 323
        },
        {
            "transformers.utils.dummy_tokenizers_objects.RemBertTokenizerFast.__init__": 330
        },
        {
            "transformers.utils.dummy_tokenizers_objects.RetriBertTokenizerFast.__init__": 337
        },
        {
            "transformers.utils.dummy_tokenizers_objects.RobertaTokenizerFast.__init__": 344
        },
        {
            "transformers.utils.dummy_tokenizers_objects.RoFormerTokenizerFast.__init__": 351
        },
        {
            "transformers.utils.dummy_tokenizers_objects.SplinterTokenizerFast.__init__": 358
        },
        {
            "transformers.utils.dummy_tokenizers_objects.SqueezeBertTokenizerFast.__init__": 365
        },
        {
            "transformers.utils.dummy_tokenizers_objects.T5TokenizerFast.__init__": 372
        },
        {
            "transformers.utils.dummy_tokenizers_objects.WhisperTokenizerFast.__init__": 379
        },
        {
            "transformers.utils.dummy_tokenizers_objects.XGLMTokenizerFast.__init__": 386
        },
        {
            "transformers.utils.dummy_tokenizers_objects.XLMRobertaTokenizerFast.__init__": 393
        },
        {
            "transformers.utils.dummy_tokenizers_objects.XLNetTokenizerFast.__init__": 400
        },
        {
            "transformers.utils.dummy_tokenizers_objects.PreTrainedTokenizerFast.__init__": 407
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/tools/image_captioning.py": [
        {
            "transformers.tools.image_captioning.ImageCaptioningTool.__init__": 40
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/tools/image_question_answering.py": [
        {
            "transformers.tools.image_question_answering.ImageQuestionAnsweringTool.__init__": 44
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/tools/base.py": [
        {
            "transformers.tools.base.get_repo_type": 54
        },
        {
            "transformers.tools.base.Tool.__init__": 108
        },
        {
            "transformers.tools.base.Tool.__call__": 111
        },
        {
            "transformers.tools.base.Tool.from_hub": 176
        },
        {
            "transformers.tools.base.RemoteTool.prepare_inputs": 365
        },
        {
            "transformers.tools.base.RemoteTool.__call__": 415
        },
        {
            "transformers.tools.base.PipelineTool.__init__": 470
        },
        {
            "transformers.tools.base.PipelineTool.__call__": 552
        },
        {
            "transformers.tools.base.fn": 578
        },
        {
            "transformers.tools.base.load_tool": 629
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/tools/document_question_answering.py": [
        {
            "transformers.tools.document_question_answering.DocumentQuestionAnsweringTool.__init__": 43
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/tools/image_segmentation.py": [
        {
            "transformers.tools.image_segmentation.ImageSegmentationTool.__init__": 42
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/tools/agents.py": [
        {
            "transformers.tools.agents.Agent.chat": 262
        },
        {
            "transformers.tools.agents.Agent.run": 312
        },
        {
            "transformers.tools.agents.LocalAgent.from_pretrained": 699
        },
        {
            "transformers.tools.agents.StopSequenceCriteria.__call__": 763
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/sagemaker/trainer_sm.py": [
        {
            "transformers.sagemaker.trainer_sm.SageMakerTrainer.__init__": 24
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/commands/add_new_model.py": [
        {
            "transformers.commands.add_new_model.AddNewModelCommand.__init__": 52
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/commands/serving.py": [
        {
            "transformers.commands.serving.Body": 34
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/commands/add_new_model_like.py": [
        {
            "transformers.commands.add_new_model_like.AddNewModelLikeCommand.__init__": 1463
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/commands/pt_to_tf.py": [
        {
            "transformers.commands.pt_to_tf.PTtoTFCommand.__init__": 177
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/commands/lfs.py": [
        {
            "transformers.commands.lfs.FileSlice.__exit__": 153
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/commands/convert.py": [
        {
            "transformers.commands.convert.ConvertCommand.__init__": 67
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/benchmark/benchmark_tf.py": [
        {
            "transformers.benchmark.benchmark_tf.run_in_eager_mode": 54
        },
        {
            "transformers.benchmark.benchmark_tf.run_in_graph_mode": 59
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/benchmark/benchmark_args.py": [
        {
            "transformers.benchmark.benchmark_args.PyTorchBenchmarkArguments.__init__": 46
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/benchmark/benchmark_args_tf.py": [
        {
            "transformers.benchmark.benchmark_args_tf.TensorFlowBenchmarkArguments.__init__": 43
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/onnx/features.py": [
        {
            "transformers.onnx.features.supported_features_mapping": 55
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/align/configuration_align.py": [
        {
            "transformers.models.align.configuration_align.AlignTextConfig.__init__": 103
        },
        {
            "transformers.models.align.configuration_align.AlignTextConfig.from_pretrained": 141
        },
        {
            "transformers.models.align.configuration_align.AlignVisionConfig.__init__": 231
        },
        {
            "transformers.models.align.configuration_align.AlignVisionConfig.from_pretrained": 282
        },
        {
            "transformers.models.align.configuration_align.AlignConfig.__init__": 349
        },
        {
            "transformers.models.align.configuration_align.AlignConfig.from_text_vision_configs": 376
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/align/processing_align.py": [
        {
            "transformers.models.align.processing_align.AlignProcessor.__call__": 45
        },
        {
            "transformers.models.align.processing_align.AlignProcessor.batch_decode": 104
        },
        {
            "transformers.models.align.processing_align.AlignProcessor.decode": 111
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/align/modeling_align.py": [
        {
            "transformers.models.align.modeling_align.AlignTextEncoder.custom_forward": 1098
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/mobilevit/modeling_tf_mobilevit.py": [
        {
            "transformers.models.mobilevit.modeling_tf_mobilevit.TFMobileViTConvLayer.__init__": 85
        },
        {
            "transformers.models.mobilevit.modeling_tf_mobilevit.TFMobileViTInvertedResidual.__init__": 151
        },
        {
            "transformers.models.mobilevit.modeling_tf_mobilevit.TFMobileViTMobileNetLayer.__init__": 195
        },
        {
            "transformers.models.mobilevit.modeling_tf_mobilevit.TFMobileViTSelfAttention.__init__": 225
        },
        {
            "transformers.models.mobilevit.modeling_tf_mobilevit.TFMobileViTSelfOutput.__init__": 277
        },
        {
            "transformers.models.mobilevit.modeling_tf_mobilevit.TFMobileViTAttention.__init__": 289
        },
        {
            "transformers.models.mobilevit.modeling_tf_mobilevit.TFMobileViTIntermediate.__init__": 304
        },
        {
            "transformers.models.mobilevit.modeling_tf_mobilevit.TFMobileViTOutput.__init__": 319
        },
        {
            "transformers.models.mobilevit.modeling_tf_mobilevit.TFMobileViTTransformerLayer.__init__": 332
        },
        {
            "transformers.models.mobilevit.modeling_tf_mobilevit.TFMobileViTTransformer.__init__": 355
        },
        {
            "transformers.models.mobilevit.modeling_tf_mobilevit.TFMobileViTLayer.__init__": 379
        },
        {
            "transformers.models.mobilevit.modeling_tf_mobilevit.TFMobileViTEncoder.__init__": 533
        },
        {
            "transformers.models.mobilevit.modeling_tf_mobilevit.TFMobileViTMainLayer.__init__": 636
        },
        {
            "transformers.models.mobilevit.modeling_tf_mobilevit.TFMobileViTModel.__init__": 801
        },
        {
            "transformers.models.mobilevit.modeling_tf_mobilevit.TFMobileViTForImageClassification.__init__": 836
        },
        {
            "transformers.models.mobilevit.modeling_tf_mobilevit.TFMobileViTASPPPooling.__init__": 889
        },
        {
            "transformers.models.mobilevit.modeling_tf_mobilevit.TFMobileViTASPP.__init__": 917
        },
        {
            "transformers.models.mobilevit.modeling_tf_mobilevit.TFMobileViTDeepLabV3.__init__": 982
        },
        {
            "transformers.models.mobilevit.modeling_tf_mobilevit.TFMobileViTForSemanticSegmentation.__init__": 1012
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/mobilevit/image_processing_mobilevit.py": [
        {
            "transformers.models.mobilevit.image_processing_mobilevit.MobileViTImageProcessor.__init__": 85
        },
        {
            "transformers.models.mobilevit.image_processing_mobilevit.MobileViTImageProcessor.resize": 112
        },
        {
            "transformers.models.mobilevit.image_processing_mobilevit.MobileViTImageProcessor.center_crop": 140
        },
        {
            "transformers.models.mobilevit.image_processing_mobilevit.MobileViTImageProcessor.rescale": 164
        },
        {
            "transformers.models.mobilevit.image_processing_mobilevit.MobileViTImageProcessor.preprocess": 198
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/mobilevit/feature_extraction_mobilevit.py": [
        {
            "transformers.models.mobilevit.feature_extraction_mobilevit.MobileViTFeatureExtractor.__init__": 27
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/mobilevit/modeling_mobilevit.py": [
        {
            "transformers.models.mobilevit.modeling_mobilevit.MobileViTEncoder.custom_forward": 631
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/mobilevit/configuration_mobilevit.py": [
        {
            "transformers.models.mobilevit.configuration_mobilevit.MobileViTConfig.__init__": 116
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/distilbert/modeling_flax_distilbert.py": [
        {
            "transformers.models.distilbert.modeling_flax_distilbert.FlaxDistilBertPreTrainedModel.__init__": 423
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/distilbert/tokenization_distilbert_fast.py": [
        {
            "transformers.models.distilbert.tokenization_distilbert_fast.DistilBertTokenizerFast.__init__": 131
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/distilbert/configuration_distilbert.py": [
        {
            "transformers.models.distilbert.configuration_distilbert.DistilBertConfig.__init__": 108
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/distilbert/tokenization_distilbert.py": [
        {
            "transformers.models.distilbert.tokenization_distilbert.DistilBertTokenizer.__init__": 137
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/distilbert/modeling_tf_distilbert.py": [
        {
            "transformers.models.distilbert.modeling_tf_distilbert.TFEmbeddings.__init__": 78
        },
        {
            "transformers.models.distilbert.modeling_tf_distilbert.TFMultiHeadSelfAttention.__init__": 131
        },
        {
            "transformers.models.distilbert.modeling_tf_distilbert.TFFFN.__init__": 217
        },
        {
            "transformers.models.distilbert.modeling_tf_distilbert.TFTransformerBlock.__init__": 237
        },
        {
            "transformers.models.distilbert.modeling_tf_distilbert.TFTransformer.__init__": 286
        },
        {
            "transformers.models.distilbert.modeling_tf_distilbert.TFDistilBertMainLayer.__init__": 344
        },
        {
            "transformers.models.distilbert.modeling_tf_distilbert.TFDistilBertModel.__init__": 517
        },
        {
            "transformers.models.distilbert.modeling_tf_distilbert.TFDistilBertLMHead.__init__": 553
        },
        {
            "transformers.models.distilbert.modeling_tf_distilbert.TFDistilBertForMaskedLM.__init__": 597
        },
        {
            "transformers.models.distilbert.modeling_tf_distilbert.TFDistilBertForSequenceClassification.__init__": 679
        },
        {
            "transformers.models.distilbert.modeling_tf_distilbert.TFDistilBertForTokenClassification.__init__": 758
        },
        {
            "transformers.models.distilbert.modeling_tf_distilbert.TFDistilBertForMultipleChoice.__init__": 826
        },
        {
            "transformers.models.distilbert.modeling_tf_distilbert.TFDistilBertForQuestionAnswering.__init__": 920
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/dpt/feature_extraction_dpt.py": [
        {
            "transformers.models.dpt.feature_extraction_dpt.DPTFeatureExtractor.__init__": 27
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/dpt/image_processing_dpt.py": [
        {
            "transformers.models.dpt.image_processing_dpt.DPTImageProcessor.__init__": 123
        },
        {
            "transformers.models.dpt.image_processing_dpt.DPTImageProcessor.resize": 151
        },
        {
            "transformers.models.dpt.image_processing_dpt.DPTImageProcessor.rescale": 194
        },
        {
            "transformers.models.dpt.image_processing_dpt.DPTImageProcessor.normalize": 214
        },
        {
            "transformers.models.dpt.image_processing_dpt.DPTImageProcessor.preprocess": 237
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/dpt/modeling_dpt.py": [
        {
            "transformers.models.dpt.modeling_dpt.DPTViTEncoder.custom_forward": 533
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/dpt/configuration_dpt.py": [
        {
            "transformers.models.dpt.configuration_dpt.DPTConfig.__init__": 125
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/git/configuration_git.py": [
        {
            "transformers.models.git.configuration_git.GitVisionConfig.__init__": 81
        },
        {
            "transformers.models.git.configuration_git.GitVisionConfig.from_pretrained": 111
        },
        {
            "transformers.models.git.configuration_git.GitConfig.__init__": 192
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/git/modeling_git.py": [
        {
            "transformers.models.git.modeling_git.GitEncoder.custom_forward": 455
        },
        {
            "transformers.models.git.modeling_git.GitVisionEncoder.custom_forward": 881
        },
        {
            "transformers.models.git.modeling_git.GitForCausalLM.prepare_inputs_for_generation": 1534
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/git/processing_git.py": [
        {
            "transformers.models.git.processing_git.GitProcessor.__call__": 44
        },
        {
            "transformers.models.git.processing_git.GitProcessor.batch_decode": 97
        },
        {
            "transformers.models.git.processing_git.GitProcessor.decode": 104
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/efficientformer/image_processing_efficientformer.py": [
        {
            "transformers.models.efficientformer.image_processing_efficientformer.EfficientFormerImageProcessor.__init__": 85
        },
        {
            "transformers.models.efficientformer.image_processing_efficientformer.EfficientFormerImageProcessor.resize": 116
        },
        {
            "transformers.models.efficientformer.image_processing_efficientformer.EfficientFormerImageProcessor.center_crop": 154
        },
        {
            "transformers.models.efficientformer.image_processing_efficientformer.EfficientFormerImageProcessor.rescale": 178
        },
        {
            "transformers.models.efficientformer.image_processing_efficientformer.EfficientFormerImageProcessor.normalize": 200
        },
        {
            "transformers.models.efficientformer.image_processing_efficientformer.EfficientFormerImageProcessor.preprocess": 229
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/efficientformer/configuration_efficientformer.py": [
        {
            "transformers.models.efficientformer.configuration_efficientformer.EfficientFormerConfig.__init__": 114
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/efficientformer/modeling_tf_efficientformer.py": [
        {
            "transformers.models.efficientformer.modeling_tf_efficientformer.TFEfficientFormerPatchEmbeddings.__init__": 73
        },
        {
            "transformers.models.efficientformer.modeling_tf_efficientformer.TFEfficientFormerSelfAttention.__init__": 105
        },
        {
            "transformers.models.efficientformer.modeling_tf_efficientformer.TFEfficientFormerConvStem.__init__": 203
        },
        {
            "transformers.models.efficientformer.modeling_tf_efficientformer.TFEfficientFormerPooling.__init__": 238
        },
        {
            "transformers.models.efficientformer.modeling_tf_efficientformer.TFEfficientFormerDenseMlp.__init__": 249
        },
        {
            "transformers.models.efficientformer.modeling_tf_efficientformer.TFEfficientFormerConvMlp.__init__": 282
        },
        {
            "transformers.models.efficientformer.modeling_tf_efficientformer.TFEfficientFormerDropPath.__init__": 340
        },
        {
            "transformers.models.efficientformer.modeling_tf_efficientformer.TFEfficientFormerFlat.__init__": 355
        },
        {
            "transformers.models.efficientformer.modeling_tf_efficientformer.TFEfficientFormerMeta3D.__init__": 365
        },
        {
            "transformers.models.efficientformer.modeling_tf_efficientformer.TFEfficientFormerMeta3DLayers.__init__": 447
        },
        {
            "transformers.models.efficientformer.modeling_tf_efficientformer.TFEfficientFormerMeta4D.__init__": 481
        },
        {
            "transformers.models.efficientformer.modeling_tf_efficientformer.TFEfficientFormerMeta4DLayers.__init__": 542
        },
        {
            "transformers.models.efficientformer.modeling_tf_efficientformer.TFEfficientFormerIntermediateStage.__init__": 565
        },
        {
            "transformers.models.efficientformer.modeling_tf_efficientformer.TFEfficientFormerLastStage.__init__": 575
        },
        {
            "transformers.models.efficientformer.modeling_tf_efficientformer.TFEfficientFormerEncoder.__init__": 594
        },
        {
            "transformers.models.efficientformer.modeling_tf_efficientformer.TFEfficientFormerMainLayer.__init__": 666
        },
        {
            "transformers.models.efficientformer.modeling_tf_efficientformer.TFEfficientFormerModel.__init__": 776
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/blip/configuration_blip.py": [
        {
            "transformers.models.blip.configuration_blip.BlipTextConfig.__init__": 115
        },
        {
            "transformers.models.blip.configuration_blip.BlipTextConfig.from_pretrained": 163
        },
        {
            "transformers.models.blip.configuration_blip.BlipVisionConfig.__init__": 230
        },
        {
            "transformers.models.blip.configuration_blip.BlipVisionConfig.from_pretrained": 262
        },
        {
            "transformers.models.blip.configuration_blip.BlipConfig.__init__": 328
        },
        {
            "transformers.models.blip.configuration_blip.BlipConfig.from_text_vision_configs": 359
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/blip/image_processing_blip.py": [
        {
            "transformers.models.blip.image_processing_blip.BlipImageProcessor.__init__": 80
        },
        {
            "transformers.models.blip.image_processing_blip.BlipImageProcessor.resize": 107
        },
        {
            "transformers.models.blip.image_processing_blip.BlipImageProcessor.rescale": 140
        },
        {
            "transformers.models.blip.image_processing_blip.BlipImageProcessor.normalize": 160
        },
        {
            "transformers.models.blip.image_processing_blip.BlipImageProcessor.preprocess": 183
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/blip/modeling_blip_text.py": [
        {
            "transformers.models.blip.modeling_blip_text.BlipTextEncoder.custom_forward": 425
        },
        {
            "transformers.models.blip.modeling_blip_text.BlipTextLMHeadModel.prepare_inputs_for_generation": 916
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/blip/processing_blip.py": [
        {
            "transformers.models.blip.processing_blip.BlipProcessor.__call__": 48
        },
        {
            "transformers.models.blip.processing_blip.BlipProcessor.batch_decode": 130
        },
        {
            "transformers.models.blip.processing_blip.BlipProcessor.decode": 137
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/blip/modeling_tf_blip_text.py": [
        {
            "transformers.models.blip.modeling_tf_blip_text.TFBlipTextEmbeddings.__init__": 80
        },
        {
            "transformers.models.blip.modeling_tf_blip_text.TFBlipTextSelfAttention.__init__": 132
        },
        {
            "transformers.models.blip.modeling_tf_blip_text.TFBlipTextSelfOutput.__init__": 254
        },
        {
            "transformers.models.blip.modeling_tf_blip_text.TFBlipTextAttention.__init__": 273
        },
        {
            "transformers.models.blip.modeling_tf_blip_text.TFBlipTextIntermediate.__init__": 307
        },
        {
            "transformers.models.blip.modeling_tf_blip_text.TFBlipTextOutput.__init__": 327
        },
        {
            "transformers.models.blip.modeling_tf_blip_text.TFBlipTextLayer.__init__": 345
        },
        {
            "transformers.models.blip.modeling_tf_blip_text.TFBlipTextEncoder.__init__": 408
        },
        {
            "transformers.models.blip.modeling_tf_blip_text.TFBlipTextPooler.__init__": 486
        },
        {
            "transformers.models.blip.modeling_tf_blip_text.TFBlipTextPredictionHeadTransform.__init__": 507
        },
        {
            "transformers.models.blip.modeling_tf_blip_text.TFBlipTextLMPredictionHead.__init__": 532
        },
        {
            "transformers.models.blip.modeling_tf_blip_text.TFBlipTextOnlyMLMHead.__init__": 557
        },
        {
            "transformers.models.blip.modeling_tf_blip_text.TFBlipTextModel.__init__": 588
        },
        {
            "transformers.models.blip.modeling_tf_blip_text.TFBlipTextLMHeadModel.__init__": 810
        },
        {
            "transformers.models.blip.modeling_tf_blip_text.TFBlipTextLMHeadModel.prepare_inputs_for_generation": 920
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/blip/modeling_blip.py": [
        {
            "transformers.models.blip.modeling_blip.BlipEncoder.custom_forward": 618
        },
        {
            "transformers.models.blip.modeling_blip.BlipForConditionalGeneration.generate": 1023
        },
        {
            "transformers.models.blip.modeling_blip.BlipForQuestionAnswering.generate": 1237
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/blip/modeling_tf_blip.py": [
        {
            "transformers.models.blip.modeling_tf_blip.TFBlipVisionEmbeddings.__init__": 228
        },
        {
            "transformers.models.blip.modeling_tf_blip.TFBlipTextEmbeddings.__init__": 279
        },
        {
            "transformers.models.blip.modeling_tf_blip.TFBlipAttention.__init__": 339
        },
        {
            "transformers.models.blip.modeling_tf_blip.TFBlipMLP.__init__": 407
        },
        {
            "transformers.models.blip.modeling_tf_blip.TFBlipEncoderLayer.__init__": 430
        },
        {
            "transformers.models.blip.modeling_tf_blip.TFBlipEncoder.__init__": 569
        },
        {
            "transformers.models.blip.modeling_tf_blip.TFBlipVisionModel.__init__": 643
        },
        {
            "transformers.models.blip.modeling_tf_blip.TFBlipMainLayer.__init__": 721
        },
        {
            "transformers.models.blip.modeling_tf_blip.TFBlipModel.__init__": 848
        },
        {
            "transformers.models.blip.modeling_tf_blip.TFBlipForConditionalGeneration.__init__": 1003
        },
        {
            "transformers.models.blip.modeling_tf_blip.TFBlipForConditionalGeneration.generate": 1088
        },
        {
            "transformers.models.blip.modeling_tf_blip.TFBlipForQuestionAnswering.__init__": 1174
        },
        {
            "transformers.models.blip.modeling_tf_blip.TFBlipForQuestionAnswering.generate": 1325
        },
        {
            "transformers.models.blip.modeling_tf_blip.TFBlipForImageTextRetrieval.__init__": 1415
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/open_llama/modeling_open_llama.py": [
        {
            "transformers.models.open_llama.modeling_open_llama.OpenLlamaModel.custom_forward": 599
        },
        {
            "transformers.models.open_llama.modeling_open_llama.OpenLlamaForCausalLM.prepare_inputs_for_generation": 768
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/open_llama/configuration_open_llama.py": [
        {
            "transformers.models.open_llama.configuration_open_llama.OpenLlamaConfig.__init__": 86
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/layoutlmv3/configuration_layoutlmv3.py": [
        {
            "transformers.models.layoutlmv3.configuration_layoutlmv3.LayoutLMv3Config.__init__": 124
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/layoutlmv3/tokenization_layoutlmv3_fast.py": [
        {
            "transformers.models.layoutlmv3.tokenization_layoutlmv3_fast.LayoutLMv3TokenizerFast.__init__": 139
        },
        {
            "transformers.models.layoutlmv3.tokenization_layoutlmv3_fast.LayoutLMv3TokenizerFast.__call__": 226
        },
        {
            "transformers.models.layoutlmv3.tokenization_layoutlmv3_fast.LayoutLMv3TokenizerFast.batch_encode_plus": 376
        },
        {
            "transformers.models.layoutlmv3.tokenization_layoutlmv3_fast.LayoutLMv3TokenizerFast.tokenize": 435
        },
        {
            "transformers.models.layoutlmv3.tokenization_layoutlmv3_fast.LayoutLMv3TokenizerFast.encode_plus": 445
        },
        {
            "transformers.models.layoutlmv3.tokenization_layoutlmv3_fast.LayoutLMv3TokenizerFast._encode_plus": 673
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/layoutlmv3/image_processing_layoutlmv3.py": [
        {
            "transformers.models.layoutlmv3.image_processing_layoutlmv3.LayoutLMv3ImageProcessor.__init__": 129
        },
        {
            "transformers.models.layoutlmv3.image_processing_layoutlmv3.LayoutLMv3ImageProcessor.resize": 160
        },
        {
            "transformers.models.layoutlmv3.image_processing_layoutlmv3.LayoutLMv3ImageProcessor.rescale": 187
        },
        {
            "transformers.models.layoutlmv3.image_processing_layoutlmv3.LayoutLMv3ImageProcessor.normalize": 207
        },
        {
            "transformers.models.layoutlmv3.image_processing_layoutlmv3.LayoutLMv3ImageProcessor.preprocess": 230
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/layoutlmv3/feature_extraction_layoutlmv3.py": [
        {
            "transformers.models.layoutlmv3.feature_extraction_layoutlmv3.LayoutLMv3FeatureExtractor.__init__": 29
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/layoutlmv3/tokenization_layoutlmv3.py": [
        {
            "transformers.models.layoutlmv3.tokenization_layoutlmv3.LayoutLMv3Tokenizer.__init__": 276
        },
        {
            "transformers.models.layoutlmv3.tokenization_layoutlmv3.LayoutLMv3Tokenizer.prepare_for_tokenization": 535
        },
        {
            "transformers.models.layoutlmv3.tokenization_layoutlmv3.LayoutLMv3Tokenizer.__call__": 549
        },
        {
            "transformers.models.layoutlmv3.tokenization_layoutlmv3.LayoutLMv3Tokenizer.batch_encode_plus": 699
        },
        {
            "transformers.models.layoutlmv3.tokenization_layoutlmv3.LayoutLMv3Tokenizer._batch_encode_plus": 758
        },
        {
            "transformers.models.layoutlmv3.tokenization_layoutlmv3.LayoutLMv3Tokenizer.encode": 887
        },
        {
            "transformers.models.layoutlmv3.tokenization_layoutlmv3.LayoutLMv3Tokenizer.encode_plus": 935
        },
        {
            "transformers.models.layoutlmv3.tokenization_layoutlmv3.LayoutLMv3Tokenizer._encode_plus": 1002
        },
        {
            "transformers.models.layoutlmv3.tokenization_layoutlmv3.LayoutLMv3Tokenizer.prepare_for_model": 1055
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/layoutlmv3/modeling_layoutlmv3.py": [
        {
            "transformers.models.layoutlmv3.modeling_layoutlmv3.LayoutLMv3Encoder.custom_forward": 665
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/layoutlmv3/modeling_tf_layoutlmv3.py": [
        {
            "transformers.models.layoutlmv3.modeling_tf_layoutlmv3.TFLayoutLMv3PatchEmbeddings.__init__": 71
        },
        {
            "transformers.models.layoutlmv3.modeling_tf_layoutlmv3.TFLayoutLMv3TextEmbeddings.__init__": 106
        },
        {
            "transformers.models.layoutlmv3.modeling_tf_layoutlmv3.TFLayoutLMv3SelfAttention.__init__": 265
        },
        {
            "transformers.models.layoutlmv3.modeling_tf_layoutlmv3.TFLayoutLMv3SelfOutput.__init__": 378
        },
        {
            "transformers.models.layoutlmv3.modeling_tf_layoutlmv3.TFLayoutLMv3Attention.__init__": 396
        },
        {
            "transformers.models.layoutlmv3.modeling_tf_layoutlmv3.TFLayoutLMv3Intermediate.__init__": 427
        },
        {
            "transformers.models.layoutlmv3.modeling_tf_layoutlmv3.TFLayoutLMv3Output.__init__": 448
        },
        {
            "transformers.models.layoutlmv3.modeling_tf_layoutlmv3.TFLayoutLMv3Layer.__init__": 466
        },
        {
            "transformers.models.layoutlmv3.modeling_tf_layoutlmv3.TFLayoutLMv3Encoder.__init__": 500
        },
        {
            "transformers.models.layoutlmv3.modeling_tf_layoutlmv3.TFLayoutLMv3MainLayer.__init__": 658
        },
        {
            "transformers.models.layoutlmv3.modeling_tf_layoutlmv3.TFLayoutLMv3Model.__init__": 1115
        },
        {
            "transformers.models.layoutlmv3.modeling_tf_layoutlmv3.TFLayoutLMv3ClassificationHead.__init__": 1189
        },
        {
            "transformers.models.layoutlmv3.modeling_tf_layoutlmv3.TFLayoutLMv3ForSequenceClassification.__init__": 1230
        },
        {
            "transformers.models.layoutlmv3.modeling_tf_layoutlmv3.TFLayoutLMv3ForTokenClassification.__init__": 1334
        },
        {
            "transformers.models.layoutlmv3.modeling_tf_layoutlmv3.TFLayoutLMv3ForQuestionAnswering.__init__": 1456
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/layoutlmv3/processing_layoutlmv3.py": [
        {
            "transformers.models.layoutlmv3.processing_layoutlmv3.LayoutLMv3Processor.__init__": 50
        },
        {
            "transformers.models.layoutlmv3.processing_layoutlmv3.LayoutLMv3Processor.__call__": 67
        },
        {
            "transformers.models.layoutlmv3.processing_layoutlmv3.LayoutLMv3Processor.batch_decode": 165
        },
        {
            "transformers.models.layoutlmv3.processing_layoutlmv3.LayoutLMv3Processor.decode": 172
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/focalnet/modeling_focalnet.py": [
        {
            "transformers.models.focalnet.modeling_focalnet.FocalNetEncoder.custom_forward": 591
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/focalnet/configuration_focalnet.py": [
        {
            "transformers.models.focalnet.configuration_focalnet.FocalNetConfig.__init__": 109
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/openai/modeling_openai.py": [
        {
            "transformers.models.openai.modeling_openai.OpenAIGPTLMHeadModel.prepare_inputs_for_generation": 609
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/openai/tokenization_openai_fast.py": [
        {
            "transformers.models.openai.tokenization_openai_fast.OpenAIGPTTokenizerFast.__init__": 67
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/openai/tokenization_openai.py": [
        {
            "transformers.models.openai.tokenization_openai.OpenAIGPTTokenizer.__init__": 259
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/openai/configuration_openai.py": [
        {
            "transformers.models.openai.configuration_openai.OpenAIGPTConfig.__init__": 121
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/openai/modeling_tf_openai.py": [
        {
            "transformers.models.openai.modeling_tf_openai.TFAttention.__init__": 64
        },
        {
            "transformers.models.openai.modeling_tf_openai.TFMLP.__init__": 158
        },
        {
            "transformers.models.openai.modeling_tf_openai.TFBlock.__init__": 174
        },
        {
            "transformers.models.openai.modeling_tf_openai.TFOpenAIGPTMainLayer.__init__": 198
        },
        {
            "transformers.models.openai.modeling_tf_openai.TFOpenAIGPTModel.__init__": 493
        },
        {
            "transformers.models.openai.modeling_tf_openai.TFOpenAIGPTLMHeadModel.__init__": 540
        },
        {
            "transformers.models.openai.modeling_tf_openai.TFOpenAIGPTLMHeadModel.prepare_inputs_for_generation": 613
        },
        {
            "transformers.models.openai.modeling_tf_openai.TFOpenAIGPTDoubleHeadsModel.__init__": 627
        },
        {
            "transformers.models.openai.modeling_tf_openai.TFOpenAIGPTForSequenceClassification.__init__": 754
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/sew/configuration_sew.py": [
        {
            "transformers.models.sew.configuration_sew.SEWConfig.__init__": 157
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/sew/modeling_sew.py": [
        {
            "transformers.models.sew.modeling_sew.SEWFeatureEncoder.custom_forward": 365
        },
        {
            "transformers.models.sew.modeling_sew.SEWEncoder.custom_forward": 678
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/vit_hybrid/configuration_vit_hybrid.py": [
        {
            "transformers.models.vit_hybrid.configuration_vit_hybrid.ViTHybridConfig.__init__": 93
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/vit_hybrid/image_processing_vit_hybrid.py": [
        {
            "transformers.models.vit_hybrid.image_processing_vit_hybrid.ViTHybridImageProcessor.__init__": 91
        },
        {
            "transformers.models.vit_hybrid.image_processing_vit_hybrid.ViTHybridImageProcessor.resize": 124
        },
        {
            "transformers.models.vit_hybrid.image_processing_vit_hybrid.ViTHybridImageProcessor.center_crop": 152
        },
        {
            "transformers.models.vit_hybrid.image_processing_vit_hybrid.ViTHybridImageProcessor.rescale": 176
        },
        {
            "transformers.models.vit_hybrid.image_processing_vit_hybrid.ViTHybridImageProcessor.normalize": 196
        },
        {
            "transformers.models.vit_hybrid.image_processing_vit_hybrid.ViTHybridImageProcessor.preprocess": 219
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/vit_hybrid/modeling_vit_hybrid.py": [
        {
            "transformers.models.vit_hybrid.modeling_vit_hybrid.ViTHybridEncoder.custom_forward": 420
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/swin2sr/configuration_swin2sr.py": [
        {
            "transformers.models.swin2sr.configuration_swin2sr.Swin2SRConfig.__init__": 106
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/swin2sr/image_processing_swin2sr.py": [
        {
            "transformers.models.swin2sr.image_processing_swin2sr.Swin2SRImageProcessor.__init__": 45
        },
        {
            "transformers.models.swin2sr.image_processing_swin2sr.Swin2SRImageProcessor.rescale": 60
        },
        {
            "transformers.models.swin2sr.image_processing_swin2sr.Swin2SRImageProcessor.preprocess": 106
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/swin2sr/modeling_swin2sr.py": [
        {
            "transformers.models.swin2sr.modeling_swin2sr.Swin2SREncoder.custom_forward": 751
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/canine/configuration_canine.py": [
        {
            "transformers.models.canine.configuration_canine.CanineConfig.__init__": 94
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/canine/tokenization_canine.py": [
        {
            "transformers.models.canine.tokenization_canine.CanineTokenizer.__init__": 79
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/canine/modeling_canine.py": [
        {
            "transformers.models.canine.modeling_canine.CanineEncoder.custom_forward": 798
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/gpt_neox/modeling_gpt_neox.py": [
        {
            "transformers.models.gpt_neox.modeling_gpt_neox.GPTNeoXModel.custom_forward": 550
        },
        {
            "transformers.models.gpt_neox.modeling_gpt_neox.GPTNeoXForCausalLM.prepare_inputs_for_generation": 711
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/gpt_neox/configuration_gpt_neox.py": [
        {
            "transformers.models.gpt_neox.configuration_gpt_neox.GPTNeoXConfig.__init__": 92
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/gpt_neox/tokenization_gpt_neox_fast.py": [
        {
            "transformers.models.gpt_neox.tokenization_gpt_neox_fast.GPTNeoXTokenizerFast.__init__": 102
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/mobilenet_v2/configuration_mobilenet_v2.py": [
        {
            "transformers.models.mobilenet_v2.configuration_mobilenet_v2.MobileNetV2Config.__init__": 101
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/mobilenet_v2/image_processing_mobilenet_v2.py": [
        {
            "transformers.models.mobilenet_v2.image_processing_mobilenet_v2.MobileNetV2ImageProcessor.__init__": 91
        },
        {
            "transformers.models.mobilenet_v2.image_processing_mobilenet_v2.MobileNetV2ImageProcessor.resize": 121
        },
        {
            "transformers.models.mobilenet_v2.image_processing_mobilenet_v2.MobileNetV2ImageProcessor.center_crop": 149
        },
        {
            "transformers.models.mobilenet_v2.image_processing_mobilenet_v2.MobileNetV2ImageProcessor.rescale": 173
        },
        {
            "transformers.models.mobilenet_v2.image_processing_mobilenet_v2.MobileNetV2ImageProcessor.normalize": 195
        },
        {
            "transformers.models.mobilenet_v2.image_processing_mobilenet_v2.MobileNetV2ImageProcessor.preprocess": 224
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/mobilenet_v2/feature_extraction_mobilenet_v2.py": [
        {
            "transformers.models.mobilenet_v2.feature_extraction_mobilenet_v2.MobileNetV2FeatureExtractor.__init__": 27
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/bertweet/tokenization_bertweet.py": [
        {
            "transformers.models.bertweet.tokenization_bertweet.BertweetTokenizer.__init__": 123
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/blenderbot/tokenization_blenderbot.py": [
        {
            "transformers.models.blenderbot.tokenization_blenderbot.BlenderbotTokenizer.__init__": 177
        },
        {
            "transformers.models.blenderbot.tokenization_blenderbot.BlenderbotTokenizer.prepare_for_tokenization": 394
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/blenderbot/configuration_blenderbot.py": [
        {
            "transformers.models.blenderbot.configuration_blenderbot.BlenderbotConfig.__init__": 111
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/blenderbot/modeling_tf_blenderbot.py": [
        {
            "transformers.models.blenderbot.modeling_tf_blenderbot.TFBlenderbotLearnedPositionalEmbedding.__init__": 126
        },
        {
            "transformers.models.blenderbot.modeling_tf_blenderbot.TFBlenderbotAttention.__init__": 145
        },
        {
            "transformers.models.blenderbot.modeling_tf_blenderbot.TFBlenderbotEncoderLayer.__init__": 297
        },
        {
            "transformers.models.blenderbot.modeling_tf_blenderbot.TFBlenderbotDecoderLayer.__init__": 354
        },
        {
            "transformers.models.blenderbot.modeling_tf_blenderbot.TFBlenderbotEncoder.__init__": 626
        },
        {
            "transformers.models.blenderbot.modeling_tf_blenderbot.TFBlenderbotDecoder.__init__": 791
        },
        {
            "transformers.models.blenderbot.modeling_tf_blenderbot.TFBlenderbotMainLayer.__init__": 1014
        },
        {
            "transformers.models.blenderbot.modeling_tf_blenderbot.TFBlenderbotMainLayer.call": 1039
        },
        {
            "transformers.models.blenderbot.modeling_tf_blenderbot.TFBlenderbotModel.__init__": 1123
        },
        {
            "transformers.models.blenderbot.modeling_tf_blenderbot.TFBlenderbotModel.from_pretrained": 1135
        },
        {
            "transformers.models.blenderbot.modeling_tf_blenderbot.TFBlenderbotModel.call": 1157
        },
        {
            "transformers.models.blenderbot.modeling_tf_blenderbot.BiasLayer.__init__": 1228
        },
        {
            "transformers.models.blenderbot.modeling_tf_blenderbot.TFBlenderbotForConditionalGeneration.__init__": 1249
        },
        {
            "transformers.models.blenderbot.modeling_tf_blenderbot.TFBlenderbotForConditionalGeneration.from_pretrained": 1282
        },
        {
            "transformers.models.blenderbot.modeling_tf_blenderbot.TFBlenderbotForConditionalGeneration.prepare_inputs_for_generation": 1402
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/blenderbot/tokenization_blenderbot_fast.py": [
        {
            "transformers.models.blenderbot.tokenization_blenderbot_fast.BlenderbotTokenizerFast.__init__": 138
        },
        {
            "transformers.models.blenderbot.tokenization_blenderbot_fast.BlenderbotTokenizerFast._batch_encode_plus": 235
        },
        {
            "transformers.models.blenderbot.tokenization_blenderbot_fast.BlenderbotTokenizerFast._encode_plus": 245
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/blenderbot/modeling_flax_blenderbot.py": [
        {
            "transformers.models.blenderbot.modeling_flax_blenderbot.FlaxBlenderbotPreTrainedModel.__init__": 884
        },
        {
            "transformers.models.blenderbot.modeling_flax_blenderbot.FlaxBlenderbotPreTrainedModel._decoder_forward": 953
        },
        {
            "transformers.models.blenderbot.modeling_flax_blenderbot.FlaxBlenderbotPreTrainedModel._encoder_forward": 1019
        },
        {
            "transformers.models.blenderbot.modeling_flax_blenderbot.FlaxBlenderbotPreTrainedModel._decoder_forward": 1116
        },
        {
            "transformers.models.blenderbot.modeling_flax_blenderbot.FlaxBlenderbotForConditionalGeneration._decoder_forward": 1384
        },
        {
            "transformers.models.blenderbot.modeling_flax_blenderbot.FlaxBlenderbotForConditionalGeneration.prepare_inputs_for_generation": 1443
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/blenderbot/modeling_blenderbot.py": [
        {
            "transformers.models.blenderbot.modeling_blenderbot.BlenderbotEncoder.custom_forward": 777
        },
        {
            "transformers.models.blenderbot.modeling_blenderbot.BlenderbotDecoder.custom_forward": 1031
        },
        {
            "transformers.models.blenderbot.modeling_blenderbot.BlenderbotModel.from_pretrained": 1115
        },
        {
            "transformers.models.blenderbot.modeling_blenderbot.BlenderbotForConditionalGeneration.from_pretrained": 1260
        },
        {
            "transformers.models.blenderbot.modeling_blenderbot.BlenderbotForConditionalGeneration.prepare_inputs_for_generation": 1381
        },
        {
            "transformers.models.blenderbot.modeling_blenderbot.BlenderbotDecoderWrapper.forward": 1431
        },
        {
            "transformers.models.blenderbot.modeling_blenderbot.BlenderbotForCausalLM.prepare_inputs_for_generation": 1616
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/imagegpt/feature_extraction_imagegpt.py": [
        {
            "transformers.models.imagegpt.feature_extraction_imagegpt.ImageGPTFeatureExtractor.__init__": 27
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/imagegpt/configuration_imagegpt.py": [
        {
            "transformers.models.imagegpt.configuration_imagegpt.ImageGPTConfig.__init__": 110
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/imagegpt/image_processing_imagegpt.py": [
        {
            "transformers.models.imagegpt.image_processing_imagegpt.ImageGPTImageProcessor.__init__": 82
        },
        {
            "transformers.models.imagegpt.image_processing_imagegpt.ImageGPTImageProcessor.resize": 103
        },
        {
            "transformers.models.imagegpt.image_processing_imagegpt.ImageGPTImageProcessor.preprocess": 149
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/imagegpt/modeling_imagegpt.py": [
        {
            "transformers.models.imagegpt.modeling_imagegpt.ImageGPTPreTrainedModel.__init__": 498
        },
        {
            "transformers.models.imagegpt.modeling_imagegpt.ImageGPTModel.forward": 652
        },
        {
            "transformers.models.imagegpt.modeling_imagegpt.ImageGPTModel.custom_forward": 823
        },
        {
            "transformers.models.imagegpt.modeling_imagegpt.ImageGPTForCausalImageModeling.prepare_inputs_for_generation": 915
        },
        {
            "transformers.models.imagegpt.modeling_imagegpt.ImageGPTForCausalImageModeling.forward": 945
        },
        {
            "transformers.models.imagegpt.modeling_imagegpt.ImageGPTForImageClassification.forward": 1100
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/byt5/tokenization_byt5.py": [
        {
            "transformers.models.byt5.tokenization_byt5.ByT5Tokenizer.__init__": 63
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/chinese_clip/modeling_chinese_clip.py": [
        {
            "transformers.models.chinese_clip.modeling_chinese_clip.ChineseCLIPTextEncoder.custom_forward": 912
        },
        {
            "transformers.models.chinese_clip.modeling_chinese_clip.ChineseCLIPVisionEncoder.custom_forward": 1021
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/chinese_clip/image_processing_chinese_clip.py": [
        {
            "transformers.models.chinese_clip.image_processing_chinese_clip.ChineseCLIPImageProcessor.__init__": 91
        },
        {
            "transformers.models.chinese_clip.image_processing_chinese_clip.ChineseCLIPImageProcessor.resize": 124
        },
        {
            "transformers.models.chinese_clip.image_processing_chinese_clip.ChineseCLIPImageProcessor.center_crop": 152
        },
        {
            "transformers.models.chinese_clip.image_processing_chinese_clip.ChineseCLIPImageProcessor.rescale": 174
        },
        {
            "transformers.models.chinese_clip.image_processing_chinese_clip.ChineseCLIPImageProcessor.normalize": 194
        },
        {
            "transformers.models.chinese_clip.image_processing_chinese_clip.ChineseCLIPImageProcessor.preprocess": 217
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/chinese_clip/configuration_chinese_clip.py": [
        {
            "transformers.models.chinese_clip.configuration_chinese_clip.ChineseCLIPTextConfig.__init__": 107
        },
        {
            "transformers.models.chinese_clip.configuration_chinese_clip.ChineseCLIPTextConfig.from_pretrained": 146
        },
        {
            "transformers.models.chinese_clip.configuration_chinese_clip.ChineseCLIPVisionConfig.__init__": 215
        },
        {
            "transformers.models.chinese_clip.configuration_chinese_clip.ChineseCLIPVisionConfig.from_pretrained": 249
        },
        {
            "transformers.models.chinese_clip.configuration_chinese_clip.ChineseCLIPConfig.__init__": 315
        },
        {
            "transformers.models.chinese_clip.configuration_chinese_clip.ChineseCLIPConfig.from_text_vision_configs": 405
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/chinese_clip/feature_extraction_chinese_clip.py": [
        {
            "transformers.models.chinese_clip.feature_extraction_chinese_clip.ChineseCLIPFeatureExtractor.__init__": 27
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/chinese_clip/processing_chinese_clip.py": [
        {
            "transformers.models.chinese_clip.processing_chinese_clip.ChineseCLIPProcessor.__init__": 43
        },
        {
            "transformers.models.chinese_clip.processing_chinese_clip.ChineseCLIPProcessor.__call__": 61
        },
        {
            "transformers.models.chinese_clip.processing_chinese_clip.ChineseCLIPProcessor.batch_decode": 114
        },
        {
            "transformers.models.chinese_clip.processing_chinese_clip.ChineseCLIPProcessor.decode": 121
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/esm/modeling_esm.py": [
        {
            "transformers.models.esm.modeling_esm.EsmEncoder.custom_forward": 608
        },
        {
            "transformers.models.esm.modeling_esm.EsmLMHead.forward": 1065
        },
        {
            "transformers.models.esm.modeling_esm.EsmClassificationHead.forward": 1260
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/esm/tokenization_esm.py": [
        {
            "transformers.models.esm.tokenization_esm.EsmTokenizer.__init__": 57
        },
        {
            "transformers.models.esm.tokenization_esm.EsmTokenizer._tokenize": 85
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/esm/modeling_tf_esm.py": [
        {
            "transformers.models.esm.modeling_tf_esm.TFEsmIntermediate.__init__": 473
        },
        {
            "transformers.models.esm.modeling_tf_esm.TFEsmPooler.__init__": 671
        },
        {
            "transformers.models.esm.modeling_tf_esm.TFEsmMainLayer.__init__": 776
        },
        {
            "transformers.models.esm.modeling_tf_esm.TFEsmModel.__init__": 976
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/esm/configuration_esm.py": [
        {
            "transformers.models.esm.configuration_esm.EsmConfig.__init__": 102
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/esm/modeling_esmfold.py": [
        {
            "transformers.models.esm.modeling_esmfold.EsmFoldTriangularSelfAttentionBlock.forward": 1186
        },
        {
            "transformers.models.esm.modeling_esmfold.EsmForProteinFolding.infer_pdb": 2311
        },
        {
            "transformers.models.esm.modeling_esmfold.EsmForProteinFolding.infer_pdbs": 2317
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/esm/openfold_utils/loss.py": [
        {
            "transformers.models.esm.openfold_utils.loss.compute_predicted_aligned_error": 39
        },
        {
            "transformers.models.esm.openfold_utils.loss.compute_tm": 74
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/regnet/configuration_regnet.py": [
        {
            "transformers.models.regnet.configuration_regnet.RegNetConfig.__init__": 72
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/regnet/modeling_flax_regnet.py": [
        {
            "transformers.models.regnet.modeling_flax_regnet.Identity.__call__": 98
        },
        {
            "transformers.models.regnet.modeling_flax_regnet.FlaxRegNetPreTrainedModel.__init__": 564
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/regnet/modeling_tf_regnet.py": [
        {
            "transformers.models.regnet.modeling_tf_regnet.TFRegNetConvLayer.__init__": 54
        },
        {
            "transformers.models.regnet.modeling_tf_regnet.TFRegNetEmbeddings.__init__": 91
        },
        {
            "transformers.models.regnet.modeling_tf_regnet.TFRegNetShortCut.__init__": 123
        },
        {
            "transformers.models.regnet.modeling_tf_regnet.TFRegNetSELayer.__init__": 139
        },
        {
            "transformers.models.regnet.modeling_tf_regnet.TFRegNetXLayer.__init__": 161
        },
        {
            "transformers.models.regnet.modeling_tf_regnet.TFRegNetYLayer.__init__": 195
        },
        {
            "transformers.models.regnet.modeling_tf_regnet.TFRegNetStage.__init__": 229
        },
        {
            "transformers.models.regnet.modeling_tf_regnet.TFRegNetEncoder.__init__": 248
        },
        {
            "transformers.models.regnet.modeling_tf_regnet.TFRegNetMainLayer.__init__": 290
        },
        {
            "transformers.models.regnet.modeling_tf_regnet.TFRegNetModel.__init__": 381
        },
        {
            "transformers.models.regnet.modeling_tf_regnet.TFRegNetForImageClassification.__init__": 430
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/swin/modeling_tf_swin.py": [
        {
            "transformers.models.swin.modeling_tf_swin.TFSwinEmbeddings.__init__": 275
        },
        {
            "transformers.models.swin.modeling_tf_swin.TFSwinPatchEmbeddings.__init__": 330
        },
        {
            "transformers.models.swin.modeling_tf_swin.TFSwinPatchMerging.__init__": 398
        },
        {
            "transformers.models.swin.modeling_tf_swin.TFSwinDropPath.__init__": 450
        },
        {
            "transformers.models.swin.modeling_tf_swin.TFSwinSelfAttention.__init__": 460
        },
        {
            "transformers.models.swin.modeling_tf_swin.TFSwinSelfOutput.__init__": 596
        },
        {
            "transformers.models.swin.modeling_tf_swin.TFSwinAttention.__init__": 608
        },
        {
            "transformers.models.swin.modeling_tf_swin.TFSwinIntermediate.__init__": 636
        },
        {
            "transformers.models.swin.modeling_tf_swin.TFSwinOutput.__init__": 651
        },
        {
            "transformers.models.swin.modeling_tf_swin.TFSwinLayer.__init__": 663
        },
        {
            "transformers.models.swin.modeling_tf_swin.TFSwinStage.__init__": 794
        },
        {
            "transformers.models.swin.modeling_tf_swin.TFSwinEncoder.__init__": 866
        },
        {
            "transformers.models.swin.modeling_tf_swin.AdaptiveAveragePooling1D.__init__": 1032
        },
        {
            "transformers.models.swin.modeling_tf_swin.AdaptiveAveragePooling1D.call": 1044
        },
        {
            "transformers.models.swin.modeling_tf_swin.TFSwinMainLayer.__init__": 1077
        },
        {
            "transformers.models.swin.modeling_tf_swin.TFSwinModel.__init__": 1174
        },
        {
            "transformers.models.swin.modeling_tf_swin.TFSwinPixelShuffle.__init__": 1229
        },
        {
            "transformers.models.swin.modeling_tf_swin.TFSwinDecoder.__init__": 1253
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/swin/modeling_swin.py": [
        {
            "transformers.models.swin.modeling_swin.SwinEncoder.custom_forward": 830
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/swin/configuration_swin.py": [
        {
            "transformers.models.swin.configuration_swin.SwinConfig.__init__": 115
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/t5/modeling_t5.py": [
        {
            "transformers.models.t5.modeling_t5.T5Stack.custom_forward": 1072
        },
        {
            "transformers.models.t5.modeling_t5.T5ForConditionalGeneration.prepare_inputs_for_generation": 1774
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/t5/configuration_t5.py": [
        {
            "transformers.models.t5.configuration_t5.T5Config.__init__": 82
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/t5/tokenization_t5.py": [
        {
            "transformers.models.t5.tokenization_t5.T5Tokenizer.__init__": 114
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/t5/tokenization_t5_fast.py": [
        {
            "transformers.models.t5.tokenization_t5_fast.T5TokenizerFast.__init__": 109
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/t5/modeling_tf_t5.py": [
        {
            "transformers.models.t5.modeling_tf_t5.TFT5LayerNorm.__init__": 78
        },
        {
            "transformers.models.t5.modeling_tf_t5.TFT5DenseActDense.__init__": 97
        },
        {
            "transformers.models.t5.modeling_tf_t5.TFT5DenseGatedActDense.__init__": 123
        },
        {
            "transformers.models.t5.modeling_tf_t5.TFT5LayerFF.__init__": 153
        },
        {
            "transformers.models.t5.modeling_tf_t5.TFT5Attention.__init__": 173
        },
        {
            "transformers.models.t5.modeling_tf_t5.TFT5LayerSelfAttention.__init__": 435
        },
        {
            "transformers.models.t5.modeling_tf_t5.TFT5LayerCrossAttention.__init__": 473
        },
        {
            "transformers.models.t5.modeling_tf_t5.TFT5Block.__init__": 515
        },
        {
            "transformers.models.t5.modeling_tf_t5.TFT5MainLayer.__init__": 625
        },
        {
            "transformers.models.t5.modeling_tf_t5.TFT5Model.__init__": 1094
        },
        {
            "transformers.models.t5.modeling_tf_t5.TFT5ForConditionalGeneration.__init__": 1227
        },
        {
            "transformers.models.t5.modeling_tf_t5.TFT5ForConditionalGeneration.prepare_inputs_for_generation": 1443
        },
        {
            "transformers.models.t5.modeling_tf_t5.TFT5EncoderModel.__init__": 1480
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/t5/modeling_flax_t5.py": [
        {
            "transformers.models.t5.modeling_flax_t5.FlaxT5PreTrainedModel.__init__": 937
        },
        {
            "transformers.models.t5.modeling_flax_t5.FlaxT5PreTrainedModel._decoder_forward": 1054
        },
        {
            "transformers.models.t5.modeling_flax_t5.FlaxT5PreTrainedModel._encoder_forward": 1114
        },
        {
            "transformers.models.t5.modeling_flax_t5.FlaxT5PreTrainedModel._decoder_forward": 1199
        },
        {
            "transformers.models.t5.modeling_flax_t5.FlaxT5ForConditionalGeneration._decoder_forward": 1677
        },
        {
            "transformers.models.t5.modeling_flax_t5.FlaxT5ForConditionalGeneration.prepare_inputs_for_generation": 1739
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/efficientnet/image_processing_efficientnet.py": [
        {
            "transformers.models.efficientnet.image_processing_efficientnet.EfficientNetImageProcessor.__init__": 84
        },
        {
            "transformers.models.efficientnet.image_processing_efficientnet.EfficientNetImageProcessor.resize": 119
        },
        {
            "transformers.models.efficientnet.image_processing_efficientnet.EfficientNetImageProcessor.center_crop": 147
        },
        {
            "transformers.models.efficientnet.image_processing_efficientnet.EfficientNetImageProcessor.rescale": 171
        },
        {
            "transformers.models.efficientnet.image_processing_efficientnet.EfficientNetImageProcessor.normalize": 201
        },
        {
            "transformers.models.efficientnet.image_processing_efficientnet.EfficientNetImageProcessor.preprocess": 224
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/efficientnet/configuration_efficientnet.py": [
        {
            "transformers.models.efficientnet.configuration_efficientnet.EfficientNetConfig.__init__": 105
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/fnet/tokenization_fnet_fast.py": [
        {
            "transformers.models.fnet.tokenization_fnet_fast.FNetTokenizerFast.__init__": 95
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/fnet/tokenization_fnet.py": [
        {
            "transformers.models.fnet.tokenization_fnet.FNetTokenizer.__init__": 104
        },
        {
            "transformers.models.fnet.tokenization_fnet.FNetTokenizer._decode": 235
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/fnet/configuration_fnet.py": [
        {
            "transformers.models.fnet.configuration_fnet.FNetConfig.__init__": 89
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/fnet/modeling_fnet.py": [
        {
            "transformers.models.fnet.modeling_fnet.FNetEncoder.custom_forward": 295
        },
        {
            "transformers.models.fnet.modeling_fnet.FNetForNextSentencePrediction.forward": 799
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/splinter/configuration_splinter.py": [
        {
            "transformers.models.splinter.configuration_splinter.SplinterConfig.__init__": 93
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/splinter/tokenization_splinter.py": [
        {
            "transformers.models.splinter.tokenization_splinter.SplinterTokenizer.__init__": 124
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/splinter/modeling_splinter.py": [
        {
            "transformers.models.splinter.modeling_splinter.SplinterEncoder.custom_forward": 462
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/splinter/tokenization_splinter_fast.py": [
        {
            "transformers.models.splinter.tokenization_splinter_fast.SplinterTokenizerFast.__init__": 103
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/albert/modeling_flax_albert.py": [
        {
            "transformers.models.albert.modeling_flax_albert.FlaxAlbertPreTrainedModel.__init__": 518
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/albert/configuration_albert.py": [
        {
            "transformers.models.albert.configuration_albert.AlbertConfig.__init__": 113
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/albert/modeling_tf_albert.py": [
        {
            "transformers.models.albert.modeling_tf_albert.TFAlbertEmbeddings.__init__": 139
        },
        {
            "transformers.models.albert.modeling_tf_albert.TFAlbertAttention.__init__": 218
        },
        {
            "transformers.models.albert.modeling_tf_albert.TFAlbertLayer.__init__": 312
        },
        {
            "transformers.models.albert.modeling_tf_albert.TFAlbertLayerGroup.__init__": 361
        },
        {
            "transformers.models.albert.modeling_tf_albert.TFAlbertTransformer.__init__": 404
        },
        {
            "transformers.models.albert.modeling_tf_albert.TFAlbertMLMHead.__init__": 472
        },
        {
            "transformers.models.albert.modeling_tf_albert.TFAlbertMainLayer.__init__": 531
        },
        {
            "transformers.models.albert.modeling_tf_albert.TFAlbertModel.__init__": 788
        },
        {
            "transformers.models.albert.modeling_tf_albert.TFAlbertForPreTraining.__init__": 840
        },
        {
            "transformers.models.albert.modeling_tf_albert.TFAlbertSOPHead.__init__": 926
        },
        {
            "transformers.models.albert.modeling_tf_albert.TFAlbertForMaskedLM.__init__": 948
        },
        {
            "transformers.models.albert.modeling_tf_albert.TFAlbertForSequenceClassification.__init__": 1051
        },
        {
            "transformers.models.albert.modeling_tf_albert.TFAlbertForTokenClassification.__init__": 1133
        },
        {
            "transformers.models.albert.modeling_tf_albert.TFAlbertForQuestionAnswering.__init__": 1215
        },
        {
            "transformers.models.albert.modeling_tf_albert.TFAlbertForMultipleChoice.__init__": 1311
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/albert/tokenization_albert.py": [
        {
            "transformers.models.albert.tokenization_albert.AlbertTokenizer.__init__": 136
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/albert/tokenization_albert_fast.py": [
        {
            "transformers.models.albert.tokenization_albert_fast.AlbertTokenizerFast.__init__": 124
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/xlm_roberta_xl/configuration_xlm_roberta_xl.py": [
        {
            "transformers.models.xlm_roberta_xl.configuration_xlm_roberta_xl.XLMRobertaXLConfig.__init__": 102
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/xlm_roberta_xl/modeling_xlm_roberta_xl.py": [
        {
            "transformers.models.xlm_roberta_xl.modeling_xlm_roberta_xl.XLMRobertaXLEncoder.custom_forward": 502
        },
        {
            "transformers.models.xlm_roberta_xl.modeling_xlm_roberta_xl.XLMRobertaXLForCausalLM.prepare_inputs_for_generation": 980
        },
        {
            "transformers.models.xlm_roberta_xl.modeling_xlm_roberta_xl.XLMRobertaXLLMHead.forward": 1107
        },
        {
            "transformers.models.xlm_roberta_xl.modeling_xlm_roberta_xl.XLMRobertaXLClassificationHead.forward": 1415
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/nezha/modeling_nezha.py": [
        {
            "transformers.models.nezha.modeling_nezha.NezhaEncoder.custom_forward": 582
        },
        {
            "transformers.models.nezha.modeling_nezha.NezhaForMaskedLM.prepare_inputs_for_generation": 1227
        },
        {
            "transformers.models.nezha.modeling_nezha.NezhaForNextSentencePrediction.forward": 1260
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/nezha/configuration_nezha.py": [
        {
            "transformers.models.nezha.configuration_nezha.NezhaConfig.__init__": 69
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/squeezebert/configuration_squeezebert.py": [
        {
            "transformers.models.squeezebert.configuration_squeezebert.SqueezeBertConfig.__init__": 115
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/squeezebert/tokenization_squeezebert.py": [
        {
            "transformers.models.squeezebert.tokenization_squeezebert.SqueezeBertTokenizer.__init__": 126
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/squeezebert/tokenization_squeezebert_fast.py": [
        {
            "transformers.models.squeezebert.tokenization_squeezebert_fast.SqueezeBertTokenizerFast.__init__": 115
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/lilt/modeling_lilt.py": [
        {
            "transformers.models.lilt.modeling_lilt.LiltEncoder.custom_forward": 517
        },
        {
            "transformers.models.lilt.modeling_lilt.LiltClassificationHead.forward": 1081
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/lilt/configuration_lilt.py": [
        {
            "transformers.models.lilt.configuration_lilt.LiltConfig.__init__": 95
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/vit_msn/modeling_vit_msn.py": [
        {
            "transformers.models.vit_msn.modeling_vit_msn.ViTMSNEncoder.custom_forward": 392
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/vit_msn/configuration_vit_msn.py": [
        {
            "transformers.models.vit_msn.configuration_vit_msn.ViTMSNConfig.__init__": 86
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/swiftformer/configuration_swiftformer.py": [
        {
            "transformers.models.swiftformer.configuration_swiftformer.SwiftFormerConfig.__init__": 90
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/videomae/configuration_videomae.py": [
        {
            "transformers.models.videomae.configuration_videomae.VideoMAEConfig.__init__": 99
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/videomae/feature_extraction_videomae.py": [
        {
            "transformers.models.videomae.feature_extraction_videomae.VideoMAEFeatureExtractor.__init__": 27
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/videomae/modeling_videomae.py": [
        {
            "transformers.models.videomae.modeling_videomae.VideoMAEEncoder.custom_forward": 439
        },
        {
            "transformers.models.videomae.modeling_videomae.VideoMAEDecoder.custom_forward": 722
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/videomae/image_processing_videomae.py": [
        {
            "transformers.models.videomae.image_processing_videomae.VideoMAEImageProcessor.__init__": 103
        },
        {
            "transformers.models.videomae.image_processing_videomae.VideoMAEImageProcessor.resize": 134
        },
        {
            "transformers.models.videomae.image_processing_videomae.VideoMAEImageProcessor.center_crop": 166
        },
        {
            "transformers.models.videomae.image_processing_videomae.VideoMAEImageProcessor.rescale": 190
        },
        {
            "transformers.models.videomae.image_processing_videomae.VideoMAEImageProcessor.normalize": 210
        },
        {
            "transformers.models.videomae.image_processing_videomae.VideoMAEImageProcessor.preprocess": 279
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/xmod/configuration_xmod.py": [
        {
            "transformers.models.xmod.configuration_xmod.XmodConfig.__init__": 124
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/xmod/modeling_xmod.py": [
        {
            "transformers.models.xmod.modeling_xmod.XmodEncoder.custom_forward": 576
        },
        {
            "transformers.models.xmod.modeling_xmod.XmodForCausalLM.prepare_inputs_for_generation": 1129
        },
        {
            "transformers.models.xmod.modeling_xmod.XmodLMHead.forward": 1259
        },
        {
            "transformers.models.xmod.modeling_xmod.XmodClassificationHead.forward": 1559
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/mbart/modeling_mbart.py": [
        {
            "transformers.models.mbart.modeling_mbart.MBartEncoder.custom_forward": 829
        },
        {
            "transformers.models.mbart.modeling_mbart.MBartDecoder.custom_forward": 1086
        },
        {
            "transformers.models.mbart.modeling_mbart.MBartForConditionalGeneration.prepare_inputs_for_generation": 1398
        },
        {
            "transformers.models.mbart.modeling_mbart.MBartForSequenceClassification.__init__": 1450
        },
        {
            "transformers.models.mbart.modeling_mbart.MBartDecoderWrapper.forward": 1704
        },
        {
            "transformers.models.mbart.modeling_mbart.MBartForCausalLM.prepare_inputs_for_generation": 1887
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/mbart/configuration_mbart.py": [
        {
            "transformers.models.mbart.configuration_mbart.MBartConfig.__init__": 111
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/mbart/tokenization_mbart_fast.py": [
        {
            "transformers.models.mbart.tokenization_mbart_fast.MBartTokenizerFast.__init__": 96
        },
        {
            "transformers.models.mbart.tokenization_mbart_fast.MBartTokenizerFast._build_translation_inputs": 215
        },
        {
            "transformers.models.mbart.tokenization_mbart_fast.MBartTokenizerFast.prepare_seq2seq_batch": 227
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/mbart/tokenization_mbart.py": [
        {
            "transformers.models.mbart.tokenization_mbart.MBartTokenizer.__init__": 82
        },
        {
            "transformers.models.mbart.tokenization_mbart.MBartTokenizer._build_translation_inputs": 269
        },
        {
            "transformers.models.mbart.tokenization_mbart.MBartTokenizer.prepare_seq2seq_batch": 326
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/mbart/modeling_tf_mbart.py": [
        {
            "transformers.models.mbart.modeling_tf_mbart.TFMBartLearnedPositionalEmbedding.__init__": 125
        },
        {
            "transformers.models.mbart.modeling_tf_mbart.TFMBartAttention.__init__": 151
        },
        {
            "transformers.models.mbart.modeling_tf_mbart.TFMBartEncoderLayer.__init__": 302
        },
        {
            "transformers.models.mbart.modeling_tf_mbart.TFMBartDecoderLayer.__init__": 358
        },
        {
            "transformers.models.mbart.modeling_tf_mbart.TFMBartEncoder.__init__": 648
        },
        {
            "transformers.models.mbart.modeling_tf_mbart.TFMBartDecoder.__init__": 816
        },
        {
            "transformers.models.mbart.modeling_tf_mbart.TFMBartMainLayer.__init__": 1048
        },
        {
            "transformers.models.mbart.modeling_tf_mbart.TFMBartMainLayer.call": 1073
        },
        {
            "transformers.models.mbart.modeling_tf_mbart.TFMBartModel.__init__": 1163
        },
        {
            "transformers.models.mbart.modeling_tf_mbart.TFMBartModel.call": 1181
        },
        {
            "transformers.models.mbart.modeling_tf_mbart.BiasLayer.__init__": 1252
        },
        {
            "transformers.models.mbart.modeling_tf_mbart.TFMBartForConditionalGeneration.__init__": 1273
        },
        {
            "transformers.models.mbart.modeling_tf_mbart.TFMBartForConditionalGeneration.prepare_inputs_for_generation": 1409
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/mbart/modeling_flax_mbart.py": [
        {
            "transformers.models.mbart.modeling_flax_mbart.FlaxMBartPreTrainedModel.__init__": 947
        },
        {
            "transformers.models.mbart.modeling_flax_mbart.FlaxMBartPreTrainedModel._decoder_forward": 1017
        },
        {
            "transformers.models.mbart.modeling_flax_mbart.FlaxMBartPreTrainedModel._encoder_forward": 1083
        },
        {
            "transformers.models.mbart.modeling_flax_mbart.FlaxMBartPreTrainedModel._decoder_forward": 1177
        },
        {
            "transformers.models.mbart.modeling_flax_mbart.FlaxMBartForConditionalGeneration._decoder_forward": 1442
        },
        {
            "transformers.models.mbart.modeling_flax_mbart.FlaxMBartForConditionalGeneration.prepare_inputs_for_generation": 1501
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/led/modeling_tf_led.py": [
        {
            "transformers.models.led.modeling_tf_led.TFLEDLearnedPositionalEmbedding.__init__": 122
        },
        {
            "transformers.models.led.modeling_tf_led.TFLEDEncoderSelfAttention.__init__": 136
        },
        {
            "transformers.models.led.modeling_tf_led.TFLEDEncoderAttention.__init__": 982
        },
        {
            "transformers.models.led.modeling_tf_led.TFLEDDecoderAttention.__init__": 1011
        },
        {
            "transformers.models.led.modeling_tf_led.TFLEDEncoderLayer.__init__": 1160
        },
        {
            "transformers.models.led.modeling_tf_led.TFLEDDecoderLayer.__init__": 1219
        },
        {
            "transformers.models.led.modeling_tf_led.TFLEDEncoder.__init__": 1637
        },
        {
            "transformers.models.led.modeling_tf_led.TFLEDDecoder.__init__": 1899
        },
        {
            "transformers.models.led.modeling_tf_led.TFLEDMainLayer.__init__": 2112
        },
        {
            "transformers.models.led.modeling_tf_led.TFLEDMainLayer.call": 2136
        },
        {
            "transformers.models.led.modeling_tf_led.TFLEDModel.__init__": 2219
        },
        {
            "transformers.models.led.modeling_tf_led.TFLEDModel.call": 2237
        },
        {
            "transformers.models.led.modeling_tf_led.BiasLayer.__init__": 2307
        },
        {
            "transformers.models.led.modeling_tf_led.TFLEDForConditionalGeneration.__init__": 2328
        },
        {
            "transformers.models.led.modeling_tf_led.TFLEDForConditionalGeneration.prepare_inputs_for_generation": 2471
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/led/tokenization_led.py": [
        {
            "transformers.models.led.tokenization_led.LEDTokenizer.__init__": 177
        },
        {
            "transformers.models.led.tokenization_led.LEDTokenizer.prepare_for_tokenization": 420
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/led/modeling_led.py": [
        {
            "transformers.models.led.modeling_led.LEDEncoder.custom_forward": 1882
        },
        {
            "transformers.models.led.modeling_led.LEDDecoder.custom_forward": 2147
        },
        {
            "transformers.models.led.modeling_led.LEDForConditionalGeneration.prepare_inputs_for_generation": 2479
        },
        {
            "transformers.models.led.modeling_led.LEDForSequenceClassification.__init__": 2533
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/led/configuration_led.py": [
        {
            "transformers.models.led.configuration_led.LEDConfig.__init__": 108
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/led/tokenization_led_fast.py": [
        {
            "transformers.models.led.tokenization_led_fast.LEDTokenizerFast.__init__": 138
        },
        {
            "transformers.models.led.tokenization_led_fast.LEDTokenizerFast._batch_encode_plus": 236
        },
        {
            "transformers.models.led.tokenization_led_fast.LEDTokenizerFast._encode_plus": 248
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/realm/tokenization_realm_fast.py": [
        {
            "transformers.models.realm.tokenization_realm_fast.RealmTokenizerFast.__init__": 151
        },
        {
            "transformers.models.realm.tokenization_realm_fast.RealmTokenizerFast.batch_encode_candidates": 193
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/realm/configuration_realm.py": [
        {
            "transformers.models.realm.configuration_realm.RealmConfig.__init__": 130
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/realm/retrieval_realm.py": [
        {
            "transformers.models.realm.retrieval_realm.RealmRetriever.from_pretrained": 110
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/realm/tokenization_realm.py": [
        {
            "transformers.models.realm.tokenization_realm.RealmTokenizer.__init__": 145
        },
        {
            "transformers.models.realm.tokenization_realm.RealmTokenizer.batch_encode_candidates": 228
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/realm/modeling_realm.py": [
        {
            "transformers.models.realm.modeling_realm.RealmEncoder.custom_forward": 589
        },
        {
            "transformers.models.realm.modeling_realm.RealmPreTrainedModel._flatten_inputs": 989
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/autoformer/configuration_autoformer.py": [
        {
            "transformers.models.autoformer.configuration_autoformer.AutoformerConfig.__init__": 141
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/autoformer/modeling_autoformer.py": [
        {
            "transformers.models.autoformer.modeling_autoformer.AutoformerEncoder.custom_forward": 1207
        },
        {
            "transformers.models.autoformer.modeling_autoformer.AutoformerDecoder.custom_forward": 1424
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/timesformer/modeling_timesformer.py": [
        {
            "transformers.models.timesformer.modeling_timesformer.TimesformerEncoder.custom_forward": 444
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/timesformer/configuration_timesformer.py": [
        {
            "transformers.models.timesformer.configuration_timesformer.TimesformerConfig.__init__": 90
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/donut/processing_donut.py": [
        {
            "transformers.models.donut.processing_donut.DonutProcessor.__init__": 44
        },
        {
            "transformers.models.donut.processing_donut.DonutProcessor.__call__": 63
        },
        {
            "transformers.models.donut.processing_donut.DonutProcessor.batch_decode": 96
        },
        {
            "transformers.models.donut.processing_donut.DonutProcessor.decode": 103
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/donut/image_processing_donut.py": [
        {
            "transformers.models.donut.image_processing_donut.DonutImageProcessor.__init__": 91
        },
        {
            "transformers.models.donut.image_processing_donut.DonutImageProcessor.rotate_image": 154
        },
        {
            "transformers.models.donut.image_processing_donut.DonutImageProcessor.pad": 199
        },
        {
            "transformers.models.donut.image_processing_donut.DonutImageProcessor.thumbnail": 203
        },
        {
            "transformers.models.donut.image_processing_donut.DonutImageProcessor.resize": 244
        },
        {
            "transformers.models.donut.image_processing_donut.DonutImageProcessor.rescale": 272
        },
        {
            "transformers.models.donut.image_processing_donut.DonutImageProcessor.normalize": 292
        },
        {
            "transformers.models.donut.image_processing_donut.DonutImageProcessor.preprocess": 315
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/donut/modeling_donut_swin.py": [
        {
            "transformers.models.donut.modeling_donut_swin.DonutSwinEncoder.custom_forward": 754
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/donut/feature_extraction_donut.py": [
        {
            "transformers.models.donut.feature_extraction_donut.DonutFeatureExtractor.__init__": 27
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/donut/configuration_donut_swin.py": [
        {
            "transformers.models.donut.configuration_donut_swin.DonutSwinConfig.__init__": 95
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/gptsan_japanese/configuration_gptsan_japanese.py": [
        {
            "transformers.models.gptsan_japanese.configuration_gptsan_japanese.GPTSanJapaneseConfig.__init__": 100
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/gptsan_japanese/modeling_gptsan_japanese.py": [
        {
            "transformers.models.gptsan_japanese.modeling_gptsan_japanese.GPTSanJapaneseForConditionalGeneration.prepare_inputs_for_generation": 1282
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/wavlm/modeling_wavlm.py": [
        {
            "transformers.models.wavlm.modeling_wavlm.WavLMFeatureEncoder.custom_forward": 359
        },
        {
            "transformers.models.wavlm.modeling_wavlm.WavLMEncoder.custom_forward": 718
        },
        {
            "transformers.models.wavlm.modeling_wavlm.WavLMEncoderStableLayerNorm.custom_forward": 809
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/wavlm/configuration_wavlm.py": [
        {
            "transformers.models.wavlm.configuration_wavlm.WavLMConfig.__init__": 195
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/upernet/configuration_upernet.py": [
        {
            "transformers.models.upernet.configuration_upernet.UperNetConfig.__init__": 75
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/mbart50/tokenization_mbart50_fast.py": [
        {
            "transformers.models.mbart50.tokenization_mbart50_fast.MBart50TokenizerFast.__init__": 113
        },
        {
            "transformers.models.mbart50.tokenization_mbart50_fast.MBart50TokenizerFast.prepare_seq2seq_batch": 199
        },
        {
            "transformers.models.mbart50.tokenization_mbart50_fast.MBart50TokenizerFast._build_translation_inputs": 247
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/mbart50/tokenization_mbart50.py": [
        {
            "transformers.models.mbart50.tokenization_mbart50.MBart50Tokenizer.__init__": 116
        },
        {
            "transformers.models.mbart50.tokenization_mbart50.MBart50Tokenizer._build_translation_inputs": 328
        },
        {
            "transformers.models.mbart50.tokenization_mbart50.MBart50Tokenizer.prepare_seq2seq_batch": 340
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/time_series_transformer/configuration_time_series_transformer.py": [
        {
            "transformers.models.time_series_transformer.configuration_time_series_transformer.TimeSeriesTransformerConfig.__init__": 137
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/time_series_transformer/modeling_time_series_transformer.py": [
        {
            "transformers.models.time_series_transformer.modeling_time_series_transformer.TimeSeriesTransformerEncoder.custom_forward": 947
        },
        {
            "transformers.models.time_series_transformer.modeling_time_series_transformer.TimeSeriesTransformerDecoder.custom_forward": 1163
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/segformer/image_processing_segformer.py": [
        {
            "transformers.models.segformer.image_processing_segformer.SegformerImageProcessor.__init__": 85
        },
        {
            "transformers.models.segformer.image_processing_segformer.SegformerImageProcessor.from_dict": 129
        },
        {
            "transformers.models.segformer.image_processing_segformer.SegformerImageProcessor.resize": 140
        },
        {
            "transformers.models.segformer.image_processing_segformer.SegformerImageProcessor.rescale": 168
        },
        {
            "transformers.models.segformer.image_processing_segformer.SegformerImageProcessor.normalize": 188
        },
        {
            "transformers.models.segformer.image_processing_segformer.SegformerImageProcessor.__call__": 308
        },
        {
            "transformers.models.segformer.image_processing_segformer.SegformerImageProcessor.preprocess": 317
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/segformer/modeling_tf_segformer.py": [
        {
            "transformers.models.segformer.modeling_tf_segformer.TFSegformerDropPath.__init__": 65
        },
        {
            "transformers.models.segformer.modeling_tf_segformer.TFSegformerOverlapPatchEmbeddings.__init__": 82
        },
        {
            "transformers.models.segformer.modeling_tf_segformer.TFSegformerEfficientSelfAttention.__init__": 107
        },
        {
            "transformers.models.segformer.modeling_tf_segformer.TFSegformerSelfOutput.__init__": 201
        },
        {
            "transformers.models.segformer.modeling_tf_segformer.TFSegformerAttention.__init__": 213
        },
        {
            "transformers.models.segformer.modeling_tf_segformer.TFSegformerDWConv.__init__": 242
        },
        {
            "transformers.models.segformer.modeling_tf_segformer.TFSegformerMixFFN.__init__": 262
        },
        {
            "transformers.models.segformer.modeling_tf_segformer.TFSegformerLayer.__init__": 294
        },
        {
            "transformers.models.segformer.modeling_tf_segformer.TFSegformerEncoder.__init__": 352
        },
        {
            "transformers.models.segformer.modeling_tf_segformer.TFSegformerMainLayer.__init__": 457
        },
        {
            "transformers.models.segformer.modeling_tf_segformer.TFSegformerModel.__init__": 575
        },
        {
            "transformers.models.segformer.modeling_tf_segformer.TFSegformerForImageClassification.__init__": 617
        },
        {
            "transformers.models.segformer.modeling_tf_segformer.TFSegformerMLP.__init__": 677
        },
        {
            "transformers.models.segformer.modeling_tf_segformer.TFSegformerDecodeHead.__init__": 691
        },
        {
            "transformers.models.segformer.modeling_tf_segformer.TFSegformerForSemanticSegmentation.__init__": 751
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/segformer/configuration_segformer.py": [
        {
            "transformers.models.segformer.configuration_segformer.SegformerConfig.__init__": 105
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/segformer/feature_extraction_segformer.py": [
        {
            "transformers.models.segformer.feature_extraction_segformer.SegformerFeatureExtractor.__init__": 27
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/layoutlmv2/image_processing_layoutlmv2.py": [
        {
            "transformers.models.layoutlmv2.image_processing_layoutlmv2.LayoutLMv2ImageProcessor.__init__": 113
        },
        {
            "transformers.models.layoutlmv2.image_processing_layoutlmv2.LayoutLMv2ImageProcessor.resize": 134
        },
        {
            "transformers.models.layoutlmv2.image_processing_layoutlmv2.LayoutLMv2ImageProcessor.preprocess": 161
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/layoutlmv2/processing_layoutlmv2.py": [
        {
            "transformers.models.layoutlmv2.processing_layoutlmv2.LayoutLMv2Processor.__init__": 50
        },
        {
            "transformers.models.layoutlmv2.processing_layoutlmv2.LayoutLMv2Processor.__call__": 67
        },
        {
            "transformers.models.layoutlmv2.processing_layoutlmv2.LayoutLMv2Processor.batch_decode": 167
        },
        {
            "transformers.models.layoutlmv2.processing_layoutlmv2.LayoutLMv2Processor.decode": 174
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/layoutlmv2/modeling_layoutlmv2.py": [
        {
            "transformers.models.layoutlmv2.modeling_layoutlmv2.LayoutLMv2Encoder.custom_forward": 453
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/layoutlmv2/tokenization_layoutlmv2.py": [
        {
            "transformers.models.layoutlmv2.tokenization_layoutlmv2.LayoutLMv2Tokenizer.__init__": 225
        },
        {
            "transformers.models.layoutlmv2.tokenization_layoutlmv2.LayoutLMv2Tokenizer.__call__": 426
        },
        {
            "transformers.models.layoutlmv2.tokenization_layoutlmv2.LayoutLMv2Tokenizer.batch_encode_plus": 575
        },
        {
            "transformers.models.layoutlmv2.tokenization_layoutlmv2.LayoutLMv2Tokenizer._batch_encode_plus": 633
        },
        {
            "transformers.models.layoutlmv2.tokenization_layoutlmv2.LayoutLMv2Tokenizer.encode": 760
        },
        {
            "transformers.models.layoutlmv2.tokenization_layoutlmv2.LayoutLMv2Tokenizer.encode_plus": 807
        },
        {
            "transformers.models.layoutlmv2.tokenization_layoutlmv2.LayoutLMv2Tokenizer._encode_plus": 873
        },
        {
            "transformers.models.layoutlmv2.tokenization_layoutlmv2.LayoutLMv2Tokenizer.prepare_for_model": 926
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/layoutlmv2/feature_extraction_layoutlmv2.py": [
        {
            "transformers.models.layoutlmv2.feature_extraction_layoutlmv2.LayoutLMv2FeatureExtractor.__init__": 29
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/layoutlmv2/tokenization_layoutlmv2_fast.py": [
        {
            "transformers.models.layoutlmv2.tokenization_layoutlmv2_fast.LayoutLMv2TokenizerFast.__init__": 122
        },
        {
            "transformers.models.layoutlmv2.tokenization_layoutlmv2_fast.LayoutLMv2TokenizerFast.__call__": 180
        },
        {
            "transformers.models.layoutlmv2.tokenization_layoutlmv2_fast.LayoutLMv2TokenizerFast.batch_encode_plus": 329
        },
        {
            "transformers.models.layoutlmv2.tokenization_layoutlmv2_fast.LayoutLMv2TokenizerFast.tokenize": 387
        },
        {
            "transformers.models.layoutlmv2.tokenization_layoutlmv2_fast.LayoutLMv2TokenizerFast.encode_plus": 396
        },
        {
            "transformers.models.layoutlmv2.tokenization_layoutlmv2_fast.LayoutLMv2TokenizerFast._encode_plus": 618
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/layoutlmv2/configuration_layoutlmv2.py": [
        {
            "transformers.models.layoutlmv2.configuration_layoutlmv2.LayoutLMv2Config.__init__": 119
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/xlm/configuration_xlm.py": [
        {
            "transformers.models.xlm.configuration_xlm.XLMConfig.__init__": 160
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/xlm/modeling_tf_xlm.py": [
        {
            "transformers.models.xlm.modeling_tf_xlm.TFXLMMultiHeadAttention.__init__": 121
        },
        {
            "transformers.models.xlm.modeling_tf_xlm.TFXLMTransformerFFN.__init__": 211
        },
        {
            "transformers.models.xlm.modeling_tf_xlm.TFXLMMainLayer.__init__": 232
        },
        {
            "transformers.models.xlm.modeling_tf_xlm.TFXLMModel.__init__": 690
        },
        {
            "transformers.models.xlm.modeling_tf_xlm.TFXLMPredLayer.__init__": 741
        },
        {
            "transformers.models.xlm.modeling_tf_xlm.TFXLMWithLMHeadModel.__init__": 795
        },
        {
            "transformers.models.xlm.modeling_tf_xlm.TFXLMWithLMHeadModel.prepare_inputs_for_generation": 809
        },
        {
            "transformers.models.xlm.modeling_tf_xlm.TFXLMForSequenceClassification.__init__": 881
        },
        {
            "transformers.models.xlm.modeling_tf_xlm.TFXLMForMultipleChoice.__init__": 959
        },
        {
            "transformers.models.xlm.modeling_tf_xlm.TFXLMForTokenClassification.__init__": 1078
        },
        {
            "transformers.models.xlm.modeling_tf_xlm.TFXLMForQuestionAnsweringSimple.__init__": 1158
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/xlm/tokenization_xlm.py": [
        {
            "transformers.models.xlm.tokenization_xlm.XLMTokenizer.__init__": 589
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/xlm/modeling_xlm.py": [
        {
            "transformers.models.xlm.modeling_xlm.XLMPreTrainedModel.__init__": 231
        },
        {
            "transformers.models.xlm.modeling_xlm.XLMWithLMHeadModel.prepare_inputs_for_generation": 689
        },
        {
            "transformers.models.xlm.modeling_xlm.XLMForMultipleChoice.__init__": 1181
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/speecht5/configuration_speecht5.py": [
        {
            "transformers.models.speecht5.configuration_speecht5.SpeechT5Config.__init__": 200
        },
        {
            "transformers.models.speecht5.configuration_speecht5.SpeechT5HifiGanConfig.__init__": 403
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/speecht5/tokenization_speecht5.py": [
        {
            "transformers.models.speecht5.tokenization_speecht5.SpeechT5Tokenizer.__init__": 93
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/speecht5/feature_extraction_speecht5.py": [
        {
            "transformers.models.speecht5.feature_extraction_speecht5.SpeechT5FeatureExtractor.__init__": 79
        },
        {
            "transformers.models.speecht5.feature_extraction_speecht5.SpeechT5FeatureExtractor.__call__": 182
        },
        {
            "transformers.models.speecht5.feature_extraction_speecht5.SpeechT5FeatureExtractor._process_audio": 299
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/speecht5/processing_speecht5.py": [
        {
            "transformers.models.speecht5.processing_speecht5.SpeechT5Processor.__call__": 39
        },
        {
            "transformers.models.speecht5.processing_speecht5.SpeechT5Processor.pad": 110
        },
        {
            "transformers.models.speecht5.processing_speecht5.SpeechT5Processor.batch_decode": 170
        },
        {
            "transformers.models.speecht5.processing_speecht5.SpeechT5Processor.decode": 177
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/speecht5/modeling_speecht5.py": [
        {
            "transformers.models.speecht5.modeling_speecht5.SpeechT5FeatureEncoder.custom_forward": 526
        },
        {
            "transformers.models.speecht5.modeling_speecht5.SpeechT5Encoder.custom_forward": 1392
        },
        {
            "transformers.models.speecht5.modeling_speecht5.SpeechT5Decoder.custom_forward": 1720
        },
        {
            "transformers.models.speecht5.modeling_speecht5.SpeechT5ForSpeechToText.prepare_inputs_for_generation": 2507
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/retribert/modeling_retribert.py": [
        {
            "transformers.models.retribert.modeling_retribert.RetriBertModel.partial_encode": 125
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/retribert/tokenization_retribert.py": [
        {
            "transformers.models.retribert.tokenization_retribert.RetriBertTokenizer.__init__": 120
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/retribert/configuration_retribert.py": [
        {
            "transformers.models.retribert.configuration_retribert.RetriBertConfig.__init__": 77
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/retribert/tokenization_retribert_fast.py": [
        {
            "transformers.models.retribert.tokenization_retribert_fast.RetriBertTokenizerFast.__init__": 105
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/dinat/configuration_dinat.py": [
        {
            "transformers.models.dinat.configuration_dinat.DinatConfig.__init__": 104
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/dinat/modeling_dinat.py": [
        {
            "transformers.models.dinat.modeling_dinat.natten2dqkrpb": 50
        },
        {
            "transformers.models.dinat.modeling_dinat.natten2dav": 53
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/mobilenet_v1/image_processing_mobilenet_v1.py": [
        {
            "transformers.models.mobilenet_v1.image_processing_mobilenet_v1.MobileNetV1ImageProcessor.__init__": 87
        },
        {
            "transformers.models.mobilenet_v1.image_processing_mobilenet_v1.MobileNetV1ImageProcessor.resize": 117
        },
        {
            "transformers.models.mobilenet_v1.image_processing_mobilenet_v1.MobileNetV1ImageProcessor.center_crop": 145
        },
        {
            "transformers.models.mobilenet_v1.image_processing_mobilenet_v1.MobileNetV1ImageProcessor.rescale": 167
        },
        {
            "transformers.models.mobilenet_v1.image_processing_mobilenet_v1.MobileNetV1ImageProcessor.normalize": 189
        },
        {
            "transformers.models.mobilenet_v1.image_processing_mobilenet_v1.MobileNetV1ImageProcessor.preprocess": 218
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/mobilenet_v1/configuration_mobilenet_v1.py": [
        {
            "transformers.models.mobilenet_v1.configuration_mobilenet_v1.MobileNetV1Config.__init__": 83
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/mobilenet_v1/feature_extraction_mobilenet_v1.py": [
        {
            "transformers.models.mobilenet_v1.feature_extraction_mobilenet_v1.MobileNetV1FeatureExtractor.__init__": 27
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/roberta_prelayernorm/modeling_tf_roberta_prelayernorm.py": [
        {
            "transformers.models.roberta_prelayernorm.modeling_tf_roberta_prelayernorm.TFRobertaPreLayerNormEmbeddings.__init__": 86
        },
        {
            "transformers.models.roberta_prelayernorm.modeling_tf_roberta_prelayernorm.TFRobertaPreLayerNormPooler.__init__": 183
        },
        {
            "transformers.models.roberta_prelayernorm.modeling_tf_roberta_prelayernorm.TFRobertaPreLayerNormSelfAttention.__init__": 204
        },
        {
            "transformers.models.roberta_prelayernorm.modeling_tf_roberta_prelayernorm.TFRobertaPreLayerNormSelfOutput.__init__": 321
        },
        {
            "transformers.models.roberta_prelayernorm.modeling_tf_roberta_prelayernorm.TFRobertaPreLayerNormAttention.__init__": 338
        },
        {
            "transformers.models.roberta_prelayernorm.modeling_tf_roberta_prelayernorm.TFRobertaPreLayerNormIntermediate.__init__": 381
        },
        {
            "transformers.models.roberta_prelayernorm.modeling_tf_roberta_prelayernorm.TFRobertaPreLayerNormOutput.__init__": 403
        },
        {
            "transformers.models.roberta_prelayernorm.modeling_tf_roberta_prelayernorm.TFRobertaPreLayerNormLayer.__init__": 421
        },
        {
            "transformers.models.roberta_prelayernorm.modeling_tf_roberta_prelayernorm.TFRobertaPreLayerNormEncoder.__init__": 508
        },
        {
            "transformers.models.roberta_prelayernorm.modeling_tf_roberta_prelayernorm.TFRobertaPreLayerNormMainLayer.__init__": 580
        },
        {
            "transformers.models.roberta_prelayernorm.modeling_tf_roberta_prelayernorm.TFRobertaPreLayerNormModel.__init__": 884
        },
        {
            "transformers.models.roberta_prelayernorm.modeling_tf_roberta_prelayernorm.TFRobertaPreLayerNormLMHead.__init__": 956
        },
        {
            "transformers.models.roberta_prelayernorm.modeling_tf_roberta_prelayernorm.TFRobertaPreLayerNormForMaskedLM.__init__": 1013
        },
        {
            "transformers.models.roberta_prelayernorm.modeling_tf_roberta_prelayernorm.TFRobertaPreLayerNormForCausalLM.__init__": 1094
        },
        {
            "transformers.models.roberta_prelayernorm.modeling_tf_roberta_prelayernorm.TFRobertaPreLayerNormForCausalLM.prepare_inputs_for_generation": 1117
        },
        {
            "transformers.models.roberta_prelayernorm.modeling_tf_roberta_prelayernorm.TFRobertaPreLayerNormClassificationHead.__init__": 1222
        },
        {
            "transformers.models.roberta_prelayernorm.modeling_tf_roberta_prelayernorm.TFRobertaPreLayerNormForSequenceClassification.__init__": 1260
        },
        {
            "transformers.models.roberta_prelayernorm.modeling_tf_roberta_prelayernorm.TFRobertaPreLayerNormForMultipleChoice.__init__": 1339
        },
        {
            "transformers.models.roberta_prelayernorm.modeling_tf_roberta_prelayernorm.TFRobertaPreLayerNormForTokenClassification.__init__": 1431
        },
        {
            "transformers.models.roberta_prelayernorm.modeling_tf_roberta_prelayernorm.TFRobertaPreLayerNormForQuestionAnswering.__init__": 1514
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/roberta_prelayernorm/modeling_flax_roberta_prelayernorm.py": [
        {
            "transformers.models.roberta_prelayernorm.modeling_flax_roberta_prelayernorm.FlaxRobertaPreLayerNormPreTrainedModel.__init__": 736
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/roberta_prelayernorm/modeling_roberta_prelayernorm.py": [
        {
            "transformers.models.roberta_prelayernorm.modeling_roberta_prelayernorm.RobertaPreLayerNormEncoder.custom_forward": 515
        },
        {
            "transformers.models.roberta_prelayernorm.modeling_roberta_prelayernorm.RobertaPreLayerNormForCausalLM.prepare_inputs_for_generation": 1024
        },
        {
            "transformers.models.roberta_prelayernorm.modeling_roberta_prelayernorm.RobertaPreLayerNormLMHead.forward": 1159
        },
        {
            "transformers.models.roberta_prelayernorm.modeling_roberta_prelayernorm.RobertaPreLayerNormClassificationHead.forward": 1475
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/roberta_prelayernorm/configuration_roberta_prelayernorm.py": [
        {
            "transformers.models.roberta_prelayernorm.configuration_roberta_prelayernorm.RobertaPreLayerNormConfig.__init__": 107
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/nllb_moe/modeling_nllb_moe.py": [
        {
            "transformers.models.nllb_moe.modeling_nllb_moe.NllbMoeEncoder.custom_forward": 1153
        },
        {
            "transformers.models.nllb_moe.modeling_nllb_moe.NllbMoeDecoder.custom_forward": 1426
        },
        {
            "transformers.models.nllb_moe.modeling_nllb_moe.NllbMoeForConditionalGeneration.prepare_inputs_for_generation": 1815
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/nllb_moe/configuration_nllb_moe.py": [
        {
            "transformers.models.nllb_moe.configuration_nllb_moe.NllbMoeConfig.__init__": 132
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/gpt_bigcode/modeling_gpt_bigcode.py": [
        {
            "transformers.models.gpt_bigcode.modeling_gpt_bigcode.GPTBigCodePreTrainedModel.__init__": 377
        },
        {
            "transformers.models.gpt_bigcode.modeling_gpt_bigcode.GPTBigCodeModel.custom_forward": 658
        },
        {
            "transformers.models.gpt_bigcode.modeling_gpt_bigcode.GPTBigCodeForCausalLM.prepare_inputs_for_generation": 741
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/gpt_bigcode/configuration_gpt_bigcode.py": [
        {
            "transformers.models.gpt_bigcode.configuration_gpt_bigcode.GPTBigCodeConfig.__init__": 101
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/opt/configuration_opt.py": [
        {
            "transformers.models.opt.configuration_opt.OPTConfig.__init__": 99
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/opt/modeling_opt.py": [
        {
            "transformers.models.opt.modeling_opt.OPTDecoder.custom_forward": 697
        },
        {
            "transformers.models.opt.modeling_opt.OPTForCausalLM.prepare_inputs_for_generation": 982
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/opt/modeling_flax_opt.py": [
        {
            "transformers.models.opt.modeling_flax_opt.FlaxOPTPreTrainedModel.__init__": 522
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/opt/modeling_tf_opt.py": [
        {
            "transformers.models.opt.modeling_tf_opt.TFOPTLearnedPositionalEmbedding.__init__": 99
        },
        {
            "transformers.models.opt.modeling_tf_opt.TFOPTAttention.__init__": 122
        },
        {
            "transformers.models.opt.modeling_tf_opt.TFOPTDecoderLayer.__init__": 273
        },
        {
            "transformers.models.opt.modeling_tf_opt.TFOPTDecoder.__init__": 467
        },
        {
            "transformers.models.opt.modeling_tf_opt.TFOPTMainLayer.__init__": 699
        },
        {
            "transformers.models.opt.modeling_tf_opt.TFOPTMainLayer.call": 711
        },
        {
            "transformers.models.opt.modeling_tf_opt.TFOPTModel.__init__": 764
        },
        {
            "transformers.models.opt.modeling_tf_opt.TFOPTModel.call": 783
        },
        {
            "transformers.models.opt.modeling_tf_opt.TFOPTForCausalLM.__init__": 850
        },
        {
            "transformers.models.opt.modeling_tf_opt.TFOPTForCausalLM.prepare_inputs_for_generation": 858
        },
        {
            "transformers.models.opt.modeling_tf_opt.TFOPTForCausalLM.call": 880
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/blenderbot_small/modeling_blenderbot_small.py": [
        {
            "transformers.models.blenderbot_small.modeling_blenderbot_small.BlenderbotSmallEncoder.custom_forward": 775
        },
        {
            "transformers.models.blenderbot_small.modeling_blenderbot_small.BlenderbotSmallDecoder.custom_forward": 1028
        },
        {
            "transformers.models.blenderbot_small.modeling_blenderbot_small.BlenderbotSmallForConditionalGeneration.prepare_inputs_for_generation": 1348
        },
        {
            "transformers.models.blenderbot_small.modeling_blenderbot_small.BlenderbotSmallDecoderWrapper.forward": 1398
        },
        {
            "transformers.models.blenderbot_small.modeling_blenderbot_small.BlenderbotSmallForCausalLM.prepare_inputs_for_generation": 1583
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/blenderbot_small/tokenization_blenderbot_small_fast.py": [
        {
            "transformers.models.blenderbot_small.tokenization_blenderbot_small_fast.BlenderbotSmallTokenizerFast.__init__": 66
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/blenderbot_small/configuration_blenderbot_small.py": [
        {
            "transformers.models.blenderbot_small.configuration_blenderbot_small.BlenderbotSmallConfig.__init__": 111
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/blenderbot_small/modeling_flax_blenderbot_small.py": [
        {
            "transformers.models.blenderbot_small.modeling_flax_blenderbot_small.FlaxBlenderbotSmallPreTrainedModel.__init__": 881
        },
        {
            "transformers.models.blenderbot_small.modeling_flax_blenderbot_small.FlaxBlenderbotSmallPreTrainedModel._decoder_forward": 950
        },
        {
            "transformers.models.blenderbot_small.modeling_flax_blenderbot_small.FlaxBlenderbotSmallPreTrainedModel._encoder_forward": 1016
        },
        {
            "transformers.models.blenderbot_small.modeling_flax_blenderbot_small.FlaxBlenderbotSmallPreTrainedModel._decoder_forward": 1113
        },
        {
            "transformers.models.blenderbot_small.modeling_flax_blenderbot_small.FlaxBlenderbotSmallForConditionalGeneration._decoder_forward": 1381
        },
        {
            "transformers.models.blenderbot_small.modeling_flax_blenderbot_small.FlaxBlenderbotSmallForConditionalGeneration.prepare_inputs_for_generation": 1440
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/blenderbot_small/modeling_tf_blenderbot_small.py": [
        {
            "transformers.models.blenderbot_small.modeling_tf_blenderbot_small.TFBlenderbotSmallLearnedPositionalEmbedding.__init__": 126
        },
        {
            "transformers.models.blenderbot_small.modeling_tf_blenderbot_small.TFBlenderbotSmallAttention.__init__": 145
        },
        {
            "transformers.models.blenderbot_small.modeling_tf_blenderbot_small.TFBlenderbotSmallEncoderLayer.__init__": 297
        },
        {
            "transformers.models.blenderbot_small.modeling_tf_blenderbot_small.TFBlenderbotSmallDecoderLayer.__init__": 354
        },
        {
            "transformers.models.blenderbot_small.modeling_tf_blenderbot_small.TFBlenderbotSmallEncoder.__init__": 630
        },
        {
            "transformers.models.blenderbot_small.modeling_tf_blenderbot_small.TFBlenderbotSmallDecoder.__init__": 796
        },
        {
            "transformers.models.blenderbot_small.modeling_tf_blenderbot_small.TFBlenderbotSmallMainLayer.__init__": 1022
        },
        {
            "transformers.models.blenderbot_small.modeling_tf_blenderbot_small.TFBlenderbotSmallMainLayer.call": 1047
        },
        {
            "transformers.models.blenderbot_small.modeling_tf_blenderbot_small.TFBlenderbotSmallModel.__init__": 1131
        },
        {
            "transformers.models.blenderbot_small.modeling_tf_blenderbot_small.TFBlenderbotSmallModel.call": 1149
        },
        {
            "transformers.models.blenderbot_small.modeling_tf_blenderbot_small.BiasLayer.__init__": 1220
        },
        {
            "transformers.models.blenderbot_small.modeling_tf_blenderbot_small.TFBlenderbotSmallForConditionalGeneration.__init__": 1241
        },
        {
            "transformers.models.blenderbot_small.modeling_tf_blenderbot_small.TFBlenderbotSmallForConditionalGeneration.prepare_inputs_for_generation": 1379
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/blenderbot_small/tokenization_blenderbot_small.py": [
        {
            "transformers.models.blenderbot_small.tokenization_blenderbot_small.BlenderbotSmallTokenizer.__init__": 99
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/yolos/image_processing_yolos.py": [
        {
            "transformers.models.yolos.image_processing_yolos.YolosImageProcessor.__init__": 691
        },
        {
            "transformers.models.yolos.image_processing_yolos.YolosImageProcessor.from_dict": 743
        },
        {
            "transformers.models.yolos.image_processing_yolos.YolosImageProcessor.convert_coco_poly_to_mask": 793
        },
        {
            "transformers.models.yolos.image_processing_yolos.YolosImageProcessor.prepare_coco_detection": 800
        },
        {
            "transformers.models.yolos.image_processing_yolos.YolosImageProcessor.prepare_coco_panoptic": 807
        },
        {
            "transformers.models.yolos.image_processing_yolos.YolosImageProcessor.resize": 814
        },
        {
            "transformers.models.yolos.image_processing_yolos.YolosImageProcessor.preprocess": 945
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/yolos/feature_extraction_yolos.py": [
        {
            "transformers.models.yolos.feature_extraction_yolos.YolosFeatureExtractor.__init__": 27
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/yolos/modeling_yolos.py": [
        {
            "transformers.models.yolos.modeling_yolos.YolosEncoder.custom_forward": 497
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/yolos/configuration_yolos.py": [
        {
            "transformers.models.yolos.configuration_yolos.YolosConfig.__init__": 108
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/x_clip/processing_x_clip.py": [
        {
            "transformers.models.x_clip.processing_x_clip.XCLIPProcessor.__init__": 42
        },
        {
            "transformers.models.x_clip.processing_x_clip.XCLIPProcessor.__call__": 60
        },
        {
            "transformers.models.x_clip.processing_x_clip.XCLIPProcessor.batch_decode": 114
        },
        {
            "transformers.models.x_clip.processing_x_clip.XCLIPProcessor.decode": 121
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/x_clip/configuration_x_clip.py": [
        {
            "transformers.models.x_clip.configuration_x_clip.XCLIPTextConfig.__init__": 87
        },
        {
            "transformers.models.x_clip.configuration_x_clip.XCLIPTextConfig.from_pretrained": 120
        },
        {
            "transformers.models.x_clip.configuration_x_clip.XCLIPVisionConfig.__init__": 201
        },
        {
            "transformers.models.x_clip.configuration_x_clip.XCLIPVisionConfig.from_pretrained": 245
        },
        {
            "transformers.models.x_clip.configuration_x_clip.XCLIPConfig.__init__": 300
        },
        {
            "transformers.models.x_clip.configuration_x_clip.XCLIPConfig.from_text_vision_configs": 406
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/x_clip/modeling_x_clip.py": [
        {
            "transformers.models.x_clip.modeling_x_clip.XCLIPEncoder.custom_forward": 706
        },
        {
            "transformers.models.x_clip.modeling_x_clip.XCLIPVisionEncoder.custom_forward": 953
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/biogpt/tokenization_biogpt.py": [
        {
            "transformers.models.biogpt.tokenization_biogpt.BioGptTokenizer.__init__": 104
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/biogpt/modeling_biogpt.py": [
        {
            "transformers.models.biogpt.modeling_biogpt.BioGptModel.custom_forward": 591
        },
        {
            "transformers.models.biogpt.modeling_biogpt.BioGptForCausalLM.prepare_inputs_for_generation": 729
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/biogpt/configuration_biogpt.py": [
        {
            "transformers.models.biogpt.configuration_biogpt.BioGptConfig.__init__": 97
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/swinv2/configuration_swinv2.py": [
        {
            "transformers.models.swinv2.configuration_swinv2.Swinv2Config.__init__": 99
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/swinv2/modeling_swinv2.py": [
        {
            "transformers.models.swinv2.modeling_swinv2.Swinv2Encoder.custom_forward": 906
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/poolformer/modeling_poolformer.py": [
        {
            "transformers.models.poolformer.modeling_poolformer.PoolFormerGroupNorm.__init__": 113
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/poolformer/image_processing_poolformer.py": [
        {
            "transformers.models.poolformer.image_processing_poolformer.PoolFormerImageProcessor.__init__": 103
        },
        {
            "transformers.models.poolformer.image_processing_poolformer.PoolFormerImageProcessor.resize": 136
        },
        {
            "transformers.models.poolformer.image_processing_poolformer.PoolFormerImageProcessor.center_crop": 198
        },
        {
            "transformers.models.poolformer.image_processing_poolformer.PoolFormerImageProcessor.rescale": 222
        },
        {
            "transformers.models.poolformer.image_processing_poolformer.PoolFormerImageProcessor.normalize": 242
        },
        {
            "transformers.models.poolformer.image_processing_poolformer.PoolFormerImageProcessor.preprocess": 265
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/poolformer/configuration_poolformer.py": [
        {
            "transformers.models.poolformer.configuration_poolformer.PoolFormerConfig.__init__": 96
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/poolformer/feature_extraction_poolformer.py": [
        {
            "transformers.models.poolformer.feature_extraction_poolformer.PoolFormerFeatureExtractor.__init__": 27
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/clipseg/processing_clipseg.py": [
        {
            "transformers.models.clipseg.processing_clipseg.CLIPSegProcessor.__init__": 42
        },
        {
            "transformers.models.clipseg.processing_clipseg.CLIPSegProcessor.__call__": 59
        },
        {
            "transformers.models.clipseg.processing_clipseg.CLIPSegProcessor.batch_decode": 132
        },
        {
            "transformers.models.clipseg.processing_clipseg.CLIPSegProcessor.decode": 139
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/clipseg/configuration_clipseg.py": [
        {
            "transformers.models.clipseg.configuration_clipseg.CLIPSegTextConfig.__init__": 86
        },
        {
            "transformers.models.clipseg.configuration_clipseg.CLIPSegTextConfig.from_pretrained": 119
        },
        {
            "transformers.models.clipseg.configuration_clipseg.CLIPSegVisionConfig.__init__": 188
        },
        {
            "transformers.models.clipseg.configuration_clipseg.CLIPSegVisionConfig.from_pretrained": 220
        },
        {
            "transformers.models.clipseg.configuration_clipseg.CLIPSegConfig.__init__": 303
        },
        {
            "transformers.models.clipseg.configuration_clipseg.CLIPSegConfig.from_text_vision_configs": 413
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/clipseg/modeling_clipseg.py": [
        {
            "transformers.models.clipseg.modeling_clipseg.CLIPSegEncoder.custom_forward": 652
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/tapex/tokenization_tapex.py": [
        {
            "transformers.models.tapex.tokenization_tapex.TapexTokenizer.__init__": 272
        },
        {
            "transformers.models.tapex.tokenization_tapex.TapexTokenizer.prepare_for_tokenization": 406
        },
        {
            "transformers.models.tapex.tokenization_tapex.TapexTokenizer.__call__": 515
        },
        {
            "transformers.models.tapex.tokenization_tapex.TapexTokenizer.source_call_func": 592
        },
        {
            "transformers.models.tapex.tokenization_tapex.TapexTokenizer.batch_encode_plus": 680
        },
        {
            "transformers.models.tapex.tokenization_tapex.TapexTokenizer._batch_encode_plus": 737
        },
        {
            "transformers.models.tapex.tokenization_tapex.TapexTokenizer.encode": 867
        },
        {
            "transformers.models.tapex.tokenization_tapex.TapexTokenizer.encode_plus": 899
        },
        {
            "transformers.models.tapex.tokenization_tapex.TapexTokenizer._encode_plus": 947
        },
        {
            "transformers.models.tapex.tokenization_tapex.TapexTokenizer.target_call_func": 1005
        },
        {
            "transformers.models.tapex.tokenization_tapex.TapexTokenizer.target_batch_encode_plus": 1070
        },
        {
            "transformers.models.tapex.tokenization_tapex.TapexTokenizer._target_batch_encode_plus": 1123
        },
        {
            "transformers.models.tapex.tokenization_tapex.TapexTokenizer.target_encode": 1183
        },
        {
            "transformers.models.tapex.tokenization_tapex.TapexTokenizer.target_encode_plus": 1214
        },
        {
            "transformers.models.tapex.tokenization_tapex.TapexTokenizer._target_encode_plus": 1265
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/bigbird_pegasus/modeling_bigbird_pegasus.py": [
        {
            "transformers.models.bigbird_pegasus.modeling_bigbird_pegasus.BigBirdPegasusEncoder.custom_forward": 1943
        },
        {
            "transformers.models.bigbird_pegasus.modeling_bigbird_pegasus.BigBirdPegasusDecoder.custom_forward": 2288
        },
        {
            "transformers.models.bigbird_pegasus.modeling_bigbird_pegasus.BigBirdPegasusForConditionalGeneration.prepare_inputs_for_generation": 2613
        },
        {
            "transformers.models.bigbird_pegasus.modeling_bigbird_pegasus.BigBirdPegasusForSequenceClassification.__init__": 2667
        },
        {
            "transformers.models.bigbird_pegasus.modeling_bigbird_pegasus.BigBirdPegasusDecoderWrapper.forward": 2921
        },
        {
            "transformers.models.bigbird_pegasus.modeling_bigbird_pegasus.BigBirdPegasusForCausalLM.prepare_inputs_for_generation": 3101
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/bigbird_pegasus/configuration_bigbird_pegasus.py": [
        {
            "transformers.models.bigbird_pegasus.configuration_bigbird_pegasus.BigBirdPegasusConfig.__init__": 131
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/detr/image_processing_detr.py": [
        {
            "transformers.models.detr.image_processing_detr.DetrImageProcessor.__init__": 764
        },
        {
            "transformers.models.detr.image_processing_detr.DetrImageProcessor.from_dict": 814
        },
        {
            "transformers.models.detr.image_processing_detr.DetrImageProcessor.convert_coco_poly_to_mask": 861
        },
        {
            "transformers.models.detr.image_processing_detr.DetrImageProcessor.prepare_coco_detection": 867
        },
        {
            "transformers.models.detr.image_processing_detr.DetrImageProcessor.prepare_coco_panoptic": 873
        },
        {
            "transformers.models.detr.image_processing_detr.DetrImageProcessor.resize": 879
        },
        {
            "transformers.models.detr.image_processing_detr.DetrImageProcessor.preprocess": 1044
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/detr/modeling_detr.py": [
        {
            "transformers.models.detr.modeling_detr.DetrDecoder.custom_forward": 1131
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/detr/configuration_detr.py": [
        {
            "transformers.models.detr.configuration_detr.DetrConfig.__init__": 143
        },
        {
            "transformers.models.detr.configuration_detr.DetrConfig.from_backbone_config": 240
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/detr/feature_extraction_detr.py": [
        {
            "transformers.models.detr.feature_extraction_detr.DetrFeatureExtractor.__init__": 27
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/gpt_neox_japanese/configuration_gpt_neox_japanese.py": [
        {
            "transformers.models.gpt_neox_japanese.configuration_gpt_neox_japanese.GPTNeoXJapaneseConfig.__init__": 86
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/perceiver/image_processing_perceiver.py": [
        {
            "transformers.models.perceiver.image_processing_perceiver.PerceiverImageProcessor.__init__": 83
        },
        {
            "transformers.models.perceiver.image_processing_perceiver.PerceiverImageProcessor.center_crop": 114
        },
        {
            "transformers.models.perceiver.image_processing_perceiver.PerceiverImageProcessor.resize": 149
        },
        {
            "transformers.models.perceiver.image_processing_perceiver.PerceiverImageProcessor.rescale": 177
        },
        {
            "transformers.models.perceiver.image_processing_perceiver.PerceiverImageProcessor.normalize": 197
        },
        {
            "transformers.models.perceiver.image_processing_perceiver.PerceiverImageProcessor.preprocess": 220
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/perceiver/configuration_perceiver.py": [
        {
            "transformers.models.perceiver.configuration_perceiver.PerceiverConfig.__init__": 120
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/perceiver/tokenization_perceiver.py": [
        {
            "transformers.models.perceiver.tokenization_perceiver.PerceiverTokenizer.__init__": 60
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/perceiver/modeling_perceiver.py": [
        {
            "transformers.models.perceiver.modeling_perceiver.PerceiverBasicDecoder.__init__": 2113
        },
        {
            "transformers.models.perceiver.modeling_perceiver.PerceiverClassificationDecoder.__init__": 2274
        },
        {
            "transformers.models.perceiver.modeling_perceiver.PerceiverOpticalFlowDecoder.__init__": 2312
        },
        {
            "transformers.models.perceiver.modeling_perceiver.PerceiverBasicVideoAutoencodingDecoder.__init__": 2358
        },
        {
            "transformers.models.perceiver.modeling_perceiver.PerceiverMultimodalDecoder.__init__": 2447
        },
        {
            "transformers.models.perceiver.modeling_perceiver.Conv2dSamePadding.__init__": 2598
        },
        {
            "transformers.models.perceiver.modeling_perceiver.PerceiverAbstractPositionEncoding.output_size": 2730
        },
        {
            "transformers.models.perceiver.modeling_perceiver.PerceiverTrainablePositionEncoding.output_size": 2754
        },
        {
            "transformers.models.perceiver.modeling_perceiver.PerceiverImagePreprocessor.__init__": 3040
        },
        {
            "transformers.models.perceiver.modeling_perceiver.PerceiverAudioPreprocessor.__init__": 3281
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/perceiver/feature_extraction_perceiver.py": [
        {
            "transformers.models.perceiver.feature_extraction_perceiver.PerceiverFeatureExtractor.__init__": 27
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/tvlt/processing_tvlt.py": [
        {
            "transformers.models.tvlt.processing_tvlt.TvltProcessor.__call__": 45
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/tvlt/image_processing_tvlt.py": [
        {
            "transformers.models.tvlt.image_processing_tvlt.TvltImageProcessor.__init__": 119
        },
        {
            "transformers.models.tvlt.image_processing_tvlt.TvltImageProcessor.resize": 155
        },
        {
            "transformers.models.tvlt.image_processing_tvlt.TvltImageProcessor.center_crop": 187
        },
        {
            "transformers.models.tvlt.image_processing_tvlt.TvltImageProcessor.rescale": 211
        },
        {
            "transformers.models.tvlt.image_processing_tvlt.TvltImageProcessor.normalize": 232
        },
        {
            "transformers.models.tvlt.image_processing_tvlt.TvltImageProcessor.preprocess": 306
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/tvlt/modeling_tvlt.py": [
        {
            "transformers.models.tvlt.modeling_tvlt.TvltEncoder.custom_forward": 565
        },
        {
            "transformers.models.tvlt.modeling_tvlt.TvltDecoder.custom_forward": 882
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/tvlt/configuration_tvlt.py": [
        {
            "transformers.models.tvlt.configuration_tvlt.TvltConfig.__init__": 115
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/tvlt/feature_extraction_tvlt.py": [
        {
            "transformers.models.tvlt.feature_extraction_tvlt.TvltFeatureExtractor.__init__": 59
        },
        {
            "transformers.models.tvlt.feature_extraction_tvlt.TvltFeatureExtractor.__call__": 116
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/graphormer/configuration_graphormer.py": [
        {
            "transformers.models.graphormer.configuration_graphormer.GraphormerConfig.__init__": 133
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/graphormer/modeling_graphormer.py": [
        {
            "transformers.models.graphormer.modeling_graphormer.GraphormerDecoderHead.forward": 702
        },
        {
            "transformers.models.graphormer.modeling_graphormer.GraphormerModel.forward": 811
        },
        {
            "transformers.models.graphormer.modeling_graphormer.GraphormerForGraphClassification.forward": 876
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/jukebox/configuration_jukebox.py": [
        {
            "transformers.models.jukebox.configuration_jukebox.JukeboxPriorConfig.__init__": 260
        },
        {
            "transformers.models.jukebox.configuration_jukebox.JukeboxPriorConfig.from_pretrained": 353
        },
        {
            "transformers.models.jukebox.configuration_jukebox.JukeboxVQVAEConfig.__init__": 440
        },
        {
            "transformers.models.jukebox.configuration_jukebox.JukeboxVQVAEConfig.from_pretrained": 488
        },
        {
            "transformers.models.jukebox.configuration_jukebox.JukeboxConfig.__init__": 562
        },
        {
            "transformers.models.jukebox.configuration_jukebox.JukeboxConfig.from_configs": 609
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/jukebox/tokenization_jukebox.py": [
        {
            "transformers.models.jukebox.tokenization_jukebox.JukeboxTokenizer.__init__": 119
        },
        {
            "transformers.models.jukebox.tokenization_jukebox.JukeboxTokenizer.tokenize": 191
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/jukebox/modeling_jukebox.py": [
        {
            "transformers.models.jukebox.modeling_jukebox.JukeboxPreTrainedModel.__init__": 2280
        },
        {
            "transformers.models.jukebox.modeling_jukebox.JukeboxModel.ancestral_sample": 2591
        },
        {
            "transformers.models.jukebox.modeling_jukebox.JukeboxModel.continue_sample": 2632
        },
        {
            "transformers.models.jukebox.modeling_jukebox.JukeboxModel.upsample": 2647
        },
        {
            "transformers.models.jukebox.modeling_jukebox.JukeboxModel.primed_sample": 2664
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/nllb/tokenization_nllb.py": [
        {
            "transformers.models.nllb.tokenization_nllb.NllbTokenizer.__init__": 128
        },
        {
            "transformers.models.nllb.tokenization_nllb.NllbTokenizer._build_translation_inputs": 317
        },
        {
            "transformers.models.nllb.tokenization_nllb.NllbTokenizer.prepare_seq2seq_batch": 374
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/nllb/tokenization_nllb_fast.py": [
        {
            "transformers.models.nllb.tokenization_nllb_fast.NllbTokenizerFast.__init__": 140
        },
        {
            "transformers.models.nllb.tokenization_nllb_fast.NllbTokenizerFast._build_translation_inputs": 261
        },
        {
            "transformers.models.nllb.tokenization_nllb_fast.NllbTokenizerFast.prepare_seq2seq_batch": 273
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/clip/modeling_flax_clip.py": [
        {
            "transformers.models.clip.modeling_flax_clip.FlaxCLIPTextPreTrainedModel.__init__": 589
        },
        {
            "transformers.models.clip.modeling_flax_clip.FlaxCLIPVisionPreTrainedModel.__init__": 669
        },
        {
            "transformers.models.clip.modeling_flax_clip.FlaxCLIPPreTrainedModel.__init__": 740
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/clip/modeling_tf_clip.py": [
        {
            "transformers.models.clip.modeling_tf_clip.TFCLIPVisionEmbeddings.__init__": 131
        },
        {
            "transformers.models.clip.modeling_tf_clip.TFCLIPTextEmbeddings.__init__": 200
        },
        {
            "transformers.models.clip.modeling_tf_clip.TFCLIPAttention.__init__": 260
        },
        {
            "transformers.models.clip.modeling_tf_clip.TFCLIPMLP.__init__": 357
        },
        {
            "transformers.models.clip.modeling_tf_clip.TFCLIPEncoderLayer.__init__": 381
        },
        {
            "transformers.models.clip.modeling_tf_clip.TFCLIPEncoder.__init__": 441
        },
        {
            "transformers.models.clip.modeling_tf_clip.TFCLIPTextTransformer.__init__": 488
        },
        {
            "transformers.models.clip.modeling_tf_clip.TFCLIPTextMainLayer.__init__": 575
        },
        {
            "transformers.models.clip.modeling_tf_clip.TFCLIPVisionTransformer.__init__": 620
        },
        {
            "transformers.models.clip.modeling_tf_clip.TFCLIPVisionMainLayer.__init__": 668
        },
        {
            "transformers.models.clip.modeling_tf_clip.TFCLIPMainLayer.__init__": 703
        },
        {
            "transformers.models.clip.modeling_tf_clip.TFCLIPTextModel.__init__": 1044
        },
        {
            "transformers.models.clip.modeling_tf_clip.TFCLIPVisionModel.__init__": 1097
        },
        {
            "transformers.models.clip.modeling_tf_clip.TFCLIPModel.__init__": 1151
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/clip/feature_extraction_clip.py": [
        {
            "transformers.models.clip.feature_extraction_clip.CLIPFeatureExtractor.__init__": 27
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/clip/tokenization_clip.py": [
        {
            "transformers.models.clip.tokenization_clip.CLIPTokenizer.__init__": 289
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/clip/configuration_clip.py": [
        {
            "transformers.models.clip.configuration_clip.CLIPTextConfig.__init__": 94
        },
        {
            "transformers.models.clip.configuration_clip.CLIPTextConfig.from_pretrained": 129
        },
        {
            "transformers.models.clip.configuration_clip.CLIPVisionConfig.__init__": 198
        },
        {
            "transformers.models.clip.configuration_clip.CLIPVisionConfig.from_pretrained": 232
        },
        {
            "transformers.models.clip.configuration_clip.CLIPConfig.__init__": 297
        },
        {
            "transformers.models.clip.configuration_clip.CLIPConfig.from_text_vision_configs": 386
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/clip/image_processing_clip.py": [
        {
            "transformers.models.clip.image_processing_clip.CLIPImageProcessor.__init__": 91
        },
        {
            "transformers.models.clip.image_processing_clip.CLIPImageProcessor.resize": 124
        },
        {
            "transformers.models.clip.image_processing_clip.CLIPImageProcessor.center_crop": 152
        },
        {
            "transformers.models.clip.image_processing_clip.CLIPImageProcessor.rescale": 176
        },
        {
            "transformers.models.clip.image_processing_clip.CLIPImageProcessor.normalize": 196
        },
        {
            "transformers.models.clip.image_processing_clip.CLIPImageProcessor.preprocess": 219
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/clip/tokenization_clip_fast.py": [
        {
            "transformers.models.clip.tokenization_clip_fast.CLIPTokenizerFast.__init__": 78
        },
        {
            "transformers.models.clip.tokenization_clip_fast.CLIPTokenizerFast.new_decode_method": 116
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/clip/processing_clip.py": [
        {
            "transformers.models.clip.processing_clip.CLIPProcessor.__init__": 42
        },
        {
            "transformers.models.clip.processing_clip.CLIPProcessor.__call__": 59
        },
        {
            "transformers.models.clip.processing_clip.CLIPProcessor.batch_decode": 112
        },
        {
            "transformers.models.clip.processing_clip.CLIPProcessor.decode": 119
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/clip/modeling_clip.py": [
        {
            "transformers.models.clip.modeling_clip.CLIPEncoder.custom_forward": 642
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/dpr/tokenization_dpr.py": [
        {
            "transformers.models.dpr.tokenization_dpr.CustomDPRReaderTokenizerMixin.__call__": 223
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/dpr/convert_dpr_original_checkpoint_to_pytorch.py": [
        {
            "transformers.models.dpr.convert_dpr_original_checkpoint_to_pytorch.DPRState.from_type": 44
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/dpr/configuration_dpr.py": [
        {
            "transformers.models.dpr.configuration_dpr.DPRConfig.__init__": 112
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/dpr/tokenization_dpr_fast.py": [
        {
            "transformers.models.dpr.tokenization_dpr_fast.CustomDPRReaderTokenizerMixin.__call__": 224
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/dpr/modeling_tf_dpr.py": [
        {
            "transformers.models.dpr.modeling_tf_dpr.TFDPREncoderLayer.__init__": 153
        },
        {
            "transformers.models.dpr.modeling_tf_dpr.TFDPRSpanPredictorLayer.__init__": 216
        },
        {
            "transformers.models.dpr.modeling_tf_dpr.TFDPRSpanPredictor.__init__": 280
        },
        {
            "transformers.models.dpr.modeling_tf_dpr.TFDPREncoder.__init__": 312
        },
        {
            "transformers.models.dpr.modeling_tf_dpr.TFDPRContextEncoder.__init__": 527
        },
        {
            "transformers.models.dpr.modeling_tf_dpr.TFDPRQuestionEncoder.__init__": 608
        },
        {
            "transformers.models.dpr.modeling_tf_dpr.TFDPRReader.__init__": 688
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/convnextv2/configuration_convnextv2.py": [
        {
            "transformers.models.convnextv2.configuration_convnextv2.ConvNextV2Config.__init__": 84
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/resnet/modeling_flax_resnet.py": [
        {
            "transformers.models.resnet.modeling_flax_resnet.Identity.__call__": 92
        },
        {
            "transformers.models.resnet.modeling_flax_resnet.FlaxResNetPreTrainedModel.__init__": 456
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/resnet/modeling_tf_resnet.py": [
        {
            "transformers.models.resnet.modeling_tf_resnet.TFResNetConvLayer.__init__": 53
        },
        {
            "transformers.models.resnet.modeling_tf_resnet.TFResNetEmbeddings.__init__": 84
        },
        {
            "transformers.models.resnet.modeling_tf_resnet.TFResNetShortCut.__init__": 115
        },
        {
            "transformers.models.resnet.modeling_tf_resnet.TFResNetBasicLayer.__init__": 135
        },
        {
            "transformers.models.resnet.modeling_tf_resnet.TFResNetBottleNeckLayer.__init__": 167
        },
        {
            "transformers.models.resnet.modeling_tf_resnet.TFResNetStage.__init__": 205
        },
        {
            "transformers.models.resnet.modeling_tf_resnet.TFResNetEncoder.__init__": 226
        },
        {
            "transformers.models.resnet.modeling_tf_resnet.TFResNetMainLayer.__init__": 314
        },
        {
            "transformers.models.resnet.modeling_tf_resnet.TFResNetModel.__init__": 373
        },
        {
            "transformers.models.resnet.modeling_tf_resnet.TFResNetForImageClassification.__init__": 415
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/resnet/configuration_resnet.py": [
        {
            "transformers.models.resnet.configuration_resnet.ResNetConfig.__init__": 88
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/longt5/modeling_longt5.py": [
        {
            "transformers.models.longt5.modeling_longt5.LongT5LayerLocalSelfAttention.forward": 1059
        },
        {
            "transformers.models.longt5.modeling_longt5.LongT5LayerTransientGlobalSelfAttention.forward": 1092
        },
        {
            "transformers.models.longt5.modeling_longt5.LongT5Stack.custom_forward": 1515
        },
        {
            "transformers.models.longt5.modeling_longt5.LongT5ForConditionalGeneration.prepare_inputs_for_generation": 2101
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/longt5/modeling_flax_longt5.py": [
        {
            "transformers.models.longt5.modeling_flax_longt5.FlaxLongT5LayerLocalSelfAttention.__call__": 1119
        },
        {
            "transformers.models.longt5.modeling_flax_longt5.FlaxLongT5LayerTransientGlobalSelfAttention.__call__": 1157
        },
        {
            "transformers.models.longt5.modeling_flax_longt5.FlaxLongT5PreTrainedModel.__init__": 1676
        },
        {
            "transformers.models.longt5.modeling_flax_longt5.FlaxLongT5PreTrainedModel._decoder_forward": 1792
        },
        {
            "transformers.models.longt5.modeling_flax_longt5.FlaxLongT5PreTrainedModel._encoder_forward": 1852
        },
        {
            "transformers.models.longt5.modeling_flax_longt5.FlaxLongT5PreTrainedModel._decoder_forward": 1937
        },
        {
            "transformers.models.longt5.modeling_flax_longt5.FlaxLongT5ForConditionalGeneration._decoder_forward": 2325
        },
        {
            "transformers.models.longt5.modeling_flax_longt5.FlaxLongT5ForConditionalGeneration.prepare_inputs_for_generation": 2387
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/longt5/configuration_longt5.py": [
        {
            "transformers.models.longt5.configuration_longt5.LongT5Config.__init__": 89
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/reformer/tokenization_reformer_fast.py": [
        {
            "transformers.models.reformer.tokenization_reformer_fast.ReformerTokenizerFast.__init__": 94
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/reformer/tokenization_reformer.py": [
        {
            "transformers.models.reformer.tokenization_reformer.ReformerTokenizer.__init__": 98
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/reformer/configuration_reformer.py": [
        {
            "transformers.models.reformer.configuration_reformer.ReformerConfig.__init__": 165
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/mt5/modeling_mt5.py": [
        {
            "transformers.models.mt5.modeling_mt5.MT5Stack.custom_forward": 1044
        },
        {
            "transformers.models.mt5.modeling_mt5.MT5ForConditionalGeneration.prepare_inputs_for_generation": 1808
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/mt5/configuration_mt5.py": [
        {
            "transformers.models.mt5.configuration_mt5.MT5Config.__init__": 72
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/auto/auto_factory.py": [
        {
            "transformers.models.auto.auto_factory._BaseAutoModelClass.__init__": 398
        },
        {
            "transformers.models.auto.auto_factory._BaseAutoModelClass.from_config": 406
        },
        {
            "transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained": 433
        },
        {
            "transformers.models.auto.auto_factory._BaseAutoBackboneClass._load_timm_backbone_from_pretrained": 517
        },
        {
            "transformers.models.auto.auto_factory._BaseAutoBackboneClass.from_pretrained": 547
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/auto/modeling_auto.py": [
        {
            "transformers.models.auto.modeling_auto.AutoModelWithLMHead.from_pretrained": 1361
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/auto/processing_auto.py": [
        {
            "transformers.models.auto.processing_auto.AutoProcessor.from_pretrained": 128
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/auto/feature_extraction_auto.py": [
        {
            "transformers.models.auto.feature_extraction_auto.get_feature_extractor_config": 131
        },
        {
            "transformers.models.auto.feature_extraction_auto.AutoFeatureExtractor.from_pretrained": 237
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/auto/configuration_auto.py": [
        {
            "transformers.models.auto.configuration_auto.AutoConfig.for_model": 848
        },
        {
            "transformers.models.auto.configuration_auto.AutoConfig.from_pretrained": 858
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/auto/image_processing_auto.py": [
        {
            "transformers.models.auto.image_processing_auto.get_image_processor_config": 138
        },
        {
            "transformers.models.auto.image_processing_auto.AutoImageProcessor.from_pretrained": 244
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/auto/modeling_tf_auto.py": [
        {
            "transformers.models.auto.modeling_tf_auto.TFAutoModelWithLMHead.from_pretrained": 680
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/auto/tokenization_auto.py": [
        {
            "transformers.models.auto.tokenization_auto.get_tokenizer_config": 413
        },
        {
            "transformers.models.auto.tokenization_auto.AutoTokenizer.from_pretrained": 529
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/electra/configuration_electra.py": [
        {
            "transformers.models.electra.configuration_electra.ElectraConfig.__init__": 135
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/electra/modeling_flax_electra.py": [
        {
            "transformers.models.electra.modeling_flax_electra.FlaxElectraPreTrainedModel.__init__": 686
        },
        {
            "transformers.models.electra.modeling_flax_electra.identity": 1178
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/electra/modeling_tf_electra.py": [
        {
            "transformers.models.electra.modeling_tf_electra.TFElectraSelfAttention.__init__": 80
        },
        {
            "transformers.models.electra.modeling_tf_electra.TFElectraSelfOutput.__init__": 198
        },
        {
            "transformers.models.electra.modeling_tf_electra.TFElectraAttention.__init__": 217
        },
        {
            "transformers.models.electra.modeling_tf_electra.TFElectraIntermediate.__init__": 258
        },
        {
            "transformers.models.electra.modeling_tf_electra.TFElectraOutput.__init__": 279
        },
        {
            "transformers.models.electra.modeling_tf_electra.TFElectraLayer.__init__": 298
        },
        {
            "transformers.models.electra.modeling_tf_electra.TFElectraEncoder.__init__": 385
        },
        {
            "transformers.models.electra.modeling_tf_electra.TFElectraPooler.__init__": 455
        },
        {
            "transformers.models.electra.modeling_tf_electra.TFElectraEmbeddings.__init__": 478
        },
        {
            "transformers.models.electra.modeling_tf_electra.TFElectraDiscriminatorPredictions.__init__": 555
        },
        {
            "transformers.models.electra.modeling_tf_electra.TFElectraGeneratorPredictions.__init__": 571
        },
        {
            "transformers.models.electra.modeling_tf_electra.TFElectraMainLayer.__init__": 602
        },
        {
            "transformers.models.electra.modeling_tf_electra.TFElectraModel.__init__": 912
        },
        {
            "transformers.models.electra.modeling_tf_electra.TFElectraForPreTraining.__init__": 991
        },
        {
            "transformers.models.electra.modeling_tf_electra.TFElectraMaskedLMHead.__init__": 1054
        },
        {
            "transformers.models.electra.modeling_tf_electra.TFElectraForMaskedLM.__init__": 1100
        },
        {
            "transformers.models.electra.modeling_tf_electra.TFElectraClassificationHead.__init__": 1184
        },
        {
            "transformers.models.electra.modeling_tf_electra.TFElectraClassificationHead.call": 1200
        },
        {
            "transformers.models.electra.modeling_tf_electra.TFElectraForSequenceClassification.__init__": 1219
        },
        {
            "transformers.models.electra.modeling_tf_electra.TFElectraForMultipleChoice.__init__": 1290
        },
        {
            "transformers.models.electra.modeling_tf_electra.TFElectraForTokenClassification.__init__": 1383
        },
        {
            "transformers.models.electra.modeling_tf_electra.TFElectraForQuestionAnswering.__init__": 1460
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/electra/modeling_electra.py": [
        {
            "transformers.models.electra.modeling_electra.ElectraEncoder.custom_forward": 574
        },
        {
            "transformers.models.electra.modeling_electra.ElectraClassificationHead.forward": 947
        },
        {
            "transformers.models.electra.modeling_electra.ElectraForCausalLM.prepare_inputs_for_generation": 1663
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/electra/tokenization_electra.py": [
        {
            "transformers.models.electra.tokenization_electra.ElectraTokenizer.__init__": 140
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/electra/tokenization_electra_fast.py": [
        {
            "transformers.models.electra.tokenization_electra_fast.ElectraTokenizerFast.__init__": 134
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/m2m_100/configuration_m2m_100.py": [
        {
            "transformers.models.m2m_100.configuration_m2m_100.M2M100Config.__init__": 106
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/m2m_100/modeling_m2m_100.py": [
        {
            "transformers.models.m2m_100.modeling_m2m_100.M2M100Encoder.custom_forward": 825
        },
        {
            "transformers.models.m2m_100.modeling_m2m_100.M2M100Decoder.custom_forward": 1071
        },
        {
            "transformers.models.m2m_100.modeling_m2m_100.M2M100ForConditionalGeneration.prepare_inputs_for_generation": 1377
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/m2m_100/tokenization_m2m_100.py": [
        {
            "transformers.models.m2m_100.tokenization_m2m_100.M2M100Tokenizer.__init__": 131
        },
        {
            "transformers.models.m2m_100.tokenization_m2m_100.M2M100Tokenizer.prepare_seq2seq_batch": 334
        },
        {
            "transformers.models.m2m_100.tokenization_m2m_100.M2M100Tokenizer._build_translation_inputs": 347
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/herbert/tokenization_herbert_fast.py": [
        {
            "transformers.models.herbert.tokenization_herbert_fast.HerbertTokenizerFast.__init__": 65
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/herbert/tokenization_herbert.py": [
        {
            "transformers.models.herbert.tokenization_herbert.HerbertTokenizer.__init__": 297
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/bit/configuration_bit.py": [
        {
            "transformers.models.bit.configuration_bit.BitConfig.__init__": 92
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/bit/image_processing_bit.py": [
        {
            "transformers.models.bit.image_processing_bit.BitImageProcessor.__init__": 91
        },
        {
            "transformers.models.bit.image_processing_bit.BitImageProcessor.resize": 124
        },
        {
            "transformers.models.bit.image_processing_bit.BitImageProcessor.center_crop": 152
        },
        {
            "transformers.models.bit.image_processing_bit.BitImageProcessor.rescale": 176
        },
        {
            "transformers.models.bit.image_processing_bit.BitImageProcessor.normalize": 196
        },
        {
            "transformers.models.bit.image_processing_bit.BitImageProcessor.preprocess": 219
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/mluke/tokenization_mluke.py": [
        {
            "transformers.models.mluke.tokenization_mluke.MLukeTokenizer.__init__": 237
        },
        {
            "transformers.models.mluke.tokenization_mluke.MLukeTokenizer.__call__": 366
        },
        {
            "transformers.models.mluke.tokenization_mluke.MLukeTokenizer._encode_plus": 512
        },
        {
            "transformers.models.mluke.tokenization_mluke.MLukeTokenizer._batch_encode_plus": 593
        },
        {
            "transformers.models.mluke.tokenization_mluke.MLukeTokenizer._create_input_sequence": 721
        },
        {
            "transformers.models.mluke.tokenization_mluke.MLukeTokenizer.prepare_for_model": 958
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/vit_mae/modeling_tf_vit_mae.py": [
        {
            "transformers.models.vit_mae.modeling_tf_vit_mae.TFViTMAEEmbeddings.__init__": 208
        },
        {
            "transformers.models.vit_mae.modeling_tf_vit_mae.TFViTMAEPatchEmbeddings.__init__": 303
        },
        {
            "transformers.models.vit_mae.modeling_tf_vit_mae.TFViTMAESelfAttention.__init__": 358
        },
        {
            "transformers.models.vit_mae.modeling_tf_vit_mae.TFViTMAESelfOutput.__init__": 439
        },
        {
            "transformers.models.vit_mae.modeling_tf_vit_mae.TFViTMAEAttention.__init__": 456
        },
        {
            "transformers.models.vit_mae.modeling_tf_vit_mae.TFViTMAEIntermediate.__init__": 485
        },
        {
            "transformers.models.vit_mae.modeling_tf_vit_mae.TFViTMAEOutput.__init__": 506
        },
        {
            "transformers.models.vit_mae.modeling_tf_vit_mae.TFViTMAELayer.__init__": 526
        },
        {
            "transformers.models.vit_mae.modeling_tf_vit_mae.TFViTMAEEncoder.__init__": 575
        },
        {
            "transformers.models.vit_mae.modeling_tf_vit_mae.TFViTMAEMainLayer.__init__": 623
        },
        {
            "transformers.models.vit_mae.modeling_tf_vit_mae.TFViTMAEModel.__init__": 779
        },
        {
            "transformers.models.vit_mae.modeling_tf_vit_mae.TFViTMAEDecoder.__init__": 834
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/vit_mae/modeling_vit_mae.py": [
        {
            "transformers.models.vit_mae.modeling_vit_mae.ViTMAEEncoder.custom_forward": 541
        },
        {
            "transformers.models.vit_mae.modeling_vit_mae.ViTMAEDecoder.custom_forward": 798
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/vit_mae/configuration_vit_mae.py": [
        {
            "transformers.models.vit_mae.configuration_vit_mae.ViTMAEConfig.__init__": 98
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/convbert/configuration_convbert.py": [
        {
            "transformers.models.convbert.configuration_convbert.ConvBertConfig.__init__": 101
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/convbert/modeling_tf_convbert.py": [
        {
            "transformers.models.convbert.modeling_tf_convbert.TFConvBertEmbeddings.__init__": 74
        },
        {
            "transformers.models.convbert.modeling_tf_convbert.TFConvBertSelfAttention.__init__": 151
        },
        {
            "transformers.models.convbert.modeling_tf_convbert.TFConvBertSelfOutput.__init__": 302
        },
        {
            "transformers.models.convbert.modeling_tf_convbert.TFConvBertAttention.__init__": 320
        },
        {
            "transformers.models.convbert.modeling_tf_convbert.GroupedLinearLayer.__init__": 340
        },
        {
            "transformers.models.convbert.modeling_tf_convbert.TFConvBertIntermediate.__init__": 373
        },
        {
            "transformers.models.convbert.modeling_tf_convbert.TFConvBertOutput.__init__": 401
        },
        {
            "transformers.models.convbert.modeling_tf_convbert.TFConvBertLayer.__init__": 428
        },
        {
            "transformers.models.convbert.modeling_tf_convbert.TFConvBertEncoder.__init__": 448
        },
        {
            "transformers.models.convbert.modeling_tf_convbert.TFConvBertPredictionHeadTransform.__init__": 491
        },
        {
            "transformers.models.convbert.modeling_tf_convbert.TFConvBertMainLayer.__init__": 517
        },
        {
            "transformers.models.convbert.modeling_tf_convbert.TFConvBertModel.__init__": 733
        },
        {
            "transformers.models.convbert.modeling_tf_convbert.TFConvBertMaskedLMHead.__init__": 775
        },
        {
            "transformers.models.convbert.modeling_tf_convbert.TFConvBertGeneratorPredictions.__init__": 812
        },
        {
            "transformers.models.convbert.modeling_tf_convbert.TFConvBertForMaskedLM.__init__": 828
        },
        {
            "transformers.models.convbert.modeling_tf_convbert.TFConvBertClassificationHead.__init__": 908
        },
        {
            "transformers.models.convbert.modeling_tf_convbert.TFConvBertClassificationHead.call": 924
        },
        {
            "transformers.models.convbert.modeling_tf_convbert.TFConvBertForSequenceClassification.__init__": 942
        },
        {
            "transformers.models.convbert.modeling_tf_convbert.TFConvBertForMultipleChoice.__init__": 1011
        },
        {
            "transformers.models.convbert.modeling_tf_convbert.TFConvBertForTokenClassification.__init__": 1104
        },
        {
            "transformers.models.convbert.modeling_tf_convbert.TFConvBertForQuestionAnswering.__init__": 1179
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/convbert/tokenization_convbert.py": [
        {
            "transformers.models.convbert.tokenization_convbert.ConvBertTokenizer.__init__": 123
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/convbert/tokenization_convbert_fast.py": [
        {
            "transformers.models.convbert.tokenization_convbert_fast.ConvBertTokenizerFast.__init__": 101
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/convbert/modeling_convbert.py": [
        {
            "transformers.models.convbert.modeling_convbert.SeparableConv1D.__init__": 275
        },
        {
            "transformers.models.convbert.modeling_convbert.ConvBertEncoder.custom_forward": 637
        },
        {
            "transformers.models.convbert.modeling_convbert.ConvBertClassificationHead.forward": 976
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/flava/processing_flava.py": [
        {
            "transformers.models.flava.processing_flava.FlavaProcessor.__init__": 43
        },
        {
            "transformers.models.flava.processing_flava.FlavaProcessor.__call__": 61
        },
        {
            "transformers.models.flava.processing_flava.FlavaProcessor.batch_decode": 129
        },
        {
            "transformers.models.flava.processing_flava.FlavaProcessor.decode": 136
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/flava/feature_extraction_flava.py": [
        {
            "transformers.models.flava.feature_extraction_flava.FlavaFeatureExtractor.__init__": 27
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/flava/image_processing_flava.py": [
        {
            "transformers.models.flava.image_processing_flava.FlavaImageProcessor.__init__": 223
        },
        {
            "transformers.models.flava.image_processing_flava.FlavaImageProcessor.from_dict": 303
        },
        {
            "transformers.models.flava.image_processing_flava.FlavaImageProcessor.resize": 334
        },
        {
            "transformers.models.flava.image_processing_flava.FlavaImageProcessor.center_crop": 362
        },
        {
            "transformers.models.flava.image_processing_flava.FlavaImageProcessor.rescale": 386
        },
        {
            "transformers.models.flava.image_processing_flava.FlavaImageProcessor.normalize": 406
        },
        {
            "transformers.models.flava.image_processing_flava.FlavaImageProcessor.preprocess": 480
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/flava/modeling_flava.py": [
        {
            "transformers.models.flava.modeling_flava.FlavaEncoder.custom_forward": 666
        },
        {
            "transformers.models.flava.modeling_flava.FlavaImageCodebookResPath.__init__": 1444
        },
        {
            "transformers.models.flava.modeling_flava.FlavaImageCodebookBlock.__init__": 1465
        },
        {
            "transformers.models.flava.modeling_flava.FlavaImageCodebook.__init__": 1515
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/flava/configuration_flava.py": [
        {
            "transformers.models.flava.configuration_flava.FlavaImageConfig.__init__": 95
        },
        {
            "transformers.models.flava.configuration_flava.FlavaImageConfig.from_pretrained": 133
        },
        {
            "transformers.models.flava.configuration_flava.FlavaTextConfig.__init__": 222
        },
        {
            "transformers.models.flava.configuration_flava.FlavaTextConfig.from_pretrained": 260
        },
        {
            "transformers.models.flava.configuration_flava.FlavaMultimodalConfig.__init__": 331
        },
        {
            "transformers.models.flava.configuration_flava.FlavaMultimodalConfig.from_pretrained": 361
        },
        {
            "transformers.models.flava.configuration_flava.FlavaImageCodebookConfig.__init__": 423
        },
        {
            "transformers.models.flava.configuration_flava.FlavaImageCodebookConfig.from_pretrained": 444
        },
        {
            "transformers.models.flava.configuration_flava.FlavaConfig.__init__": 533
        },
        {
            "transformers.models.flava.configuration_flava.FlavaConfig.from_configs": 736
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/visual_bert/configuration_visual_bert.py": [
        {
            "transformers.models.visual_bert.configuration_visual_bert.VisualBertConfig.__init__": 113
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/visual_bert/modeling_visual_bert.py": [
        {
            "transformers.models.visual_bert.modeling_visual_bert.VisualBertEncoder.custom_forward": 421
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/transfo_xl/configuration_transfo_xl.py": [
        {
            "transformers.models.transfo_xl.configuration_transfo_xl.TransfoXLConfig.__init__": 116
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/transfo_xl/modeling_tf_transfo_xl.py": [
        {
            "transformers.models.transfo_xl.modeling_tf_transfo_xl.TFPositionalEmbedding.__init__": 60
        },
        {
            "transformers.models.transfo_xl.modeling_tf_transfo_xl.TFPositionwiseFF.__init__": 77
        },
        {
            "transformers.models.transfo_xl.modeling_tf_transfo_xl.TFRelPartialLearnableMultiHeadAttn.__init__": 120
        },
        {
            "transformers.models.transfo_xl.modeling_tf_transfo_xl.TFRelPartialLearnableDecoderLayer.__init__": 272
        },
        {
            "transformers.models.transfo_xl.modeling_tf_transfo_xl.TFTransfoEmbeddings.__init__": 324
        },
        {
            "transformers.models.transfo_xl.modeling_tf_transfo_xl.TFAdaptiveEmbedding.__init__": 345
        },
        {
            "transformers.models.transfo_xl.modeling_tf_transfo_xl.TFTransfoXLMainLayer.__init__": 424
        },
        {
            "transformers.models.transfo_xl.modeling_tf_transfo_xl.TFTransfoXLModel.__init__": 872
        },
        {
            "transformers.models.transfo_xl.modeling_tf_transfo_xl.TFTransfoXLLMHeadModel.prepare_inputs_for_generation": 995
        },
        {
            "transformers.models.transfo_xl.modeling_tf_transfo_xl.TFTransfoXLForSequenceClassification.__init__": 1023
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/transfo_xl/modeling_tf_transfo_xl_utilities.py": [
        {
            "transformers.models.transfo_xl.modeling_tf_transfo_xl_utilities.TFAdaptiveSoftmaxMask.__init__": 27
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/transfo_xl/modeling_transfo_xl.py": [
        {
            "transformers.models.transfo_xl.modeling_transfo_xl.RelPartialLearnableDecoderLayer.__init__": 373
        },
        {
            "transformers.models.transfo_xl.modeling_transfo_xl.TransfoXLLMHeadModel.prepare_inputs_for_generation": 1148
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/transfo_xl/tokenization_transfo_xl.py": [
        {
            "transformers.models.transfo_xl.tokenization_transfo_xl.TransfoXLTokenizer.__init__": 168
        },
        {
            "transformers.models.transfo_xl.tokenization_transfo_xl.TransfoXLCorpus.from_pretrained": 678
        },
        {
            "transformers.models.transfo_xl.tokenization_transfo_xl.TransfoXLCorpus.__init__": 713
        },
        {
            "transformers.models.transfo_xl.tokenization_transfo_xl.TransfoXLCorpus.get_iterator": 754
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/sew_d/configuration_sew_d.py": [
        {
            "transformers.models.sew_d.configuration_sew_d.SEWDConfig.__init__": 172
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/sew_d/modeling_sew_d.py": [
        {
            "transformers.models.sew_d.modeling_sew_d.SEWDFeatureEncoder.custom_forward": 458
        },
        {
            "transformers.models.sew_d.modeling_sew_d.SEWDTransformerEncoder.custom_forward": 1139
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/ctrl/configuration_ctrl.py": [
        {
            "transformers.models.ctrl.configuration_ctrl.CTRLConfig.__init__": 87
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/ctrl/modeling_ctrl.py": [
        {
            "transformers.models.ctrl.modeling_ctrl.CTRLLMHeadModel.prepare_inputs_for_generation": 528
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/ctrl/tokenization_ctrl.py": [
        {
            "transformers.models.ctrl.tokenization_ctrl.CTRLTokenizer.__init__": 141
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/ctrl/modeling_tf_ctrl.py": [
        {
            "transformers.models.ctrl.modeling_tf_ctrl.TFMultiHeadAttention.__init__": 97
        },
        {
            "transformers.models.ctrl.modeling_tf_ctrl.TFPointWiseFeedForwardLayer.__init__": 150
        },
        {
            "transformers.models.ctrl.modeling_tf_ctrl.TFEncoderLayer.__init__": 164
        },
        {
            "transformers.models.ctrl.modeling_tf_ctrl.TFCTRLMainLayer.__init__": 213
        },
        {
            "transformers.models.ctrl.modeling_tf_ctrl.TFCTRLModel.__init__": 525
        },
        {
            "transformers.models.ctrl.modeling_tf_ctrl.TFCTRLLMHead.__init__": 569
        },
        {
            "transformers.models.ctrl.modeling_tf_ctrl.TFCTRLLMHeadModel.__init__": 611
        },
        {
            "transformers.models.ctrl.modeling_tf_ctrl.TFCTRLLMHeadModel.prepare_inputs_for_generation": 626
        },
        {
            "transformers.models.ctrl.modeling_tf_ctrl.TFCTRLForSequenceClassification.__init__": 716
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/yoso/configuration_yoso.py": [
        {
            "transformers.models.yoso.configuration_yoso.YosoConfig.__init__": 99
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/yoso/modeling_yoso.py": [
        {
            "transformers.models.yoso.modeling_yoso.YosoEncoder.custom_forward": 564
        },
        {
            "transformers.models.yoso.modeling_yoso.YosoClassificationHead.forward": 943
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/xlm_roberta/tokenization_xlm_roberta.py": [
        {
            "transformers.models.xlm_roberta.tokenization_xlm_roberta.XLMRobertaTokenizer.__init__": 137
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/xlm_roberta/modeling_tf_xlm_roberta.py": [
        {
            "transformers.models.xlm_roberta.modeling_tf_xlm_roberta.TFXLMRobertaEmbeddings.__init__": 170
        },
        {
            "transformers.models.xlm_roberta.modeling_tf_xlm_roberta.TFXLMRobertaPooler.__init__": 267
        },
        {
            "transformers.models.xlm_roberta.modeling_tf_xlm_roberta.TFXLMRobertaSelfAttention.__init__": 288
        },
        {
            "transformers.models.xlm_roberta.modeling_tf_xlm_roberta.TFXLMRobertaSelfOutput.__init__": 406
        },
        {
            "transformers.models.xlm_roberta.modeling_tf_xlm_roberta.TFXLMRobertaAttention.__init__": 425
        },
        {
            "transformers.models.xlm_roberta.modeling_tf_xlm_roberta.TFXLMRobertaIntermediate.__init__": 466
        },
        {
            "transformers.models.xlm_roberta.modeling_tf_xlm_roberta.TFXLMRobertaOutput.__init__": 487
        },
        {
            "transformers.models.xlm_roberta.modeling_tf_xlm_roberta.TFXLMRobertaLayer.__init__": 506
        },
        {
            "transformers.models.xlm_roberta.modeling_tf_xlm_roberta.TFXLMRobertaEncoder.__init__": 593
        },
        {
            "transformers.models.xlm_roberta.modeling_tf_xlm_roberta.TFXLMRobertaMainLayer.__init__": 666
        },
        {
            "transformers.models.xlm_roberta.modeling_tf_xlm_roberta.TFXLMRobertaModel.__init__": 876
        },
        {
            "transformers.models.xlm_roberta.modeling_tf_xlm_roberta.TFXLMRobertaLMHead.__init__": 948
        },
        {
            "transformers.models.xlm_roberta.modeling_tf_xlm_roberta.TFXLMRobertaForMaskedLM.__init__": 1003
        },
        {
            "transformers.models.xlm_roberta.modeling_tf_xlm_roberta.TFXLMRobertaForCausalLM.__init__": 1085
        },
        {
            "transformers.models.xlm_roberta.modeling_tf_xlm_roberta.TFXLMRobertaForCausalLM.prepare_inputs_for_generation": 1102
        },
        {
            "transformers.models.xlm_roberta.modeling_tf_xlm_roberta.TFXLMRobertaClassificationHead.__init__": 1207
        },
        {
            "transformers.models.xlm_roberta.modeling_tf_xlm_roberta.TFXLMRobertaForSequenceClassification.__init__": 1244
        },
        {
            "transformers.models.xlm_roberta.modeling_tf_xlm_roberta.TFXLMRobertaForMultipleChoice.__init__": 1322
        },
        {
            "transformers.models.xlm_roberta.modeling_tf_xlm_roberta.TFXLMRobertaForTokenClassification.__init__": 1415
        },
        {
            "transformers.models.xlm_roberta.modeling_tf_xlm_roberta.TFXLMRobertaForQuestionAnswering.__init__": 1498
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/xlm_roberta/modeling_xlm_roberta.py": [
        {
            "transformers.models.xlm_roberta.modeling_xlm_roberta.XLMRobertaEncoder.custom_forward": 514
        },
        {
            "transformers.models.xlm_roberta.modeling_xlm_roberta.XLMRobertaForCausalLM.prepare_inputs_for_generation": 1021
        },
        {
            "transformers.models.xlm_roberta.modeling_xlm_roberta.XLMRobertaLMHead.forward": 1156
        },
        {
            "transformers.models.xlm_roberta.modeling_xlm_roberta.XLMRobertaClassificationHead.forward": 1476
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/xlm_roberta/configuration_xlm_roberta.py": [
        {
            "transformers.models.xlm_roberta.configuration_xlm_roberta.XLMRobertaConfig.__init__": 115
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/xlm_roberta/modeling_flax_xlm_roberta.py": [
        {
            "transformers.models.xlm_roberta.modeling_flax_xlm_roberta.FlaxXLMRobertaPreTrainedModel.__init__": 746
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/xlm_roberta/tokenization_xlm_roberta_fast.py": [
        {
            "transformers.models.xlm_roberta.tokenization_xlm_roberta_fast.XLMRobertaTokenizerFast.__init__": 139
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/gpt2/configuration_gpt2.py": [
        {
            "transformers.models.gpt2.configuration_gpt2.GPT2Config.__init__": 140
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/gpt2/tokenization_gpt2.py": [
        {
            "transformers.models.gpt2.tokenization_gpt2.GPT2Tokenizer.__init__": 159
        },
        {
            "transformers.models.gpt2.tokenization_gpt2.GPT2Tokenizer.prepare_for_tokenization": 351
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/gpt2/tokenization_gpt2_fast.py": [
        {
            "transformers.models.gpt2.tokenization_gpt2_fast.GPT2TokenizerFast.__init__": 129
        },
        {
            "transformers.models.gpt2.tokenization_gpt2_fast.GPT2TokenizerFast._batch_encode_plus": 161
        },
        {
            "transformers.models.gpt2.tokenization_gpt2_fast.GPT2TokenizerFast._encode_plus": 170
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/gpt2/modeling_tf_gpt2.py": [
        {
            "transformers.models.gpt2.modeling_tf_gpt2.TFAttention.__init__": 71
        },
        {
            "transformers.models.gpt2.modeling_tf_gpt2.TFMLP.__init__": 207
        },
        {
            "transformers.models.gpt2.modeling_tf_gpt2.TFBlock.__init__": 223
        },
        {
            "transformers.models.gpt2.modeling_tf_gpt2.TFGPT2MainLayer.__init__": 304
        },
        {
            "transformers.models.gpt2.modeling_tf_gpt2.TFGPT2Model.__init__": 676
        },
        {
            "transformers.models.gpt2.modeling_tf_gpt2.TFGPT2LMHeadModel.__init__": 753
        },
        {
            "transformers.models.gpt2.modeling_tf_gpt2.TFGPT2LMHeadModel.prepare_inputs_for_generation": 763
        },
        {
            "transformers.models.gpt2.modeling_tf_gpt2.TFGPT2DoubleHeadsModel.__init__": 887
        },
        {
            "transformers.models.gpt2.modeling_tf_gpt2.TFGPT2ForSequenceClassification.__init__": 1022
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/gpt2/modeling_flax_gpt2.py": [
        {
            "transformers.models.gpt2.modeling_flax_gpt2.FlaxGPT2PreTrainedModel.__init__": 390
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/gpt2/modeling_gpt2.py": [
        {
            "transformers.models.gpt2.modeling_gpt2.GPT2PreTrainedModel.__init__": 454
        },
        {
            "transformers.models.gpt2.modeling_gpt2.GPT2Model.custom_forward": 887
        },
        {
            "transformers.models.gpt2.modeling_gpt2.GPT2LMHeadModel.prepare_inputs_for_generation": 1012
        },
        {
            "transformers.models.gpt2.modeling_gpt2.GPT2DoubleHeadsModel.prepare_inputs_for_generation": 1209
        },
        {
            "transformers.models.gpt2.modeling_gpt2.GPT2DoubleHeadsModel.forward": 1240
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/gpt2/tokenization_gpt2_tf.py": [
        {
            "transformers.models.gpt2.tokenization_gpt2_tf.TFGPT2Tokenizer.from_tokenizer": 36
        },
        {
            "transformers.models.gpt2.tokenization_gpt2_tf.TFGPT2Tokenizer.from_pretrained": 56
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/informer/configuration_informer.py": [
        {
            "transformers.models.informer.configuration_informer.InformerConfig.__init__": 143
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/informer/modeling_informer.py": [
        {
            "transformers.models.informer.modeling_informer.InformerEncoder.custom_forward": 1215
        },
        {
            "transformers.models.informer.modeling_informer.InformerDecoder.custom_forward": 1437
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/funnel/modeling_tf_funnel.py": [
        {
            "transformers.models.funnel.modeling_tf_funnel.TFFunnelEmbeddings.__init__": 83
        },
        {
            "transformers.models.funnel.modeling_tf_funnel.TFFunnelRelMultiheadAttention.__init__": 386
        },
        {
            "transformers.models.funnel.modeling_tf_funnel.TFFunnelPositionwiseFFN.__init__": 551
        },
        {
            "transformers.models.funnel.modeling_tf_funnel.TFFunnelLayer.__init__": 571
        },
        {
            "transformers.models.funnel.modeling_tf_funnel.TFFunnelEncoder.__init__": 585
        },
        {
            "transformers.models.funnel.modeling_tf_funnel.TFFunnelDecoder.__init__": 675
        },
        {
            "transformers.models.funnel.modeling_tf_funnel.TFFunnelBaseLayer.__init__": 735
        },
        {
            "transformers.models.funnel.modeling_tf_funnel.TFFunnelMainLayer.__init__": 805
        },
        {
            "transformers.models.funnel.modeling_tf_funnel.TFFunnelDiscriminatorPredictions.__init__": 902
        },
        {
            "transformers.models.funnel.modeling_tf_funnel.TFFunnelMaskedLMHead.__init__": 917
        },
        {
            "transformers.models.funnel.modeling_tf_funnel.TFFunnelClassificationHead.__init__": 953
        },
        {
            "transformers.models.funnel.modeling_tf_funnel.TFFunnelBaseModel.__init__": 1108
        },
        {
            "transformers.models.funnel.modeling_tf_funnel.TFFunnelModel.__init__": 1156
        },
        {
            "transformers.models.funnel.modeling_tf_funnel.TFFunnelForPreTraining.__init__": 1206
        },
        {
            "transformers.models.funnel.modeling_tf_funnel.TFFunnelForPreTraining.call": 1215
        },
        {
            "transformers.models.funnel.modeling_tf_funnel.TFFunnelForMaskedLM.__init__": 1274
        },
        {
            "transformers.models.funnel.modeling_tf_funnel.TFFunnelForSequenceClassification.__init__": 1352
        },
        {
            "transformers.models.funnel.modeling_tf_funnel.TFFunnelForMultipleChoice.__init__": 1427
        },
        {
            "transformers.models.funnel.modeling_tf_funnel.TFFunnelForTokenClassification.__init__": 1522
        },
        {
            "transformers.models.funnel.modeling_tf_funnel.TFFunnelForQuestionAnswering.__init__": 1599
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/funnel/tokenization_funnel_fast.py": [
        {
            "transformers.models.funnel.tokenization_funnel_fast.FunnelTokenizerFast.__init__": 145
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/funnel/configuration_funnel.py": [
        {
            "transformers.models.funnel.configuration_funnel.FunnelConfig.__init__": 105
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/funnel/tokenization_funnel.py": [
        {
            "transformers.models.funnel.tokenization_funnel.FunnelTokenizer.__init__": 143
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/pegasus_x/configuration_pegasus_x.py": [
        {
            "transformers.models.pegasus_x.configuration_pegasus_x.PegasusXConfig.__init__": 110
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/pegasus_x/modeling_pegasus_x.py": [
        {
            "transformers.models.pegasus_x.modeling_pegasus_x.PegasusXEncoder.custom_forward": 1070
        },
        {
            "transformers.models.pegasus_x.modeling_pegasus_x.PegasusXDecoder.custom_forward": 1327
        },
        {
            "transformers.models.pegasus_x.modeling_pegasus_x.PegasusXForConditionalGeneration.prepare_inputs_for_generation": 1665
        },
        {
            "transformers.models.pegasus_x.modeling_pegasus_x.PegasusXDecoderWrapper.forward": 1712
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/deberta/configuration_deberta.py": [
        {
            "transformers.models.deberta.configuration_deberta.DebertaConfig.__init__": 110
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/deberta/tokenization_deberta_fast.py": [
        {
            "transformers.models.deberta.tokenization_deberta_fast.DebertaTokenizerFast.__init__": 145
        },
        {
            "transformers.models.deberta.tokenization_deberta_fast.DebertaTokenizerFast._batch_encode_plus": 267
        },
        {
            "transformers.models.deberta.tokenization_deberta_fast.DebertaTokenizerFast._encode_plus": 277
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/deberta/tokenization_deberta.py": [
        {
            "transformers.models.deberta.tokenization_deberta.DebertaTokenizer.__init__": 182
        },
        {
            "transformers.models.deberta.tokenization_deberta.DebertaTokenizer.prepare_for_tokenization": 431
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/deberta/modeling_deberta.py": [
        {
            "transformers.models.deberta.modeling_deberta.DebertaEncoder.custom_forward": 462
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/deberta/modeling_tf_deberta.py": [
        {
            "transformers.models.deberta.modeling_tf_deberta.TFDebertaContextPooler.__init__": 62
        },
        {
            "transformers.models.deberta.modeling_tf_deberta.TFDebertaXSoftmax.__init__": 92
        },
        {
            "transformers.models.deberta.modeling_tf_deberta.TFDebertaStableDropout.__init__": 112
        },
        {
            "transformers.models.deberta.modeling_tf_deberta.TFDebertaLayerNorm.__init__": 147
        },
        {
            "transformers.models.deberta.modeling_tf_deberta.TFDebertaSelfOutput.__init__": 165
        },
        {
            "transformers.models.deberta.modeling_tf_deberta.TFDebertaAttention.__init__": 179
        },
        {
            "transformers.models.deberta.modeling_tf_deberta.TFDebertaIntermediate.__init__": 216
        },
        {
            "transformers.models.deberta.modeling_tf_deberta.TFDebertaOutput.__init__": 236
        },
        {
            "transformers.models.deberta.modeling_tf_deberta.TFDebertaLayer.__init__": 254
        },
        {
            "transformers.models.deberta.modeling_tf_deberta.TFDebertaEncoder.__init__": 291
        },
        {
            "transformers.models.deberta.modeling_tf_deberta.TFDebertaDisentangledSelfAttention.__init__": 476
        },
        {
            "transformers.models.deberta.modeling_tf_deberta.TFDebertaEmbeddings.__init__": 719
        },
        {
            "transformers.models.deberta.modeling_tf_deberta.TFDebertaPredictionHeadTransform.__init__": 820
        },
        {
            "transformers.models.deberta.modeling_tf_deberta.TFDebertaLMPredictionHead.__init__": 844
        },
        {
            "transformers.models.deberta.modeling_tf_deberta.TFDebertaOnlyMLMHead.__init__": 887
        },
        {
            "transformers.models.deberta.modeling_tf_deberta.TFDebertaMainLayer.__init__": 901
        },
        {
            "transformers.models.deberta.modeling_tf_deberta.TFDebertaModel.__init__": 1082
        },
        {
            "transformers.models.deberta.modeling_tf_deberta.TFDebertaForMaskedLM.__init__": 1123
        },
        {
            "transformers.models.deberta.modeling_tf_deberta.TFDebertaForSequenceClassification.__init__": 1199
        },
        {
            "transformers.models.deberta.modeling_tf_deberta.TFDebertaForTokenClassification.__init__": 1280
        },
        {
            "transformers.models.deberta.modeling_tf_deberta.TFDebertaForQuestionAnswering.__init__": 1351
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/qdqbert/configuration_qdqbert.py": [
        {
            "transformers.models.qdqbert.configuration_qdqbert.QDQBertConfig.__init__": 90
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/qdqbert/modeling_qdqbert.py": [
        {
            "transformers.models.qdqbert.modeling_qdqbert.QDQBertEncoder.custom_forward": 584
        },
        {
            "transformers.models.qdqbert.modeling_qdqbert.QDQBertLMHeadModel.prepare_inputs_for_generation": 1141
        },
        {
            "transformers.models.qdqbert.modeling_qdqbert.QDQBertForMaskedLM.prepare_inputs_for_generation": 1255
        },
        {
            "transformers.models.qdqbert.modeling_qdqbert.QDQBertForNextSentencePrediction.forward": 1290
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/mvp/tokenization_mvp_fast.py": [
        {
            "transformers.models.mvp.tokenization_mvp_fast.MvpTokenizerFast.__init__": 139
        },
        {
            "transformers.models.mvp.tokenization_mvp_fast.MvpTokenizerFast._batch_encode_plus": 235
        },
        {
            "transformers.models.mvp.tokenization_mvp_fast.MvpTokenizerFast._encode_plus": 246
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/mvp/modeling_mvp.py": [
        {
            "transformers.models.mvp.modeling_mvp.MvpEncoder.custom_forward": 951
        },
        {
            "transformers.models.mvp.modeling_mvp.MvpDecoder.custom_forward": 1228
        },
        {
            "transformers.models.mvp.modeling_mvp.MvpForConditionalGeneration.prepare_inputs_for_generation": 1557
        },
        {
            "transformers.models.mvp.modeling_mvp.MvpForSequenceClassification.__init__": 1610
        },
        {
            "transformers.models.mvp.modeling_mvp.MvpDecoderWrapper.forward": 1862
        },
        {
            "transformers.models.mvp.modeling_mvp.MvpForCausalLM.prepare_inputs_for_generation": 2046
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/mvp/tokenization_mvp.py": [
        {
            "transformers.models.mvp.tokenization_mvp.MvpTokenizer.__init__": 172
        },
        {
            "transformers.models.mvp.tokenization_mvp.MvpTokenizer.prepare_for_tokenization": 402
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/mvp/configuration_mvp.py": [
        {
            "transformers.models.mvp.configuration_mvp.MvpConfig.__init__": 111
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/layoutxlm/processing_layoutxlm.py": [
        {
            "transformers.models.layoutxlm.processing_layoutxlm.LayoutXLMProcessor.__call__": 47
        },
        {
            "transformers.models.layoutxlm.processing_layoutxlm.LayoutXLMProcessor.batch_decode": 148
        },
        {
            "transformers.models.layoutxlm.processing_layoutxlm.LayoutXLMProcessor.decode": 155
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/layoutxlm/tokenization_layoutxlm_fast.py": [
        {
            "transformers.models.layoutxlm.tokenization_layoutxlm_fast.LayoutXLMTokenizerFast.__init__": 220
        },
        {
            "transformers.models.layoutxlm.tokenization_layoutxlm_fast.LayoutXLMTokenizerFast.__call__": 270
        },
        {
            "transformers.models.layoutxlm.tokenization_layoutxlm_fast.LayoutXLMTokenizerFast.tokenize": 418
        },
        {
            "transformers.models.layoutxlm.tokenization_layoutxlm_fast.LayoutXLMTokenizerFast._batch_encode_plus": 426
        },
        {
            "transformers.models.layoutxlm.tokenization_layoutxlm_fast.LayoutXLMTokenizerFast._encode_plus": 583
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/layoutxlm/tokenization_layoutxlm.py": [
        {
            "transformers.models.layoutxlm.tokenization_layoutxlm.LayoutXLMTokenizer.__init__": 234
        },
        {
            "transformers.models.layoutxlm.tokenization_layoutxlm.LayoutXLMTokenizer.__call__": 445
        },
        {
            "transformers.models.layoutxlm.tokenization_layoutxlm.LayoutXLMTokenizer._batch_encode_plus": 593
        },
        {
            "transformers.models.layoutxlm.tokenization_layoutxlm.LayoutXLMTokenizer._encode_plus": 719
        },
        {
            "transformers.models.layoutxlm.tokenization_layoutxlm.LayoutXLMTokenizer.prepare_for_model": 772
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/maskformer/configuration_maskformer.py": [
        {
            "transformers.models.maskformer.configuration_maskformer.MaskFormerConfig.__init__": 103
        },
        {
            "transformers.models.maskformer.configuration_maskformer.MaskFormerConfig.from_backbone_and_decoder_configs": 184
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/maskformer/modeling_maskformer.py": [
        {
            "transformers.models.maskformer.modeling_maskformer.DetrDecoder.custom_forward": 777
        },
        {
            "transformers.models.maskformer.modeling_maskformer.MaskFormerPixelDecoder.__init__": 1243
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/maskformer/feature_extraction_maskformer.py": [
        {
            "transformers.models.maskformer.feature_extraction_maskformer.MaskFormerFeatureExtractor.__init__": 27
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/maskformer/modeling_maskformer_swin.py": [
        {
            "transformers.models.maskformer.modeling_maskformer_swin.MaskFormerSwinEncoder.custom_forward": 693
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/maskformer/configuration_maskformer_swin.py": [
        {
            "transformers.models.maskformer.configuration_maskformer_swin.MaskFormerSwinConfig.__init__": 100
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/maskformer/image_processing_maskformer.py": [
        {
            "transformers.models.maskformer.image_processing_maskformer.MaskFormerImageProcessor.__init__": 385
        },
        {
            "transformers.models.maskformer.image_processing_maskformer.MaskFormerImageProcessor.from_dict": 443
        },
        {
            "transformers.models.maskformer.image_processing_maskformer.MaskFormerImageProcessor.resize": 482
        },
        {
            "transformers.models.maskformer.image_processing_maskformer.MaskFormerImageProcessor.convert_segmentation_map_to_binary_masks": 545
        },
        {
            "transformers.models.maskformer.image_processing_maskformer.MaskFormerImageProcessor.__call__": 562
        },
        {
            "transformers.models.maskformer.image_processing_maskformer.MaskFormerImageProcessor.preprocess": 650
        },
        {
            "transformers.models.maskformer.image_processing_maskformer.MaskFormerImageProcessor.encode_inputs": 815
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/vision_text_dual_encoder/modeling_flax_vision_text_dual_encoder.py": [
        {
            "transformers.models.vision_text_dual_encoder.modeling_flax_vision_text_dual_encoder.FlaxVisionTextDualEncoderModel.__init__": 223
        },
        {
            "transformers.models.vision_text_dual_encoder.modeling_flax_vision_text_dual_encoder.FlaxVisionTextDualEncoderModel.from_vision_text_pretrained": 415
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/vision_text_dual_encoder/modeling_vision_text_dual_encoder.py": [
        {
            "transformers.models.vision_text_dual_encoder.modeling_vision_text_dual_encoder.VisionTextDualEncoderModel.from_pretrained": 408
        },
        {
            "transformers.models.vision_text_dual_encoder.modeling_vision_text_dual_encoder.VisionTextDualEncoderModel.from_vision_text_pretrained": 415
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/vision_text_dual_encoder/processing_vision_text_dual_encoder.py": [
        {
            "transformers.models.vision_text_dual_encoder.processing_vision_text_dual_encoder.VisionTextDualEncoderProcessor.__init__": 44
        },
        {
            "transformers.models.vision_text_dual_encoder.processing_vision_text_dual_encoder.VisionTextDualEncoderProcessor.__call__": 62
        },
        {
            "transformers.models.vision_text_dual_encoder.processing_vision_text_dual_encoder.VisionTextDualEncoderProcessor.batch_decode": 115
        },
        {
            "transformers.models.vision_text_dual_encoder.processing_vision_text_dual_encoder.VisionTextDualEncoderProcessor.decode": 122
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/vision_text_dual_encoder/modeling_tf_vision_text_dual_encoder.py": [
        {
            "transformers.models.vision_text_dual_encoder.modeling_tf_vision_text_dual_encoder.TFVisionTextDualEncoderModel.from_pretrained": 231
        },
        {
            "transformers.models.vision_text_dual_encoder.modeling_tf_vision_text_dual_encoder.TFVisionTextDualEncoderModel.from_vision_text_pretrained": 462
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/vision_text_dual_encoder/configuration_vision_text_dual_encoder.py": [
        {
            "transformers.models.vision_text_dual_encoder.configuration_vision_text_dual_encoder.VisionTextDualEncoderConfig.__init__": 78
        },
        {
            "transformers.models.vision_text_dual_encoder.configuration_vision_text_dual_encoder.VisionTextDualEncoderConfig.from_vision_text_configs": 106
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/prophetnet/configuration_prophetnet.py": [
        {
            "transformers.models.prophetnet.configuration_prophetnet.ProphetNetConfig.__init__": 107
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/prophetnet/modeling_prophetnet.py": [
        {
            "transformers.models.prophetnet.modeling_prophetnet.ProphetNetEncoder.custom_forward": 1334
        },
        {
            "transformers.models.prophetnet.modeling_prophetnet.ProphetNetDecoder.custom_forward": 1574
        },
        {
            "transformers.models.prophetnet.modeling_prophetnet.ProphetNetForConditionalGeneration.prepare_inputs_for_generation": 2036
        },
        {
            "transformers.models.prophetnet.modeling_prophetnet.ProphetNetForCausalLM.prepare_inputs_for_generation": 2290
        },
        {
            "transformers.models.prophetnet.modeling_prophetnet.ProphetNetDecoderWrapper.forward": 2333
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/prophetnet/tokenization_prophetnet.py": [
        {
            "transformers.models.prophetnet.tokenization_prophetnet.ProphetNetTokenizer.__init__": 330
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/mobilebert/modeling_tf_mobilebert.py": [
        {
            "transformers.models.mobilebert.modeling_tf_mobilebert.TFMobileBertIntermediate.__init__": 124
        },
        {
            "transformers.models.mobilebert.modeling_tf_mobilebert.TFLayerNorm.__init__": 142
        },
        {
            "transformers.models.mobilebert.modeling_tf_mobilebert.TFNoNorm.__init__": 147
        },
        {
            "transformers.models.mobilebert.modeling_tf_mobilebert.TFMobileBertEmbeddings.__init__": 166
        },
        {
            "transformers.models.mobilebert.modeling_tf_mobilebert.TFMobileBertSelfAttention.__init__": 259
        },
        {
            "transformers.models.mobilebert.modeling_tf_mobilebert.TFMobileBertSelfOutput.__init__": 337
        },
        {
            "transformers.models.mobilebert.modeling_tf_mobilebert.TFMobileBertAttention.__init__": 358
        },
        {
            "transformers.models.mobilebert.modeling_tf_mobilebert.TFOutputBottleneck.__init__": 387
        },
        {
            "transformers.models.mobilebert.modeling_tf_mobilebert.TFMobileBertOutput.__init__": 403
        },
        {
            "transformers.models.mobilebert.modeling_tf_mobilebert.TFBottleneckLayer.__init__": 429
        },
        {
            "transformers.models.mobilebert.modeling_tf_mobilebert.TFBottleneck.__init__": 443
        },
        {
            "transformers.models.mobilebert.modeling_tf_mobilebert.TFFFNOutput.__init__": 479
        },
        {
            "transformers.models.mobilebert.modeling_tf_mobilebert.TFFFNLayer.__init__": 493
        },
        {
            "transformers.models.mobilebert.modeling_tf_mobilebert.TFMobileBertLayer.__init__": 505
        },
        {
            "transformers.models.mobilebert.modeling_tf_mobilebert.TFMobileBertEncoder.__init__": 565
        },
        {
            "transformers.models.mobilebert.modeling_tf_mobilebert.TFMobileBertPooler.__init__": 608
        },
        {
            "transformers.models.mobilebert.modeling_tf_mobilebert.TFMobileBertPredictionHeadTransform.__init__": 631
        },
        {
            "transformers.models.mobilebert.modeling_tf_mobilebert.TFMobileBertLMPredictionHead.__init__": 650
        },
        {
            "transformers.models.mobilebert.modeling_tf_mobilebert.TFMobileBertMLMHead.__init__": 693
        },
        {
            "transformers.models.mobilebert.modeling_tf_mobilebert.TFMobileBertMainLayer.__init__": 706
        },
        {
            "transformers.models.mobilebert.modeling_tf_mobilebert.TFMobileBertModel.__init__": 962
        },
        {
            "transformers.models.mobilebert.modeling_tf_mobilebert.TFMobileBertForPreTraining.__init__": 1010
        },
        {
            "transformers.models.mobilebert.modeling_tf_mobilebert.TFMobileBertForMaskedLM.__init__": 1101
        },
        {
            "transformers.models.mobilebert.modeling_tf_mobilebert.TFMobileBertOnlyNSPHead.__init__": 1173
        },
        {
            "transformers.models.mobilebert.modeling_tf_mobilebert.TFMobileBertForNextSentencePrediction.__init__": 1190
        },
        {
            "transformers.models.mobilebert.modeling_tf_mobilebert.TFMobileBertForSequenceClassification.__init__": 1281
        },
        {
            "transformers.models.mobilebert.modeling_tf_mobilebert.TFMobileBertForQuestionAnswering.__init__": 1371
        },
        {
            "transformers.models.mobilebert.modeling_tf_mobilebert.TFMobileBertForMultipleChoice.__init__": 1470
        },
        {
            "transformers.models.mobilebert.modeling_tf_mobilebert.TFMobileBertForTokenClassification.__init__": 1572
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/mobilebert/tokenization_mobilebert_fast.py": [
        {
            "transformers.models.mobilebert.tokenization_mobilebert_fast.MobileBertTokenizerFast.__init__": 92
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/mobilebert/modeling_mobilebert.py": [
        {
            "transformers.models.mobilebert.modeling_mobilebert.MobileBertForNextSentencePrediction.forward": 1154
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/mobilebert/configuration_mobilebert.py": [
        {
            "transformers.models.mobilebert.configuration_mobilebert.MobileBertConfig.__init__": 114
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/mobilebert/tokenization_mobilebert.py": [
        {
            "transformers.models.mobilebert.tokenization_mobilebert.MobileBertTokenizer.__init__": 112
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/rwkv/modeling_rwkv.py": [
        {
            "transformers.models.rwkv.modeling_rwkv.RwkvForCausalLM.prepare_inputs_for_generation": 749
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/rwkv/configuration_rwkv.py": [
        {
            "transformers.models.rwkv.configuration_rwkv.RwkvConfig.__init__": 99
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/mpnet/configuration_mpnet.py": [
        {
            "transformers.models.mpnet.configuration_mpnet.MPNetConfig.__init__": 84
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/mpnet/modeling_mpnet.py": [
        {
            "transformers.models.mpnet.modeling_mpnet.MPNetEmbeddings.forward": 88
        },
        {
            "transformers.models.mpnet.modeling_mpnet.MPNetSelfAttention.forward": 157
        },
        {
            "transformers.models.mpnet.modeling_mpnet.MPNetAttention.forward": 230
        },
        {
            "transformers.models.mpnet.modeling_mpnet.MPNetLayer.forward": 289
        },
        {
            "transformers.models.mpnet.modeling_mpnet.MPNetEncoder.forward": 322
        },
        {
            "transformers.models.mpnet.modeling_mpnet.MPNetModel.forward": 515
        },
        {
            "transformers.models.mpnet.modeling_mpnet.MPNetLMHead.forward": 662
        },
        {
            "transformers.models.mpnet.modeling_mpnet.MPNetClassificationHead.forward": 946
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/mpnet/tokenization_mpnet_fast.py": [
        {
            "transformers.models.mpnet.tokenization_mpnet_fast.MPNetTokenizerFast.__init__": 113
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/mpnet/modeling_tf_mpnet.py": [
        {
            "transformers.models.mpnet.modeling_tf_mpnet.TFMPNetEmbeddings.__init__": 83
        },
        {
            "transformers.models.mpnet.modeling_tf_mpnet.TFMPNetPooler.__init__": 159
        },
        {
            "transformers.models.mpnet.modeling_tf_mpnet.TFMPNetSelfAttention.__init__": 179
        },
        {
            "transformers.models.mpnet.modeling_tf_mpnet.TFMPNetAttention.__init__": 252
        },
        {
            "transformers.models.mpnet.modeling_tf_mpnet.TFMPNetIntermediate.__init__": 273
        },
        {
            "transformers.models.mpnet.modeling_tf_mpnet.TFMPNetOutput.__init__": 294
        },
        {
            "transformers.models.mpnet.modeling_tf_mpnet.TFMPNetLayer.__init__": 312
        },
        {
            "transformers.models.mpnet.modeling_tf_mpnet.TFMPNetEncoder.__init__": 334
        },
        {
            "transformers.models.mpnet.modeling_tf_mpnet.TFMPNetMainLayer.__init__": 448
        },
        {
            "transformers.models.mpnet.modeling_tf_mpnet.TFMPNetModel.__init__": 660
        },
        {
            "transformers.models.mpnet.modeling_tf_mpnet.TFMPNetLMHead.__init__": 700
        },
        {
            "transformers.models.mpnet.modeling_tf_mpnet.TFMPNetForMaskedLM.__init__": 753
        },
        {
            "transformers.models.mpnet.modeling_tf_mpnet.TFMPNetClassificationHead.__init__": 823
        },
        {
            "transformers.models.mpnet.modeling_tf_mpnet.TFMPNetForSequenceClassification.__init__": 855
        },
        {
            "transformers.models.mpnet.modeling_tf_mpnet.TFMPNetForMultipleChoice.__init__": 925
        },
        {
            "transformers.models.mpnet.modeling_tf_mpnet.TFMPNetForTokenClassification.__init__": 1013
        },
        {
            "transformers.models.mpnet.modeling_tf_mpnet.TFMPNetForQuestionAnswering.__init__": 1087
        },
        {
            "transformers.models.mpnet.modeling_tf_mpnet.TFMPNetForQuestionAnswering.call": 1103
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/mpnet/tokenization_mpnet.py": [
        {
            "transformers.models.mpnet.tokenization_mpnet.MPNetTokenizer.__init__": 133
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/bridgetower/modeling_bridgetower.py": [
        {
            "transformers.models.bridgetower.modeling_bridgetower.BridgeTowerTextEncoder.custom_forward": 814
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/bridgetower/configuration_bridgetower.py": [
        {
            "transformers.models.bridgetower.configuration_bridgetower.BridgeTowerVisionConfig.__init__": 79
        },
        {
            "transformers.models.bridgetower.configuration_bridgetower.BridgeTowerVisionConfig.from_pretrained": 106
        },
        {
            "transformers.models.bridgetower.configuration_bridgetower.BridgeTowerTextConfig.__init__": 189
        },
        {
            "transformers.models.bridgetower.configuration_bridgetower.BridgeTowerTextConfig.from_pretrained": 235
        },
        {
            "transformers.models.bridgetower.configuration_bridgetower.BridgeTowerConfig.__init__": 305
        },
        {
            "transformers.models.bridgetower.configuration_bridgetower.BridgeTowerConfig.from_text_vision_configs": 351
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/bridgetower/processing_bridgetower.py": [
        {
            "transformers.models.bridgetower.processing_bridgetower.BridgeTowerProcessor.__call__": 48
        },
        {
            "transformers.models.bridgetower.processing_bridgetower.BridgeTowerProcessor.batch_decode": 100
        },
        {
            "transformers.models.bridgetower.processing_bridgetower.BridgeTowerProcessor.decode": 107
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/bridgetower/image_processing_bridgetower.py": [
        {
            "transformers.models.bridgetower.image_processing_bridgetower.BridgeTowerImageProcessor.__init__": 159
        },
        {
            "transformers.models.bridgetower.image_processing_bridgetower.BridgeTowerImageProcessor.resize": 194
        },
        {
            "transformers.models.bridgetower.image_processing_bridgetower.BridgeTowerImageProcessor.rescale": 231
        },
        {
            "transformers.models.bridgetower.image_processing_bridgetower.BridgeTowerImageProcessor.center_crop": 251
        },
        {
            "transformers.models.bridgetower.image_processing_bridgetower.BridgeTowerImageProcessor.normalize": 274
        },
        {
            "transformers.models.bridgetower.image_processing_bridgetower.BridgeTowerImageProcessor.preprocess": 391
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/camembert/modeling_tf_camembert.py": [
        {
            "transformers.models.camembert.modeling_tf_camembert.TFCamembertEmbeddings.__init__": 176
        },
        {
            "transformers.models.camembert.modeling_tf_camembert.TFCamembertPooler.__init__": 273
        },
        {
            "transformers.models.camembert.modeling_tf_camembert.TFCamembertSelfAttention.__init__": 294
        },
        {
            "transformers.models.camembert.modeling_tf_camembert.TFCamembertSelfOutput.__init__": 412
        },
        {
            "transformers.models.camembert.modeling_tf_camembert.TFCamembertAttention.__init__": 431
        },
        {
            "transformers.models.camembert.modeling_tf_camembert.TFCamembertIntermediate.__init__": 472
        },
        {
            "transformers.models.camembert.modeling_tf_camembert.TFCamembertOutput.__init__": 493
        },
        {
            "transformers.models.camembert.modeling_tf_camembert.TFCamembertLayer.__init__": 512
        },
        {
            "transformers.models.camembert.modeling_tf_camembert.TFCamembertEncoder.__init__": 599
        },
        {
            "transformers.models.camembert.modeling_tf_camembert.TFCamembertMainLayer.__init__": 672
        },
        {
            "transformers.models.camembert.modeling_tf_camembert.TFCamembertModel.__init__": 881
        },
        {
            "transformers.models.camembert.modeling_tf_camembert.TFCamembertLMHead.__init__": 953
        },
        {
            "transformers.models.camembert.modeling_tf_camembert.TFCamembertForMaskedLM.__init__": 1011
        },
        {
            "transformers.models.camembert.modeling_tf_camembert.TFCamembertClassificationHead.__init__": 1088
        },
        {
            "transformers.models.camembert.modeling_tf_camembert.TFCamembertForSequenceClassification.__init__": 1125
        },
        {
            "transformers.models.camembert.modeling_tf_camembert.TFCamembertForTokenClassification.__init__": 1203
        },
        {
            "transformers.models.camembert.modeling_tf_camembert.TFCamembertForMultipleChoice.__init__": 1287
        },
        {
            "transformers.models.camembert.modeling_tf_camembert.TFCamembertForQuestionAnswering.__init__": 1379
        },
        {
            "transformers.models.camembert.modeling_tf_camembert.TFCamembertForCausalLM.__init__": 1468
        },
        {
            "transformers.models.camembert.modeling_tf_camembert.TFCamembertForCausalLM.prepare_inputs_for_generation": 1485
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/camembert/modeling_camembert.py": [
        {
            "transformers.models.camembert.modeling_camembert.CamembertEncoder.custom_forward": 527
        },
        {
            "transformers.models.camembert.modeling_camembert.CamembertClassificationHead.forward": 703
        },
        {
            "transformers.models.camembert.modeling_camembert.CamembertLMHead.forward": 726
        },
        {
            "transformers.models.camembert.modeling_camembert.CamembertForCausalLM.prepare_inputs_for_generation": 1566
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/camembert/configuration_camembert.py": [
        {
            "transformers.models.camembert.configuration_camembert.CamembertConfig.__init__": 109
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/camembert/tokenization_camembert_fast.py": [
        {
            "transformers.models.camembert.tokenization_camembert_fast.CamembertTokenizerFast.__init__": 111
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/camembert/tokenization_camembert.py": [
        {
            "transformers.models.camembert.tokenization_camembert.CamembertTokenizer.__init__": 120
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/ibert/configuration_ibert.py": [
        {
            "transformers.models.ibert.configuration_ibert.IBertConfig.__init__": 93
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/ibert/modeling_ibert.py": [
        {
            "transformers.models.ibert.modeling_ibert.IBertLMHead.forward": 948
        },
        {
            "transformers.models.ibert.modeling_ibert.IBertClassificationHead.forward": 1240
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/xglm/modeling_flax_xglm.py": [
        {
            "transformers.models.xglm.modeling_flax_xglm.FlaxXGLMPreTrainedModel.__init__": 545
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/xglm/modeling_tf_xglm.py": [
        {
            "transformers.models.xglm.modeling_tf_xglm.TFXGLMAttention.__init__": 155
        },
        {
            "transformers.models.xglm.modeling_tf_xglm.TFXGLMDecoderLayer.__init__": 306
        },
        {
            "transformers.models.xglm.modeling_tf_xglm.TFXGLMMainLayer.__init__": 423
        },
        {
            "transformers.models.xglm.modeling_tf_xglm.TFXGLMMainLayer.call": 486
        },
        {
            "transformers.models.xglm.modeling_tf_xglm.TFXGLMModel.__init__": 750
        },
        {
            "transformers.models.xglm.modeling_tf_xglm.TFXGLMModel.call": 764
        },
        {
            "transformers.models.xglm.modeling_tf_xglm.TFXGLMForCausalLM.__init__": 818
        },
        {
            "transformers.models.xglm.modeling_tf_xglm.TFXGLMForCausalLM.prepare_inputs_for_generation": 837
        },
        {
            "transformers.models.xglm.modeling_tf_xglm.TFXGLMForCausalLM.call": 866
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/xglm/configuration_xglm.py": [
        {
            "transformers.models.xglm.configuration_xglm.XGLMConfig.__init__": 97
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/xglm/tokenization_xglm.py": [
        {
            "transformers.models.xglm.tokenization_xglm.XGLMTokenizer.__init__": 117
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/xglm/tokenization_xglm_fast.py": [
        {
            "transformers.models.xglm.tokenization_xglm_fast.XGLMTokenizerFast.__init__": 103
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/xglm/modeling_xglm.py": [
        {
            "transformers.models.xglm.modeling_xglm.XGLMModel.custom_forward": 680
        },
        {
            "transformers.models.xglm.modeling_xglm.XGLMForCausalLM.prepare_inputs_for_generation": 859
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/audio_spectrogram_transformer/configuration_audio_spectrogram_transformer.py": [
        {
            "transformers.models.audio_spectrogram_transformer.configuration_audio_spectrogram_transformer.ASTConfig.__init__": 91
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/audio_spectrogram_transformer/feature_extraction_audio_spectrogram_transformer.py": [
        {
            "transformers.models.audio_spectrogram_transformer.feature_extraction_audio_spectrogram_transformer.ASTFeatureExtractor.__init__": 65
        },
        {
            "transformers.models.audio_spectrogram_transformer.feature_extraction_audio_spectrogram_transformer.ASTFeatureExtractor.__call__": 125
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/audio_spectrogram_transformer/modeling_audio_spectrogram_transformer.py": [
        {
            "transformers.models.audio_spectrogram_transformer.modeling_audio_spectrogram_transformer.ASTEncoder.custom_forward": 341
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/tapas/configuration_tapas.py": [
        {
            "transformers.models.tapas.configuration_tapas.TapasConfig.__init__": 157
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/tapas/tokenization_tapas.py": [
        {
            "transformers.models.tapas.tokenization_tapas.TapasTokenizer.__init__": 320
        },
        {
            "transformers.models.tapas.tokenization_tapas.TapasTokenizer.__call__": 576
        },
        {
            "transformers.models.tapas.tokenization_tapas.TapasTokenizer.batch_encode_plus": 693
        },
        {
            "transformers.models.tapas.tokenization_tapas.TapasTokenizer._batch_encode_plus": 802
        },
        {
            "transformers.models.tapas.tokenization_tapas.TapasTokenizer._batch_prepare_for_model": 859
        },
        {
            "transformers.models.tapas.tokenization_tapas.TapasTokenizer.encode": 931
        },
        {
            "transformers.models.tapas.tokenization_tapas.TapasTokenizer.encode_plus": 974
        },
        {
            "transformers.models.tapas.tokenization_tapas.TapasTokenizer._encode_plus": 1057
        },
        {
            "transformers.models.tapas.tokenization_tapas.TapasTokenizer.prepare_for_model": 1113
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/tapas/modeling_tf_tapas.py": [
        {
            "transformers.models.tapas.modeling_tf_tapas.TFTapasEmbeddings.__init__": 151
        },
        {
            "transformers.models.tapas.modeling_tf_tapas.TFTapasSelfAttention.__init__": 256
        },
        {
            "transformers.models.tapas.modeling_tf_tapas.TFTapasSelfOutput.__init__": 374
        },
        {
            "transformers.models.tapas.modeling_tf_tapas.TFTapasAttention.__init__": 393
        },
        {
            "transformers.models.tapas.modeling_tf_tapas.TFTapasIntermediate.__init__": 434
        },
        {
            "transformers.models.tapas.modeling_tf_tapas.TFTapasOutput.__init__": 455
        },
        {
            "transformers.models.tapas.modeling_tf_tapas.TFTapasLayer.__init__": 474
        },
        {
            "transformers.models.tapas.modeling_tf_tapas.TFTapasEncoder.__init__": 561
        },
        {
            "transformers.models.tapas.modeling_tf_tapas.TFTapasPooler.__init__": 631
        },
        {
            "transformers.models.tapas.modeling_tf_tapas.TFTapasPredictionHeadTransform.__init__": 652
        },
        {
            "transformers.models.tapas.modeling_tf_tapas.TFTapasLMPredictionHead.__init__": 678
        },
        {
            "transformers.models.tapas.modeling_tf_tapas.TFTapasMLMHead.__init__": 722
        },
        {
            "transformers.models.tapas.modeling_tf_tapas.TFTapasMainLayer.__init__": 737
        },
        {
            "transformers.models.tapas.modeling_tf_tapas.TFTapasModel.__init__": 975
        },
        {
            "transformers.models.tapas.modeling_tf_tapas.TFTapasForMaskedLM.__init__": 1039
        },
        {
            "transformers.models.tapas.modeling_tf_tapas.TFTapasComputeTokenLogits.__init__": 1134
        },
        {
            "transformers.models.tapas.modeling_tf_tapas.TFTapasComputeColumnLogits.__init__": 1170
        },
        {
            "transformers.models.tapas.modeling_tf_tapas.TFTapasForQuestionAnswering.__init__": 1239
        },
        {
            "transformers.models.tapas.modeling_tf_tapas.TFTapasForSequenceClassification.__init__": 1564
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/tapas/modeling_tapas.py": [
        {
            "transformers.models.tapas.modeling_tapas.TapasEncoder.custom_forward": 644
        },
        {
            "transformers.models.tapas.modeling_tapas.TapasForMaskedLM.forward": 1015
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/plbart/modeling_plbart.py": [
        {
            "transformers.models.plbart.modeling_plbart.PLBartEncoder.custom_forward": 808
        },
        {
            "transformers.models.plbart.modeling_plbart.PLBartDecoder.custom_forward": 1064
        },
        {
            "transformers.models.plbart.modeling_plbart.PLBartForConditionalGeneration.prepare_inputs_for_generation": 1369
        },
        {
            "transformers.models.plbart.modeling_plbart.PLBartForSequenceClassification.__init__": 1421
        },
        {
            "transformers.models.plbart.modeling_plbart.PLBartDecoderWrapper.forward": 1551
        },
        {
            "transformers.models.plbart.modeling_plbart.PLBartForCausalLM.prepare_inputs_for_generation": 1734
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/plbart/tokenization_plbart.py": [
        {
            "transformers.models.plbart.tokenization_plbart.PLBartTokenizer.__init__": 176
        },
        {
            "transformers.models.plbart.tokenization_plbart.PLBartTokenizer._build_translation_inputs": 384
        },
        {
            "transformers.models.plbart.tokenization_plbart.PLBartTokenizer.prepare_seq2seq_batch": 442
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/plbart/configuration_plbart.py": [
        {
            "transformers.models.plbart.configuration_plbart.PLBartConfig.__init__": 109
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/cvt/configuration_cvt.py": [
        {
            "transformers.models.cvt.configuration_cvt.CvtConfig.__init__": 101
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/cvt/modeling_tf_cvt.py": [
        {
            "transformers.models.cvt.modeling_tf_cvt.TFCvtDropPath.__init__": 89
        },
        {
            "transformers.models.cvt.modeling_tf_cvt.TFCvtEmbeddings.__init__": 106
        },
        {
            "transformers.models.cvt.modeling_tf_cvt.TFCvtConvEmbeddings.__init__": 136
        },
        {
            "transformers.models.cvt.modeling_tf_cvt.TFCvtSelfAttentionConvProjection.__init__": 172
        },
        {
            "transformers.models.cvt.modeling_tf_cvt.TFCvtSelfAttentionProjection.__init__": 208
        },
        {
            "transformers.models.cvt.modeling_tf_cvt.TFCvtSelfAttention.__init__": 237
        },
        {
            "transformers.models.cvt.modeling_tf_cvt.TFCvtSelfOutput.__init__": 355
        },
        {
            "transformers.models.cvt.modeling_tf_cvt.TFCvtAttention.__init__": 371
        },
        {
            "transformers.models.cvt.modeling_tf_cvt.TFCvtIntermediate.__init__": 418
        },
        {
            "transformers.models.cvt.modeling_tf_cvt.TFCvtOutput.__init__": 437
        },
        {
            "transformers.models.cvt.modeling_tf_cvt.TFCvtLayer.__init__": 458
        },
        {
            "transformers.models.cvt.modeling_tf_cvt.TFCvtStage.__init__": 536
        },
        {
            "transformers.models.cvt.modeling_tf_cvt.TFCvtEncoder.__init__": 618
        },
        {
            "transformers.models.cvt.modeling_tf_cvt.TFCvtMainLayer.__init__": 665
        },
        {
            "transformers.models.cvt.modeling_tf_cvt.TFCvtModel.__init__": 763
        },
        {
            "transformers.models.cvt.modeling_tf_cvt.TFCvtForImageClassification.__init__": 827
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/cvt/modeling_cvt.py": [
        {
            "transformers.models.cvt.modeling_cvt.CvtSelfAttention.__init__": 202
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/timm_backbone/configuration_timm_backbone.py": [
        {
            "transformers.models.timm_backbone.configuration_timm_backbone.TimmBackboneConfig.__init__": 63
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/timm_backbone/modeling_timm_backbone.py": [
        {
            "transformers.models.timm_backbone.modeling_timm_backbone.TimmBackbone.__init__": 43
        },
        {
            "transformers.models.timm_backbone.modeling_timm_backbone.TimmBackbone.from_pretrained": 80
        },
        {
            "transformers.models.timm_backbone.modeling_timm_backbone.TimmBackbone.forward": 109
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/unispeech/modeling_unispeech.py": [
        {
            "transformers.models.unispeech.modeling_unispeech.UniSpeechFeatureEncoder.custom_forward": 389
        },
        {
            "transformers.models.unispeech.modeling_unispeech.UniSpeechEncoder.custom_forward": 772
        },
        {
            "transformers.models.unispeech.modeling_unispeech.UniSpeechEncoderStableLayerNorm.custom_forward": 862
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/unispeech/configuration_unispeech.py": [
        {
            "transformers.models.unispeech.configuration_unispeech.UniSpeechConfig.__init__": 183
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/oneformer/modeling_oneformer.py": [
        {
            "transformers.models.oneformer.modeling_oneformer.sample_point": 207
        },
        {
            "transformers.models.oneformer.modeling_oneformer.OneFormerTextContextDecoder.__init__": 2501
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/oneformer/image_processing_oneformer.py": [
        {
            "transformers.models.oneformer.image_processing_oneformer.OneFormerImageProcessor.__init__": 391
        },
        {
            "transformers.models.oneformer.image_processing_oneformer.OneFormerImageProcessor.resize": 440
        },
        {
            "transformers.models.oneformer.image_processing_oneformer.OneFormerImageProcessor.convert_segmentation_map_to_binary_masks": 504
        },
        {
            "transformers.models.oneformer.image_processing_oneformer.OneFormerImageProcessor.__call__": 521
        },
        {
            "transformers.models.oneformer.image_processing_oneformer.OneFormerImageProcessor.preprocess": 604
        },
        {
            "transformers.models.oneformer.image_processing_oneformer.OneFormerImageProcessor.encode_inputs": 875
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/oneformer/configuration_oneformer.py": [
        {
            "transformers.models.oneformer.configuration_oneformer.OneFormerConfig.__init__": 144
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/oneformer/processing_oneformer.py": [
        {
            "transformers.models.oneformer.processing_oneformer.OneFormerProcessor.__init__": 49
        },
        {
            "transformers.models.oneformer.processing_oneformer.OneFormerProcessor.__call__": 78
        },
        {
            "transformers.models.oneformer.processing_oneformer.OneFormerProcessor.encode_inputs": 145
        },
        {
            "transformers.models.oneformer.processing_oneformer.OneFormerProcessor.post_process_semantic_segmentation": 185
        },
        {
            "transformers.models.oneformer.processing_oneformer.OneFormerProcessor.post_process_instance_segmentation": 192
        },
        {
            "transformers.models.oneformer.processing_oneformer.OneFormerProcessor.post_process_panoptic_segmentation": 199
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/trajectory_transformer/configuration_trajectory_transformer.py": [
        {
            "transformers.models.trajectory_transformer.configuration_trajectory_transformer.TrajectoryTransformerConfig.__init__": 111
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/trajectory_transformer/modeling_trajectory_transformer.py": [
        {
            "transformers.models.trajectory_transformer.modeling_trajectory_transformer.TrajectoryTransformerModel.custom_forward": 554
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/levit/image_processing_levit.py": [
        {
            "transformers.models.levit.image_processing_levit.LevitImageProcessor.__init__": 88
        },
        {
            "transformers.models.levit.image_processing_levit.LevitImageProcessor.resize": 119
        },
        {
            "transformers.models.levit.image_processing_levit.LevitImageProcessor.center_crop": 164
        },
        {
            "transformers.models.levit.image_processing_levit.LevitImageProcessor.rescale": 187
        },
        {
            "transformers.models.levit.image_processing_levit.LevitImageProcessor.normalize": 207
        },
        {
            "transformers.models.levit.image_processing_levit.LevitImageProcessor.preprocess": 230
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/levit/configuration_levit.py": [
        {
            "transformers.models.levit.configuration_levit.LevitConfig.__init__": 92
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/levit/feature_extraction_levit.py": [
        {
            "transformers.models.levit.feature_extraction_levit.LevitFeatureExtractor.__init__": 27
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/whisper/modeling_whisper.py": [
        {
            "transformers.models.whisper.modeling_whisper.WhisperEncoder.custom_forward": 851
        },
        {
            "transformers.models.whisper.modeling_whisper.WhisperDecoder.custom_forward": 1082
        },
        {
            "transformers.models.whisper.modeling_whisper.WhisperForConditionalGeneration.generate": 1460
        },
        {
            "transformers.models.whisper.modeling_whisper.WhisperForConditionalGeneration.prepare_inputs_for_generation": 1673
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/whisper/tokenization_whisper_fast.py": [
        {
            "transformers.models.whisper.tokenization_whisper_fast.WhisperTokenizerFast.__init__": 134
        },
        {
            "transformers.models.whisper.tokenization_whisper_fast.WhisperTokenizerFast._batch_encode_plus": 181
        },
        {
            "transformers.models.whisper.tokenization_whisper_fast.WhisperTokenizerFast._encode_plus": 191
        },
        {
            "transformers.models.whisper.tokenization_whisper_fast.WhisperTokenizerFast.decode": 267
        },
        {
            "transformers.models.whisper.tokenization_whisper_fast.WhisperTokenizerFast._decode": 318
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/whisper/feature_extraction_whisper.py": [
        {
            "transformers.models.whisper.feature_extraction_whisper.WhisperFeatureExtractor.__init__": 60
        },
        {
            "transformers.models.whisper.feature_extraction_whisper.WhisperFeatureExtractor.__call__": 136
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/whisper/modeling_tf_whisper.py": [
        {
            "transformers.models.whisper.modeling_tf_whisper.TFWhisperPositionalEmbedding.__init__": 117
        },
        {
            "transformers.models.whisper.modeling_tf_whisper.TFWhisperAttention.__init__": 140
        },
        {
            "transformers.models.whisper.modeling_tf_whisper.TFWhisperEncoderLayer.__init__": 294
        },
        {
            "transformers.models.whisper.modeling_tf_whisper.TFWhisperDecoderLayer.__init__": 350
        },
        {
            "transformers.models.whisper.modeling_tf_whisper.TFWhisperEncoder.__init__": 604
        },
        {
            "transformers.models.whisper.modeling_tf_whisper.TFWhisperDecoder.__init__": 734
        },
        {
            "transformers.models.whisper.modeling_tf_whisper.TFWhisperMainLayer.__init__": 972
        },
        {
            "transformers.models.whisper.modeling_tf_whisper.TFWhisperModel.__init__": 1092
        },
        {
            "transformers.models.whisper.modeling_tf_whisper.TFWhisperForConditionalGeneration.__init__": 1210
        },
        {
            "transformers.models.whisper.modeling_tf_whisper.TFWhisperForConditionalGeneration.prepare_inputs_for_generation": 1347
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/whisper/tokenization_whisper.py": [
        {
            "transformers.models.whisper.tokenization_whisper.WhisperTokenizer.__init__": 257
        },
        {
            "transformers.models.whisper.tokenization_whisper.WhisperTokenizer.decode": 557
        },
        {
            "transformers.models.whisper.tokenization_whisper.WhisperTokenizer._decode": 608
        },
        {
            "transformers.models.whisper.tokenization_whisper.WhisperTokenizer.prepare_for_tokenization": 692
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/whisper/configuration_whisper.py": [
        {
            "transformers.models.whisper.configuration_whisper.WhisperConfig.__init__": 194
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/whisper/modeling_flax_whisper.py": [
        {
            "transformers.models.whisper.modeling_flax_whisper.FlaxWhisperPreTrainedModel.__init__": 845
        },
        {
            "transformers.models.whisper.modeling_flax_whisper.FlaxWhisperPreTrainedModel._decoder_forward": 919
        },
        {
            "transformers.models.whisper.modeling_flax_whisper.FlaxWhisperPreTrainedModel.encode": 941
        },
        {
            "transformers.models.whisper.modeling_flax_whisper.FlaxWhisperPreTrainedModel._encoder_forward": 980
        },
        {
            "transformers.models.whisper.modeling_flax_whisper.FlaxWhisperPreTrainedModel._decoder_forward": 1075
        },
        {
            "transformers.models.whisper.modeling_flax_whisper.FlaxWhisperForConditionalGeneration._decoder_forward": 1325
        },
        {
            "transformers.models.whisper.modeling_flax_whisper.FlaxWhisperForConditionalGeneration.generate": 1382
        },
        {
            "transformers.models.whisper.modeling_flax_whisper.FlaxWhisperForConditionalGeneration.prepare_inputs_for_generation": 1447
        },
        {
            "transformers.models.whisper.modeling_flax_whisper.FlaxWhisperForAudioClassification.__call__": 1602
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/whisper/processing_whisper.py": [
        {
            "transformers.models.whisper.processing_whisper.WhisperProcessor.__call__": 48
        },
        {
            "transformers.models.whisper.processing_whisper.WhisperProcessor.batch_decode": 82
        },
        {
            "transformers.models.whisper.processing_whisper.WhisperProcessor.decode": 89
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/gpt_sw3/tokenization_gpt_sw3.py": [
        {
            "transformers.models.gpt_sw3.tokenization_gpt_sw3.GPTSw3Tokenizer.__init__": 108
        },
        {
            "transformers.models.gpt_sw3.tokenization_gpt_sw3.GPTSw3Tokenizer._tokenize": 208
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/cpmant/tokenization_cpmant.py": [
        {
            "transformers.models.cpmant.tokenization_cpmant.CpmAntTokenizer.__init__": 119
        },
        {
            "transformers.models.cpmant.tokenization_cpmant.CpmAntTokenizer._decode": 186
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/cpmant/configuration_cpmant.py": [
        {
            "transformers.models.cpmant.configuration_cpmant.CpmAntConfig.__init__": 89
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/cpmant/modeling_cpmant.py": [
        {
            "transformers.models.cpmant.modeling_cpmant.CpmAntModel.set_input_embeddings": 621
        },
        {
            "transformers.models.cpmant.modeling_cpmant.CpmAntModel.forward": 648
        },
        {
            "transformers.models.cpmant.modeling_cpmant.CpmAntForCausalLM.forward": 770
        },
        {
            "transformers.models.cpmant.modeling_cpmant.CpmAntForCausalLM.prepare_inputs_for_generation": 863
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/speech_to_text_2/processing_speech_to_text_2.py": [
        {
            "transformers.models.speech_to_text_2.processing_speech_to_text_2.Speech2Text2Processor.__call__": 46
        },
        {
            "transformers.models.speech_to_text_2.processing_speech_to_text_2.Speech2Text2Processor.batch_decode": 85
        },
        {
            "transformers.models.speech_to_text_2.processing_speech_to_text_2.Speech2Text2Processor.decode": 92
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/speech_to_text_2/modeling_speech_to_text_2.py": [
        {
            "transformers.models.speech_to_text_2.modeling_speech_to_text_2.Speech2Text2Decoder.custom_forward": 674
        },
        {
            "transformers.models.speech_to_text_2.modeling_speech_to_text_2.Speech2Text2DecoderWrapper.forward": 749
        },
        {
            "transformers.models.speech_to_text_2.modeling_speech_to_text_2.Speech2Text2ForCausalLM.prepare_inputs_for_generation": 958
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/speech_to_text_2/configuration_speech_to_text_2.py": [
        {
            "transformers.models.speech_to_text_2.configuration_speech_to_text_2.Speech2Text2Config.__init__": 93
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/speech_to_text_2/tokenization_speech_to_text_2.py": [
        {
            "transformers.models.speech_to_text_2.tokenization_speech_to_text_2.Speech2Text2Tokenizer.__init__": 102
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/convnext/configuration_convnext.py": [
        {
            "transformers.models.convnext.configuration_convnext.ConvNextConfig.__init__": 92
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/convnext/feature_extraction_convnext.py": [
        {
            "transformers.models.convnext.feature_extraction_convnext.ConvNextFeatureExtractor.__init__": 27
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/convnext/modeling_tf_convnext.py": [
        {
            "transformers.models.convnext.modeling_tf_convnext.TFConvNextDropPath.__init__": 53
        },
        {
            "transformers.models.convnext.modeling_tf_convnext.TFConvNextEmbeddings.__init__": 72
        },
        {
            "transformers.models.convnext.modeling_tf_convnext.TFConvNextLayer.__init__": 120
        },
        {
            "transformers.models.convnext.modeling_tf_convnext.TFConvNextStage.__init__": 198
        },
        {
            "transformers.models.convnext.modeling_tf_convnext.TFConvNextEncoder.__init__": 245
        },
        {
            "transformers.models.convnext.modeling_tf_convnext.TFConvNextMainLayer.__init__": 288
        },
        {
            "transformers.models.convnext.modeling_tf_convnext.TFConvNextModel.__init__": 417
        },
        {
            "transformers.models.convnext.modeling_tf_convnext.TFConvNextForImageClassification.__init__": 484
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/convnext/image_processing_convnext.py": [
        {
            "transformers.models.convnext.image_processing_convnext.ConvNextImageProcessor.__init__": 88
        },
        {
            "transformers.models.convnext.image_processing_convnext.ConvNextImageProcessor.resize": 116
        },
        {
            "transformers.models.convnext.image_processing_convnext.ConvNextImageProcessor.rescale": 161
        },
        {
            "transformers.models.convnext.image_processing_convnext.ConvNextImageProcessor.normalize": 181
        },
        {
            "transformers.models.convnext.image_processing_convnext.ConvNextImageProcessor.preprocess": 204
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/deberta_v2/configuration_deberta_v2.py": [
        {
            "transformers.models.deberta_v2.configuration_deberta_v2.DebertaV2Config.__init__": 112
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/deberta_v2/modeling_tf_deberta_v2.py": [
        {
            "transformers.models.deberta_v2.modeling_tf_deberta_v2.TFDebertaV2ContextPooler.__init__": 62
        },
        {
            "transformers.models.deberta_v2.modeling_tf_deberta_v2.TFDebertaV2XSoftmax.__init__": 93
        },
        {
            "transformers.models.deberta_v2.modeling_tf_deberta_v2.TFDebertaV2StableDropout.__init__": 114
        },
        {
            "transformers.models.deberta_v2.modeling_tf_deberta_v2.TFDebertaV2SelfOutput.__init__": 148
        },
        {
            "transformers.models.deberta_v2.modeling_tf_deberta_v2.TFDebertaV2Attention.__init__": 163
        },
        {
            "transformers.models.deberta_v2.modeling_tf_deberta_v2.TFDebertaV2Intermediate.__init__": 201
        },
        {
            "transformers.models.deberta_v2.modeling_tf_deberta_v2.TFDebertaV2Output.__init__": 222
        },
        {
            "transformers.models.deberta_v2.modeling_tf_deberta_v2.TFDebertaV2Layer.__init__": 241
        },
        {
            "transformers.models.deberta_v2.modeling_tf_deberta_v2.TFDebertaV2ConvLayer.__init__": 278
        },
        {
            "transformers.models.deberta_v2.modeling_tf_deberta_v2.TFDebertaV2Encoder.__init__": 333
        },
        {
            "transformers.models.deberta_v2.modeling_tf_deberta_v2.TFDebertaV2DisentangledSelfAttention.__init__": 553
        },
        {
            "transformers.models.deberta_v2.modeling_tf_deberta_v2.TFDebertaV2Embeddings.__init__": 809
        },
        {
            "transformers.models.deberta_v2.modeling_tf_deberta_v2.TFDebertaV2PredictionHeadTransform.__init__": 911
        },
        {
            "transformers.models.deberta_v2.modeling_tf_deberta_v2.TFDebertaV2LMPredictionHead.__init__": 936
        },
        {
            "transformers.models.deberta_v2.modeling_tf_deberta_v2.TFDebertaV2OnlyMLMHead.__init__": 980
        },
        {
            "transformers.models.deberta_v2.modeling_tf_deberta_v2.TFDebertaV2MainLayer.__init__": 994
        },
        {
            "transformers.models.deberta_v2.modeling_tf_deberta_v2.TFDebertaV2Model.__init__": 1177
        },
        {
            "transformers.models.deberta_v2.modeling_tf_deberta_v2.TFDebertaV2ForMaskedLM.__init__": 1219
        },
        {
            "transformers.models.deberta_v2.modeling_tf_deberta_v2.TFDebertaV2ForSequenceClassification.__init__": 1296
        },
        {
            "transformers.models.deberta_v2.modeling_tf_deberta_v2.TFDebertaV2ForTokenClassification.__init__": 1378
        },
        {
            "transformers.models.deberta_v2.modeling_tf_deberta_v2.TFDebertaV2ForQuestionAnswering.__init__": 1450
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/deberta_v2/tokenization_deberta_v2.py": [
        {
            "transformers.models.deberta_v2.tokenization_deberta_v2.DebertaV2Tokenizer.__init__": 110
        },
        {
            "transformers.models.deberta_v2.tokenization_deberta_v2.DebertaV2Tokenizer.prepare_for_tokenization": 261
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/deberta_v2/tokenization_deberta_v2_fast.py": [
        {
            "transformers.models.deberta_v2.tokenization_deberta_v2_fast.DebertaV2TokenizerFast.__init__": 118
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/deberta_v2/modeling_deberta_v2.py": [
        {
            "transformers.models.deberta_v2.modeling_deberta_v2.DebertaV2Encoder.custom_forward": 506
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/data2vec/configuration_data2vec_audio.py": [
        {
            "transformers.models.data2vec.configuration_data2vec_audio.Data2VecAudioConfig.__init__": 171
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/data2vec/modeling_tf_data2vec_vision.py": [
        {
            "transformers.models.data2vec.modeling_tf_data2vec_vision.TFData2VecVisionDropPath.__init__": 110
        },
        {
            "transformers.models.data2vec.modeling_tf_data2vec_vision.TFData2VecVisionEmbeddings.__init__": 130
        },
        {
            "transformers.models.data2vec.modeling_tf_data2vec_vision.TFData2VecVisionPatchEmbeddings.__init__": 196
        },
        {
            "transformers.models.data2vec.modeling_tf_data2vec_vision.TFData2VecVisionSelfAttention.__init__": 253
        },
        {
            "transformers.models.data2vec.modeling_tf_data2vec_vision.TFData2VecVisionSelfOutput.__init__": 354
        },
        {
            "transformers.models.data2vec.modeling_tf_data2vec_vision.TFData2VecVisionAttention.__init__": 370
        },
        {
            "transformers.models.data2vec.modeling_tf_data2vec_vision.TFData2VecVisionIntermediate.__init__": 404
        },
        {
            "transformers.models.data2vec.modeling_tf_data2vec_vision.TFData2VecVisionOutput.__init__": 424
        },
        {
            "transformers.models.data2vec.modeling_tf_data2vec_vision.TFData2VecVisionLayer.__init__": 442
        },
        {
            "transformers.models.data2vec.modeling_tf_data2vec_vision.TFData2VecVisionRelativePositionBias.__init__": 534
        },
        {
            "transformers.models.data2vec.modeling_tf_data2vec_vision.TFData2VecVisionEncoder.__init__": 590
        },
        {
            "transformers.models.data2vec.modeling_tf_data2vec_vision.TFData2VecVisionMainLayer.__init__": 658
        },
        {
            "transformers.models.data2vec.modeling_tf_data2vec_vision.TFData2VecVisionPooler.__init__": 746
        },
        {
            "transformers.models.data2vec.modeling_tf_data2vec_vision.TFData2VecVisionModel.__init__": 853
        },
        {
            "transformers.models.data2vec.modeling_tf_data2vec_vision.TFData2VecVisionForImageClassification.__init__": 908
        },
        {
            "transformers.models.data2vec.modeling_tf_data2vec_vision.TFData2VecVisionConvModule.__init__": 980
        },
        {
            "transformers.models.data2vec.modeling_tf_data2vec_vision.TFAdaptiveAvgPool1D.__init__": 1011
        },
        {
            "transformers.models.data2vec.modeling_tf_data2vec_vision.TFAdaptiveAvgPool2D.__init__": 1066
        },
        {
            "transformers.models.data2vec.modeling_tf_data2vec_vision.TFData2VecVisionPyramidPoolingModule.__init__": 1103
        },
        {
            "transformers.models.data2vec.modeling_tf_data2vec_vision.TFData2VecVisionUperHead.__init__": 1140
        },
        {
            "transformers.models.data2vec.modeling_tf_data2vec_vision.TFData2VecVisionFCNHead.__init__": 1215
        },
        {
            "transformers.models.data2vec.modeling_tf_data2vec_vision.TFData2VecVisionForSemanticSegmentation.__init__": 1280
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/data2vec/modeling_data2vec_text.py": [
        {
            "transformers.models.data2vec.modeling_data2vec_text.Data2VecTextEncoder.custom_forward": 513
        },
        {
            "transformers.models.data2vec.modeling_data2vec_text.Data2VecTextForCausalLM.prepare_inputs_for_generation": 1019
        },
        {
            "transformers.models.data2vec.modeling_data2vec_text.Data2VecTextLMHead.forward": 1148
        },
        {
            "transformers.models.data2vec.modeling_data2vec_text.Data2VecTextClassificationHead.forward": 1461
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/data2vec/configuration_data2vec_text.py": [
        {
            "transformers.models.data2vec.configuration_data2vec_text.Data2VecTextConfig.__init__": 100
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/data2vec/modeling_data2vec_vision.py": [
        {
            "transformers.models.data2vec.modeling_data2vec_vision.Data2VecVisionEncoder.custom_forward": 527
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/data2vec/modeling_data2vec_audio.py": [
        {
            "transformers.models.data2vec.modeling_data2vec_audio.Data2VecAudioFeatureEncoder.custom_forward": 298
        },
        {
            "transformers.models.data2vec.modeling_data2vec_audio.Data2VecAudioEncoder.custom_forward": 598
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/data2vec/configuration_data2vec_vision.py": [
        {
            "transformers.models.data2vec.configuration_data2vec_vision.Data2VecVisionConfig.__init__": 116
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/sam/modeling_tf_sam.py": [
        {
            "transformers.models.sam.modeling_tf_sam.TFSamPatchEmbeddings.__init__": 124
        },
        {
            "transformers.models.sam.modeling_tf_sam.TFSamMLPBlock.__init__": 155
        },
        {
            "transformers.models.sam.modeling_tf_sam.TFSamLayerNorm.__init__": 174
        },
        {
            "transformers.models.sam.modeling_tf_sam.TFSamAttention.__init__": 201
        },
        {
            "transformers.models.sam.modeling_tf_sam.TFSamTwoWayAttentionBlock.__init__": 262
        },
        {
            "transformers.models.sam.modeling_tf_sam.TFSamTwoWayTransformer.__init__": 350
        },
        {
            "transformers.models.sam.modeling_tf_sam.TFSamFeedForward.__init__": 417
        },
        {
            "transformers.models.sam.modeling_tf_sam.TFSamMaskDecoder.__init__": 444
        },
        {
            "transformers.models.sam.modeling_tf_sam.TFSamPositionalEmbedding.__init__": 571
        },
        {
            "transformers.models.sam.modeling_tf_sam.TFSamMaskEmbedding.__init__": 609
        },
        {
            "transformers.models.sam.modeling_tf_sam.TFSamPromptEncoder.__init__": 653
        },
        {
            "transformers.models.sam.modeling_tf_sam.TFSamVisionAttention.__init__": 791
        },
        {
            "transformers.models.sam.modeling_tf_sam.TFSamVisionLayer.__init__": 944
        },
        {
            "transformers.models.sam.modeling_tf_sam.TFSamVisionNeck.__init__": 1020
        },
        {
            "transformers.models.sam.modeling_tf_sam.TFSamVisionEncoder.__init__": 1051
        },
        {
            "transformers.models.sam.modeling_tf_sam.TFSamModel.__init__": 1239
        },
        {
            "transformers.models.sam.modeling_tf_sam.TFSamModel.call": 1328
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/sam/configuration_sam.py": [
        {
            "transformers.models.sam.configuration_sam.SamPromptEncoderConfig.__init__": 57
        },
        {
            "transformers.models.sam.configuration_sam.SamMaskDecoderConfig.__init__": 113
        },
        {
            "transformers.models.sam.configuration_sam.SamVisionConfig.__init__": 200
        },
        {
            "transformers.models.sam.configuration_sam.SamConfig.__init__": 307
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/sam/modeling_sam.py": [
        {
            "transformers.models.sam.modeling_sam.SamVisionEncoder.custom_forward": 1047
        },
        {
            "transformers.models.sam.modeling_sam.SamModel.forward": 1286
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/sam/image_processing_sam.py": [
        {
            "transformers.models.sam.image_processing_sam.SamImageProcessor.__init__": 107
        },
        {
            "transformers.models.sam.image_processing_sam.SamImageProcessor.pad_image": 141
        },
        {
            "transformers.models.sam.image_processing_sam.SamImageProcessor.resize": 180
        },
        {
            "transformers.models.sam.image_processing_sam.SamImageProcessor.rescale": 215
        },
        {
            "transformers.models.sam.image_processing_sam.SamImageProcessor.normalize": 235
        },
        {
            "transformers.models.sam.image_processing_sam.SamImageProcessor.preprocess": 258
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/sam/processing_sam.py": [
        {
            "transformers.models.sam.processing_sam.SamProcessor.__call__": 56
        },
        {
            "transformers.models.sam.processing_sam.SamProcessor.post_process_masks": 262
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/roformer/configuration_roformer.py": [
        {
            "transformers.models.roformer.configuration_roformer.RoFormerConfig.__init__": 111
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/roformer/tokenization_roformer_fast.py": [
        {
            "transformers.models.roformer.tokenization_roformer_fast.RoFormerTokenizerFast.__init__": 97
        },
        {
            "transformers.models.roformer.tokenization_roformer_fast.RoFormerTokenizerFast.save_pretrained": 204
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/roformer/tokenization_roformer.py": [
        {
            "transformers.models.roformer.tokenization_roformer.RoFormerTokenizer.__init__": 354
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/roformer/modeling_flax_roformer.py": [
        {
            "transformers.models.roformer.modeling_flax_roformer.FlaxRoFormerPreTrainedModel.__init__": 617
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/roformer/modeling_tf_roformer.py": [
        {
            "transformers.models.roformer.modeling_tf_roformer.TFRoFormerSinusoidalPositionalEmbedding.__init__": 80
        },
        {
            "transformers.models.roformer.modeling_tf_roformer.TFRoFormerEmbeddings.__init__": 136
        },
        {
            "transformers.models.roformer.modeling_tf_roformer.TFRoFormerSelfAttention.__init__": 196
        },
        {
            "transformers.models.roformer.modeling_tf_roformer.TFRoFormerSelfOutput.__init__": 313
        },
        {
            "transformers.models.roformer.modeling_tf_roformer.TFRoFormerAttention.__init__": 331
        },
        {
            "transformers.models.roformer.modeling_tf_roformer.TFRoFormerIntermediate.__init__": 367
        },
        {
            "transformers.models.roformer.modeling_tf_roformer.TFRoFormerOutput.__init__": 388
        },
        {
            "transformers.models.roformer.modeling_tf_roformer.TFRoFormerLayer.__init__": 406
        },
        {
            "transformers.models.roformer.modeling_tf_roformer.TFRoFormerEncoder.__init__": 441
        },
        {
            "transformers.models.roformer.modeling_tf_roformer.TFRoFormerPredictionHeadTransform.__init__": 496
        },
        {
            "transformers.models.roformer.modeling_tf_roformer.TFRoFormerLMPredictionHead.__init__": 521
        },
        {
            "transformers.models.roformer.modeling_tf_roformer.TFRoFormerMLMHead.__init__": 565
        },
        {
            "transformers.models.roformer.modeling_tf_roformer.TFRoFormerMainLayer.__init__": 580
        },
        {
            "transformers.models.roformer.modeling_tf_roformer.TFRoFormerModel.__init__": 799
        },
        {
            "transformers.models.roformer.modeling_tf_roformer.TFRoFormerForMaskedLM.__init__": 840
        },
        {
            "transformers.models.roformer.modeling_tf_roformer.TFRoFormerForCausalLM.__init__": 912
        },
        {
            "transformers.models.roformer.modeling_tf_roformer.TFRoFormerClassificationHead.__init__": 984
        },
        {
            "transformers.models.roformer.modeling_tf_roformer.TFRoFormerForSequenceClassification.__init__": 1018
        },
        {
            "transformers.models.roformer.modeling_tf_roformer.TFRoFormerForMultipleChoice.__init__": 1087
        },
        {
            "transformers.models.roformer.modeling_tf_roformer.TFRoFormerForTokenClassification.__init__": 1179
        },
        {
            "transformers.models.roformer.modeling_tf_roformer.TFRoFormerForQuestionAnswering.__init__": 1250
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/roformer/modeling_roformer.py": [
        {
            "transformers.models.roformer.modeling_roformer.RoFormerEncoder.custom_forward": 583
        },
        {
            "transformers.models.roformer.modeling_roformer.RoFormerForMaskedLM.prepare_inputs_for_generation": 1038
        },
        {
            "transformers.models.roformer.modeling_roformer.RoFormerForCausalLM.prepare_inputs_for_generation": 1178
        },
        {
            "transformers.models.roformer.modeling_roformer.RoFormerClassificationHead.forward": 1211
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/mgp_str/processing_mgp_str.py": [
        {
            "transformers.models.mgp_str.processing_mgp_str.MgpstrProcessor.__init__": 56
        },
        {
            "transformers.models.mgp_str.processing_mgp_str.MgpstrProcessor.__call__": 77
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/mgp_str/configuration_mgp_str.py": [
        {
            "transformers.models.mgp_str.configuration_mgp_str.MgpstrConfig.__init__": 94
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/mgp_str/tokenization_mgp_str.py": [
        {
            "transformers.models.mgp_str.tokenization_mgp_str.MgpstrTokenizer.__init__": 64
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/rag/tokenization_rag.py": [
        {
            "transformers.models.rag.tokenization_rag.RagTokenizer.from_pretrained": 44
        },
        {
            "transformers.models.rag.tokenization_rag.RagTokenizer.__call__": 61
        },
        {
            "transformers.models.rag.tokenization_rag.RagTokenizer.batch_decode": 64
        },
        {
            "transformers.models.rag.tokenization_rag.RagTokenizer.decode": 67
        },
        {
            "transformers.models.rag.tokenization_rag.RagTokenizer.prepare_seq2seq_batch": 76
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/rag/retrieval_rag.py": [
        {
            "transformers.models.rag.retrieval_rag.RagRetriever.from_pretrained": 419
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/rag/modeling_tf_rag.py": [
        {
            "transformers.models.rag.modeling_tf_rag.TFRagPreTrainedModel.from_pretrained_question_encoder_generator": 232
        },
        {
            "transformers.models.rag.modeling_tf_rag.TFRagModel.__init__": 499
        },
        {
            "transformers.models.rag.modeling_tf_rag.TFRagModel.call": 549
        },
        {
            "transformers.models.rag.modeling_tf_rag.TFRagTokenForGeneration.__init__": 732
        },
        {
            "transformers.models.rag.modeling_tf_rag.TFRagTokenForGeneration.prepare_inputs_for_generation": 765
        },
        {
            "transformers.models.rag.modeling_tf_rag.TFRagTokenForGeneration.call": 845
        },
        {
            "transformers.models.rag.modeling_tf_rag.TFRagTokenForGeneration.generate": 997
        },
        {
            "transformers.models.rag.modeling_tf_rag.TFRagSequenceForGeneration.__init__": 1304
        },
        {
            "transformers.models.rag.modeling_tf_rag.TFRagSequenceForGeneration.call": 1351
        },
        {
            "transformers.models.rag.modeling_tf_rag.TFRagSequenceForGeneration.generate": 1583
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/rag/configuration_rag.py": [
        {
            "transformers.models.rag.configuration_rag.RagConfig.__init__": 86
        },
        {
            "transformers.models.rag.configuration_rag.RagConfig.from_question_encoder_generator_configs": 171
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/rag/modeling_rag.py": [
        {
            "transformers.models.rag.modeling_rag.RagPreTrainedModel.from_pretrained": 237
        },
        {
            "transformers.models.rag.modeling_rag.RagPreTrainedModel.from_pretrained_question_encoder_generator": 244
        },
        {
            "transformers.models.rag.modeling_rag.RagModel.__init__": 495
        },
        {
            "transformers.models.rag.modeling_rag.RagSequenceForGeneration.__init__": 741
        },
        {
            "transformers.models.rag.modeling_rag.RagSequenceForGeneration.forward": 771
        },
        {
            "transformers.models.rag.modeling_rag.RagSequenceForGeneration.generate": 911
        },
        {
            "transformers.models.rag.modeling_rag.RagTokenForGeneration.__init__": 1139
        },
        {
            "transformers.models.rag.modeling_rag.RagTokenForGeneration.prepare_inputs_for_generation": 1168
        },
        {
            "transformers.models.rag.modeling_rag.RagTokenForGeneration.forward": 1238
        },
        {
            "transformers.models.rag.modeling_rag.RagTokenForGeneration.generate": 1378
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/luke/modeling_luke.py": [
        {
            "transformers.models.luke.modeling_luke.LukeEncoder.custom_forward": 793
        },
        {
            "transformers.models.luke.modeling_luke.LukeLMHead.forward": 1254
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/luke/tokenization_luke.py": [
        {
            "transformers.models.luke.tokenization_luke.LukeTokenizer.__init__": 294
        },
        {
            "transformers.models.luke.tokenization_luke.LukeTokenizer.prepare_for_tokenization": 569
        },
        {
            "transformers.models.luke.tokenization_luke.LukeTokenizer.__call__": 576
        },
        {
            "transformers.models.luke.tokenization_luke.LukeTokenizer._encode_plus": 721
        },
        {
            "transformers.models.luke.tokenization_luke.LukeTokenizer._batch_encode_plus": 801
        },
        {
            "transformers.models.luke.tokenization_luke.LukeTokenizer._create_input_sequence": 927
        },
        {
            "transformers.models.luke.tokenization_luke.LukeTokenizer.prepare_for_model": 1162
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/luke/configuration_luke.py": [
        {
            "transformers.models.luke.configuration_luke.LukeConfig.__init__": 96
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/pix2struct/modeling_pix2struct.py": [
        {
            "transformers.models.pix2struct.modeling_pix2struct.Pix2StructVisionEncoder.custom_forward": 348
        },
        {
            "transformers.models.pix2struct.modeling_pix2struct.Pix2StructTextModel.forward": 1387
        },
        {
            "transformers.models.pix2struct.modeling_pix2struct.Pix2StructTextModel.custom_forward": 1499
        },
        {
            "transformers.models.pix2struct.modeling_pix2struct.Pix2StructForConditionalGeneration.prepare_inputs_for_generation": 1789
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/pix2struct/image_processing_pix2struct.py": [
        {
            "transformers.models.pix2struct.image_processing_pix2struct.render_header": 147
        },
        {
            "transformers.models.pix2struct.image_processing_pix2struct.Pix2StructImageProcessor.__init__": 210
        },
        {
            "transformers.models.pix2struct.image_processing_pix2struct.Pix2StructImageProcessor.extract_flattened_patches": 226
        },
        {
            "transformers.models.pix2struct.image_processing_pix2struct.Pix2StructImageProcessor.normalize": 300
        },
        {
            "transformers.models.pix2struct.image_processing_pix2struct.Pix2StructImageProcessor.preprocess": 323
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/pix2struct/configuration_pix2struct.py": [
        {
            "transformers.models.pix2struct.configuration_pix2struct.Pix2StructTextConfig.__init__": 102
        },
        {
            "transformers.models.pix2struct.configuration_pix2struct.Pix2StructTextConfig.from_pretrained": 153
        },
        {
            "transformers.models.pix2struct.configuration_pix2struct.Pix2StructVisionConfig.__init__": 240
        },
        {
            "transformers.models.pix2struct.configuration_pix2struct.Pix2StructVisionConfig.from_pretrained": 286
        },
        {
            "transformers.models.pix2struct.configuration_pix2struct.Pix2StructConfig.__init__": 355
        },
        {
            "transformers.models.pix2struct.configuration_pix2struct.Pix2StructConfig.from_text_vision_configs": 392
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/pix2struct/processing_pix2struct.py": [
        {
            "transformers.models.pix2struct.processing_pix2struct.Pix2StructProcessor.__call__": 48
        },
        {
            "transformers.models.pix2struct.processing_pix2struct.Pix2StructProcessor.batch_decode": 144
        },
        {
            "transformers.models.pix2struct.processing_pix2struct.Pix2StructProcessor.decode": 151
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/decision_transformer/modeling_decision_transformer.py": [
        {
            "transformers.models.decision_transformer.modeling_decision_transformer.DecisionTransformerGPT2PreTrainedModel.__init__": 443
        },
        {
            "transformers.models.decision_transformer.modeling_decision_transformer.DecisionTransformerGPT2Model.custom_forward": 640
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/decision_transformer/configuration_decision_transformer.py": [
        {
            "transformers.models.decision_transformer.configuration_decision_transformer.DecisionTransformerConfig.__init__": 111
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/deta/modeling_deta.py": [
        {
            "transformers.models.deta.modeling_deta.DetaDecoder.custom_forward": 1270
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/deta/configuration_deta.py": [
        {
            "transformers.models.deta.configuration_deta.DetaConfig.__init__": 134
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/deta/image_processing_deta.py": [
        {
            "transformers.models.deta.image_processing_deta.DetaImageProcessor.__init__": 486
        },
        {
            "transformers.models.deta.image_processing_deta.DetaImageProcessor.convert_coco_poly_to_mask": 555
        },
        {
            "transformers.models.deta.image_processing_deta.DetaImageProcessor.prepare_coco_detection": 562
        },
        {
            "transformers.models.deta.image_processing_deta.DetaImageProcessor.prepare_coco_panoptic": 569
        },
        {
            "transformers.models.deta.image_processing_deta.DetaImageProcessor.resize": 575
        },
        {
            "transformers.models.deta.image_processing_deta.DetaImageProcessor.preprocess": 739
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/encoder_decoder/configuration_encoder_decoder.py": [
        {
            "transformers.models.encoder_decoder.configuration_encoder_decoder.EncoderDecoderConfig.__init__": 75
        },
        {
            "transformers.models.encoder_decoder.configuration_encoder_decoder.EncoderDecoderConfig.from_encoder_decoder_configs": 92
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/encoder_decoder/modeling_flax_encoder_decoder.py": [
        {
            "transformers.models.encoder_decoder.modeling_flax_encoder_decoder.FlaxEncoderDecoderModel.__init__": 313
        },
        {
            "transformers.models.encoder_decoder.modeling_flax_encoder_decoder.FlaxEncoderDecoderModel._decoder_forward": 408
        },
        {
            "transformers.models.encoder_decoder.modeling_flax_encoder_decoder.FlaxEncoderDecoderModel._encoder_forward": 476
        },
        {
            "transformers.models.encoder_decoder.modeling_flax_encoder_decoder.FlaxEncoderDecoderModel._decoder_forward": 582
        },
        {
            "transformers.models.encoder_decoder.modeling_flax_encoder_decoder.FlaxEncoderDecoderModel.prepare_inputs_for_generation": 721
        },
        {
            "transformers.models.encoder_decoder.modeling_flax_encoder_decoder.FlaxEncoderDecoderModel.from_encoder_decoder_pretrained": 760
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/encoder_decoder/modeling_tf_encoder_decoder.py": [
        {
            "transformers.models.encoder_decoder.modeling_tf_encoder_decoder.TFEncoderDecoderModel.from_pretrained": 294
        },
        {
            "transformers.models.encoder_decoder.modeling_tf_encoder_decoder.TFEncoderDecoderModel.from_encoder_decoder_pretrained": 323
        },
        {
            "transformers.models.encoder_decoder.modeling_tf_encoder_decoder.TFEncoderDecoderModel.call": 472
        },
        {
            "transformers.models.encoder_decoder.modeling_tf_encoder_decoder.TFEncoderDecoderModel.prepare_inputs_for_generation": 631
        },
        {
            "transformers.models.encoder_decoder.modeling_tf_encoder_decoder.TFEncoderDecoderModel.resize_token_embeddings": 654
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/encoder_decoder/modeling_encoder_decoder.py": [
        {
            "transformers.models.encoder_decoder.modeling_encoder_decoder.EncoderDecoderModel.from_pretrained": 289
        },
        {
            "transformers.models.encoder_decoder.modeling_encoder_decoder.EncoderDecoderModel.from_encoder_decoder_pretrained": 390
        },
        {
            "transformers.models.encoder_decoder.modeling_encoder_decoder.EncoderDecoderModel.forward": 541
        },
        {
            "transformers.models.encoder_decoder.modeling_encoder_decoder.EncoderDecoderModel.prepare_inputs_for_generation": 668
        },
        {
            "transformers.models.encoder_decoder.modeling_encoder_decoder.EncoderDecoderModel.resize_token_embeddings": 683
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/bert_generation/tokenization_bert_generation.py": [
        {
            "transformers.models.bert_generation.tokenization_bert_generation.BertGenerationTokenizer.__init__": 86
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/bert_generation/modeling_bert_generation.py": [
        {
            "transformers.models.bert_generation.modeling_bert_generation.BertEncoder.custom_forward": 406
        },
        {
            "transformers.models.bert_generation.modeling_bert_generation.BertGenerationDecoder.prepare_inputs_for_generation": 988
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/bert_generation/configuration_bert_generation.py": [
        {
            "transformers.models.bert_generation.configuration_bert_generation.BertGenerationConfig.__init__": 85
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/bert/tokenization_bert_fast.py": [
        {
            "transformers.models.bert.tokenization_bert_fast.BertTokenizerFast.__init__": 207
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/bert/tokenization_bert.py": [
        {
            "transformers.models.bert.tokenization_bert.BertTokenizer.__init__": 184
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/bert/configuration_bert.py": [
        {
            "transformers.models.bert.configuration_bert.BertConfig.__init__": 141
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/bert/modeling_flax_bert.py": [
        {
            "transformers.models.bert.modeling_flax_bert.FlaxBertPreTrainedModel.__init__": 769
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/bert/modeling_bert.py": [
        {
            "transformers.models.bert.modeling_bert.BertEncoder.custom_forward": 596
        },
        {
            "transformers.models.bert.modeling_bert.BertLMHeadModel.prepare_inputs_for_generation": 1274
        },
        {
            "transformers.models.bert.modeling_bert.BertForMaskedLM.prepare_inputs_for_generation": 1391
        },
        {
            "transformers.models.bert.modeling_bert.BertForNextSentencePrediction.forward": 1424
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/bert/tokenization_bert_tf.py": [
        {
            "transformers.models.bert.tokenization_bert_tf.TFBertTokenizer.from_tokenizer": 100
        },
        {
            "transformers.models.bert.tokenization_bert_tf.TFBertTokenizer.from_pretrained": 139
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/bert/modeling_tf_bert.py": [
        {
            "transformers.models.bert.modeling_tf_bert.TFBertEmbeddings.__init__": 149
        },
        {
            "transformers.models.bert.modeling_tf_bert.TFBertSelfAttention.__init__": 225
        },
        {
            "transformers.models.bert.modeling_tf_bert.TFBertSelfOutput.__init__": 342
        },
        {
            "transformers.models.bert.modeling_tf_bert.TFBertAttention.__init__": 360
        },
        {
            "transformers.models.bert.modeling_tf_bert.TFBertIntermediate.__init__": 400
        },
        {
            "transformers.models.bert.modeling_tf_bert.TFBertOutput.__init__": 420
        },
        {
            "transformers.models.bert.modeling_tf_bert.TFBertLayer.__init__": 438
        },
        {
            "transformers.models.bert.modeling_tf_bert.TFBertEncoder.__init__": 524
        },
        {
            "transformers.models.bert.modeling_tf_bert.TFBertPooler.__init__": 593
        },
        {
            "transformers.models.bert.modeling_tf_bert.TFBertPredictionHeadTransform.__init__": 613
        },
        {
            "transformers.models.bert.modeling_tf_bert.TFBertLMPredictionHead.__init__": 638
        },
        {
            "transformers.models.bert.modeling_tf_bert.TFBertMLMHead.__init__": 681
        },
        {
            "transformers.models.bert.modeling_tf_bert.TFBertNSPHead.__init__": 693
        },
        {
            "transformers.models.bert.modeling_tf_bert.TFBertMainLayer.__init__": 712
        },
        {
            "transformers.models.bert.modeling_tf_bert.TFBertModel.__init__": 1039
        },
        {
            "transformers.models.bert.modeling_tf_bert.TFBertForPreTraining.__init__": 1122
        },
        {
            "transformers.models.bert.modeling_tf_bert.TFBertForMaskedLM.__init__": 1229
        },
        {
            "transformers.models.bert.modeling_tf_bert.TFBertLMHeadModel.__init__": 1314
        },
        {
            "transformers.models.bert.modeling_tf_bert.TFBertLMHeadModel.prepare_inputs_for_generation": 1330
        },
        {
            "transformers.models.bert.modeling_tf_bert.TFBertLMHeadModel.call": 1348
        },
        {
            "transformers.models.bert.modeling_tf_bert.TFBertForNextSentencePrediction.__init__": 1438
        },
        {
            "transformers.models.bert.modeling_tf_bert.TFBertForSequenceClassification.__init__": 1524
        },
        {
            "transformers.models.bert.modeling_tf_bert.TFBertForMultipleChoice.__init__": 1610
        },
        {
            "transformers.models.bert.modeling_tf_bert.TFBertForTokenClassification.__init__": 1715
        },
        {
            "transformers.models.bert.modeling_tf_bert.TFBertForQuestionAnswering.__init__": 1804
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/speech_to_text/configuration_speech_to_text.py": [
        {
            "transformers.models.speech_to_text.configuration_speech_to_text.Speech2TextConfig.__init__": 116
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/speech_to_text/modeling_tf_speech_to_text.py": [
        {
            "transformers.models.speech_to_text.modeling_tf_speech_to_text.TFConv1dSubsampler.__init__": 130
        },
        {
            "transformers.models.speech_to_text.modeling_tf_speech_to_text.TFSpeech2TextSinusoidalPositionalEmbedding.__init__": 173
        },
        {
            "transformers.models.speech_to_text.modeling_tf_speech_to_text.TFSpeech2TextAttention.__init__": 244
        },
        {
            "transformers.models.speech_to_text.modeling_tf_speech_to_text.TFSpeech2TextEncoderLayer.__init__": 395
        },
        {
            "transformers.models.speech_to_text.modeling_tf_speech_to_text.TFSpeech2TextDecoderLayer.__init__": 450
        },
        {
            "transformers.models.speech_to_text.modeling_tf_speech_to_text.TFSpeech2TextEncoder.__init__": 726
        },
        {
            "transformers.models.speech_to_text.modeling_tf_speech_to_text.TFSpeech2TextDecoder.__init__": 894
        },
        {
            "transformers.models.speech_to_text.modeling_tf_speech_to_text.TFSpeech2TextMainLayer.__init__": 1110
        },
        {
            "transformers.models.speech_to_text.modeling_tf_speech_to_text.TFSpeech2TextMainLayer.call": 1124
        },
        {
            "transformers.models.speech_to_text.modeling_tf_speech_to_text.TFSpeech2TextModel.__init__": 1216
        },
        {
            "transformers.models.speech_to_text.modeling_tf_speech_to_text.TFSpeech2TextModel.call": 1234
        },
        {
            "transformers.models.speech_to_text.modeling_tf_speech_to_text.TFSpeech2TextForConditionalGeneration.call": 1324
        },
        {
            "transformers.models.speech_to_text.modeling_tf_speech_to_text.TFSpeech2TextForConditionalGeneration.prepare_inputs_for_generation": 1446
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/speech_to_text/processing_speech_to_text.py": [
        {
            "transformers.models.speech_to_text.processing_speech_to_text.Speech2TextProcessor.__call__": 47
        },
        {
            "transformers.models.speech_to_text.processing_speech_to_text.Speech2TextProcessor.batch_decode": 86
        },
        {
            "transformers.models.speech_to_text.processing_speech_to_text.Speech2TextProcessor.decode": 93
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/speech_to_text/tokenization_speech_to_text.py": [
        {
            "transformers.models.speech_to_text.tokenization_speech_to_text.Speech2TextTokenizer.__init__": 113
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/speech_to_text/modeling_speech_to_text.py": [
        {
            "transformers.models.speech_to_text.modeling_speech_to_text.Speech2TextEncoder.custom_forward": 818
        },
        {
            "transformers.models.speech_to_text.modeling_speech_to_text.Speech2TextDecoder.custom_forward": 1065
        },
        {
            "transformers.models.speech_to_text.modeling_speech_to_text.Speech2TextForConditionalGeneration.prepare_inputs_for_generation": 1399
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/speech_to_text/feature_extraction_speech_to_text.py": [
        {
            "transformers.models.speech_to_text.feature_extraction_speech_to_text.Speech2TextFeatureExtractor.__init__": 62
        },
        {
            "transformers.models.speech_to_text.feature_extraction_speech_to_text.Speech2TextFeatureExtractor.__call__": 126
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/nat/configuration_nat.py": [
        {
            "transformers.models.nat.configuration_nat.NatConfig.__init__": 102
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/nat/modeling_nat.py": [
        {
            "transformers.models.nat.modeling_nat.natten2dqkrpb": 50
        },
        {
            "transformers.models.nat.modeling_nat.natten2dav": 53
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/roberta/modeling_flax_roberta.py": [
        {
            "transformers.models.roberta.modeling_flax_roberta.FlaxRobertaPreTrainedModel.__init__": 733
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/roberta/modeling_roberta.py": [
        {
            "transformers.models.roberta.modeling_roberta.RobertaEncoder.custom_forward": 513
        },
        {
            "transformers.models.roberta.modeling_roberta.RobertaForCausalLM.prepare_inputs_for_generation": 1017
        },
        {
            "transformers.models.roberta.modeling_roberta.RobertaLMHead.forward": 1147
        },
        {
            "transformers.models.roberta.modeling_roberta.RobertaClassificationHead.forward": 1461
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/roberta/tokenization_roberta_fast.py": [
        {
            "transformers.models.roberta.tokenization_roberta_fast.RobertaTokenizerFast.__init__": 163
        },
        {
            "transformers.models.roberta.tokenization_roberta_fast.RobertaTokenizerFast._batch_encode_plus": 258
        },
        {
            "transformers.models.roberta.tokenization_roberta_fast.RobertaTokenizerFast._encode_plus": 267
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/roberta/modeling_tf_roberta.py": [
        {
            "transformers.models.roberta.modeling_tf_roberta.TFRobertaEmbeddings.__init__": 81
        },
        {
            "transformers.models.roberta.modeling_tf_roberta.TFRobertaPooler.__init__": 178
        },
        {
            "transformers.models.roberta.modeling_tf_roberta.TFRobertaSelfAttention.__init__": 199
        },
        {
            "transformers.models.roberta.modeling_tf_roberta.TFRobertaSelfOutput.__init__": 317
        },
        {
            "transformers.models.roberta.modeling_tf_roberta.TFRobertaAttention.__init__": 336
        },
        {
            "transformers.models.roberta.modeling_tf_roberta.TFRobertaIntermediate.__init__": 377
        },
        {
            "transformers.models.roberta.modeling_tf_roberta.TFRobertaOutput.__init__": 398
        },
        {
            "transformers.models.roberta.modeling_tf_roberta.TFRobertaLayer.__init__": 417
        },
        {
            "transformers.models.roberta.modeling_tf_roberta.TFRobertaEncoder.__init__": 504
        },
        {
            "transformers.models.roberta.modeling_tf_roberta.TFRobertaMainLayer.__init__": 576
        },
        {
            "transformers.models.roberta.modeling_tf_roberta.TFRobertaModel.__init__": 882
        },
        {
            "transformers.models.roberta.modeling_tf_roberta.TFRobertaLMHead.__init__": 953
        },
        {
            "transformers.models.roberta.modeling_tf_roberta.TFRobertaForMaskedLM.__init__": 1007
        },
        {
            "transformers.models.roberta.modeling_tf_roberta.TFRobertaForCausalLM.__init__": 1084
        },
        {
            "transformers.models.roberta.modeling_tf_roberta.TFRobertaForCausalLM.prepare_inputs_for_generation": 1101
        },
        {
            "transformers.models.roberta.modeling_tf_roberta.TFRobertaClassificationHead.__init__": 1205
        },
        {
            "transformers.models.roberta.modeling_tf_roberta.TFRobertaForSequenceClassification.__init__": 1241
        },
        {
            "transformers.models.roberta.modeling_tf_roberta.TFRobertaForMultipleChoice.__init__": 1318
        },
        {
            "transformers.models.roberta.modeling_tf_roberta.TFRobertaForTokenClassification.__init__": 1408
        },
        {
            "transformers.models.roberta.modeling_tf_roberta.TFRobertaForQuestionAnswering.__init__": 1490
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/roberta/tokenization_roberta.py": [
        {
            "transformers.models.roberta.tokenization_roberta.RobertaTokenizer.__init__": 190
        },
        {
            "transformers.models.roberta.tokenization_roberta.RobertaTokenizer.prepare_for_tokenization": 421
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/roberta/configuration_roberta.py": [
        {
            "transformers.models.roberta.configuration_roberta.RobertaConfig.__init__": 106
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/marian/modeling_tf_marian.py": [
        {
            "transformers.models.marian.modeling_tf_marian.TFMarianSinusoidalPositionalEmbedding.__init__": 123
        },
        {
            "transformers.models.marian.modeling_tf_marian.TFMarianAttention.__init__": 182
        },
        {
            "transformers.models.marian.modeling_tf_marian.TFMarianEncoderLayer.__init__": 334
        },
        {
            "transformers.models.marian.modeling_tf_marian.TFMarianDecoderLayer.__init__": 391
        },
        {
            "transformers.models.marian.modeling_tf_marian.TFMarianEncoder.__init__": 658
        },
        {
            "transformers.models.marian.modeling_tf_marian.TFMarianDecoder.__init__": 821
        },
        {
            "transformers.models.marian.modeling_tf_marian.TFMarianMainLayer.__init__": 1046
        },
        {
            "transformers.models.marian.modeling_tf_marian.TFMarianMainLayer.call": 1071
        },
        {
            "transformers.models.marian.modeling_tf_marian.TFMarianModel.__init__": 1158
        },
        {
            "transformers.models.marian.modeling_tf_marian.TFMarianModel.call": 1176
        },
        {
            "transformers.models.marian.modeling_tf_marian.BiasLayer.__init__": 1247
        },
        {
            "transformers.models.marian.modeling_tf_marian.TFMarianMTModel.__init__": 1268
        },
        {
            "transformers.models.marian.modeling_tf_marian.TFMarianMTModel.prepare_inputs_for_generation": 1406
        },
        {
            "transformers.models.marian.modeling_tf_marian.TFMarianMTModel.adjust_logits_during_generation": 1447
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/marian/tokenization_marian.py": [
        {
            "transformers.models.marian.tokenization_marian.MarianTokenizer.__init__": 127
        },
        {
            "transformers.models.marian.tokenization_marian.MarianTokenizer.batch_decode": 219
        },
        {
            "transformers.models.marian.tokenization_marian.MarianTokenizer.decode": 242
        },
        {
            "transformers.models.marian.tokenization_marian.MarianTokenizer.num_special_tokens_to_add": 375
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/marian/modeling_marian.py": [
        {
            "transformers.models.marian.modeling_marian.MarianEncoder.custom_forward": 788
        },
        {
            "transformers.models.marian.modeling_marian.MarianDecoder.custom_forward": 1036
        },
        {
            "transformers.models.marian.modeling_marian.MarianMTModel.prepare_inputs_for_generation": 1495
        },
        {
            "transformers.models.marian.modeling_marian.MarianDecoderWrapper.forward": 1552
        },
        {
            "transformers.models.marian.modeling_marian.MarianForCausalLM.prepare_inputs_for_generation": 1735
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/marian/modeling_flax_marian.py": [
        {
            "transformers.models.marian.modeling_flax_marian.FlaxMarianPreTrainedModel.__init__": 878
        },
        {
            "transformers.models.marian.modeling_flax_marian.FlaxMarianPreTrainedModel._decoder_forward": 947
        },
        {
            "transformers.models.marian.modeling_flax_marian.FlaxMarianPreTrainedModel._encoder_forward": 1009
        },
        {
            "transformers.models.marian.modeling_flax_marian.FlaxMarianPreTrainedModel._decoder_forward": 1104
        },
        {
            "transformers.models.marian.modeling_flax_marian.FlaxMarianMTModel._decoder_forward": 1371
        },
        {
            "transformers.models.marian.modeling_flax_marian.FlaxMarianMTModel.prepare_inputs_for_generation": 1435
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/marian/configuration_marian.py": [
        {
            "transformers.models.marian.configuration_marian.MarianConfig.__init__": 109
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/pegasus/modeling_flax_pegasus.py": [
        {
            "transformers.models.pegasus.modeling_flax_pegasus.FlaxPegasusPreTrainedModel.__init__": 898
        },
        {
            "transformers.models.pegasus.modeling_flax_pegasus.FlaxPegasusPreTrainedModel._decoder_forward": 965
        },
        {
            "transformers.models.pegasus.modeling_flax_pegasus.FlaxPegasusPreTrainedModel._encoder_forward": 1031
        },
        {
            "transformers.models.pegasus.modeling_flax_pegasus.FlaxPegasusPreTrainedModel._decoder_forward": 1126
        },
        {
            "transformers.models.pegasus.modeling_flax_pegasus.FlaxPegasusForConditionalGeneration._decoder_forward": 1394
        },
        {
            "transformers.models.pegasus.modeling_flax_pegasus.FlaxPegasusForConditionalGeneration.prepare_inputs_for_generation": 1453
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/pegasus/configuration_pegasus.py": [
        {
            "transformers.models.pegasus.configuration_pegasus.PegasusConfig.__init__": 104
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/pegasus/modeling_pegasus.py": [
        {
            "transformers.models.pegasus.modeling_pegasus.PegasusEncoder.custom_forward": 803
        },
        {
            "transformers.models.pegasus.modeling_pegasus.PegasusDecoder.custom_forward": 1086
        },
        {
            "transformers.models.pegasus.modeling_pegasus.PegasusForConditionalGeneration.prepare_inputs_for_generation": 1456
        },
        {
            "transformers.models.pegasus.modeling_pegasus.PegasusDecoderWrapper.forward": 1509
        },
        {
            "transformers.models.pegasus.modeling_pegasus.PegasusForCausalLM.prepare_inputs_for_generation": 1714
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/pegasus/tokenization_pegasus_fast.py": [
        {
            "transformers.models.pegasus.tokenization_pegasus_fast.PegasusTokenizerFast.__init__": 100
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/pegasus/modeling_tf_pegasus.py": [
        {
            "transformers.models.pegasus.modeling_tf_pegasus.TFPegasusSinusoidalPositionalEmbedding.__init__": 125
        },
        {
            "transformers.models.pegasus.modeling_tf_pegasus.TFPegasusAttention.__init__": 184
        },
        {
            "transformers.models.pegasus.modeling_tf_pegasus.TFPegasusEncoderLayer.__init__": 336
        },
        {
            "transformers.models.pegasus.modeling_tf_pegasus.TFPegasusDecoderLayer.__init__": 393
        },
        {
            "transformers.models.pegasus.modeling_tf_pegasus.TFPegasusEncoder.__init__": 661
        },
        {
            "transformers.models.pegasus.modeling_tf_pegasus.TFPegasusDecoder.__init__": 827
        },
        {
            "transformers.models.pegasus.modeling_tf_pegasus.TFPegasusMainLayer.__init__": 1055
        },
        {
            "transformers.models.pegasus.modeling_tf_pegasus.TFPegasusMainLayer.call": 1080
        },
        {
            "transformers.models.pegasus.modeling_tf_pegasus.TFPegasusModel.__init__": 1167
        },
        {
            "transformers.models.pegasus.modeling_tf_pegasus.TFPegasusModel.call": 1185
        },
        {
            "transformers.models.pegasus.modeling_tf_pegasus.BiasLayer.__init__": 1256
        },
        {
            "transformers.models.pegasus.modeling_tf_pegasus.TFPegasusForConditionalGeneration.__init__": 1277
        },
        {
            "transformers.models.pegasus.modeling_tf_pegasus.TFPegasusForConditionalGeneration.prepare_inputs_for_generation": 1415
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/pegasus/tokenization_pegasus.py": [
        {
            "transformers.models.pegasus.tokenization_pegasus.PegasusTokenizer.__init__": 105
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/wav2vec2_conformer/configuration_wav2vec2_conformer.py": [
        {
            "transformers.models.wav2vec2_conformer.configuration_wav2vec2_conformer.Wav2Vec2ConformerConfig.__init__": 212
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/wav2vec2_conformer/modeling_wav2vec2_conformer.py": [
        {
            "transformers.models.wav2vec2_conformer.modeling_wav2vec2_conformer.Wav2Vec2ConformerFeatureEncoder.custom_forward": 521
        },
        {
            "transformers.models.wav2vec2_conformer.modeling_wav2vec2_conformer.Wav2Vec2ConformerEncoder.custom_forward": 914
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/barthez/tokenization_barthez.py": [
        {
            "transformers.models.barthez.tokenization_barthez.BarthezTokenizer.__init__": 126
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/barthez/tokenization_barthez_fast.py": [
        {
            "transformers.models.barthez.tokenization_barthez_fast.BarthezTokenizerFast.__init__": 119
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/speech_encoder_decoder/modeling_flax_speech_encoder_decoder.py": [
        {
            "transformers.models.speech_encoder_decoder.modeling_flax_speech_encoder_decoder.FlaxSpeechEncoderDecoderModel.__init__": 341
        },
        {
            "transformers.models.speech_encoder_decoder.modeling_flax_speech_encoder_decoder.FlaxSpeechEncoderDecoderModel._decoder_forward": 441
        },
        {
            "transformers.models.speech_encoder_decoder.modeling_flax_speech_encoder_decoder.FlaxSpeechEncoderDecoderModel._encoder_forward": 510
        },
        {
            "transformers.models.speech_encoder_decoder.modeling_flax_speech_encoder_decoder.FlaxSpeechEncoderDecoderModel._decoder_forward": 615
        },
        {
            "transformers.models.speech_encoder_decoder.modeling_flax_speech_encoder_decoder.FlaxSpeechEncoderDecoderModel.prepare_inputs_for_generation": 744
        },
        {
            "transformers.models.speech_encoder_decoder.modeling_flax_speech_encoder_decoder.FlaxSpeechEncoderDecoderModel.from_encoder_decoder_pretrained": 783
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/speech_encoder_decoder/configuration_speech_encoder_decoder.py": [
        {
            "transformers.models.speech_encoder_decoder.configuration_speech_encoder_decoder.SpeechEncoderDecoderConfig.__init__": 76
        },
        {
            "transformers.models.speech_encoder_decoder.configuration_speech_encoder_decoder.SpeechEncoderDecoderConfig.from_encoder_decoder_configs": 94
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/speech_encoder_decoder/modeling_speech_encoder_decoder.py": [
        {
            "transformers.models.speech_encoder_decoder.modeling_speech_encoder_decoder.SpeechEncoderDecoderModel.from_pretrained": 277
        },
        {
            "transformers.models.speech_encoder_decoder.modeling_speech_encoder_decoder.SpeechEncoderDecoderModel.from_encoder_decoder_pretrained": 288
        },
        {
            "transformers.models.speech_encoder_decoder.modeling_speech_encoder_decoder.SpeechEncoderDecoderModel.forward": 444
        },
        {
            "transformers.models.speech_encoder_decoder.modeling_speech_encoder_decoder.SpeechEncoderDecoderModel.prepare_inputs_for_generation": 585
        },
        {
            "transformers.models.speech_encoder_decoder.modeling_speech_encoder_decoder.SpeechEncoderDecoderModel.resize_token_embeddings": 600
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/wav2vec2_phoneme/tokenization_wav2vec2_phoneme.py": [
        {
            "transformers.models.wav2vec2_phoneme.tokenization_wav2vec2_phoneme.Wav2Vec2PhonemeCTCTokenizer.__init__": 132
        },
        {
            "transformers.models.wav2vec2_phoneme.tokenization_wav2vec2_phoneme.Wav2Vec2PhonemeCTCTokenizer._tokenize": 235
        },
        {
            "transformers.models.wav2vec2_phoneme.tokenization_wav2vec2_phoneme.Wav2Vec2PhonemeCTCTokenizer.decode": 455
        },
        {
            "transformers.models.wav2vec2_phoneme.tokenization_wav2vec2_phoneme.Wav2Vec2PhonemeCTCTokenizer.batch_decode": 511
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/big_bird/configuration_big_bird.py": [
        {
            "transformers.models.big_bird.configuration_big_bird.BigBirdConfig.__init__": 109
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/big_bird/tokenization_big_bird.py": [
        {
            "transformers.models.big_bird.tokenization_big_bird.BigBirdTokenizer.__init__": 105
        },
        {
            "transformers.models.big_bird.tokenization_big_bird.BigBirdTokenizer._decode": 203
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/big_bird/modeling_big_bird.py": [
        {
            "transformers.models.big_bird.modeling_big_bird.BigBirdEncoder.custom_forward": 1620
        },
        {
            "transformers.models.big_bird.modeling_big_bird.BigBirdForMaskedLM.prepare_inputs_for_generation": 2494
        },
        {
            "transformers.models.big_bird.modeling_big_bird.BigBirdForCausalLM.prepare_inputs_for_generation": 2627
        },
        {
            "transformers.models.big_bird.modeling_big_bird.BigBirdClassificationHead.forward": 2663
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/big_bird/tokenization_big_bird_fast.py": [
        {
            "transformers.models.big_bird.tokenization_big_bird_fast.BigBirdTokenizerFast.__init__": 116
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/big_bird/modeling_flax_big_bird.py": [
        {
            "transformers.models.big_bird.modeling_flax_big_bird.FlaxBigBirdPreTrainedModel.__init__": 1623
        },
        {
            "transformers.models.big_bird.modeling_flax_big_bird.FlaxBigBirdForMultipleChoice.__init__": 2234
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/ernie_m/tokenization_ernie_m.py": [
        {
            "transformers.models.ernie_m.tokenization_ernie_m.ErnieMTokenizer.__init__": 97
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/ernie_m/configuration_ernie_m.py": [
        {
            "transformers.models.ernie_m.configuration_ernie_m.ErnieMConfig.__init__": 84
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/groupvit/modeling_tf_groupvit.py": [
        {
            "transformers.models.groupvit.modeling_tf_groupvit.TFGroupViTCrossAttentionLayer.__init__": 268
        },
        {
            "transformers.models.groupvit.modeling_tf_groupvit.TFGroupViTAssignAttention.__init__": 284
        },
        {
            "transformers.models.groupvit.modeling_tf_groupvit.TFGroupViTTokenAssign.__init__": 332
        },
        {
            "transformers.models.groupvit.modeling_tf_groupvit.TFGroupViTPatchEmbeddings.__init__": 398
        },
        {
            "transformers.models.groupvit.modeling_tf_groupvit.TFGroupViTVisionEmbeddings.__init__": 468
        },
        {
            "transformers.models.groupvit.modeling_tf_groupvit.TFGroupViTTextEmbeddings.__init__": 534
        },
        {
            "transformers.models.groupvit.modeling_tf_groupvit.TFGroupViTStage.__init__": 594
        },
        {
            "transformers.models.groupvit.modeling_tf_groupvit.TFGroupViTMLP.__init__": 707
        },
        {
            "transformers.models.groupvit.modeling_tf_groupvit.TFGroupViTAttention.__init__": 741
        },
        {
            "transformers.models.groupvit.modeling_tf_groupvit.TFGroupViTEncoderLayer.__init__": 847
        },
        {
            "transformers.models.groupvit.modeling_tf_groupvit.TFGroupViTTextEncoder.__init__": 900
        },
        {
            "transformers.models.groupvit.modeling_tf_groupvit.TFGroupViTVisionEncoder.__init__": 944
        },
        {
            "transformers.models.groupvit.modeling_tf_groupvit.TFGroupViTTextTransformer.__init__": 996
        },
        {
            "transformers.models.groupvit.modeling_tf_groupvit.TFGroupViTVisionTransformer.__init__": 1081
        },
        {
            "transformers.models.groupvit.modeling_tf_groupvit.TFGroupViTTextMainLayer.__init__": 1127
        },
        {
            "transformers.models.groupvit.modeling_tf_groupvit.TFGroupViTVisionMainLayer.__init__": 1176
        },
        {
            "transformers.models.groupvit.modeling_tf_groupvit.TFGroupViTMainLayer.__init__": 1212
        },
        {
            "transformers.models.groupvit.modeling_tf_groupvit.TFGroupViTTextModel.__init__": 1605
        },
        {
            "transformers.models.groupvit.modeling_tf_groupvit.TFGroupViTVisionModel.__init__": 1658
        },
        {
            "transformers.models.groupvit.modeling_tf_groupvit.TFGroupViTModel.__init__": 1712
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/groupvit/configuration_groupvit.py": [
        {
            "transformers.models.groupvit.configuration_groupvit.GroupViTTextConfig.__init__": 94
        },
        {
            "transformers.models.groupvit.configuration_groupvit.GroupViTTextConfig.from_pretrained": 129
        },
        {
            "transformers.models.groupvit.configuration_groupvit.GroupViTVisionConfig.__init__": 203
        },
        {
            "transformers.models.groupvit.configuration_groupvit.GroupViTVisionConfig.from_pretrained": 252
        },
        {
            "transformers.models.groupvit.configuration_groupvit.GroupViTConfig.__init__": 297
        },
        {
            "transformers.models.groupvit.configuration_groupvit.GroupViTConfig.from_text_vision_configs": 395
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/groupvit/modeling_groupvit.py": [
        {
            "transformers.models.groupvit.modeling_groupvit.GroupViTTextEncoder.custom_forward": 1035
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/trocr/processing_trocr.py": [
        {
            "transformers.models.trocr.processing_trocr.TrOCRProcessor.__init__": 42
        },
        {
            "transformers.models.trocr.processing_trocr.TrOCRProcessor.__call__": 61
        },
        {
            "transformers.models.trocr.processing_trocr.TrOCRProcessor.batch_decode": 94
        },
        {
            "transformers.models.trocr.processing_trocr.TrOCRProcessor.decode": 101
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/trocr/modeling_trocr.py": [
        {
            "transformers.models.trocr.modeling_trocr.TrOCRDecoder.custom_forward": 706
        },
        {
            "transformers.models.trocr.modeling_trocr.TrOCRDecoderWrapper.forward": 781
        },
        {
            "transformers.models.trocr.modeling_trocr.TrOCRForCausalLM.prepare_inputs_for_generation": 998
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/trocr/configuration_trocr.py": [
        {
            "transformers.models.trocr.configuration_trocr.TrOCRConfig.__init__": 102
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/markuplm/processing_markuplm.py": [
        {
            "transformers.models.markuplm.processing_markuplm.MarkupLMProcessor.__call__": 48
        },
        {
            "transformers.models.markuplm.processing_markuplm.MarkupLMProcessor.batch_decode": 128
        },
        {
            "transformers.models.markuplm.processing_markuplm.MarkupLMProcessor.decode": 135
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/markuplm/modeling_markuplm.py": [
        {
            "transformers.models.markuplm.modeling_markuplm.MarkupLMEncoder.custom_forward": 651
        },
        {
            "transformers.models.markuplm.modeling_markuplm.MarkupLMPreTrainedModel.from_pretrained": 736
        },
        {
            "transformers.models.markuplm.modeling_markuplm.MarkupLMModel.prepare_inputs_for_generation": 939
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/markuplm/tokenization_markuplm_fast.py": [
        {
            "transformers.models.markuplm.tokenization_markuplm_fast.MarkupLMTokenizerFast.__init__": 162
        },
        {
            "transformers.models.markuplm.tokenization_markuplm_fast.MarkupLMTokenizerFast.__call__": 285
        },
        {
            "transformers.models.markuplm.tokenization_markuplm_fast.MarkupLMTokenizerFast.batch_encode_plus": 430
        },
        {
            "transformers.models.markuplm.tokenization_markuplm_fast.MarkupLMTokenizerFast.tokenize": 488
        },
        {
            "transformers.models.markuplm.tokenization_markuplm_fast.MarkupLMTokenizerFast.encode_plus": 497
        },
        {
            "transformers.models.markuplm.tokenization_markuplm_fast.MarkupLMTokenizerFast._encode_plus": 720
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/markuplm/tokenization_markuplm.py": [
        {
            "transformers.models.markuplm.tokenization_markuplm.MarkupLMTokenizer.__init__": 204
        },
        {
            "transformers.models.markuplm.tokenization_markuplm.MarkupLMTokenizer.prepare_for_tokenization": 417
        },
        {
            "transformers.models.markuplm.tokenization_markuplm.MarkupLMTokenizer.__call__": 510
        },
        {
            "transformers.models.markuplm.tokenization_markuplm.MarkupLMTokenizer.batch_encode_plus": 655
        },
        {
            "transformers.models.markuplm.tokenization_markuplm.MarkupLMTokenizer._batch_encode_plus": 713
        },
        {
            "transformers.models.markuplm.tokenization_markuplm.MarkupLMTokenizer.encode": 840
        },
        {
            "transformers.models.markuplm.tokenization_markuplm.MarkupLMTokenizer.encode_plus": 887
        },
        {
            "transformers.models.markuplm.tokenization_markuplm.MarkupLMTokenizer._encode_plus": 953
        },
        {
            "transformers.models.markuplm.tokenization_markuplm.MarkupLMTokenizer.prepare_for_model": 1006
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/markuplm/feature_extraction_markuplm.py": [
        {
            "transformers.models.markuplm.feature_extraction_markuplm.MarkupLMFeatureExtractor.__init__": 43
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/markuplm/configuration_markuplm.py": [
        {
            "transformers.models.markuplm.configuration_markuplm.MarkupLMConfig.__init__": 102
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/deit/feature_extraction_deit.py": [
        {
            "transformers.models.deit.feature_extraction_deit.DeiTFeatureExtractor.__init__": 27
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/deit/image_processing_deit.py": [
        {
            "transformers.models.deit.image_processing_deit.DeiTImageProcessor.__init__": 79
        },
        {
            "transformers.models.deit.image_processing_deit.DeiTImageProcessor.resize": 110
        },
        {
            "transformers.models.deit.image_processing_deit.DeiTImageProcessor.center_crop": 138
        },
        {
            "transformers.models.deit.image_processing_deit.DeiTImageProcessor.rescale": 162
        },
        {
            "transformers.models.deit.image_processing_deit.DeiTImageProcessor.normalize": 182
        },
        {
            "transformers.models.deit.image_processing_deit.DeiTImageProcessor.preprocess": 205
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/deit/configuration_deit.py": [
        {
            "transformers.models.deit.configuration_deit.DeiTConfig.__init__": 96
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/deit/modeling_tf_deit.py": [
        {
            "transformers.models.deit.modeling_tf_deit.TFDeiTEmbeddings.__init__": 109
        },
        {
            "transformers.models.deit.modeling_tf_deit.TFDeiTPatchEmbeddings.__init__": 174
        },
        {
            "transformers.models.deit.modeling_tf_deit.TFDeiTSelfAttention.__init__": 209
        },
        {
            "transformers.models.deit.modeling_tf_deit.TFDeiTSelfOutput.__init__": 290
        },
        {
            "transformers.models.deit.modeling_tf_deit.TFDeiTAttention.__init__": 307
        },
        {
            "transformers.models.deit.modeling_tf_deit.TFDeiTIntermediate.__init__": 336
        },
        {
            "transformers.models.deit.modeling_tf_deit.TFDeiTOutput.__init__": 357
        },
        {
            "transformers.models.deit.modeling_tf_deit.TFDeiTLayer.__init__": 376
        },
        {
            "transformers.models.deit.modeling_tf_deit.TFDeiTEncoder.__init__": 425
        },
        {
            "transformers.models.deit.modeling_tf_deit.TFDeiTMainLayer.__init__": 473
        },
        {
            "transformers.models.deit.modeling_tf_deit.TFDeiTModel.__init__": 611
        },
        {
            "transformers.models.deit.modeling_tf_deit.TFDeiTPooler.__init__": 653
        },
        {
            "transformers.models.deit.modeling_tf_deit.TFDeitPixelShuffle.__init__": 675
        },
        {
            "transformers.models.deit.modeling_tf_deit.TFDeitDecoder.__init__": 699
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/deit/modeling_deit.py": [
        {
            "transformers.models.deit.modeling_deit.DeiTEncoder.custom_forward": 362
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/deformable_detr/modeling_deformable_detr.py": [
        {
            "transformers.models.deformable_detr.modeling_deformable_detr.DeformableDetrDecoder.custom_forward": 1378
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/deformable_detr/image_processing_deformable_detr.py": [
        {
            "transformers.models.deformable_detr.image_processing_deformable_detr.DeformableDetrImageProcessor.__init__": 780
        },
        {
            "transformers.models.deformable_detr.image_processing_deformable_detr.DeformableDetrImageProcessor.from_dict": 832
        },
        {
            "transformers.models.deformable_detr.image_processing_deformable_detr.DeformableDetrImageProcessor.convert_coco_poly_to_mask": 882
        },
        {
            "transformers.models.deformable_detr.image_processing_deformable_detr.DeformableDetrImageProcessor.prepare_coco_detection": 889
        },
        {
            "transformers.models.deformable_detr.image_processing_deformable_detr.DeformableDetrImageProcessor.prepare_coco_panoptic": 896
        },
        {
            "transformers.models.deformable_detr.image_processing_deformable_detr.DeformableDetrImageProcessor.resize": 903
        },
        {
            "transformers.models.deformable_detr.image_processing_deformable_detr.DeformableDetrImageProcessor.preprocess": 1076
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/deformable_detr/feature_extraction_deformable_detr.py": [
        {
            "transformers.models.deformable_detr.feature_extraction_deformable_detr.DeformableDetrFeatureExtractor.__init__": 27
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/deformable_detr/configuration_deformable_detr.py": [
        {
            "transformers.models.deformable_detr.configuration_deformable_detr.DeformableDetrConfig.__init__": 152
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/beit/modeling_flax_beit.py": [
        {
            "transformers.models.beit.modeling_flax_beit.FlaxBeitPreTrainedModel.__init__": 597
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/beit/configuration_beit.py": [
        {
            "transformers.models.beit.configuration_beit.BeitConfig.__init__": 120
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/beit/modeling_beit.py": [
        {
            "transformers.models.beit.modeling_beit.BeitEncoder.custom_forward": 515
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/beit/image_processing_beit.py": [
        {
            "transformers.models.beit.image_processing_beit.BeitImageProcessor.__init__": 92
        },
        {
            "transformers.models.beit.image_processing_beit.BeitImageProcessor.from_dict": 141
        },
        {
            "transformers.models.beit.image_processing_beit.BeitImageProcessor.resize": 151
        },
        {
            "transformers.models.beit.image_processing_beit.BeitImageProcessor.center_crop": 179
        },
        {
            "transformers.models.beit.image_processing_beit.BeitImageProcessor.rescale": 201
        },
        {
            "transformers.models.beit.image_processing_beit.BeitImageProcessor.normalize": 221
        },
        {
            "transformers.models.beit.image_processing_beit.BeitImageProcessor.__call__": 356
        },
        {
            "transformers.models.beit.image_processing_beit.BeitImageProcessor.preprocess": 361
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/beit/feature_extraction_beit.py": [
        {
            "transformers.models.beit.feature_extraction_beit.BeitFeatureExtractor.__init__": 27
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/hubert/modeling_hubert.py": [
        {
            "transformers.models.hubert.modeling_hubert.HubertFeatureEncoder.custom_forward": 351
        },
        {
            "transformers.models.hubert.modeling_hubert.HubertEncoder.custom_forward": 736
        },
        {
            "transformers.models.hubert.modeling_hubert.HubertEncoderStableLayerNorm.custom_forward": 826
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/hubert/modeling_tf_hubert.py": [
        {
            "transformers.models.hubert.modeling_tf_hubert.TFHubertGroupNorm.__init__": 177
        },
        {
            "transformers.models.hubert.modeling_tf_hubert.TFHubertWeightNormConv1D.__init__": 392
        },
        {
            "transformers.models.hubert.modeling_tf_hubert.TFHubertNoLayerNormConvLayer.__init__": 451
        },
        {
            "transformers.models.hubert.modeling_tf_hubert.TFHubertLayerNormConvLayer.__init__": 473
        },
        {
            "transformers.models.hubert.modeling_tf_hubert.TFHubertGroupNormConvLayer.__init__": 497
        },
        {
            "transformers.models.hubert.modeling_tf_hubert.TFHubertPositionalConvEmbedding.__init__": 521
        },
        {
            "transformers.models.hubert.modeling_tf_hubert.TFHubertSamePadLayer.__init__": 542
        },
        {
            "transformers.models.hubert.modeling_tf_hubert.TFHubertFeatureEncoder.__init__": 553
        },
        {
            "transformers.models.hubert.modeling_tf_hubert.TFHubertFeatureExtractor.__init__": 580
        },
        {
            "transformers.models.hubert.modeling_tf_hubert.TFHubertFeatureProjection.__init__": 591
        },
        {
            "transformers.models.hubert.modeling_tf_hubert.TFHubertAttention.__init__": 614
        },
        {
            "transformers.models.hubert.modeling_tf_hubert.TFHubertFeedForward.__init__": 766
        },
        {
            "transformers.models.hubert.modeling_tf_hubert.TFHubertEncoderLayer.__init__": 799
        },
        {
            "transformers.models.hubert.modeling_tf_hubert.TFHubertEncoderLayerStableLayerNorm.__init__": 843
        },
        {
            "transformers.models.hubert.modeling_tf_hubert.TFHubertEncoder.__init__": 885
        },
        {
            "transformers.models.hubert.modeling_tf_hubert.TFHubertEncoderStableLayerNorm.__init__": 951
        },
        {
            "transformers.models.hubert.modeling_tf_hubert.TFHubertMainLayer.__init__": 1021
        },
        {
            "transformers.models.hubert.modeling_tf_hubert.TFHubertMainLayer.call": 1099
        },
        {
            "transformers.models.hubert.modeling_tf_hubert.TFHubertPreTrainedModel.__init__": 1167
        },
        {
            "transformers.models.hubert.modeling_tf_hubert.TFHubertModel.__init__": 1278
        },
        {
            "transformers.models.hubert.modeling_tf_hubert.TFHubertForCTC.__init__": 1352
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/hubert/configuration_hubert.py": [
        {
            "transformers.models.hubert.configuration_hubert.HubertConfig.__init__": 162
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/mobilevitv2/configuration_mobilevitv2.py": [
        {
            "transformers.models.mobilevitv2.configuration_mobilevitv2.MobileViTV2Config.__init__": 102
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/mobilevitv2/modeling_mobilevitv2.py": [
        {
            "transformers.models.mobilevitv2.modeling_mobilevitv2.MobileViTV2Encoder.custom_forward": 587
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/switch_transformers/modeling_switch_transformers.py": [
        {
            "transformers.models.switch_transformers.modeling_switch_transformers.SwitchTransformersStack.custom_forward": 1073
        },
        {
            "transformers.models.switch_transformers.modeling_switch_transformers.SwitchTransformersForConditionalGeneration.prepare_inputs_for_generation": 1756
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/switch_transformers/configuration_switch_transformers.py": [
        {
            "transformers.models.switch_transformers.configuration_switch_transformers.SwitchTransformersConfig.__init__": 101
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/table_transformer/configuration_table_transformer.py": [
        {
            "transformers.models.table_transformer.configuration_table_transformer.TableTransformerConfig.__init__": 144
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/table_transformer/modeling_table_transformer.py": [
        {
            "transformers.models.table_transformer.modeling_table_transformer.TableTransformerDecoder.custom_forward": 1075
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/codegen/tokenization_codegen.py": [
        {
            "transformers.models.codegen.tokenization_codegen.CodeGenTokenizer.__init__": 153
        },
        {
            "transformers.models.codegen.tokenization_codegen.CodeGenTokenizer.prepare_for_tokenization": 313
        },
        {
            "transformers.models.codegen.tokenization_codegen.CodeGenTokenizer.decode": 319
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/codegen/modeling_codegen.py": [
        {
            "transformers.models.codegen.modeling_codegen.CodeGenPreTrainedModel.__init__": 320
        },
        {
            "transformers.models.codegen.modeling_codegen.CodeGenModel.custom_forward": 546
        },
        {
            "transformers.models.codegen.modeling_codegen.CodeGenForCausalLM.prepare_inputs_for_generation": 619
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/codegen/configuration_codegen.py": [
        {
            "transformers.models.codegen.configuration_codegen.CodeGenConfig.__init__": 107
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/codegen/tokenization_codegen_fast.py": [
        {
            "transformers.models.codegen.tokenization_codegen_fast.CodeGenTokenizerFast.__init__": 122
        },
        {
            "transformers.models.codegen.tokenization_codegen_fast.CodeGenTokenizerFast._batch_encode_plus": 163
        },
        {
            "transformers.models.codegen.tokenization_codegen_fast.CodeGenTokenizerFast._encode_plus": 172
        },
        {
            "transformers.models.codegen.tokenization_codegen_fast.CodeGenTokenizerFast.decode": 186
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/glpn/configuration_glpn.py": [
        {
            "transformers.models.glpn.configuration_glpn.GLPNConfig.__init__": 95
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/glpn/image_processing_glpn.py": [
        {
            "transformers.models.glpn.image_processing_glpn.GLPNImageProcessor.__init__": 58
        },
        {
            "transformers.models.glpn.image_processing_glpn.GLPNImageProcessor.resize": 72
        },
        {
            "transformers.models.glpn.image_processing_glpn.GLPNImageProcessor.rescale": 104
        },
        {
            "transformers.models.glpn.image_processing_glpn.GLPNImageProcessor.preprocess": 126
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/glpn/feature_extraction_glpn.py": [
        {
            "transformers.models.glpn.feature_extraction_glpn.GLPNFeatureExtractor.__init__": 27
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/clap/processing_clap.py": [
        {
            "transformers.models.clap.processing_clap.ClapProcessor.__call__": 42
        },
        {
            "transformers.models.clap.processing_clap.ClapProcessor.batch_decode": 98
        },
        {
            "transformers.models.clap.processing_clap.ClapProcessor.decode": 105
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/clap/feature_extraction_clap.py": [
        {
            "transformers.models.clap.feature_extraction_clap.ClapFeatureExtractor.__init__": 85
        },
        {
            "transformers.models.clap.feature_extraction_clap.ClapFeatureExtractor.__call__": 259
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/clap/configuration_clap.py": [
        {
            "transformers.models.clap.configuration_clap.ClapTextConfig.__init__": 107
        },
        {
            "transformers.models.clap.configuration_clap.ClapTextConfig.from_pretrained": 154
        },
        {
            "transformers.models.clap.configuration_clap.ClapAudioConfig.__init__": 260
        },
        {
            "transformers.models.clap.configuration_clap.ClapAudioConfig.from_pretrained": 322
        },
        {
            "transformers.models.clap.configuration_clap.ClapConfig.__init__": 391
        },
        {
            "transformers.models.clap.configuration_clap.ClapConfig.from_text_audio_configs": 428
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/clap/modeling_clap.py": [
        {
            "transformers.models.clap.modeling_clap.ClapAudioEncoder.custom_forward": 945
        },
        {
            "transformers.models.clap.modeling_clap.ClapTextEncoder.custom_forward": 1599
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/mega/modeling_mega.py": [
        {
            "transformers.models.mega.modeling_mega.MegaForCausalLM.prepare_inputs_for_generation": 1802
        },
        {
            "transformers.models.mega.modeling_mega.MegaClassificationHead.forward": 2197
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/mega/configuration_mega.py": [
        {
            "transformers.models.mega.configuration_mega.MegaConfig.__init__": 150
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/lxmert/tokenization_lxmert.py": [
        {
            "transformers.models.lxmert.tokenization_lxmert.LxmertTokenizer.__init__": 114
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/lxmert/modeling_tf_lxmert.py": [
        {
            "transformers.models.lxmert.modeling_tf_lxmert.TFLxmertVisualFeatureEncoder.__init__": 155
        },
        {
            "transformers.models.lxmert.modeling_tf_lxmert.TFLxmertEmbeddings.__init__": 194
        },
        {
            "transformers.models.lxmert.modeling_tf_lxmert.TFLxmertAttention.__init__": 257
        },
        {
            "transformers.models.lxmert.modeling_tf_lxmert.TFLxmertIntermediate.__init__": 333
        },
        {
            "transformers.models.lxmert.modeling_tf_lxmert.TFLxmertOutput.__init__": 352
        },
        {
            "transformers.models.lxmert.modeling_tf_lxmert.TFLxmertAttentionOutput.__init__": 371
        },
        {
            "transformers.models.lxmert.modeling_tf_lxmert.TFLxmertSelfAttentionLayer.__init__": 389
        },
        {
            "transformers.models.lxmert.modeling_tf_lxmert.TFLxmertCrossAttentionLayer.__init__": 404
        },
        {
            "transformers.models.lxmert.modeling_tf_lxmert.TFLxmertLayer.__init__": 426
        },
        {
            "transformers.models.lxmert.modeling_tf_lxmert.TFLxmertXLayer.__init__": 442
        },
        {
            "transformers.models.lxmert.modeling_tf_lxmert.TFLxmertEncoder.__init__": 547
        },
        {
            "transformers.models.lxmert.modeling_tf_lxmert.TFLxmertMainLayer.__init__": 639
        },
        {
            "transformers.models.lxmert.modeling_tf_lxmert.TFLxmertModel.__init__": 928
        },
        {
            "transformers.models.lxmert.modeling_tf_lxmert.TFLxmertPooler.__init__": 971
        },
        {
            "transformers.models.lxmert.modeling_tf_lxmert.TFLxmertPredictionHeadTransform.__init__": 990
        },
        {
            "transformers.models.lxmert.modeling_tf_lxmert.TFLxmertLMPredictionHead.__init__": 1016
        },
        {
            "transformers.models.lxmert.modeling_tf_lxmert.TFLxmertMLMHead.__init__": 1060
        },
        {
            "transformers.models.lxmert.modeling_tf_lxmert.TFLxmertPreTrainingHeads.__init__": 1072
        },
        {
            "transformers.models.lxmert.modeling_tf_lxmert.TFLxmertVisualAnswerHead.__init__": 1089
        },
        {
            "transformers.models.lxmert.modeling_tf_lxmert.TFLxmertVisualObjHead.__init__": 1115
        },
        {
            "transformers.models.lxmert.modeling_tf_lxmert.TFLxmertForPreTraining.__init__": 1150
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/lxmert/tokenization_lxmert_fast.py": [
        {
            "transformers.models.lxmert.tokenization_lxmert_fast.LxmertTokenizerFast.__init__": 94
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/lxmert/modeling_lxmert.py": [
        {
            "transformers.models.lxmert.modeling_lxmert.LxmertForPreTraining.forward": 1151
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/lxmert/configuration_lxmert.py": [
        {
            "transformers.models.lxmert.configuration_lxmert.LxmertConfig.__init__": 118
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/flaubert/modeling_tf_flaubert.py": [
        {
            "transformers.models.flaubert.modeling_tf_flaubert.TFFlaubertModel.__init__": 248
        },
        {
            "transformers.models.flaubert.modeling_tf_flaubert.TFFlaubertMultiHeadAttention.__init__": 298
        },
        {
            "transformers.models.flaubert.modeling_tf_flaubert.TFFlaubertTransformerFFN.__init__": 389
        },
        {
            "transformers.models.flaubert.modeling_tf_flaubert.TFFlaubertMainLayer.__init__": 410
        },
        {
            "transformers.models.flaubert.modeling_tf_flaubert.TFFlaubertPredLayer.__init__": 685
        },
        {
            "transformers.models.flaubert.modeling_tf_flaubert.TFFlaubertWithLMHeadModel.__init__": 765
        },
        {
            "transformers.models.flaubert.modeling_tf_flaubert.TFFlaubertWithLMHeadModel.prepare_inputs_for_generation": 779
        },
        {
            "transformers.models.flaubert.modeling_tf_flaubert.TFFlaubertForSequenceClassification.__init__": 851
        },
        {
            "transformers.models.flaubert.modeling_tf_flaubert.TFFlaubertForQuestionAnsweringSimple.__init__": 930
        },
        {
            "transformers.models.flaubert.modeling_tf_flaubert.TFFlaubertForTokenClassification.__init__": 1022
        },
        {
            "transformers.models.flaubert.modeling_tf_flaubert.TFFlaubertForMultipleChoice.__init__": 1103
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/flaubert/modeling_flaubert.py": [
        {
            "transformers.models.flaubert.modeling_flaubert.FlaubertPreTrainedModel.__init__": 351
        },
        {
            "transformers.models.flaubert.modeling_flaubert.FlaubertWithLMHeadModel.prepare_inputs_for_generation": 673
        },
        {
            "transformers.models.flaubert.modeling_flaubert.FlaubertForMultipleChoice.__init__": 1214
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/flaubert/configuration_flaubert.py": [
        {
            "transformers.models.flaubert.configuration_flaubert.FlaubertConfig.__init__": 146
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/flaubert/tokenization_flaubert.py": [
        {
            "transformers.models.flaubert.tokenization_flaubert.FlaubertTokenizer.__init__": 223
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/unispeech_sat/modeling_unispeech_sat.py": [
        {
            "transformers.models.unispeech_sat.modeling_unispeech_sat.UniSpeechSatFeatureEncoder.custom_forward": 403
        },
        {
            "transformers.models.unispeech_sat.modeling_unispeech_sat.UniSpeechSatEncoder.custom_forward": 786
        },
        {
            "transformers.models.unispeech_sat.modeling_unispeech_sat.UniSpeechSatEncoderStableLayerNorm.custom_forward": 876
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/unispeech_sat/configuration_unispeech_sat.py": [
        {
            "transformers.models.unispeech_sat.configuration_unispeech_sat.UniSpeechSatConfig.__init__": 193
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/wav2vec2_with_lm/processing_wav2vec2_with_lm.py": [
        {
            "transformers.models.wav2vec2_with_lm.processing_wav2vec2_with_lm.Wav2Vec2ProcessorWithLM.from_pretrained": 113
        },
        {
            "transformers.models.wav2vec2_with_lm.processing_wav2vec2_with_lm.Wav2Vec2ProcessorWithLM.__call__": 214
        },
        {
            "transformers.models.wav2vec2_with_lm.processing_wav2vec2_with_lm.Wav2Vec2ProcessorWithLM.pad": 253
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/xlm_prophetnet/tokenization_xlm_prophetnet.py": [
        {
            "transformers.models.xlm_prophetnet.tokenization_xlm_prophetnet.XLMProphetNetTokenizer.__init__": 133
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/xlm_prophetnet/modeling_xlm_prophetnet.py": [
        {
            "transformers.models.xlm_prophetnet.modeling_xlm_prophetnet.XLMProphetNetEncoder.custom_forward": 1354
        },
        {
            "transformers.models.xlm_prophetnet.modeling_xlm_prophetnet.XLMProphetNetDecoder.custom_forward": 1597
        },
        {
            "transformers.models.xlm_prophetnet.modeling_xlm_prophetnet.XLMProphetNetForConditionalGeneration.prepare_inputs_for_generation": 2063
        },
        {
            "transformers.models.xlm_prophetnet.modeling_xlm_prophetnet.XLMProphetNetForCausalLM.prepare_inputs_for_generation": 2318
        },
        {
            "transformers.models.xlm_prophetnet.modeling_xlm_prophetnet.XLMProphetNetDecoderWrapper.forward": 2362
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/xlm_prophetnet/configuration_xlm_prophetnet.py": [
        {
            "transformers.models.xlm_prophetnet.configuration_xlm_prophetnet.XLMProphetNetConfig.__init__": 109
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/vit/modeling_tf_vit.py": [
        {
            "transformers.models.vit.modeling_tf_vit.TFViTEmbeddings.__init__": 62
        },
        {
            "transformers.models.vit.modeling_tf_vit.TFViTPatchEmbeddings.__init__": 152
        },
        {
            "transformers.models.vit.modeling_tf_vit.TFViTSelfAttention.__init__": 210
        },
        {
            "transformers.models.vit.modeling_tf_vit.TFViTSelfOutput.__init__": 290
        },
        {
            "transformers.models.vit.modeling_tf_vit.TFViTAttention.__init__": 306
        },
        {
            "transformers.models.vit.modeling_tf_vit.TFViTIntermediate.__init__": 334
        },
        {
            "transformers.models.vit.modeling_tf_vit.TFViTOutput.__init__": 354
        },
        {
            "transformers.models.vit.modeling_tf_vit.TFViTLayer.__init__": 373
        },
        {
            "transformers.models.vit.modeling_tf_vit.TFViTEncoder.__init__": 421
        },
        {
            "transformers.models.vit.modeling_tf_vit.TFViTMainLayer.__init__": 469
        },
        {
            "transformers.models.vit.modeling_tf_vit.TFViTModel.__init__": 632
        },
        {
            "transformers.models.vit.modeling_tf_vit.TFViTPooler.__init__": 670
        },
        {
            "transformers.models.vit.modeling_tf_vit.TFViTForImageClassification.__init__": 705
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/vit/modeling_vit.py": [
        {
            "transformers.models.vit.modeling_vit.ViTEncoder.custom_forward": 402
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/vit/image_processing_vit.py": [
        {
            "transformers.models.vit.image_processing_vit.ViTImageProcessor.__init__": 72
        },
        {
            "transformers.models.vit.image_processing_vit.ViTImageProcessor.resize": 96
        },
        {
            "transformers.models.vit.image_processing_vit.ViTImageProcessor.rescale": 130
        },
        {
            "transformers.models.vit.image_processing_vit.ViTImageProcessor.normalize": 152
        },
        {
            "transformers.models.vit.image_processing_vit.ViTImageProcessor.preprocess": 181
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/vit/configuration_vit.py": [
        {
            "transformers.models.vit.configuration_vit.ViTConfig.__init__": 93
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/vit/modeling_flax_vit.py": [
        {
            "transformers.models.vit.modeling_flax_vit.FlaxViTPreTrainedModel.__init__": 438
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/vit/feature_extraction_vit.py": [
        {
            "transformers.models.vit.feature_extraction_vit.ViTFeatureExtractor.__init__": 27
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/megatron_bert/configuration_megatron_bert.py": [
        {
            "transformers.models.megatron_bert.configuration_megatron_bert.MegatronBertConfig.__init__": 95
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/megatron_bert/modeling_megatron_bert.py": [
        {
            "transformers.models.megatron_bert.modeling_megatron_bert.MegatronBertEncoder.custom_forward": 554
        },
        {
            "transformers.models.megatron_bert.modeling_megatron_bert.MegatronBertForCausalLM.prepare_inputs_for_generation": 1247
        },
        {
            "transformers.models.megatron_bert.modeling_megatron_bert.MegatronBertForMaskedLM.prepare_inputs_for_generation": 1355
        },
        {
            "transformers.models.megatron_bert.modeling_megatron_bert.MegatronBertForNextSentencePrediction.forward": 1389
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/rembert/tokenization_rembert_fast.py": [
        {
            "transformers.models.rembert.tokenization_rembert_fast.RemBertTokenizerFast.__init__": 103
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/rembert/tokenization_rembert.py": [
        {
            "transformers.models.rembert.tokenization_rembert.RemBertTokenizer.__init__": 99
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/rembert/configuration_rembert.py": [
        {
            "transformers.models.rembert.configuration_rembert.RemBertConfig.__init__": 101
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/rembert/modeling_rembert.py": [
        {
            "transformers.models.rembert.modeling_rembert.RemBertEncoder.custom_forward": 546
        },
        {
            "transformers.models.rembert.modeling_rembert.RemBertForMaskedLM.prepare_inputs_for_generation": 998
        },
        {
            "transformers.models.rembert.modeling_rembert.RemBertForCausalLM.prepare_inputs_for_generation": 1139
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/rembert/modeling_tf_rembert.py": [
        {
            "transformers.models.rembert.modeling_tf_rembert.TFRemBertEmbeddings.__init__": 73
        },
        {
            "transformers.models.rembert.modeling_tf_rembert.TFRemBertSelfAttention.__init__": 149
        },
        {
            "transformers.models.rembert.modeling_tf_rembert.TFRemBertSelfOutput.__init__": 267
        },
        {
            "transformers.models.rembert.modeling_tf_rembert.TFRemBertAttention.__init__": 286
        },
        {
            "transformers.models.rembert.modeling_tf_rembert.TFRemBertIntermediate.__init__": 327
        },
        {
            "transformers.models.rembert.modeling_tf_rembert.TFRemBertOutput.__init__": 348
        },
        {
            "transformers.models.rembert.modeling_tf_rembert.TFRemBertLayer.__init__": 367
        },
        {
            "transformers.models.rembert.modeling_tf_rembert.TFRemBertEncoder.__init__": 453
        },
        {
            "transformers.models.rembert.modeling_tf_rembert.TFRemBertPooler.__init__": 530
        },
        {
            "transformers.models.rembert.modeling_tf_rembert.TFRemBertLMPredictionHead.__init__": 550
        },
        {
            "transformers.models.rembert.modeling_tf_rembert.TFRemBertMLMHead.__init__": 605
        },
        {
            "transformers.models.rembert.modeling_tf_rembert.TFRemBertMainLayer.__init__": 620
        },
        {
            "transformers.models.rembert.modeling_tf_rembert.TFRemBertModel.__init__": 917
        },
        {
            "transformers.models.rembert.modeling_tf_rembert.TFRemBertForMaskedLM.__init__": 988
        },
        {
            "transformers.models.rembert.modeling_tf_rembert.TFRemBertForCausalLM.__init__": 1062
        },
        {
            "transformers.models.rembert.modeling_tf_rembert.TFRemBertForCausalLM.prepare_inputs_for_generation": 1075
        },
        {
            "transformers.models.rembert.modeling_tf_rembert.TFRemBertForSequenceClassification.__init__": 1181
        },
        {
            "transformers.models.rembert.modeling_tf_rembert.TFRemBertForMultipleChoice.__init__": 1258
        },
        {
            "transformers.models.rembert.modeling_tf_rembert.TFRemBertForTokenClassification.__init__": 1354
        },
        {
            "transformers.models.rembert.modeling_tf_rembert.TFRemBertForQuestionAnswering.__init__": 1427
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/roc_bert/tokenization_roc_bert.py": [
        {
            "transformers.models.roc_bert.tokenization_roc_bert.RoCBertTokenizer.__init__": 142
        },
        {
            "transformers.models.roc_bert.tokenization_roc_bert.RoCBertTokenizer._encode_plus": 226
        },
        {
            "transformers.models.roc_bert.tokenization_roc_bert.RoCBertTokenizer.prepare_for_model": 321
        },
        {
            "transformers.models.roc_bert.tokenization_roc_bert.RoCBertTokenizer._batch_encode_plus": 561
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/roc_bert/configuration_roc_bert.py": [
        {
            "transformers.models.roc_bert.configuration_roc_bert.RoCBertConfig.__init__": 114
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/roc_bert/modeling_roc_bert.py": [
        {
            "transformers.models.roc_bert.modeling_roc_bert.RoCBertEncoder.custom_forward": 647
        },
        {
            "transformers.models.roc_bert.modeling_roc_bert.RoCBertForPreTraining.forward": 1105
        },
        {
            "transformers.models.roc_bert.modeling_roc_bert.RoCBertForMaskedLM.prepare_inputs_for_generation": 1378
        },
        {
            "transformers.models.roc_bert.modeling_roc_bert.RoCBertForCausalLM.prepare_inputs_for_generation": 1548
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/nystromformer/modeling_nystromformer.py": [
        {
            "transformers.models.nystromformer.modeling_nystromformer.NystromformerEncoder.custom_forward": 373
        },
        {
            "transformers.models.nystromformer.modeling_nystromformer.NystromformerClassificationHead.forward": 748
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/nystromformer/configuration_nystromformer.py": [
        {
            "transformers.models.nystromformer.configuration_nystromformer.NystromformerConfig.__init__": 94
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/bloom/configuration_bloom.py": [
        {
            "transformers.models.bloom.configuration_bloom.BloomConfig.__init__": 113
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/bloom/tokenization_bloom_fast.py": [
        {
            "transformers.models.bloom.tokenization_bloom_fast.BloomTokenizerFast.__init__": 108
        },
        {
            "transformers.models.bloom.tokenization_bloom_fast.BloomTokenizerFast._batch_encode_plus": 141
        },
        {
            "transformers.models.bloom.tokenization_bloom_fast.BloomTokenizerFast._encode_plus": 151
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/bloom/modeling_bloom.py": [
        {
            "transformers.models.bloom.modeling_bloom.BloomPreTrainedModel.__init__": 486
        },
        {
            "transformers.models.bloom.modeling_bloom.BloomModel.forward": 682
        },
        {
            "transformers.models.bloom.modeling_bloom.BloomModel.custom_forward": 772
        },
        {
            "transformers.models.bloom.modeling_bloom.BloomForCausalLM.prepare_inputs_for_generation": 845
        },
        {
            "transformers.models.bloom.modeling_bloom.BloomForCausalLM.forward": 882
        },
        {
            "transformers.models.bloom.modeling_bloom.BloomForSequenceClassification.forward": 1014
        },
        {
            "transformers.models.bloom.modeling_bloom.BloomForTokenClassification.forward": 1150
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/vilt/processing_vilt.py": [
        {
            "transformers.models.vilt.processing_vilt.ViltProcessor.__init__": 44
        },
        {
            "transformers.models.vilt.processing_vilt.ViltProcessor.__call__": 62
        },
        {
            "transformers.models.vilt.processing_vilt.ViltProcessor.batch_decode": 112
        },
        {
            "transformers.models.vilt.processing_vilt.ViltProcessor.decode": 119
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/vilt/configuration_vilt.py": [
        {
            "transformers.models.vilt.configuration_vilt.ViltConfig.__init__": 101
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/vilt/image_processing_vilt.py": [
        {
            "transformers.models.vilt.image_processing_vilt.ViltImageProcessor.__init__": 153
        },
        {
            "transformers.models.vilt.image_processing_vilt.ViltImageProcessor.from_dict": 186
        },
        {
            "transformers.models.vilt.image_processing_vilt.ViltImageProcessor.resize": 197
        },
        {
            "transformers.models.vilt.image_processing_vilt.ViltImageProcessor.rescale": 233
        },
        {
            "transformers.models.vilt.image_processing_vilt.ViltImageProcessor.normalize": 253
        },
        {
            "transformers.models.vilt.image_processing_vilt.ViltImageProcessor.preprocess": 369
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/vilt/feature_extraction_vilt.py": [
        {
            "transformers.models.vilt.feature_extraction_vilt.ViltFeatureExtractor.__init__": 27
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/vilt/modeling_vilt.py": [
        {
            "transformers.models.vilt.modeling_vilt.ViltEncoder.custom_forward": 541
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/gptj/modeling_gptj.py": [
        {
            "transformers.models.gptj.modeling_gptj.GPTJPreTrainedModel.__init__": 345
        },
        {
            "transformers.models.gptj.modeling_gptj.GPTJModel.custom_forward": 674
        },
        {
            "transformers.models.gptj.modeling_gptj.GPTJForCausalLM.prepare_inputs_for_generation": 788
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/gptj/modeling_flax_gptj.py": [
        {
            "transformers.models.gptj.modeling_flax_gptj.FlaxGPTJPreTrainedModel.__init__": 368
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/gptj/modeling_tf_gptj.py": [
        {
            "transformers.models.gptj.modeling_tf_gptj.TFGPTJAttention.__init__": 86
        },
        {
            "transformers.models.gptj.modeling_tf_gptj.TFGPTJMLP.__init__": 272
        },
        {
            "transformers.models.gptj.modeling_tf_gptj.TFGPTJBlock.__init__": 295
        },
        {
            "transformers.models.gptj.modeling_tf_gptj.TFGPTJMainLayer.__init__": 340
        },
        {
            "transformers.models.gptj.modeling_tf_gptj.TFGPTJModel.__init__": 626
        },
        {
            "transformers.models.gptj.modeling_tf_gptj.TFGPTJForCausalLM.__init__": 683
        },
        {
            "transformers.models.gptj.modeling_tf_gptj.TFGPTJForCausalLM.prepare_inputs_for_generation": 696
        },
        {
            "transformers.models.gptj.modeling_tf_gptj.TFGPTJForSequenceClassification.__init__": 806
        },
        {
            "transformers.models.gptj.modeling_tf_gptj.TFGPTJForQuestionAnswering.__init__": 922
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/gptj/configuration_gptj.py": [
        {
            "transformers.models.gptj.configuration_gptj.GPTJConfig.__init__": 96
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/xlnet/modeling_tf_xlnet.py": [
        {
            "transformers.models.xlnet.modeling_tf_xlnet.TFXLNetRelativeAttention.__init__": 70
        },
        {
            "transformers.models.xlnet.modeling_tf_xlnet.TFXLNetFeedForward.__init__": 333
        },
        {
            "transformers.models.xlnet.modeling_tf_xlnet.TFXLNetLayer.__init__": 360
        },
        {
            "transformers.models.xlnet.modeling_tf_xlnet.TFXLNetLMHead.__init__": 404
        },
        {
            "transformers.models.xlnet.modeling_tf_xlnet.TFXLNetMainLayer.__init__": 439
        },
        {
            "transformers.models.xlnet.modeling_tf_xlnet.TFXLNetModel.__init__": 1133
        },
        {
            "transformers.models.xlnet.modeling_tf_xlnet.TFXLNetLMHeadModel.__init__": 1188
        },
        {
            "transformers.models.xlnet.modeling_tf_xlnet.TFXLNetLMHeadModel.prepare_inputs_for_generation": 1202
        },
        {
            "transformers.models.xlnet.modeling_tf_xlnet.TFXLNetForSequenceClassification.__init__": 1348
        },
        {
            "transformers.models.xlnet.modeling_tf_xlnet.TFXLNetForMultipleChoice.__init__": 1435
        },
        {
            "transformers.models.xlnet.modeling_tf_xlnet.TFXLNetForTokenClassification.__init__": 1536
        },
        {
            "transformers.models.xlnet.modeling_tf_xlnet.TFXLNetForQuestionAnsweringSimple.__init__": 1616
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/xlnet/tokenization_xlnet_fast.py": [
        {
            "transformers.models.xlnet.tokenization_xlnet_fast.XLNetTokenizerFast.__init__": 130
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/xlnet/configuration_xlnet.py": [
        {
            "transformers.models.xlnet.configuration_xlnet.XLNetConfig.__init__": 150
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/xlnet/tokenization_xlnet.py": [
        {
            "transformers.models.xlnet.tokenization_xlnet.XLNetTokenizer.__init__": 133
        },
        {
            "transformers.models.xlnet.tokenization_xlnet.XLNetTokenizer._decode": 253
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/xlnet/modeling_xlnet.py": [
        {
            "transformers.models.xlnet.modeling_xlnet.XLNetModel.forward": 1065
        },
        {
            "transformers.models.xlnet.modeling_xlnet.XLNetLMHeadModel.prepare_inputs_for_generation": 1314
        },
        {
            "transformers.models.xlnet.modeling_xlnet.XLNetLMHeadModel.forward": 1358
        },
        {
            "transformers.models.xlnet.modeling_xlnet.XLNetForSequenceClassification.forward": 1519
        },
        {
            "transformers.models.xlnet.modeling_xlnet.XLNetForTokenClassification.forward": 1626
        },
        {
            "transformers.models.xlnet.modeling_xlnet.XLNetForMultipleChoice.forward": 1713
        },
        {
            "transformers.models.xlnet.modeling_xlnet.XLNetForQuestionAnsweringSimple.forward": 1816
        },
        {
            "transformers.models.xlnet.modeling_xlnet.XLNetForQuestionAnswering.forward": 1925
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/fsmt/modeling_fsmt.py": [
        {
            "transformers.models.fsmt.modeling_fsmt.FSMTForConditionalGeneration.prepare_inputs_for_generation": 1269
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/fsmt/configuration_fsmt.py": [
        {
            "transformers.models.fsmt.configuration_fsmt.FSMTConfig.__init__": 141
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/fsmt/tokenization_fsmt.py": [
        {
            "transformers.models.fsmt.tokenization_fsmt.FSMTTokenizer.__init__": 187
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/gpt_neo/configuration_gpt_neo.py": [
        {
            "transformers.models.gpt_neo.configuration_gpt_neo.GPTNeoConfig.__init__": 104
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/gpt_neo/modeling_flax_gpt_neo.py": [
        {
            "transformers.models.gpt_neo.modeling_flax_gpt_neo.FlaxGPTNeoPreTrainedModel.__init__": 350
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/gpt_neo/modeling_gpt_neo.py": [
        {
            "transformers.models.gpt_neo.modeling_gpt_neo.GPTNeoPreTrainedModel.__init__": 368
        },
        {
            "transformers.models.gpt_neo.modeling_gpt_neo.GPTNeoModel.custom_forward": 610
        },
        {
            "transformers.models.gpt_neo.modeling_gpt_neo.GPTNeoForCausalLM.prepare_inputs_for_generation": 687
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/owlvit/feature_extraction_owlvit.py": [
        {
            "transformers.models.owlvit.feature_extraction_owlvit.OwlViTFeatureExtractor.__init__": 27
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/owlvit/modeling_owlvit.py": [
        {
            "transformers.models.owlvit.modeling_owlvit.OwlViTEncoder.custom_forward": 752
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/owlvit/image_processing_owlvit.py": [
        {
            "transformers.models.owlvit.image_processing_owlvit.OwlViTImageProcessor.__init__": 129
        },
        {
            "transformers.models.owlvit.image_processing_owlvit.OwlViTImageProcessor.resize": 168
        },
        {
            "transformers.models.owlvit.image_processing_owlvit.OwlViTImageProcessor.center_crop": 185
        },
        {
            "transformers.models.owlvit.image_processing_owlvit.OwlViTImageProcessor.rescale": 201
        },
        {
            "transformers.models.owlvit.image_processing_owlvit.OwlViTImageProcessor.normalize": 213
        },
        {
            "transformers.models.owlvit.image_processing_owlvit.OwlViTImageProcessor.preprocess": 226
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/owlvit/configuration_owlvit.py": [
        {
            "transformers.models.owlvit.configuration_owlvit.OwlViTTextConfig.__init__": 96
        },
        {
            "transformers.models.owlvit.configuration_owlvit.OwlViTTextConfig.from_pretrained": 129
        },
        {
            "transformers.models.owlvit.configuration_owlvit.OwlViTVisionConfig.__init__": 200
        },
        {
            "transformers.models.owlvit.configuration_owlvit.OwlViTVisionConfig.from_pretrained": 232
        },
        {
            "transformers.models.owlvit.configuration_owlvit.OwlViTConfig.__init__": 275
        },
        {
            "transformers.models.owlvit.configuration_owlvit.OwlViTConfig.from_pretrained": 303
        },
        {
            "transformers.models.owlvit.configuration_owlvit.OwlViTConfig.from_text_vision_configs": 315
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/owlvit/processing_owlvit.py": [
        {
            "transformers.models.owlvit.processing_owlvit.OwlViTProcessor.__init__": 45
        },
        {
            "transformers.models.owlvit.processing_owlvit.OwlViTProcessor.__call__": 62
        },
        {
            "transformers.models.owlvit.processing_owlvit.OwlViTProcessor.post_process": 174
        },
        {
            "transformers.models.owlvit.processing_owlvit.OwlViTProcessor.post_process_object_detection": 181
        },
        {
            "transformers.models.owlvit.processing_owlvit.OwlViTProcessor.post_process_image_guided_detection": 188
        },
        {
            "transformers.models.owlvit.processing_owlvit.OwlViTProcessor.batch_decode": 195
        },
        {
            "transformers.models.owlvit.processing_owlvit.OwlViTProcessor.decode": 202
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/blip_2/processing_blip_2.py": [
        {
            "transformers.models.blip_2.processing_blip_2.Blip2Processor.__call__": 50
        },
        {
            "transformers.models.blip_2.processing_blip_2.Blip2Processor.batch_decode": 133
        },
        {
            "transformers.models.blip_2.processing_blip_2.Blip2Processor.decode": 141
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/blip_2/configuration_blip_2.py": [
        {
            "transformers.models.blip_2.configuration_blip_2.Blip2VisionConfig.__init__": 90
        },
        {
            "transformers.models.blip_2.configuration_blip_2.Blip2VisionConfig.from_pretrained": 128
        },
        {
            "transformers.models.blip_2.configuration_blip_2.Blip2QFormerConfig.__init__": 209
        },
        {
            "transformers.models.blip_2.configuration_blip_2.Blip2QFormerConfig.from_pretrained": 248
        },
        {
            "transformers.models.blip_2.configuration_blip_2.Blip2Config.__init__": 320
        },
        {
            "transformers.models.blip_2.configuration_blip_2.Blip2Config.from_vision_qformer_text_configs": 350
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/blip_2/modeling_blip_2.py": [
        {
            "transformers.models.blip_2.modeling_blip_2.Blip2Encoder.custom_forward": 490
        },
        {
            "transformers.models.blip_2.modeling_blip_2.Blip2QFormerEncoder.custom_forward": 961
        },
        {
            "transformers.models.blip_2.modeling_blip_2.Blip2ForConditionalGeneration.generate": 1799
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/altclip/configuration_altclip.py": [
        {
            "transformers.models.altclip.configuration_altclip.AltCLIPTextConfig.__init__": 99
        },
        {
            "transformers.models.altclip.configuration_altclip.AltCLIPVisionConfig.__init__": 196
        },
        {
            "transformers.models.altclip.configuration_altclip.AltCLIPVisionConfig.from_pretrained": 230
        },
        {
            "transformers.models.altclip.configuration_altclip.AltCLIPConfig.__init__": 294
        },
        {
            "transformers.models.altclip.configuration_altclip.AltCLIPConfig.from_text_vision_configs": 383
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/altclip/processing_altclip.py": [
        {
            "transformers.models.altclip.processing_altclip.AltCLIPProcessor.__init__": 42
        },
        {
            "transformers.models.altclip.processing_altclip.AltCLIPProcessor.__call__": 59
        },
        {
            "transformers.models.altclip.processing_altclip.AltCLIPProcessor.batch_decode": 112
        },
        {
            "transformers.models.altclip.processing_altclip.AltCLIPProcessor.decode": 119
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/altclip/modeling_altclip.py": [
        {
            "transformers.models.altclip.modeling_altclip.AltRobertaEncoder.custom_forward": 649
        },
        {
            "transformers.models.altclip.modeling_altclip.AltCLIPEncoder.custom_forward": 963
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/mctct/modeling_mctct.py": [
        {
            "transformers.models.mctct.modeling_mctct.MCTCTEncoder.custom_forward": 621
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/mctct/feature_extraction_mctct.py": [
        {
            "transformers.models.mctct.feature_extraction_mctct.MCTCTFeatureExtractor.__init__": 71
        },
        {
            "transformers.models.mctct.feature_extraction_mctct.MCTCTFeatureExtractor.__call__": 164
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/mctct/processing_mctct.py": [
        {
            "transformers.models.mctct.processing_mctct.MCTCTProcessor.__call__": 45
        },
        {
            "transformers.models.mctct.processing_mctct.MCTCTProcessor.batch_decode": 83
        },
        {
            "transformers.models.mctct.processing_mctct.MCTCTProcessor.pad": 90
        },
        {
            "transformers.models.mctct.processing_mctct.MCTCTProcessor.decode": 120
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/mctct/configuration_mctct.py": [
        {
            "transformers.models.mctct.configuration_mctct.MCTCTConfig.__init__": 119
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/bartpho/tokenization_bartpho.py": [
        {
            "transformers.models.bartpho.tokenization_bartpho.BartphoTokenizer.__init__": 123
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/longformer/tokenization_longformer_fast.py": [
        {
            "transformers.models.longformer.tokenization_longformer_fast.LongformerTokenizerFast.__init__": 178
        },
        {
            "transformers.models.longformer.tokenization_longformer_fast.LongformerTokenizerFast._batch_encode_plus": 273
        },
        {
            "transformers.models.longformer.tokenization_longformer_fast.LongformerTokenizerFast._encode_plus": 282
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/longformer/modeling_tf_longformer.py": [
        {
            "transformers.models.longformer.modeling_tf_longformer.TFLongformerLMHead.__init__": 422
        },
        {
            "transformers.models.longformer.modeling_tf_longformer.TFLongformerEmbeddings.__init__": 476
        },
        {
            "transformers.models.longformer.modeling_tf_longformer.TFLongformerIntermediate.__init__": 574
        },
        {
            "transformers.models.longformer.modeling_tf_longformer.TFLongformerOutput.__init__": 595
        },
        {
            "transformers.models.longformer.modeling_tf_longformer.TFLongformerPooler.__init__": 614
        },
        {
            "transformers.models.longformer.modeling_tf_longformer.TFLongformerSelfOutput.__init__": 635
        },
        {
            "transformers.models.longformer.modeling_tf_longformer.TFLongformerSelfAttention.__init__": 653
        },
        {
            "transformers.models.longformer.modeling_tf_longformer.TFLongformerAttention.__init__": 1499
        },
        {
            "transformers.models.longformer.modeling_tf_longformer.TFLongformerLayer.__init__": 1529
        },
        {
            "transformers.models.longformer.modeling_tf_longformer.TFLongformerEncoder.__init__": 1559
        },
        {
            "transformers.models.longformer.modeling_tf_longformer.TFLongformerMainLayer.__init__": 1640
        },
        {
            "transformers.models.longformer.modeling_tf_longformer.TFLongformerModel.__init__": 2016
        },
        {
            "transformers.models.longformer.modeling_tf_longformer.TFLongformerForMaskedLM.__init__": 2062
        },
        {
            "transformers.models.longformer.modeling_tf_longformer.TFLongformerForQuestionAnswering.__init__": 2149
        },
        {
            "transformers.models.longformer.modeling_tf_longformer.TFLongformerClassificationHead.__init__": 2271
        },
        {
            "transformers.models.longformer.modeling_tf_longformer.TFLongformerForSequenceClassification.__init__": 2304
        },
        {
            "transformers.models.longformer.modeling_tf_longformer.TFLongformerForMultipleChoice.__init__": 2407
        },
        {
            "transformers.models.longformer.modeling_tf_longformer.TFLongformerForTokenClassification.__init__": 2522
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/longformer/configuration_longformer.py": [
        {
            "transformers.models.longformer.configuration_longformer.LongformerConfig.__init__": 109
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/longformer/modeling_longformer.py": [
        {
            "transformers.models.longformer.modeling_longformer.LongformerEncoder.custom_forward": 1309
        },
        {
            "transformers.models.longformer.modeling_longformer.LongformerLMHead.forward": 1396
        },
        {
            "transformers.models.longformer.modeling_longformer.LongformerClassificationHead.forward": 1999
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/longformer/tokenization_longformer.py": [
        {
            "transformers.models.longformer.tokenization_longformer.LongformerTokenizer.__init__": 199
        },
        {
            "transformers.models.longformer.tokenization_longformer.LongformerTokenizer.prepare_for_tokenization": 430
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/llama/configuration_llama.py": [
        {
            "transformers.models.llama.configuration_llama.LlamaConfig.__init__": 84
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/llama/modeling_llama.py": [
        {
            "transformers.models.llama.modeling_llama.LlamaModel.custom_forward": 564
        },
        {
            "transformers.models.llama.modeling_llama.LlamaForCausalLM.prepare_inputs_for_generation": 728
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/llama/tokenization_llama.py": [
        {
            "transformers.models.llama.tokenization_llama.LlamaTokenizer.__init__": 63
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/llama/tokenization_llama_fast.py": [
        {
            "transformers.models.llama.tokenization_llama_fast.LlamaTokenizerFast.__init__": 81
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/layoutlm/modeling_tf_layoutlm.py": [
        {
            "transformers.models.layoutlm.modeling_tf_layoutlm.TFLayoutLMEmbeddings.__init__": 65
        },
        {
            "transformers.models.layoutlm.modeling_tf_layoutlm.TFLayoutLMSelfAttention.__init__": 193
        },
        {
            "transformers.models.layoutlm.modeling_tf_layoutlm.TFLayoutLMSelfOutput.__init__": 311
        },
        {
            "transformers.models.layoutlm.modeling_tf_layoutlm.TFLayoutLMAttention.__init__": 330
        },
        {
            "transformers.models.layoutlm.modeling_tf_layoutlm.TFLayoutLMIntermediate.__init__": 371
        },
        {
            "transformers.models.layoutlm.modeling_tf_layoutlm.TFLayoutLMOutput.__init__": 392
        },
        {
            "transformers.models.layoutlm.modeling_tf_layoutlm.TFLayoutLMLayer.__init__": 411
        },
        {
            "transformers.models.layoutlm.modeling_tf_layoutlm.TFLayoutLMEncoder.__init__": 498
        },
        {
            "transformers.models.layoutlm.modeling_tf_layoutlm.TFLayoutLMPooler.__init__": 568
        },
        {
            "transformers.models.layoutlm.modeling_tf_layoutlm.TFLayoutLMPredictionHeadTransform.__init__": 589
        },
        {
            "transformers.models.layoutlm.modeling_tf_layoutlm.TFLayoutLMLMPredictionHead.__init__": 615
        },
        {
            "transformers.models.layoutlm.modeling_tf_layoutlm.TFLayoutLMMLMHead.__init__": 659
        },
        {
            "transformers.models.layoutlm.modeling_tf_layoutlm.TFLayoutLMMainLayer.__init__": 674
        },
        {
            "transformers.models.layoutlm.modeling_tf_layoutlm.TFLayoutLMModel.__init__": 913
        },
        {
            "transformers.models.layoutlm.modeling_tf_layoutlm.TFLayoutLMForMaskedLM.__init__": 1000
        },
        {
            "transformers.models.layoutlm.modeling_tf_layoutlm.TFLayoutLMForSequenceClassification.__init__": 1123
        },
        {
            "transformers.models.layoutlm.modeling_tf_layoutlm.TFLayoutLMForTokenClassification.__init__": 1247
        },
        {
            "transformers.models.layoutlm.modeling_tf_layoutlm.TFLayoutLMForQuestionAnswering.__init__": 1369
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/layoutlm/configuration_layoutlm.py": [
        {
            "transformers.models.layoutlm.configuration_layoutlm.LayoutLMConfig.__init__": 108
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/layoutlm/modeling_layoutlm.py": [
        {
            "transformers.models.layoutlm.modeling_layoutlm.LayoutLMEncoder.custom_forward": 490
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/layoutlm/tokenization_layoutlm.py": [
        {
            "transformers.models.layoutlm.tokenization_layoutlm.LayoutLMTokenizer.__init__": 122
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/layoutlm/tokenization_layoutlm_fast.py": [
        {
            "transformers.models.layoutlm.tokenization_layoutlm_fast.LayoutLMTokenizerFast.__init__": 108
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/ernie/modeling_ernie.py": [
        {
            "transformers.models.ernie.modeling_ernie.ErnieEncoder.custom_forward": 509
        },
        {
            "transformers.models.ernie.modeling_ernie.ErnieForCausalLM.prepare_inputs_for_generation": 1215
        },
        {
            "transformers.models.ernie.modeling_ernie.ErnieForMaskedLM.prepare_inputs_for_generation": 1339
        },
        {
            "transformers.models.ernie.modeling_ernie.ErnieForNextSentencePrediction.forward": 1373
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/ernie/configuration_ernie.py": [
        {
            "transformers.models.ernie.configuration_ernie.ErnieConfig.__init__": 114
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/conditional_detr/image_processing_conditional_detr.py": [
        {
            "transformers.models.conditional_detr.image_processing_conditional_detr.ConditionalDetrImageProcessor.__init__": 782
        },
        {
            "transformers.models.conditional_detr.image_processing_conditional_detr.ConditionalDetrImageProcessor.from_dict": 834
        },
        {
            "transformers.models.conditional_detr.image_processing_conditional_detr.ConditionalDetrImageProcessor.convert_coco_poly_to_mask": 884
        },
        {
            "transformers.models.conditional_detr.image_processing_conditional_detr.ConditionalDetrImageProcessor.prepare_coco_detection": 891
        },
        {
            "transformers.models.conditional_detr.image_processing_conditional_detr.ConditionalDetrImageProcessor.prepare_coco_panoptic": 898
        },
        {
            "transformers.models.conditional_detr.image_processing_conditional_detr.ConditionalDetrImageProcessor.resize": 905
        },
        {
            "transformers.models.conditional_detr.image_processing_conditional_detr.ConditionalDetrImageProcessor.preprocess": 1078
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/conditional_detr/configuration_conditional_detr.py": [
        {
            "transformers.models.conditional_detr.configuration_conditional_detr.ConditionalDetrConfig.__init__": 145
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/conditional_detr/feature_extraction_conditional_detr.py": [
        {
            "transformers.models.conditional_detr.feature_extraction_conditional_detr.ConditionalDetrFeatureExtractor.__init__": 27
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/conditional_detr/modeling_conditional_detr.py": [
        {
            "transformers.models.conditional_detr.modeling_conditional_detr.ConditionalDetrDecoder.custom_forward": 1394
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/phobert/tokenization_phobert.py": [
        {
            "transformers.models.phobert.tokenization_phobert.PhobertTokenizer.__init__": 121
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/wav2vec2/modeling_flax_wav2vec2.py": [
        {
            "transformers.models.wav2vec2.modeling_flax_wav2vec2.FlaxWav2Vec2PreTrainedModel.__init__": 857
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/wav2vec2/modeling_wav2vec2.py": [
        {
            "transformers.models.wav2vec2.modeling_wav2vec2.Wav2Vec2FeatureEncoder.custom_forward": 456
        },
        {
            "transformers.models.wav2vec2.modeling_wav2vec2.Wav2Vec2Encoder.custom_forward": 808
        },
        {
            "transformers.models.wav2vec2.modeling_wav2vec2.Wav2Vec2EncoderStableLayerNorm.custom_forward": 897
        },
        {
            "transformers.models.wav2vec2.modeling_wav2vec2.Wav2Vec2PreTrainedModel.load_adapter": 1197
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/wav2vec2/processing_wav2vec2.py": [
        {
            "transformers.models.wav2vec2.processing_wav2vec2.Wav2Vec2Processor.from_pretrained": 49
        },
        {
            "transformers.models.wav2vec2.processing_wav2vec2.Wav2Vec2Processor.__call__": 67
        },
        {
            "transformers.models.wav2vec2.processing_wav2vec2.Wav2Vec2Processor.pad": 105
        },
        {
            "transformers.models.wav2vec2.processing_wav2vec2.Wav2Vec2Processor.batch_decode": 135
        },
        {
            "transformers.models.wav2vec2.processing_wav2vec2.Wav2Vec2Processor.decode": 142
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/wav2vec2/configuration_wav2vec2.py": [
        {
            "transformers.models.wav2vec2.configuration_wav2vec2.Wav2Vec2Config.__init__": 206
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/wav2vec2/feature_extraction_wav2vec2.py": [
        {
            "transformers.models.wav2vec2.feature_extraction_wav2vec2.Wav2Vec2FeatureExtractor.__init__": 67
        },
        {
            "transformers.models.wav2vec2.feature_extraction_wav2vec2.Wav2Vec2FeatureExtractor.__call__": 102
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/wav2vec2/modeling_tf_wav2vec2.py": [
        {
            "transformers.models.wav2vec2.modeling_tf_wav2vec2.TFWav2Vec2GroupNorm.__init__": 212
        },
        {
            "transformers.models.wav2vec2.modeling_tf_wav2vec2.TFWav2Vec2WeightNormConv1D.__init__": 426
        },
        {
            "transformers.models.wav2vec2.modeling_tf_wav2vec2.TFWav2Vec2NoLayerNormConvLayer.__init__": 484
        },
        {
            "transformers.models.wav2vec2.modeling_tf_wav2vec2.TFWav2Vec2LayerNormConvLayer.__init__": 505
        },
        {
            "transformers.models.wav2vec2.modeling_tf_wav2vec2.TFWav2Vec2GroupNormConvLayer.__init__": 528
        },
        {
            "transformers.models.wav2vec2.modeling_tf_wav2vec2.TFWav2Vec2PositionalConvEmbedding.__init__": 553
        },
        {
            "transformers.models.wav2vec2.modeling_tf_wav2vec2.TFWav2Vec2SamePadLayer.__init__": 573
        },
        {
            "transformers.models.wav2vec2.modeling_tf_wav2vec2.TFWav2Vec2FeatureEncoder.__init__": 584
        },
        {
            "transformers.models.wav2vec2.modeling_tf_wav2vec2.TFWav2Vec2FeatureExtractor.__init__": 611
        },
        {
            "transformers.models.wav2vec2.modeling_tf_wav2vec2.TFWav2Vec2FeatureProjection.__init__": 622
        },
        {
            "transformers.models.wav2vec2.modeling_tf_wav2vec2.TFWav2Vec2Attention.__init__": 645
        },
        {
            "transformers.models.wav2vec2.modeling_tf_wav2vec2.TFWav2Vec2FeedForward.__init__": 796
        },
        {
            "transformers.models.wav2vec2.modeling_tf_wav2vec2.TFWav2Vec2EncoderLayer.__init__": 828
        },
        {
            "transformers.models.wav2vec2.modeling_tf_wav2vec2.TFWav2Vec2EncoderLayerStableLayerNorm.__init__": 871
        },
        {
            "transformers.models.wav2vec2.modeling_tf_wav2vec2.TFWav2Vec2Encoder.__init__": 912
        },
        {
            "transformers.models.wav2vec2.modeling_tf_wav2vec2.TFWav2Vec2EncoderStableLayerNorm.__init__": 977
        },
        {
            "transformers.models.wav2vec2.modeling_tf_wav2vec2.TFWav2Vec2MainLayer.__init__": 1047
        },
        {
            "transformers.models.wav2vec2.modeling_tf_wav2vec2.TFWav2Vec2MainLayer.call": 1125
        },
        {
            "transformers.models.wav2vec2.modeling_tf_wav2vec2.TFWav2Vec2PreTrainedModel.__init__": 1201
        },
        {
            "transformers.models.wav2vec2.modeling_tf_wav2vec2.TFWav2Vec2Model.__init__": 1352
        },
        {
            "transformers.models.wav2vec2.modeling_tf_wav2vec2.TFWav2Vec2ForCTC.__init__": 1426
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/wav2vec2/tokenization_wav2vec2.py": [
        {
            "transformers.models.wav2vec2.tokenization_wav2vec2.Wav2Vec2CTCTokenizer.__init__": 164
        },
        {
            "transformers.models.wav2vec2.tokenization_wav2vec2.Wav2Vec2CTCTokenizer._tokenize": 271
        },
        {
            "transformers.models.wav2vec2.tokenization_wav2vec2.Wav2Vec2CTCTokenizer.prepare_for_tokenization": 402
        },
        {
            "transformers.models.wav2vec2.tokenization_wav2vec2.Wav2Vec2CTCTokenizer.batch_decode": 460
        },
        {
            "transformers.models.wav2vec2.tokenization_wav2vec2.Wav2Vec2CTCTokenizer.decode": 530
        },
        {
            "transformers.models.wav2vec2.tokenization_wav2vec2.Wav2Vec2Tokenizer.__init__": 767
        },
        {
            "transformers.models.wav2vec2.tokenization_wav2vec2.Wav2Vec2Tokenizer.__call__": 838
        },
        {
            "transformers.models.wav2vec2.tokenization_wav2vec2.Wav2Vec2Tokenizer._decode": 929
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/bart/modeling_tf_bart.py": [
        {
            "transformers.models.bart.modeling_tf_bart.TFBartLearnedPositionalEmbedding.__init__": 125
        },
        {
            "transformers.models.bart.modeling_tf_bart.TFBartAttention.__init__": 150
        },
        {
            "transformers.models.bart.modeling_tf_bart.TFBartEncoderLayer.__init__": 301
        },
        {
            "transformers.models.bart.modeling_tf_bart.TFBartDecoderLayer.__init__": 357
        },
        {
            "transformers.models.bart.modeling_tf_bart.TFBartClassificationHead.__init__": 468
        },
        {
            "transformers.models.bart.modeling_tf_bart.TFBartEncoder.__init__": 666
        },
        {
            "transformers.models.bart.modeling_tf_bart.TFBartDecoder.__init__": 818
        },
        {
            "transformers.models.bart.modeling_tf_bart.TFBartMainLayer.__init__": 1034
        },
        {
            "transformers.models.bart.modeling_tf_bart.TFBartMainLayer.call": 1058
        },
        {
            "transformers.models.bart.modeling_tf_bart.TFBartModel.__init__": 1154
        },
        {
            "transformers.models.bart.modeling_tf_bart.TFBartModel.call": 1172
        },
        {
            "transformers.models.bart.modeling_tf_bart.BiasLayer.__init__": 1241
        },
        {
            "transformers.models.bart.modeling_tf_bart.TFBartForConditionalGeneration.__init__": 1260
        },
        {
            "transformers.models.bart.modeling_tf_bart.TFBartForConditionalGeneration.prepare_inputs_for_generation": 1396
        },
        {
            "transformers.models.bart.modeling_tf_bart.TFBartForSequenceClassification.__init__": 1446
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/bart/configuration_bart.py": [
        {
            "transformers.models.bart.configuration_bart.BartConfig.__init__": 114
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/bart/modeling_flax_bart.py": [
        {
            "transformers.models.bart.modeling_flax_bart.FlaxBartPreTrainedModel.__init__": 910
        },
        {
            "transformers.models.bart.modeling_flax_bart.FlaxBartPreTrainedModel._decoder_forward": 979
        },
        {
            "transformers.models.bart.modeling_flax_bart.FlaxBartPreTrainedModel._encoder_forward": 1045
        },
        {
            "transformers.models.bart.modeling_flax_bart.FlaxBartPreTrainedModel._decoder_forward": 1140
        },
        {
            "transformers.models.bart.modeling_flax_bart.FlaxBartForConditionalGeneration._decoder_forward": 1407
        },
        {
            "transformers.models.bart.modeling_flax_bart.FlaxBartForConditionalGeneration.prepare_inputs_for_generation": 1466
        },
        {
            "transformers.models.bart.modeling_flax_bart.FlaxBartDecoderPreTrainedModel.__init__": 1742
        },
        {
            "transformers.models.bart.modeling_flax_bart.FlaxBartDecoderWrapper.__call__": 1891
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/bart/tokenization_bart.py": [
        {
            "transformers.models.bart.tokenization_bart.BartTokenizer.__init__": 184
        },
        {
            "transformers.models.bart.tokenization_bart.BartTokenizer.prepare_for_tokenization": 415
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/bart/tokenization_bart_fast.py": [
        {
            "transformers.models.bart.tokenization_bart_fast.BartTokenizerFast.__init__": 156
        },
        {
            "transformers.models.bart.tokenization_bart_fast.BartTokenizerFast._batch_encode_plus": 252
        },
        {
            "transformers.models.bart.tokenization_bart_fast.BartTokenizerFast._encode_plus": 263
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/bart/modeling_bart.py": [
        {
            "transformers.models.bart.modeling_bart.BartEncoder.custom_forward": 847
        },
        {
            "transformers.models.bart.modeling_bart.BartDecoder.custom_forward": 1102
        },
        {
            "transformers.models.bart.modeling_bart.BartForConditionalGeneration.prepare_inputs_for_generation": 1422
        },
        {
            "transformers.models.bart.modeling_bart.BartForSequenceClassification.__init__": 1476
        },
        {
            "transformers.models.bart.modeling_bart.BartDecoderWrapper.forward": 1731
        },
        {
            "transformers.models.bart.modeling_bart.BartForCausalLM.prepare_inputs_for_generation": 1919
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/cpm/tokenization_cpm_fast.py": [
        {
            "transformers.models.cpm.tokenization_cpm_fast.CpmTokenizerFast.__init__": 41
        },
        {
            "transformers.models.cpm.tokenization_cpm_fast.CpmTokenizerFast._batch_encode_plus": 233
        },
        {
            "transformers.models.cpm.tokenization_cpm_fast.CpmTokenizerFast._decode": 240
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/cpm/tokenization_cpm.py": [
        {
            "transformers.models.cpm.tokenization_cpm.CpmTokenizer.__init__": 41
        },
        {
            "transformers.models.cpm.tokenization_cpm.CpmTokenizer._decode": 345
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/van/configuration_van.py": [
        {
            "transformers.models.van.configuration_van.VanConfig.__init__": 82
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/vision_encoder_decoder/modeling_flax_vision_encoder_decoder.py": [
        {
            "transformers.models.vision_encoder_decoder.modeling_flax_vision_encoder_decoder.FlaxVisionEncoderDecoderModel.__init__": 280
        },
        {
            "transformers.models.vision_encoder_decoder.modeling_flax_vision_encoder_decoder.FlaxVisionEncoderDecoderModel._decoder_forward": 374
        },
        {
            "transformers.models.vision_encoder_decoder.modeling_flax_vision_encoder_decoder.FlaxVisionEncoderDecoderModel._encoder_forward": 444
        },
        {
            "transformers.models.vision_encoder_decoder.modeling_flax_vision_encoder_decoder.FlaxVisionEncoderDecoderModel._decoder_forward": 553
        },
        {
            "transformers.models.vision_encoder_decoder.modeling_flax_vision_encoder_decoder.FlaxVisionEncoderDecoderModel.prepare_inputs_for_generation": 687
        },
        {
            "transformers.models.vision_encoder_decoder.modeling_flax_vision_encoder_decoder.FlaxVisionEncoderDecoderModel.from_encoder_decoder_pretrained": 724
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/vision_encoder_decoder/modeling_vision_encoder_decoder.py": [
        {
            "transformers.models.vision_encoder_decoder.modeling_vision_encoder_decoder.VisionEncoderDecoderModel.from_pretrained": 246
        },
        {
            "transformers.models.vision_encoder_decoder.modeling_vision_encoder_decoder.VisionEncoderDecoderModel.from_encoder_decoder_pretrained": 366
        },
        {
            "transformers.models.vision_encoder_decoder.modeling_vision_encoder_decoder.VisionEncoderDecoderModel.forward": 521
        },
        {
            "transformers.models.vision_encoder_decoder.modeling_vision_encoder_decoder.VisionEncoderDecoderModel.prepare_inputs_for_generation": 651
        },
        {
            "transformers.models.vision_encoder_decoder.modeling_vision_encoder_decoder.VisionEncoderDecoderModel.resize_token_embeddings": 666
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/vision_encoder_decoder/modeling_tf_vision_encoder_decoder.py": [
        {
            "transformers.models.vision_encoder_decoder.modeling_tf_vision_encoder_decoder.TFVisionEncoderDecoderModel.from_pretrained": 293
        },
        {
            "transformers.models.vision_encoder_decoder.modeling_tf_vision_encoder_decoder.TFVisionEncoderDecoderModel.from_encoder_decoder_pretrained": 339
        },
        {
            "transformers.models.vision_encoder_decoder.modeling_tf_vision_encoder_decoder.TFVisionEncoderDecoderModel.call": 491
        },
        {
            "transformers.models.vision_encoder_decoder.modeling_tf_vision_encoder_decoder.TFVisionEncoderDecoderModel.prepare_inputs_for_generation": 689
        },
        {
            "transformers.models.vision_encoder_decoder.modeling_tf_vision_encoder_decoder.TFVisionEncoderDecoderModel.resize_token_embeddings": 710
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/vision_encoder_decoder/configuration_vision_encoder_decoder.py": [
        {
            "transformers.models.vision_encoder_decoder.configuration_vision_encoder_decoder.VisionEncoderDecoderConfig.__init__": 83
        },
        {
            "transformers.models.vision_encoder_decoder.configuration_vision_encoder_decoder.VisionEncoderDecoderConfig.from_encoder_decoder_configs": 101
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/mask2former/modeling_mask2former.py": [
        {
            "transformers.models.mask2former.modeling_mask2former.sample_point": 265
        },
        {
            "transformers.models.mask2former.modeling_mask2former.Mask2FormerMaskedAttentionDecoder.custom_forward": 1873
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/mask2former/image_processing_mask2former.py": [
        {
            "transformers.models.mask2former.image_processing_mask2former.Mask2FormerImageProcessor.__init__": 381
        },
        {
            "transformers.models.mask2former.image_processing_mask2former.Mask2FormerImageProcessor.from_dict": 432
        },
        {
            "transformers.models.mask2former.image_processing_mask2former.Mask2FormerImageProcessor.resize": 462
        },
        {
            "transformers.models.mask2former.image_processing_mask2former.Mask2FormerImageProcessor.__call__": 541
        },
        {
            "transformers.models.mask2former.image_processing_mask2former.Mask2FormerImageProcessor.preprocess": 629
        },
        {
            "transformers.models.mask2former.image_processing_mask2former.Mask2FormerImageProcessor.encode_inputs": 784
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/models/mask2former/configuration_mask2former.py": [
        {
            "transformers.models.mask2former.configuration_mask2former.Mask2FormerConfig.__init__": 127
        },
        {
            "transformers.models.mask2former.configuration_mask2former.Mask2FormerConfig.from_backbone_config": 211
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/data/data_collator.py": [
        {
            "transformers.data.data_collator.DataCollatorForSOP.__init__": 1125
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/data/processors/glue.py": [
        {
            "transformers.data.processors.glue.MrpcProcessor.__init__": 172
        },
        {
            "transformers.data.processors.glue.MnliProcessor.__init__": 219
        },
        {
            "transformers.data.processors.glue.MnliMismatchedProcessor.__init__": 265
        },
        {
            "transformers.data.processors.glue.ColaProcessor.__init__": 281
        },
        {
            "transformers.data.processors.glue.Sst2Processor.__init__": 328
        },
        {
            "transformers.data.processors.glue.StsbProcessor.__init__": 374
        },
        {
            "transformers.data.processors.glue.QqpProcessor.__init__": 420
        },
        {
            "transformers.data.processors.glue.QnliProcessor.__init__": 472
        },
        {
            "transformers.data.processors.glue.RteProcessor.__init__": 518
        },
        {
            "transformers.data.processors.glue.WnliProcessor.__init__": 564
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.30.2/data/processors/utils.py": [
        {
            "transformers.data.processors.utils.SingleSentenceClassificationProcessor.create_from_csv": 143
        },
        {
            "transformers.data.processors.utils.SingleSentenceClassificationProcessor.create_from_examples": 160
        }
    ]
}