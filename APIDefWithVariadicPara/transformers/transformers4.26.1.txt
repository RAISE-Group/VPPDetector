{
    "/home/zhang/Packages/transformers/transformers4.26.1/integrations.py": [
        {
            "transformers.integrations.run_hp_search_optuna": 164
        },
        {
            "transformers.integrations.run_hp_search_ray": 215
        },
        {
            "transformers.integrations.dynamic_modules_import_trainable": 315
        },
        {
            "transformers.integrations.run_hp_search_sigopt": 351
        },
        {
            "transformers.integrations.run_hp_search_wandb": 450
        },
        {
            "transformers.integrations.TensorBoardCallback.on_train_begin": 593
        },
        {
            "transformers.integrations.TensorBoardCallback.on_log": 618
        },
        {
            "transformers.integrations.TensorBoardCallback.on_train_end": 639
        },
        {
            "transformers.integrations.WandbCallback.setup": 670
        },
        {
            "transformers.integrations.WandbCallback.on_train_begin": 738
        },
        {
            "transformers.integrations.WandbCallback.on_train_end": 749
        },
        {
            "transformers.integrations.WandbCallback.on_log": 783
        },
        {
            "transformers.integrations.WandbCallback.on_save": 792
        },
        {
            "transformers.integrations.CometCallback.on_train_begin": 866
        },
        {
            "transformers.integrations.CometCallback.on_log": 870
        },
        {
            "transformers.integrations.CometCallback.on_train_end": 878
        },
        {
            "transformers.integrations.AzureMLCallback.on_init_end": 900
        },
        {
            "transformers.integrations.AzureMLCallback.on_log": 906
        },
        {
            "transformers.integrations.MLflowCallback.on_train_begin": 1002
        },
        {
            "transformers.integrations.MLflowCallback.on_log": 1006
        },
        {
            "transformers.integrations.MLflowCallback.on_train_end": 1021
        },
        {
            "transformers.integrations.MLflowCallback.on_save": 1026
        },
        {
            "transformers.integrations.NeptuneCallback.__init__": 1096
        },
        {
            "transformers.integrations.NeptuneCallback._initialize_run": 1157
        },
        {
            "transformers.integrations.NeptuneCallback.on_init_end": 1251
        },
        {
            "transformers.integrations.NeptuneCallback.on_train_begin": 1259
        },
        {
            "transformers.integrations.NeptuneCallback.on_train_end": 1274
        },
        {
            "transformers.integrations.NeptuneCallback.on_save": 1283
        },
        {
            "transformers.integrations.NeptuneCallback.on_evaluate": 1287
        },
        {
            "transformers.integrations.NeptuneCallback.on_log": 1307
        },
        {
            "transformers.integrations.CodeCarbonCallback.on_init_end": 1335
        },
        {
            "transformers.integrations.CodeCarbonCallback.on_train_begin": 1340
        },
        {
            "transformers.integrations.CodeCarbonCallback.on_train_end": 1344
        },
        {
            "transformers.integrations.ClearMLCallback.setup": 1375
        },
        {
            "transformers.integrations.ClearMLCallback.on_train_begin": 1394
        },
        {
            "transformers.integrations.ClearMLCallback.on_train_end": 1402
        },
        {
            "transformers.integrations.ClearMLCallback.on_log": 1409
        },
        {
            "transformers.integrations.ClearMLCallback.on_save": 1451
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/tokenization_utils_base.py": [
        {
            "transformers.tokenization_utils_base.SpecialTokensMixin.__init__": 802
        },
        {
            "transformers.tokenization_utils_base.PreTrainedTokenizerBase.__init__": 1496
        },
        {
            "transformers.tokenization_utils_base.PreTrainedTokenizerBase.from_pretrained": 1597
        },
        {
            "transformers.tokenization_utils_base.PreTrainedTokenizerBase._from_pretrained": 1817
        },
        {
            "transformers.tokenization_utils_base.PreTrainedTokenizerBase.save_pretrained": 2049
        },
        {
            "transformers.tokenization_utils_base.PreTrainedTokenizerBase.tokenize": 2237
        },
        {
            "transformers.tokenization_utils_base.PreTrainedTokenizerBase.encode": 2267
        },
        {
            "transformers.tokenization_utils_base.PreTrainedTokenizerBase._get_padding_truncation_strategies": 2311
        },
        {
            "transformers.tokenization_utils_base.PreTrainedTokenizerBase.__call__": 2450
        },
        {
            "transformers.tokenization_utils_base.PreTrainedTokenizerBase._call_one": 2538
        },
        {
            "transformers.tokenization_utils_base.PreTrainedTokenizerBase.encode_plus": 2651
        },
        {
            "transformers.tokenization_utils_base.PreTrainedTokenizerBase._encode_plus": 2723
        },
        {
            "transformers.tokenization_utils_base.PreTrainedTokenizerBase.batch_encode_plus": 2747
        },
        {
            "transformers.tokenization_utils_base.PreTrainedTokenizerBase._batch_encode_plus": 2820
        },
        {
            "transformers.tokenization_utils_base.PreTrainedTokenizerBase.prepare_for_model": 3063
        },
        {
            "transformers.tokenization_utils_base.PreTrainedTokenizerBase.batch_decode": 3409
        },
        {
            "transformers.tokenization_utils_base.PreTrainedTokenizerBase.decode": 3442
        },
        {
            "transformers.tokenization_utils_base.PreTrainedTokenizerBase._decode": 3478
        },
        {
            "transformers.tokenization_utils_base.PreTrainedTokenizerBase.prepare_seq2seq_batch": 3618
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/optimization_tf.py": [
        {
            "transformers.optimization_tf.AdamWeightDecay.__init__": 211
        },
        {
            "transformers.optimization_tf.AdamWeightDecay.apply_gradients": 250
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/tokenization_utils.py": [
        {
            "transformers.tokenization_utils.PreTrainedTokenizer.__init__": 346
        },
        {
            "transformers.tokenization_utils.PreTrainedTokenizer.tokenize": 481
        },
        {
            "transformers.tokenization_utils.PreTrainedTokenizer._tokenize": 551
        },
        {
            "transformers.tokenization_utils.PreTrainedTokenizer._encode_plus": 593
        },
        {
            "transformers.tokenization_utils.PreTrainedTokenizer._batch_encode_plus": 671
        },
        {
            "transformers.tokenization_utils.PreTrainedTokenizer.prepare_for_tokenization": 821
        },
        {
            "transformers.tokenization_utils.PreTrainedTokenizer._decode": 921
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/pytorch_utils.py": [
        {
            "transformers.pytorch_utils.apply_chunking_to_forward": 177
        },
        {
            "transformers.pytorch_utils.meshgrid": 278
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/modelcard.py": [
        {
            "transformers.modelcard.ModelCard.__init__": 89
        },
        {
            "transformers.modelcard.ModelCard.from_pretrained": 124
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/image_processing_utils.py": [
        {
            "transformers.image_processing_utils.ImageProcessingMixin.__init__": 66
        },
        {
            "transformers.image_processing_utils.ImageProcessingMixin.from_pretrained": 83
        },
        {
            "transformers.image_processing_utils.ImageProcessingMixin.save_pretrained": 165
        },
        {
            "transformers.image_processing_utils.ImageProcessingMixin.get_image_processor_dict": 210
        },
        {
            "transformers.image_processing_utils.ImageProcessingMixin.from_dict": 303
        },
        {
            "transformers.image_processing_utils.BaseImageProcessor.__init__": 441
        },
        {
            "transformers.image_processing_utils.BaseImageProcessor.__call__": 444
        },
        {
            "transformers.image_processing_utils.BaseImageProcessor.preprocess": 448
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/processing_utils.py": [
        {
            "transformers.processing_utils.ProcessorMixin.__init__": 56
        },
        {
            "transformers.processing_utils.ProcessorMixin.save_pretrained": 95
        },
        {
            "transformers.processing_utils.ProcessorMixin.from_pretrained": 154
        },
        {
            "transformers.processing_utils.ProcessorMixin._get_arguments_from_pretrained": 214
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/modeling_utils.py": [
        {
            "transformers.modeling_utils.Identity.__init__": 141
        },
        {
            "transformers.modeling_utils.ModuleUtilsMixin._hook_rss_memory_pre_forward": 676
        },
        {
            "transformers.modeling_utils.ModuleUtilsMixin._hook_rss_memory_post_forward": 688
        },
        {
            "transformers.modeling_utils.BackboneMixin.forward_with_filtered_kwargs": 954
        },
        {
            "transformers.modeling_utils.PreTrainedModel.__init__": 1024
        },
        {
            "transformers.modeling_utils.PreTrainedModel._from_config": 1053
        },
        {
            "transformers.modeling_utils.PreTrainedModel.save_pretrained": 1561
        },
        {
            "transformers.modeling_utils.PreTrainedModel.to": 1741
        },
        {
            "transformers.modeling_utils.PreTrainedModel.half": 1751
        },
        {
            "transformers.modeling_utils.PreTrainedModel.float": 1761
        },
        {
            "transformers.modeling_utils.PreTrainedModel.from_pretrained": 1772
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/trainer_callback.py": [
        {
            "transformers.trainer_callback.TrainerCallback.on_init_end": 209
        },
        {
            "transformers.trainer_callback.TrainerCallback.on_train_begin": 215
        },
        {
            "transformers.trainer_callback.TrainerCallback.on_train_end": 221
        },
        {
            "transformers.trainer_callback.TrainerCallback.on_epoch_begin": 227
        },
        {
            "transformers.trainer_callback.TrainerCallback.on_epoch_end": 233
        },
        {
            "transformers.trainer_callback.TrainerCallback.on_step_begin": 239
        },
        {
            "transformers.trainer_callback.TrainerCallback.on_substep_end": 246
        },
        {
            "transformers.trainer_callback.TrainerCallback.on_step_end": 252
        },
        {
            "transformers.trainer_callback.TrainerCallback.on_evaluate": 259
        },
        {
            "transformers.trainer_callback.TrainerCallback.on_predict": 265
        },
        {
            "transformers.trainer_callback.TrainerCallback.on_save": 271
        },
        {
            "transformers.trainer_callback.TrainerCallback.on_log": 277
        },
        {
            "transformers.trainer_callback.TrainerCallback.on_prediction_step": 283
        },
        {
            "transformers.trainer_callback.CallbackHandler.call_event": 395
        },
        {
            "transformers.trainer_callback.DefaultFlowCallback.on_step_end": 420
        },
        {
            "transformers.trainer_callback.DefaultFlowCallback.on_epoch_end": 449
        },
        {
            "transformers.trainer_callback.ProgressCallback.on_train_begin": 474
        },
        {
            "transformers.trainer_callback.ProgressCallback.on_step_end": 479
        },
        {
            "transformers.trainer_callback.ProgressCallback.on_prediction_step": 484
        },
        {
            "transformers.trainer_callback.ProgressCallback.on_evaluate": 490
        },
        {
            "transformers.trainer_callback.ProgressCallback.on_predict": 496
        },
        {
            "transformers.trainer_callback.ProgressCallback.on_log": 502
        },
        {
            "transformers.trainer_callback.ProgressCallback.on_train_end": 507
        },
        {
            "transformers.trainer_callback.PrinterCallback.on_log": 518
        },
        {
            "transformers.trainer_callback.EarlyStoppingCallback.on_train_begin": 557
        },
        {
            "transformers.trainer_callback.EarlyStoppingCallback.on_evaluate": 566
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/trainer.py": [
        {
            "transformers.trainer.Trainer.train": 1464
        },
        {
            "transformers.trainer.Trainer.hyperparameter_search": 2342
        },
        {
            "transformers.trainer.Trainer.push_to_hub": 3451
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/hf_argparser.py": [
        {
            "transformers.hf_argparser.HfArg": 69
        },
        {
            "transformers.hf_argparser.HfArgumentParser.__init__": 127
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/keras_callbacks.py": [
        {
            "transformers.keras_callbacks.PushToHubCallback.__init__": 314
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/testing_utils.py": [
        {
            "transformers.testing_utils.CaptureStd.__exit__": 866
        },
        {
            "transformers.testing_utils.CaptureLogger.__exit__": 945
        },
        {
            "transformers.testing_utils.mockenv": 1271
        },
        {
            "transformers.testing_utils.mockenv_context": 1284
        },
        {
            "transformers.testing_utils.RequestCounter.__exit__": 1668
        },
        {
            "transformers.testing_utils.RequestCounter.new_request": 1671
        },
        {
            "transformers.testing_utils.wrapper": 1695
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/configuration_utils.py": [
        {
            "transformers.configuration_utils.PretrainedConfig.__init__": 262
        },
        {
            "transformers.configuration_utils.PretrainedConfig.save_pretrained": 418
        },
        {
            "transformers.configuration_utils.PretrainedConfig.from_pretrained": 461
        },
        {
            "transformers.configuration_utils.PretrainedConfig.get_config_dict": 548
        },
        {
            "transformers.configuration_utils.PretrainedConfig._get_config_dict": 579
        },
        {
            "transformers.configuration_utils.PretrainedConfig.from_dict": 665
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/dynamic_module_utils.py": [
        {
            "transformers.dynamic_module_utils.get_class_from_dynamic_module": 288
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/feature_extraction_sequence_utils.py": [
        {
            "transformers.feature_extraction_sequence_utils.SequenceFeatureExtractor.__init__": 42
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/convert_graph_to_onnx.py": [
        {
            "transformers.convert_graph_to_onnx.load_graph_from_args": 226
        },
        {
            "transformers.convert_graph_to_onnx.convert": 353
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/trainer_seq2seq.py": [
        {
            "transformers.trainer_seq2seq.Seq2SeqTrainer.evaluate": 31
        },
        {
            "transformers.trainer_seq2seq.Seq2SeqTrainer.predict": 80
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/tokenization_utils_fast.py": [
        {
            "transformers.tokenization_utils_fast.PreTrainedTokenizerFast.__init__": 95
        },
        {
            "transformers.tokenization_utils_fast.PreTrainedTokenizerFast.tokenize": 319
        },
        {
            "transformers.tokenization_utils_fast.PreTrainedTokenizerFast._encode_plus": 479
        },
        {
            "transformers.tokenization_utils_fast.PreTrainedTokenizerFast._decode": 540
        },
        {
            "transformers.tokenization_utils_fast.PreTrainedTokenizerFast.train_new_from_iterator": 607
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/convert_slow_tokenizer.py": [
        {
            "transformers.convert_slow_tokenizer.SpmConverter.__init__": 433
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/feature_extraction_utils.py": [
        {
            "transformers.feature_extraction_utils.BatchFeature.to": 178
        },
        {
            "transformers.feature_extraction_utils.FeatureExtractionMixin.__init__": 231
        },
        {
            "transformers.feature_extraction_utils.FeatureExtractionMixin.from_pretrained": 248
        },
        {
            "transformers.feature_extraction_utils.FeatureExtractionMixin.save_pretrained": 333
        },
        {
            "transformers.feature_extraction_utils.FeatureExtractionMixin.get_feature_extractor_dict": 378
        },
        {
            "transformers.feature_extraction_utils.FeatureExtractionMixin.from_dict": 471
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/trainer_pt_utils.py": [
        {
            "transformers.trainer_pt_utils.DistributedSamplerWithLoop.__init__": 261
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/modeling_flax_utils.py": [
        {
            "transformers.modeling_flax_utils.FlaxPreTrainedModel._from_config": 237
        },
        {
            "transformers.modeling_flax_utils.FlaxPreTrainedModel.from_pretrained": 482
        },
        {
            "transformers.modeling_flax_utils.FlaxPreTrainedModel.save_pretrained": 984
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/modeling_tf_utils.py": [
        {
            "transformers.modeling_tf_utils.wrapped_init": 163
        },
        {
            "transformers.modeling_tf_utils.booleans_processing": 367
        },
        {
            "transformers.modeling_tf_utils.run_call_with_unpacked_inputs": 417
        },
        {
            "transformers.modeling_tf_utils.input_processing": 443
        },
        {
            "transformers.modeling_tf_utils.TFPreTrainedModel.__init__": 1129
        },
        {
            "transformers.modeling_tf_utils.TFPreTrainedModel.from_config": 1148
        },
        {
            "transformers.modeling_tf_utils.TFPreTrainedModel._from_config": 1154
        },
        {
            "transformers.modeling_tf_utils.TFPreTrainedModel.compile": 1396
        },
        {
            "transformers.modeling_tf_utils.TFPreTrainedModel.compute_loss": 1447
        },
        {
            "transformers.modeling_tf_utils.TFPreTrainedModel.save_pretrained": 2221
        },
        {
            "transformers.modeling_tf_utils.TFPreTrainedModel.from_pretrained": 2370
        },
        {
            "transformers.modeling_tf_utils.TFPreTrainedModel.push_to_hub": 2884
        },
        {
            "transformers.modeling_tf_utils.TFConv1D.__init__": 3018
        },
        {
            "transformers.modeling_tf_utils.TFSharedEmbeddings.__init__": 3061
        },
        {
            "transformers.modeling_tf_utils.TFSequenceSummary.__init__": 3170
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/generation/tf_logits_process.py": [
        {
            "transformers.generation.tf_logits_process.TFLogitsProcessorList.__call__": 83
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/generation/utils.py": [
        {
            "transformers.generation.utils.GenerationMixin.prepare_inputs_for_generation": 490
        },
        {
            "transformers.generation.utils.GenerationMixin.adjust_logits_during_generation": 563
        },
        {
            "transformers.generation.utils.GenerationMixin._expand_inputs_for_generation": 654
        },
        {
            "transformers.generation.utils.GenerationMixin.generate": 1096
        },
        {
            "transformers.generation.utils.GenerationMixin.contrastive_search": 1659
        },
        {
            "transformers.generation.utils.GenerationMixin.greedy_search": 2016
        },
        {
            "transformers.generation.utils.GenerationMixin.sample": 2259
        },
        {
            "transformers.generation.utils.GenerationMixin.beam_search": 2525
        },
        {
            "transformers.generation.utils.GenerationMixin.beam_sample": 2848
        },
        {
            "transformers.generation.utils.GenerationMixin.group_beam_search": 3178
        },
        {
            "transformers.generation.utils.GenerationMixin.constrained_beam_search": 3556
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/generation/flax_utils.py": [
        {
            "transformers.generation.flax_utils.FlaxGenerationMixin.prepare_inputs_for_generation": 144
        },
        {
            "transformers.generation.flax_utils.FlaxGenerationMixin.generate": 221
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/generation/beam_search.py": [
        {
            "transformers.generation.beam_search.BeamScorer.process": 96
        },
        {
            "transformers.generation.beam_search.BeamScorer.finalize": 108
        },
        {
            "transformers.generation.beam_search.BeamSearchScorer.__init__": 155
        },
        {
            "transformers.generation.beam_search.ConstrainedBeamSearchScorer.__init__": 430
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/generation/configuration_utils.py": [
        {
            "transformers.generation.configuration_utils.GenerationConfig.__init__": 220
        },
        {
            "transformers.generation.configuration_utils.GenerationConfig.save_pretrained": 297
        },
        {
            "transformers.generation.configuration_utils.GenerationConfig.from_pretrained": 344
        },
        {
            "transformers.generation.configuration_utils.GenerationConfig.from_dict": 518
        },
        {
            "transformers.generation.configuration_utils.GenerationConfig.update": 648
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/generation/tf_utils.py": [
        {
            "transformers.generation.tf_utils.TFGenerationMixin.prepare_inputs_for_generation": 457
        },
        {
            "transformers.generation.tf_utils.TFGenerationMixin.adjust_logits_during_generation": 462
        },
        {
            "transformers.generation.tf_utils.TFGenerationMixin.generate": 531
        },
        {
            "transformers.generation.tf_utils.TFGenerationMixin._expand_inputs_for_generation": 972
        },
        {
            "transformers.generation.tf_utils.TFGenerationMixin.greedy_search": 1244
        },
        {
            "transformers.generation.tf_utils.TFGenerationMixin.sample": 1499
        },
        {
            "transformers.generation.tf_utils.TFGenerationMixin.beam_search": 1803
        },
        {
            "transformers.generation.tf_utils.TFGenerationMixin.contrastive_search": 2279
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/generation/logits_process.py": [
        {
            "transformers.generation.logits_process.LogitsProcessorList.__call__": 81
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/generation/stopping_criteria.py": [
        {
            "transformers.generation.stopping_criteria.StoppingCriteria.__call__": 37
        },
        {
            "transformers.generation.stopping_criteria.MaxLengthCriteria.__call__": 55
        },
        {
            "transformers.generation.stopping_criteria.MaxNewTokensCriteria.__call__": 84
        },
        {
            "transformers.generation.stopping_criteria.MaxTimeCriteria.__call__": 106
        },
        {
            "transformers.generation.stopping_criteria.StoppingCriteriaList.__call__": 112
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/generation/flax_logits_process.py": [
        {
            "transformers.generation.flax_logits_process.FlaxLogitsProcessorList.__call__": 80
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/pipelines/text_classification.py": [
        {
            "transformers.pipelines.text_classification.TextClassificationPipeline.__init__": 82
        },
        {
            "transformers.pipelines.text_classification.TextClassificationPipeline._sanitize_parameters": 91
        },
        {
            "transformers.pipelines.text_classification.TextClassificationPipeline.__call__": 121
        },
        {
            "transformers.pipelines.text_classification.TextClassificationPipeline.preprocess": 164
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/pipelines/question_answering.py": [
        {
            "transformers.pipelines.question_answering.QuestionAnsweringArgumentHandler.__call__": 173
        },
        {
            "transformers.pipelines.question_answering.QuestionAnsweringPipeline.__init__": 252
        },
        {
            "transformers.pipelines.question_answering.QuestionAnsweringPipeline._sanitize_parameters": 299
        },
        {
            "transformers.pipelines.question_answering.QuestionAnsweringPipeline.__call__": 342
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/pipelines/text2text_generation.py": [
        {
            "transformers.pipelines.text2text_generation.Text2TextGenerationPipeline.__init__": 64
        },
        {
            "transformers.pipelines.text2text_generation.Text2TextGenerationPipeline._sanitize_parameters": 73
        },
        {
            "transformers.pipelines.text2text_generation.Text2TextGenerationPipeline._parse_and_tokenize": 115
        },
        {
            "transformers.pipelines.text2text_generation.Text2TextGenerationPipeline.__call__": 136
        },
        {
            "transformers.pipelines.text2text_generation.Text2TextGenerationPipeline.preprocess": 174
        },
        {
            "transformers.pipelines.text2text_generation.Text2TextGenerationPipeline._forward": 178
        },
        {
            "transformers.pipelines.text2text_generation.SummarizationPipeline.__call__": 241
        },
        {
            "transformers.pipelines.text2text_generation.TranslationPipeline.preprocess": 312
        },
        {
            "transformers.pipelines.text2text_generation.TranslationPipeline._sanitize_parameters": 320
        },
        {
            "transformers.pipelines.text2text_generation.TranslationPipeline.__call__": 336
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/pipelines/token_classification.py": [
        {
            "transformers.pipelines.token_classification.TokenClassificationArgumentHandler.__call__": 24
        },
        {
            "transformers.pipelines.token_classification.TokenClassificationPipeline.__init__": 125
        },
        {
            "transformers.pipelines.token_classification.TokenClassificationPipeline.__call__": 186
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/pipelines/automatic_speech_recognition.py": [
        {
            "transformers.pipelines.automatic_speech_recognition.AutomaticSpeechRecognitionPipeline.__init__": 302
        },
        {
            "transformers.pipelines.automatic_speech_recognition.AutomaticSpeechRecognitionPipeline.__call__": 331
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/pipelines/image_classification.py": [
        {
            "transformers.pipelines.image_classification.ImageClassificationPipeline.__init__": 56
        },
        {
            "transformers.pipelines.image_classification.ImageClassificationPipeline.__call__": 71
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/pipelines/visual_question_answering.py": [
        {
            "transformers.pipelines.visual_question_answering.VisualQuestionAnsweringPipeline.__init__": 54
        },
        {
            "transformers.pipelines.visual_question_answering.VisualQuestionAnsweringPipeline._sanitize_parameters": 58
        },
        {
            "transformers.pipelines.visual_question_answering.VisualQuestionAnsweringPipeline.__call__": 68
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/pipelines/zero_shot_object_detection.py": [
        {
            "transformers.pipelines.zero_shot_object_detection.ZeroShotObjectDetectionPipeline.__init__": 56
        },
        {
            "transformers.pipelines.zero_shot_object_detection.ZeroShotObjectDetectionPipeline.__call__": 65
        },
        {
            "transformers.pipelines.zero_shot_object_detection.ZeroShotObjectDetectionPipeline._sanitize_parameters": 134
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/pipelines/zero_shot_image_classification.py": [
        {
            "transformers.pipelines.zero_shot_image_classification.ZeroShotImageClassificationPipeline.__init__": 64
        },
        {
            "transformers.pipelines.zero_shot_image_classification.ZeroShotImageClassificationPipeline.__call__": 71
        },
        {
            "transformers.pipelines.zero_shot_image_classification.ZeroShotImageClassificationPipeline._sanitize_parameters": 100
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/pipelines/audio_classification.py": [
        {
            "transformers.pipelines.audio_classification.AudioClassificationPipeline.__init__": 94
        },
        {
            "transformers.pipelines.audio_classification.AudioClassificationPipeline.__call__": 104
        },
        {
            "transformers.pipelines.audio_classification.AudioClassificationPipeline._sanitize_parameters": 133
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/pipelines/conversational.py": [
        {
            "transformers.pipelines.conversational.ConversationalPipeline.__init__": 195
        },
        {
            "transformers.pipelines.conversational.ConversationalPipeline._sanitize_parameters": 200
        },
        {
            "transformers.pipelines.conversational.ConversationalPipeline.__call__": 222
        },
        {
            "transformers.pipelines.conversational.ConversationalPipeline._forward": 268
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/pipelines/table_question_answering.py": [
        {
            "transformers.pipelines.table_question_answering.TableQuestionAnsweringArgumentHandler.__call__": 40
        },
        {
            "transformers.pipelines.table_question_answering.TableQuestionAnsweringPipeline.__init__": 122
        },
        {
            "transformers.pipelines.table_question_answering.TableQuestionAnsweringPipeline.batch_inference": 142
        },
        {
            "transformers.pipelines.table_question_answering.TableQuestionAnsweringPipeline.sequential_inference": 145
        },
        {
            "transformers.pipelines.table_question_answering.TableQuestionAnsweringPipeline.__call__": 274
        },
        {
            "transformers.pipelines.table_question_answering.TableQuestionAnsweringPipeline._sanitize_parameters": 356
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/pipelines/base.py": [
        {
            "transformers.pipelines.base.infer_framework_load_model": 175
        },
        {
            "transformers.pipelines.base.infer_framework_from_model": 272
        },
        {
            "transformers.pipelines.base.ArgumentHandler.__call__": 412
        },
        {
            "transformers.pipelines.base.Pipeline.__init__": 741
        },
        {
            "transformers.pipelines.base.Pipeline.ensure_tensor_on_device": 875
        },
        {
            "transformers.pipelines.base.Pipeline._sanitize_parameters": 933
        },
        {
            "transformers.pipelines.base.Pipeline.preprocess": 946
        },
        {
            "transformers.pipelines.base.Pipeline._forward": 954
        },
        {
            "transformers.pipelines.base.Pipeline.postprocess": 967
        },
        {
            "transformers.pipelines.base.Pipeline.forward": 983
        },
        {
            "transformers.pipelines.base.Pipeline.__call__": 1021
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/pipelines/image_to_text.py": [
        {
            "transformers.pipelines.image_to_text.ImageToTextPipeline.__init__": 52
        },
        {
            "transformers.pipelines.image_to_text.ImageToTextPipeline.__call__": 74
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/pipelines/feature_extraction.py": [
        {
            "transformers.pipelines.feature_extraction.FeatureExtractionPipeline._sanitize_parameters": 58
        },
        {
            "transformers.pipelines.feature_extraction.FeatureExtractionPipeline.preprocess": 77
        },
        {
            "transformers.pipelines.feature_extraction.FeatureExtractionPipeline.__call__": 95
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/pipelines/zero_shot_classification.py": [
        {
            "transformers.pipelines.zero_shot_classification.ZeroShotClassificationPipeline.__init__": 86
        },
        {
            "transformers.pipelines.zero_shot_classification.ZeroShotClassificationPipeline._parse_and_tokenize": 102
        },
        {
            "transformers.pipelines.zero_shot_classification.ZeroShotClassificationPipeline._sanitize_parameters": 144
        },
        {
            "transformers.pipelines.zero_shot_classification.ZeroShotClassificationPipeline.__call__": 162
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/pipelines/depth_estimation.py": [
        {
            "transformers.pipelines.depth_estimation.DepthEstimationPipeline.__init__": 48
        },
        {
            "transformers.pipelines.depth_estimation.DepthEstimationPipeline.__call__": 53
        },
        {
            "transformers.pipelines.depth_estimation.DepthEstimationPipeline._sanitize_parameters": 84
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/pipelines/document_question_answering.py": [
        {
            "transformers.pipelines.document_question_answering.DocumentQuestionAnsweringPipeline.__init__": 132
        },
        {
            "transformers.pipelines.document_question_answering.DocumentQuestionAnsweringPipeline._sanitize_parameters": 146
        },
        {
            "transformers.pipelines.document_question_answering.DocumentQuestionAnsweringPipeline.__call__": 186
        },
        {
            "transformers.pipelines.document_question_answering.DocumentQuestionAnsweringPipeline.postprocess": 425
        },
        {
            "transformers.pipelines.document_question_answering.DocumentQuestionAnsweringPipeline.postprocess_encoder_decoder_single": 434
        },
        {
            "transformers.pipelines.document_question_answering.DocumentQuestionAnsweringPipeline.postprocess_extractive_qa": 450
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/pipelines/fill_mask.py": [
        {
            "transformers.pipelines.fill_mask.FillMaskPipeline.preprocess": 93
        },
        {
            "transformers.pipelines.fill_mask.FillMaskPipeline.__call__": 217
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/pipelines/__init__.py": [
        {
            "transformers.pipelines.__init__.pipeline": 479
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/pipelines/image_segmentation.py": [
        {
            "transformers.pipelines.image_segmentation.ImageSegmentationPipeline.__init__": 67
        },
        {
            "transformers.pipelines.image_segmentation.ImageSegmentationPipeline._sanitize_parameters": 83
        },
        {
            "transformers.pipelines.image_segmentation.ImageSegmentationPipeline.__call__": 96
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/pipelines/object_detection.py": [
        {
            "transformers.pipelines.object_detection.ObjectDetectionPipeline.__init__": 49
        },
        {
            "transformers.pipelines.object_detection.ObjectDetectionPipeline._sanitize_parameters": 60
        },
        {
            "transformers.pipelines.object_detection.ObjectDetectionPipeline.__call__": 66
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/pipelines/text_generation.py": [
        {
            "transformers.pipelines.text_generation.TextGenerationPipeline.__init__": 63
        },
        {
            "transformers.pipelines.text_generation.TextGenerationPipeline._sanitize_parameters": 90
        },
        {
            "transformers.pipelines.text_generation.TextGenerationPipeline._parse_and_tokenize": 159
        },
        {
            "transformers.pipelines.text_generation.TextGenerationPipeline.__call__": 169
        },
        {
            "transformers.pipelines.text_generation.TextGenerationPipeline.preprocess": 212
        },
        {
            "transformers.pipelines.text_generation.TextGenerationPipeline._forward": 240
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/pipelines/video_classification.py": [
        {
            "transformers.pipelines.video_classification.VideoClassificationPipeline.__init__": 35
        },
        {
            "transformers.pipelines.video_classification.VideoClassificationPipeline.__call__": 52
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/utils/dummy_keras_nlp_objects.py": [
        {
            "transformers.utils.dummy_keras_nlp_objects.TFGPT2Tokenizer.__init__": 9
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/utils/dummy_sentencepiece_and_tokenizers_objects.py": [
        {
            "transformers.utils.dummy_sentencepiece_and_tokenizers_objects.convert_slow_tokenizer": 9
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/utils/doc.py": [
        {
            "transformers.utils.doc.add_start_docstrings": 23
        },
        {
            "transformers.utils.doc.add_start_docstrings_to_model_forward": 31
        },
        {
            "transformers.utils.doc.add_end_docstrings": 53
        },
        {
            "transformers.utils.doc.filter_outputs_from_example": 1045
        },
        {
            "transformers.utils.doc.add_code_sample_docstrings": 1059
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/utils/dummy_sentencepiece_objects.py": [
        {
            "transformers.utils.dummy_sentencepiece_objects.AlbertTokenizer.__init__": 9
        },
        {
            "transformers.utils.dummy_sentencepiece_objects.BarthezTokenizer.__init__": 16
        },
        {
            "transformers.utils.dummy_sentencepiece_objects.BartphoTokenizer.__init__": 23
        },
        {
            "transformers.utils.dummy_sentencepiece_objects.BertGenerationTokenizer.__init__": 30
        },
        {
            "transformers.utils.dummy_sentencepiece_objects.BigBirdTokenizer.__init__": 37
        },
        {
            "transformers.utils.dummy_sentencepiece_objects.CamembertTokenizer.__init__": 44
        },
        {
            "transformers.utils.dummy_sentencepiece_objects.CpmTokenizer.__init__": 51
        },
        {
            "transformers.utils.dummy_sentencepiece_objects.DebertaV2Tokenizer.__init__": 58
        },
        {
            "transformers.utils.dummy_sentencepiece_objects.FNetTokenizer.__init__": 65
        },
        {
            "transformers.utils.dummy_sentencepiece_objects.GPTSw3Tokenizer.__init__": 72
        },
        {
            "transformers.utils.dummy_sentencepiece_objects.LayoutXLMTokenizer.__init__": 79
        },
        {
            "transformers.utils.dummy_sentencepiece_objects.M2M100Tokenizer.__init__": 86
        },
        {
            "transformers.utils.dummy_sentencepiece_objects.MarianTokenizer.__init__": 93
        },
        {
            "transformers.utils.dummy_sentencepiece_objects.MBart50Tokenizer.__init__": 100
        },
        {
            "transformers.utils.dummy_sentencepiece_objects.MBartTokenizer.__init__": 107
        },
        {
            "transformers.utils.dummy_sentencepiece_objects.MLukeTokenizer.__init__": 114
        },
        {
            "transformers.utils.dummy_sentencepiece_objects.MT5Tokenizer.__init__": 121
        },
        {
            "transformers.utils.dummy_sentencepiece_objects.NllbTokenizer.__init__": 128
        },
        {
            "transformers.utils.dummy_sentencepiece_objects.PegasusTokenizer.__init__": 135
        },
        {
            "transformers.utils.dummy_sentencepiece_objects.PLBartTokenizer.__init__": 142
        },
        {
            "transformers.utils.dummy_sentencepiece_objects.ReformerTokenizer.__init__": 149
        },
        {
            "transformers.utils.dummy_sentencepiece_objects.RemBertTokenizer.__init__": 156
        },
        {
            "transformers.utils.dummy_sentencepiece_objects.Speech2TextTokenizer.__init__": 163
        },
        {
            "transformers.utils.dummy_sentencepiece_objects.T5Tokenizer.__init__": 170
        },
        {
            "transformers.utils.dummy_sentencepiece_objects.XGLMTokenizer.__init__": 177
        },
        {
            "transformers.utils.dummy_sentencepiece_objects.XLMProphetNetTokenizer.__init__": 184
        },
        {
            "transformers.utils.dummy_sentencepiece_objects.XLMRobertaTokenizer.__init__": 191
        },
        {
            "transformers.utils.dummy_sentencepiece_objects.XLNetTokenizer.__init__": 198
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/utils/notebook.py": [
        {
            "transformers.utils.notebook.NotebookProgressCallback.on_train_begin": 278
        },
        {
            "transformers.utils.notebook.NotebookProgressCallback.on_step_end": 287
        },
        {
            "transformers.utils.notebook.NotebookProgressCallback.on_prediction_step": 296
        },
        {
            "transformers.utils.notebook.NotebookProgressCallback.on_predict": 308
        },
        {
            "transformers.utils.notebook.NotebookProgressCallback.on_log": 313
        },
        {
            "transformers.utils.notebook.NotebookProgressCallback.on_evaluate": 321
        },
        {
            "transformers.utils.notebook.NotebookProgressCallback.on_train_end": 356
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/utils/logging.py": [
        {
            "transformers.utils.logging.warning_advice": 273
        },
        {
            "transformers.utils.logging.EmptyTqdm.__init__": 290
        },
        {
            "transformers.utils.logging.EmptyTqdm.empty_fn": 299
        },
        {
            "transformers.utils.logging._tqdm_cls.__call__": 312
        },
        {
            "transformers.utils.logging._tqdm_cls.set_lock": 318
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/utils/dummy_tensorflow_text_objects.py": [
        {
            "transformers.utils.dummy_tensorflow_text_objects.TFBertTokenizer.__init__": 9
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/utils/dummy_speech_objects.py": [
        {
            "transformers.utils.dummy_speech_objects.ASTFeatureExtractor.__init__": 9
        },
        {
            "transformers.utils.dummy_speech_objects.MCTCTFeatureExtractor.__init__": 16
        },
        {
            "transformers.utils.dummy_speech_objects.Speech2TextFeatureExtractor.__init__": 23
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/utils/fx.py": [
        {
            "transformers.utils.fx.torch_arange": 220
        },
        {
            "transformers.utils.fx.torch_full": 241
        },
        {
            "transformers.utils.fx.torch_einsum": 352
        },
        {
            "transformers.utils.fx.torch_tensor_repeat": 358
        },
        {
            "transformers.utils.fx.torch_unique_consecutive": 459
        },
        {
            "transformers.utils.fx.HFAttribute.__call__": 623
        },
        {
            "transformers.utils.fx.wrapper": 644
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/utils/dummy_flax_objects.py": [
        {
            "transformers.utils.dummy_flax_objects.FlaxForcedBOSTokenLogitsProcessor.__init__": 9
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxForcedEOSTokenLogitsProcessor.__init__": 16
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxGenerationMixin.__init__": 23
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxLogitsProcessor.__init__": 30
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxLogitsProcessorList.__init__": 37
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxLogitsWarper.__init__": 44
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxMinLengthLogitsProcessor.__init__": 51
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxTemperatureLogitsWarper.__init__": 58
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxTopKLogitsWarper.__init__": 65
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxTopPLogitsWarper.__init__": 72
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxPreTrainedModel.__init__": 79
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxAlbertForMaskedLM.__init__": 86
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxAlbertForMultipleChoice.__init__": 93
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxAlbertForPreTraining.__init__": 100
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxAlbertForQuestionAnswering.__init__": 107
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxAlbertForSequenceClassification.__init__": 114
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxAlbertForTokenClassification.__init__": 121
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxAlbertModel.__init__": 128
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxAlbertPreTrainedModel.__init__": 135
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxAutoModel.__init__": 178
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxAutoModelForCausalLM.__init__": 185
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxAutoModelForImageClassification.__init__": 192
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxAutoModelForMaskedLM.__init__": 199
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxAutoModelForMultipleChoice.__init__": 206
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxAutoModelForNextSentencePrediction.__init__": 213
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxAutoModelForPreTraining.__init__": 220
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxAutoModelForQuestionAnswering.__init__": 227
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxAutoModelForSeq2SeqLM.__init__": 234
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxAutoModelForSequenceClassification.__init__": 241
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxAutoModelForTokenClassification.__init__": 248
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxAutoModelForVision2Seq.__init__": 255
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxBartDecoderPreTrainedModel.__init__": 262
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxBartForCausalLM.__init__": 269
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxBartForConditionalGeneration.__init__": 276
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxBartForQuestionAnswering.__init__": 283
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxBartForSequenceClassification.__init__": 290
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxBartModel.__init__": 297
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxBartPreTrainedModel.__init__": 304
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxBeitForImageClassification.__init__": 311
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxBeitForMaskedImageModeling.__init__": 318
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxBeitModel.__init__": 325
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxBeitPreTrainedModel.__init__": 332
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxBertForCausalLM.__init__": 339
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxBertForMaskedLM.__init__": 346
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxBertForMultipleChoice.__init__": 353
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxBertForNextSentencePrediction.__init__": 360
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxBertForPreTraining.__init__": 367
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxBertForQuestionAnswering.__init__": 374
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxBertForSequenceClassification.__init__": 381
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxBertForTokenClassification.__init__": 388
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxBertModel.__init__": 395
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxBertPreTrainedModel.__init__": 402
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxBigBirdForCausalLM.__init__": 409
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxBigBirdForMaskedLM.__init__": 416
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxBigBirdForMultipleChoice.__init__": 423
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxBigBirdForPreTraining.__init__": 430
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxBigBirdForQuestionAnswering.__init__": 437
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxBigBirdForSequenceClassification.__init__": 444
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxBigBirdForTokenClassification.__init__": 451
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxBigBirdModel.__init__": 458
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxBigBirdPreTrainedModel.__init__": 465
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxBlenderbotForConditionalGeneration.__init__": 472
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxBlenderbotModel.__init__": 479
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxBlenderbotPreTrainedModel.__init__": 486
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxBlenderbotSmallForConditionalGeneration.__init__": 493
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxBlenderbotSmallModel.__init__": 500
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxBlenderbotSmallPreTrainedModel.__init__": 507
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxCLIPModel.__init__": 514
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxCLIPPreTrainedModel.__init__": 521
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxCLIPTextModel.__init__": 528
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxCLIPTextPreTrainedModel.__init__": 535
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxCLIPVisionModel.__init__": 542
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxCLIPVisionPreTrainedModel.__init__": 549
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxDistilBertForMaskedLM.__init__": 556
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxDistilBertForMultipleChoice.__init__": 563
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxDistilBertForQuestionAnswering.__init__": 570
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxDistilBertForSequenceClassification.__init__": 577
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxDistilBertForTokenClassification.__init__": 584
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxDistilBertModel.__init__": 591
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxDistilBertPreTrainedModel.__init__": 598
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxElectraForCausalLM.__init__": 605
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxElectraForMaskedLM.__init__": 612
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxElectraForMultipleChoice.__init__": 619
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxElectraForPreTraining.__init__": 626
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxElectraForQuestionAnswering.__init__": 633
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxElectraForSequenceClassification.__init__": 640
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxElectraForTokenClassification.__init__": 647
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxElectraModel.__init__": 654
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxElectraPreTrainedModel.__init__": 661
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxEncoderDecoderModel.__init__": 668
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxGPT2LMHeadModel.__init__": 675
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxGPT2Model.__init__": 682
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxGPT2PreTrainedModel.__init__": 689
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxGPTNeoForCausalLM.__init__": 696
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxGPTNeoModel.__init__": 703
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxGPTNeoPreTrainedModel.__init__": 710
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxGPTJForCausalLM.__init__": 717
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxGPTJModel.__init__": 724
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxGPTJPreTrainedModel.__init__": 731
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxLongT5ForConditionalGeneration.__init__": 738
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxLongT5Model.__init__": 745
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxLongT5PreTrainedModel.__init__": 752
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxMarianModel.__init__": 759
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxMarianMTModel.__init__": 766
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxMarianPreTrainedModel.__init__": 773
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxMBartForConditionalGeneration.__init__": 780
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxMBartForQuestionAnswering.__init__": 787
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxMBartForSequenceClassification.__init__": 794
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxMBartModel.__init__": 801
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxMBartPreTrainedModel.__init__": 808
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxMT5EncoderModel.__init__": 815
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxMT5ForConditionalGeneration.__init__": 822
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxMT5Model.__init__": 829
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxOPTForCausalLM.__init__": 836
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxOPTModel.__init__": 843
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxOPTPreTrainedModel.__init__": 850
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxPegasusForConditionalGeneration.__init__": 857
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxPegasusModel.__init__": 864
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxPegasusPreTrainedModel.__init__": 871
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxRobertaForCausalLM.__init__": 878
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxRobertaForMaskedLM.__init__": 885
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxRobertaForMultipleChoice.__init__": 892
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxRobertaForQuestionAnswering.__init__": 899
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxRobertaForSequenceClassification.__init__": 906
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxRobertaForTokenClassification.__init__": 913
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxRobertaModel.__init__": 920
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxRobertaPreTrainedModel.__init__": 927
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxRobertaPreLayerNormForCausalLM.__init__": 934
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxRobertaPreLayerNormForMaskedLM.__init__": 941
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxRobertaPreLayerNormForMultipleChoice.__init__": 948
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxRobertaPreLayerNormForQuestionAnswering.__init__": 955
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxRobertaPreLayerNormForSequenceClassification.__init__": 962
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxRobertaPreLayerNormForTokenClassification.__init__": 969
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxRobertaPreLayerNormModel.__init__": 976
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxRobertaPreLayerNormPreTrainedModel.__init__": 983
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxRoFormerForMaskedLM.__init__": 990
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxRoFormerForMultipleChoice.__init__": 997
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxRoFormerForQuestionAnswering.__init__": 1004
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxRoFormerForSequenceClassification.__init__": 1011
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxRoFormerForTokenClassification.__init__": 1018
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxRoFormerModel.__init__": 1025
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxRoFormerPreTrainedModel.__init__": 1032
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxSpeechEncoderDecoderModel.__init__": 1039
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxT5EncoderModel.__init__": 1046
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxT5ForConditionalGeneration.__init__": 1053
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxT5Model.__init__": 1060
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxT5PreTrainedModel.__init__": 1067
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxVisionEncoderDecoderModel.__init__": 1074
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxVisionTextDualEncoderModel.__init__": 1081
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxViTForImageClassification.__init__": 1088
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxViTModel.__init__": 1095
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxViTPreTrainedModel.__init__": 1102
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxWav2Vec2ForCTC.__init__": 1109
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxWav2Vec2ForPreTraining.__init__": 1116
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxWav2Vec2Model.__init__": 1123
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxWav2Vec2PreTrainedModel.__init__": 1130
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxXGLMForCausalLM.__init__": 1137
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxXGLMModel.__init__": 1144
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxXGLMPreTrainedModel.__init__": 1151
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxXLMRobertaForCausalLM.__init__": 1161
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxXLMRobertaForMaskedLM.__init__": 1168
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxXLMRobertaForMultipleChoice.__init__": 1175
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxXLMRobertaForQuestionAnswering.__init__": 1182
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxXLMRobertaForSequenceClassification.__init__": 1189
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxXLMRobertaForTokenClassification.__init__": 1196
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxXLMRobertaModel.__init__": 1203
        },
        {
            "transformers.utils.dummy_flax_objects.FlaxXLMRobertaPreTrainedModel.__init__": 1210
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/utils/dummy_timm_and_vision_objects.py": [
        {
            "transformers.utils.dummy_timm_and_vision_objects.ConditionalDetrForObjectDetection.__init__": 12
        },
        {
            "transformers.utils.dummy_timm_and_vision_objects.ConditionalDetrForSegmentation.__init__": 19
        },
        {
            "transformers.utils.dummy_timm_and_vision_objects.ConditionalDetrModel.__init__": 26
        },
        {
            "transformers.utils.dummy_timm_and_vision_objects.ConditionalDetrPreTrainedModel.__init__": 33
        },
        {
            "transformers.utils.dummy_timm_and_vision_objects.DeformableDetrForObjectDetection.__init__": 43
        },
        {
            "transformers.utils.dummy_timm_and_vision_objects.DeformableDetrModel.__init__": 50
        },
        {
            "transformers.utils.dummy_timm_and_vision_objects.DeformableDetrPreTrainedModel.__init__": 57
        },
        {
            "transformers.utils.dummy_timm_and_vision_objects.DetrForObjectDetection.__init__": 67
        },
        {
            "transformers.utils.dummy_timm_and_vision_objects.DetrForSegmentation.__init__": 74
        },
        {
            "transformers.utils.dummy_timm_and_vision_objects.DetrModel.__init__": 81
        },
        {
            "transformers.utils.dummy_timm_and_vision_objects.DetrPreTrainedModel.__init__": 88
        },
        {
            "transformers.utils.dummy_timm_and_vision_objects.TableTransformerForObjectDetection.__init__": 98
        },
        {
            "transformers.utils.dummy_timm_and_vision_objects.TableTransformerModel.__init__": 105
        },
        {
            "transformers.utils.dummy_timm_and_vision_objects.TableTransformerPreTrainedModel.__init__": 112
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/utils/dummy_detectron2_objects.py": [
        {
            "transformers.utils.dummy_detectron2_objects.LayoutLMv2Model.__init__": 9
        },
        {
            "transformers.utils.dummy_detectron2_objects.LayoutLMv2Model.from_pretrained": 13
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/utils/dummy_pt_objects.py": [
        {
            "transformers.utils.dummy_pt_objects.PyTorchBenchmark.__init__": 9
        },
        {
            "transformers.utils.dummy_pt_objects.PyTorchBenchmarkArguments.__init__": 16
        },
        {
            "transformers.utils.dummy_pt_objects.GlueDataset.__init__": 23
        },
        {
            "transformers.utils.dummy_pt_objects.GlueDataTrainingArguments.__init__": 30
        },
        {
            "transformers.utils.dummy_pt_objects.LineByLineTextDataset.__init__": 37
        },
        {
            "transformers.utils.dummy_pt_objects.LineByLineWithRefDataset.__init__": 44
        },
        {
            "transformers.utils.dummy_pt_objects.LineByLineWithSOPTextDataset.__init__": 51
        },
        {
            "transformers.utils.dummy_pt_objects.SquadDataset.__init__": 58
        },
        {
            "transformers.utils.dummy_pt_objects.SquadDataTrainingArguments.__init__": 65
        },
        {
            "transformers.utils.dummy_pt_objects.TextDataset.__init__": 72
        },
        {
            "transformers.utils.dummy_pt_objects.TextDatasetForNextSentencePrediction.__init__": 79
        },
        {
            "transformers.utils.dummy_pt_objects.BeamScorer.__init__": 86
        },
        {
            "transformers.utils.dummy_pt_objects.BeamSearchScorer.__init__": 93
        },
        {
            "transformers.utils.dummy_pt_objects.ConstrainedBeamSearchScorer.__init__": 100
        },
        {
            "transformers.utils.dummy_pt_objects.Constraint.__init__": 107
        },
        {
            "transformers.utils.dummy_pt_objects.ConstraintListState.__init__": 114
        },
        {
            "transformers.utils.dummy_pt_objects.DisjunctiveConstraint.__init__": 121
        },
        {
            "transformers.utils.dummy_pt_objects.ForcedBOSTokenLogitsProcessor.__init__": 128
        },
        {
            "transformers.utils.dummy_pt_objects.ForcedEOSTokenLogitsProcessor.__init__": 135
        },
        {
            "transformers.utils.dummy_pt_objects.GenerationMixin.__init__": 142
        },
        {
            "transformers.utils.dummy_pt_objects.HammingDiversityLogitsProcessor.__init__": 149
        },
        {
            "transformers.utils.dummy_pt_objects.InfNanRemoveLogitsProcessor.__init__": 156
        },
        {
            "transformers.utils.dummy_pt_objects.LogitsProcessor.__init__": 163
        },
        {
            "transformers.utils.dummy_pt_objects.LogitsProcessorList.__init__": 170
        },
        {
            "transformers.utils.dummy_pt_objects.LogitsWarper.__init__": 177
        },
        {
            "transformers.utils.dummy_pt_objects.MaxLengthCriteria.__init__": 184
        },
        {
            "transformers.utils.dummy_pt_objects.MaxTimeCriteria.__init__": 191
        },
        {
            "transformers.utils.dummy_pt_objects.MinLengthLogitsProcessor.__init__": 198
        },
        {
            "transformers.utils.dummy_pt_objects.MinNewTokensLengthLogitsProcessor.__init__": 205
        },
        {
            "transformers.utils.dummy_pt_objects.NoBadWordsLogitsProcessor.__init__": 212
        },
        {
            "transformers.utils.dummy_pt_objects.NoRepeatNGramLogitsProcessor.__init__": 219
        },
        {
            "transformers.utils.dummy_pt_objects.PhrasalConstraint.__init__": 226
        },
        {
            "transformers.utils.dummy_pt_objects.PrefixConstrainedLogitsProcessor.__init__": 233
        },
        {
            "transformers.utils.dummy_pt_objects.RepetitionPenaltyLogitsProcessor.__init__": 240
        },
        {
            "transformers.utils.dummy_pt_objects.StoppingCriteria.__init__": 247
        },
        {
            "transformers.utils.dummy_pt_objects.StoppingCriteriaList.__init__": 254
        },
        {
            "transformers.utils.dummy_pt_objects.TemperatureLogitsWarper.__init__": 261
        },
        {
            "transformers.utils.dummy_pt_objects.TopKLogitsWarper.__init__": 268
        },
        {
            "transformers.utils.dummy_pt_objects.TopPLogitsWarper.__init__": 275
        },
        {
            "transformers.utils.dummy_pt_objects.TypicalLogitsWarper.__init__": 282
        },
        {
            "transformers.utils.dummy_pt_objects.top_k_top_p_filtering": 286
        },
        {
            "transformers.utils.dummy_pt_objects.PreTrainedModel.__init__": 293
        },
        {
            "transformers.utils.dummy_pt_objects.AlbertForMaskedLM.__init__": 303
        },
        {
            "transformers.utils.dummy_pt_objects.AlbertForMultipleChoice.__init__": 310
        },
        {
            "transformers.utils.dummy_pt_objects.AlbertForPreTraining.__init__": 317
        },
        {
            "transformers.utils.dummy_pt_objects.AlbertForQuestionAnswering.__init__": 324
        },
        {
            "transformers.utils.dummy_pt_objects.AlbertForSequenceClassification.__init__": 331
        },
        {
            "transformers.utils.dummy_pt_objects.AlbertForTokenClassification.__init__": 338
        },
        {
            "transformers.utils.dummy_pt_objects.AlbertModel.__init__": 345
        },
        {
            "transformers.utils.dummy_pt_objects.AlbertPreTrainedModel.__init__": 352
        },
        {
            "transformers.utils.dummy_pt_objects.load_tf_weights_in_albert": 356
        },
        {
            "transformers.utils.dummy_pt_objects.AltCLIPModel.__init__": 366
        },
        {
            "transformers.utils.dummy_pt_objects.AltCLIPPreTrainedModel.__init__": 373
        },
        {
            "transformers.utils.dummy_pt_objects.AltCLIPTextModel.__init__": 380
        },
        {
            "transformers.utils.dummy_pt_objects.AltCLIPVisionModel.__init__": 387
        },
        {
            "transformers.utils.dummy_pt_objects.ASTForAudioClassification.__init__": 397
        },
        {
            "transformers.utils.dummy_pt_objects.ASTModel.__init__": 404
        },
        {
            "transformers.utils.dummy_pt_objects.ASTPreTrainedModel.__init__": 411
        },
        {
            "transformers.utils.dummy_pt_objects.AutoBackbone.__init__": 511
        },
        {
            "transformers.utils.dummy_pt_objects.AutoModel.__init__": 518
        },
        {
            "transformers.utils.dummy_pt_objects.AutoModelForAudioClassification.__init__": 525
        },
        {
            "transformers.utils.dummy_pt_objects.AutoModelForAudioFrameClassification.__init__": 532
        },
        {
            "transformers.utils.dummy_pt_objects.AutoModelForAudioXVector.__init__": 539
        },
        {
            "transformers.utils.dummy_pt_objects.AutoModelForCausalLM.__init__": 546
        },
        {
            "transformers.utils.dummy_pt_objects.AutoModelForCTC.__init__": 553
        },
        {
            "transformers.utils.dummy_pt_objects.AutoModelForDepthEstimation.__init__": 560
        },
        {
            "transformers.utils.dummy_pt_objects.AutoModelForDocumentQuestionAnswering.__init__": 567
        },
        {
            "transformers.utils.dummy_pt_objects.AutoModelForImageClassification.__init__": 574
        },
        {
            "transformers.utils.dummy_pt_objects.AutoModelForImageSegmentation.__init__": 581
        },
        {
            "transformers.utils.dummy_pt_objects.AutoModelForInstanceSegmentation.__init__": 588
        },
        {
            "transformers.utils.dummy_pt_objects.AutoModelForMaskedImageModeling.__init__": 595
        },
        {
            "transformers.utils.dummy_pt_objects.AutoModelForMaskedLM.__init__": 602
        },
        {
            "transformers.utils.dummy_pt_objects.AutoModelForMultipleChoice.__init__": 609
        },
        {
            "transformers.utils.dummy_pt_objects.AutoModelForNextSentencePrediction.__init__": 616
        },
        {
            "transformers.utils.dummy_pt_objects.AutoModelForObjectDetection.__init__": 623
        },
        {
            "transformers.utils.dummy_pt_objects.AutoModelForPreTraining.__init__": 630
        },
        {
            "transformers.utils.dummy_pt_objects.AutoModelForQuestionAnswering.__init__": 637
        },
        {
            "transformers.utils.dummy_pt_objects.AutoModelForSemanticSegmentation.__init__": 644
        },
        {
            "transformers.utils.dummy_pt_objects.AutoModelForSeq2SeqLM.__init__": 651
        },
        {
            "transformers.utils.dummy_pt_objects.AutoModelForSequenceClassification.__init__": 658
        },
        {
            "transformers.utils.dummy_pt_objects.AutoModelForSpeechSeq2Seq.__init__": 665
        },
        {
            "transformers.utils.dummy_pt_objects.AutoModelForTableQuestionAnswering.__init__": 672
        },
        {
            "transformers.utils.dummy_pt_objects.AutoModelForTokenClassification.__init__": 679
        },
        {
            "transformers.utils.dummy_pt_objects.AutoModelForUniversalSegmentation.__init__": 686
        },
        {
            "transformers.utils.dummy_pt_objects.AutoModelForVideoClassification.__init__": 693
        },
        {
            "transformers.utils.dummy_pt_objects.AutoModelForVision2Seq.__init__": 700
        },
        {
            "transformers.utils.dummy_pt_objects.AutoModelForVisualQuestionAnswering.__init__": 707
        },
        {
            "transformers.utils.dummy_pt_objects.AutoModelForZeroShotObjectDetection.__init__": 714
        },
        {
            "transformers.utils.dummy_pt_objects.AutoModelWithLMHead.__init__": 721
        },
        {
            "transformers.utils.dummy_pt_objects.BartForCausalLM.__init__": 731
        },
        {
            "transformers.utils.dummy_pt_objects.BartForConditionalGeneration.__init__": 738
        },
        {
            "transformers.utils.dummy_pt_objects.BartForQuestionAnswering.__init__": 745
        },
        {
            "transformers.utils.dummy_pt_objects.BartForSequenceClassification.__init__": 752
        },
        {
            "transformers.utils.dummy_pt_objects.BartModel.__init__": 759
        },
        {
            "transformers.utils.dummy_pt_objects.BartPretrainedModel.__init__": 766
        },
        {
            "transformers.utils.dummy_pt_objects.PretrainedBartModel.__init__": 773
        },
        {
            "transformers.utils.dummy_pt_objects.BeitForImageClassification.__init__": 783
        },
        {
            "transformers.utils.dummy_pt_objects.BeitForMaskedImageModeling.__init__": 790
        },
        {
            "transformers.utils.dummy_pt_objects.BeitForSemanticSegmentation.__init__": 797
        },
        {
            "transformers.utils.dummy_pt_objects.BeitModel.__init__": 804
        },
        {
            "transformers.utils.dummy_pt_objects.BeitPreTrainedModel.__init__": 811
        },
        {
            "transformers.utils.dummy_pt_objects.BertForMaskedLM.__init__": 821
        },
        {
            "transformers.utils.dummy_pt_objects.BertForMultipleChoice.__init__": 828
        },
        {
            "transformers.utils.dummy_pt_objects.BertForNextSentencePrediction.__init__": 835
        },
        {
            "transformers.utils.dummy_pt_objects.BertForPreTraining.__init__": 842
        },
        {
            "transformers.utils.dummy_pt_objects.BertForQuestionAnswering.__init__": 849
        },
        {
            "transformers.utils.dummy_pt_objects.BertForSequenceClassification.__init__": 856
        },
        {
            "transformers.utils.dummy_pt_objects.BertForTokenClassification.__init__": 863
        },
        {
            "transformers.utils.dummy_pt_objects.BertLayer.__init__": 870
        },
        {
            "transformers.utils.dummy_pt_objects.BertLMHeadModel.__init__": 877
        },
        {
            "transformers.utils.dummy_pt_objects.BertModel.__init__": 884
        },
        {
            "transformers.utils.dummy_pt_objects.BertPreTrainedModel.__init__": 891
        },
        {
            "transformers.utils.dummy_pt_objects.load_tf_weights_in_bert": 895
        },
        {
            "transformers.utils.dummy_pt_objects.BertGenerationDecoder.__init__": 902
        },
        {
            "transformers.utils.dummy_pt_objects.BertGenerationEncoder.__init__": 909
        },
        {
            "transformers.utils.dummy_pt_objects.BertGenerationPreTrainedModel.__init__": 916
        },
        {
            "transformers.utils.dummy_pt_objects.load_tf_weights_in_bert_generation": 920
        },
        {
            "transformers.utils.dummy_pt_objects.BigBirdForCausalLM.__init__": 930
        },
        {
            "transformers.utils.dummy_pt_objects.BigBirdForMaskedLM.__init__": 937
        },
        {
            "transformers.utils.dummy_pt_objects.BigBirdForMultipleChoice.__init__": 944
        },
        {
            "transformers.utils.dummy_pt_objects.BigBirdForPreTraining.__init__": 951
        },
        {
            "transformers.utils.dummy_pt_objects.BigBirdForQuestionAnswering.__init__": 958
        },
        {
            "transformers.utils.dummy_pt_objects.BigBirdForSequenceClassification.__init__": 965
        },
        {
            "transformers.utils.dummy_pt_objects.BigBirdForTokenClassification.__init__": 972
        },
        {
            "transformers.utils.dummy_pt_objects.BigBirdLayer.__init__": 979
        },
        {
            "transformers.utils.dummy_pt_objects.BigBirdModel.__init__": 986
        },
        {
            "transformers.utils.dummy_pt_objects.BigBirdPreTrainedModel.__init__": 993
        },
        {
            "transformers.utils.dummy_pt_objects.load_tf_weights_in_big_bird": 997
        },
        {
            "transformers.utils.dummy_pt_objects.BigBirdPegasusForCausalLM.__init__": 1007
        },
        {
            "transformers.utils.dummy_pt_objects.BigBirdPegasusForConditionalGeneration.__init__": 1014
        },
        {
            "transformers.utils.dummy_pt_objects.BigBirdPegasusForQuestionAnswering.__init__": 1021
        },
        {
            "transformers.utils.dummy_pt_objects.BigBirdPegasusForSequenceClassification.__init__": 1028
        },
        {
            "transformers.utils.dummy_pt_objects.BigBirdPegasusModel.__init__": 1035
        },
        {
            "transformers.utils.dummy_pt_objects.BigBirdPegasusPreTrainedModel.__init__": 1042
        },
        {
            "transformers.utils.dummy_pt_objects.BioGptForCausalLM.__init__": 1052
        },
        {
            "transformers.utils.dummy_pt_objects.BioGptModel.__init__": 1059
        },
        {
            "transformers.utils.dummy_pt_objects.BioGptPreTrainedModel.__init__": 1066
        },
        {
            "transformers.utils.dummy_pt_objects.BitBackbone.__init__": 1076
        },
        {
            "transformers.utils.dummy_pt_objects.BitForImageClassification.__init__": 1083
        },
        {
            "transformers.utils.dummy_pt_objects.BitModel.__init__": 1090
        },
        {
            "transformers.utils.dummy_pt_objects.BitPreTrainedModel.__init__": 1097
        },
        {
            "transformers.utils.dummy_pt_objects.BlenderbotForCausalLM.__init__": 1107
        },
        {
            "transformers.utils.dummy_pt_objects.BlenderbotForConditionalGeneration.__init__": 1114
        },
        {
            "transformers.utils.dummy_pt_objects.BlenderbotModel.__init__": 1121
        },
        {
            "transformers.utils.dummy_pt_objects.BlenderbotPreTrainedModel.__init__": 1128
        },
        {
            "transformers.utils.dummy_pt_objects.BlenderbotSmallForCausalLM.__init__": 1138
        },
        {
            "transformers.utils.dummy_pt_objects.BlenderbotSmallForConditionalGeneration.__init__": 1145
        },
        {
            "transformers.utils.dummy_pt_objects.BlenderbotSmallModel.__init__": 1152
        },
        {
            "transformers.utils.dummy_pt_objects.BlenderbotSmallPreTrainedModel.__init__": 1159
        },
        {
            "transformers.utils.dummy_pt_objects.BlipForConditionalGeneration.__init__": 1169
        },
        {
            "transformers.utils.dummy_pt_objects.BlipForImageTextRetrieval.__init__": 1176
        },
        {
            "transformers.utils.dummy_pt_objects.BlipForQuestionAnswering.__init__": 1183
        },
        {
            "transformers.utils.dummy_pt_objects.BlipModel.__init__": 1190
        },
        {
            "transformers.utils.dummy_pt_objects.BlipPreTrainedModel.__init__": 1197
        },
        {
            "transformers.utils.dummy_pt_objects.BlipTextModel.__init__": 1204
        },
        {
            "transformers.utils.dummy_pt_objects.BlipVisionModel.__init__": 1211
        },
        {
            "transformers.utils.dummy_pt_objects.BloomForCausalLM.__init__": 1221
        },
        {
            "transformers.utils.dummy_pt_objects.BloomForQuestionAnswering.__init__": 1228
        },
        {
            "transformers.utils.dummy_pt_objects.BloomForSequenceClassification.__init__": 1235
        },
        {
            "transformers.utils.dummy_pt_objects.BloomForTokenClassification.__init__": 1242
        },
        {
            "transformers.utils.dummy_pt_objects.BloomModel.__init__": 1249
        },
        {
            "transformers.utils.dummy_pt_objects.BloomPreTrainedModel.__init__": 1256
        },
        {
            "transformers.utils.dummy_pt_objects.CamembertForCausalLM.__init__": 1266
        },
        {
            "transformers.utils.dummy_pt_objects.CamembertForMaskedLM.__init__": 1273
        },
        {
            "transformers.utils.dummy_pt_objects.CamembertForMultipleChoice.__init__": 1280
        },
        {
            "transformers.utils.dummy_pt_objects.CamembertForQuestionAnswering.__init__": 1287
        },
        {
            "transformers.utils.dummy_pt_objects.CamembertForSequenceClassification.__init__": 1294
        },
        {
            "transformers.utils.dummy_pt_objects.CamembertForTokenClassification.__init__": 1301
        },
        {
            "transformers.utils.dummy_pt_objects.CamembertModel.__init__": 1308
        },
        {
            "transformers.utils.dummy_pt_objects.CamembertPreTrainedModel.__init__": 1315
        },
        {
            "transformers.utils.dummy_pt_objects.CanineForMultipleChoice.__init__": 1325
        },
        {
            "transformers.utils.dummy_pt_objects.CanineForQuestionAnswering.__init__": 1332
        },
        {
            "transformers.utils.dummy_pt_objects.CanineForSequenceClassification.__init__": 1339
        },
        {
            "transformers.utils.dummy_pt_objects.CanineForTokenClassification.__init__": 1346
        },
        {
            "transformers.utils.dummy_pt_objects.CanineLayer.__init__": 1353
        },
        {
            "transformers.utils.dummy_pt_objects.CanineModel.__init__": 1360
        },
        {
            "transformers.utils.dummy_pt_objects.CaninePreTrainedModel.__init__": 1367
        },
        {
            "transformers.utils.dummy_pt_objects.load_tf_weights_in_canine": 1371
        },
        {
            "transformers.utils.dummy_pt_objects.ChineseCLIPModel.__init__": 1381
        },
        {
            "transformers.utils.dummy_pt_objects.ChineseCLIPPreTrainedModel.__init__": 1388
        },
        {
            "transformers.utils.dummy_pt_objects.ChineseCLIPTextModel.__init__": 1395
        },
        {
            "transformers.utils.dummy_pt_objects.ChineseCLIPVisionModel.__init__": 1402
        },
        {
            "transformers.utils.dummy_pt_objects.CLIPModel.__init__": 1412
        },
        {
            "transformers.utils.dummy_pt_objects.CLIPPreTrainedModel.__init__": 1419
        },
        {
            "transformers.utils.dummy_pt_objects.CLIPTextModel.__init__": 1426
        },
        {
            "transformers.utils.dummy_pt_objects.CLIPTextModelWithProjection.__init__": 1433
        },
        {
            "transformers.utils.dummy_pt_objects.CLIPVisionModel.__init__": 1440
        },
        {
            "transformers.utils.dummy_pt_objects.CLIPVisionModelWithProjection.__init__": 1447
        },
        {
            "transformers.utils.dummy_pt_objects.CLIPSegForImageSegmentation.__init__": 1457
        },
        {
            "transformers.utils.dummy_pt_objects.CLIPSegModel.__init__": 1464
        },
        {
            "transformers.utils.dummy_pt_objects.CLIPSegPreTrainedModel.__init__": 1471
        },
        {
            "transformers.utils.dummy_pt_objects.CLIPSegTextModel.__init__": 1478
        },
        {
            "transformers.utils.dummy_pt_objects.CLIPSegVisionModel.__init__": 1485
        },
        {
            "transformers.utils.dummy_pt_objects.CodeGenForCausalLM.__init__": 1495
        },
        {
            "transformers.utils.dummy_pt_objects.CodeGenModel.__init__": 1502
        },
        {
            "transformers.utils.dummy_pt_objects.CodeGenPreTrainedModel.__init__": 1509
        },
        {
            "transformers.utils.dummy_pt_objects.ConvBertForMaskedLM.__init__": 1519
        },
        {
            "transformers.utils.dummy_pt_objects.ConvBertForMultipleChoice.__init__": 1526
        },
        {
            "transformers.utils.dummy_pt_objects.ConvBertForQuestionAnswering.__init__": 1533
        },
        {
            "transformers.utils.dummy_pt_objects.ConvBertForSequenceClassification.__init__": 1540
        },
        {
            "transformers.utils.dummy_pt_objects.ConvBertForTokenClassification.__init__": 1547
        },
        {
            "transformers.utils.dummy_pt_objects.ConvBertLayer.__init__": 1554
        },
        {
            "transformers.utils.dummy_pt_objects.ConvBertModel.__init__": 1561
        },
        {
            "transformers.utils.dummy_pt_objects.ConvBertPreTrainedModel.__init__": 1568
        },
        {
            "transformers.utils.dummy_pt_objects.load_tf_weights_in_convbert": 1572
        },
        {
            "transformers.utils.dummy_pt_objects.ConvNextBackbone.__init__": 1582
        },
        {
            "transformers.utils.dummy_pt_objects.ConvNextForImageClassification.__init__": 1589
        },
        {
            "transformers.utils.dummy_pt_objects.ConvNextModel.__init__": 1596
        },
        {
            "transformers.utils.dummy_pt_objects.ConvNextPreTrainedModel.__init__": 1603
        },
        {
            "transformers.utils.dummy_pt_objects.CTRLForSequenceClassification.__init__": 1613
        },
        {
            "transformers.utils.dummy_pt_objects.CTRLLMHeadModel.__init__": 1620
        },
        {
            "transformers.utils.dummy_pt_objects.CTRLModel.__init__": 1627
        },
        {
            "transformers.utils.dummy_pt_objects.CTRLPreTrainedModel.__init__": 1634
        },
        {
            "transformers.utils.dummy_pt_objects.CvtForImageClassification.__init__": 1644
        },
        {
            "transformers.utils.dummy_pt_objects.CvtModel.__init__": 1651
        },
        {
            "transformers.utils.dummy_pt_objects.CvtPreTrainedModel.__init__": 1658
        },
        {
            "transformers.utils.dummy_pt_objects.Data2VecAudioForAudioFrameClassification.__init__": 1674
        },
        {
            "transformers.utils.dummy_pt_objects.Data2VecAudioForCTC.__init__": 1681
        },
        {
            "transformers.utils.dummy_pt_objects.Data2VecAudioForSequenceClassification.__init__": 1688
        },
        {
            "transformers.utils.dummy_pt_objects.Data2VecAudioForXVector.__init__": 1695
        },
        {
            "transformers.utils.dummy_pt_objects.Data2VecAudioModel.__init__": 1702
        },
        {
            "transformers.utils.dummy_pt_objects.Data2VecAudioPreTrainedModel.__init__": 1709
        },
        {
            "transformers.utils.dummy_pt_objects.Data2VecTextForCausalLM.__init__": 1716
        },
        {
            "transformers.utils.dummy_pt_objects.Data2VecTextForMaskedLM.__init__": 1723
        },
        {
            "transformers.utils.dummy_pt_objects.Data2VecTextForMultipleChoice.__init__": 1730
        },
        {
            "transformers.utils.dummy_pt_objects.Data2VecTextForQuestionAnswering.__init__": 1737
        },
        {
            "transformers.utils.dummy_pt_objects.Data2VecTextForSequenceClassification.__init__": 1744
        },
        {
            "transformers.utils.dummy_pt_objects.Data2VecTextForTokenClassification.__init__": 1751
        },
        {
            "transformers.utils.dummy_pt_objects.Data2VecTextModel.__init__": 1758
        },
        {
            "transformers.utils.dummy_pt_objects.Data2VecTextPreTrainedModel.__init__": 1765
        },
        {
            "transformers.utils.dummy_pt_objects.Data2VecVisionForImageClassification.__init__": 1772
        },
        {
            "transformers.utils.dummy_pt_objects.Data2VecVisionForSemanticSegmentation.__init__": 1779
        },
        {
            "transformers.utils.dummy_pt_objects.Data2VecVisionModel.__init__": 1786
        },
        {
            "transformers.utils.dummy_pt_objects.Data2VecVisionPreTrainedModel.__init__": 1793
        },
        {
            "transformers.utils.dummy_pt_objects.DebertaForMaskedLM.__init__": 1803
        },
        {
            "transformers.utils.dummy_pt_objects.DebertaForQuestionAnswering.__init__": 1810
        },
        {
            "transformers.utils.dummy_pt_objects.DebertaForSequenceClassification.__init__": 1817
        },
        {
            "transformers.utils.dummy_pt_objects.DebertaForTokenClassification.__init__": 1824
        },
        {
            "transformers.utils.dummy_pt_objects.DebertaModel.__init__": 1831
        },
        {
            "transformers.utils.dummy_pt_objects.DebertaPreTrainedModel.__init__": 1838
        },
        {
            "transformers.utils.dummy_pt_objects.DebertaV2ForMaskedLM.__init__": 1848
        },
        {
            "transformers.utils.dummy_pt_objects.DebertaV2ForMultipleChoice.__init__": 1855
        },
        {
            "transformers.utils.dummy_pt_objects.DebertaV2ForQuestionAnswering.__init__": 1862
        },
        {
            "transformers.utils.dummy_pt_objects.DebertaV2ForSequenceClassification.__init__": 1869
        },
        {
            "transformers.utils.dummy_pt_objects.DebertaV2ForTokenClassification.__init__": 1876
        },
        {
            "transformers.utils.dummy_pt_objects.DebertaV2Model.__init__": 1883
        },
        {
            "transformers.utils.dummy_pt_objects.DebertaV2PreTrainedModel.__init__": 1890
        },
        {
            "transformers.utils.dummy_pt_objects.DecisionTransformerGPT2Model.__init__": 1900
        },
        {
            "transformers.utils.dummy_pt_objects.DecisionTransformerGPT2PreTrainedModel.__init__": 1907
        },
        {
            "transformers.utils.dummy_pt_objects.DecisionTransformerModel.__init__": 1914
        },
        {
            "transformers.utils.dummy_pt_objects.DecisionTransformerPreTrainedModel.__init__": 1921
        },
        {
            "transformers.utils.dummy_pt_objects.DeiTForImageClassification.__init__": 1931
        },
        {
            "transformers.utils.dummy_pt_objects.DeiTForImageClassificationWithTeacher.__init__": 1938
        },
        {
            "transformers.utils.dummy_pt_objects.DeiTForMaskedImageModeling.__init__": 1945
        },
        {
            "transformers.utils.dummy_pt_objects.DeiTModel.__init__": 1952
        },
        {
            "transformers.utils.dummy_pt_objects.DeiTPreTrainedModel.__init__": 1959
        },
        {
            "transformers.utils.dummy_pt_objects.DinatBackbone.__init__": 1969
        },
        {
            "transformers.utils.dummy_pt_objects.DinatForImageClassification.__init__": 1976
        },
        {
            "transformers.utils.dummy_pt_objects.DinatModel.__init__": 1983
        },
        {
            "transformers.utils.dummy_pt_objects.DinatPreTrainedModel.__init__": 1990
        },
        {
            "transformers.utils.dummy_pt_objects.DistilBertForMaskedLM.__init__": 2000
        },
        {
            "transformers.utils.dummy_pt_objects.DistilBertForMultipleChoice.__init__": 2007
        },
        {
            "transformers.utils.dummy_pt_objects.DistilBertForQuestionAnswering.__init__": 2014
        },
        {
            "transformers.utils.dummy_pt_objects.DistilBertForSequenceClassification.__init__": 2021
        },
        {
            "transformers.utils.dummy_pt_objects.DistilBertForTokenClassification.__init__": 2028
        },
        {
            "transformers.utils.dummy_pt_objects.DistilBertModel.__init__": 2035
        },
        {
            "transformers.utils.dummy_pt_objects.DistilBertPreTrainedModel.__init__": 2042
        },
        {
            "transformers.utils.dummy_pt_objects.DonutSwinModel.__init__": 2052
        },
        {
            "transformers.utils.dummy_pt_objects.DonutSwinPreTrainedModel.__init__": 2059
        },
        {
            "transformers.utils.dummy_pt_objects.DPRContextEncoder.__init__": 2075
        },
        {
            "transformers.utils.dummy_pt_objects.DPRPretrainedContextEncoder.__init__": 2082
        },
        {
            "transformers.utils.dummy_pt_objects.DPRPreTrainedModel.__init__": 2089
        },
        {
            "transformers.utils.dummy_pt_objects.DPRPretrainedQuestionEncoder.__init__": 2096
        },
        {
            "transformers.utils.dummy_pt_objects.DPRPretrainedReader.__init__": 2103
        },
        {
            "transformers.utils.dummy_pt_objects.DPRQuestionEncoder.__init__": 2110
        },
        {
            "transformers.utils.dummy_pt_objects.DPRReader.__init__": 2117
        },
        {
            "transformers.utils.dummy_pt_objects.DPTForDepthEstimation.__init__": 2127
        },
        {
            "transformers.utils.dummy_pt_objects.DPTForSemanticSegmentation.__init__": 2134
        },
        {
            "transformers.utils.dummy_pt_objects.DPTModel.__init__": 2141
        },
        {
            "transformers.utils.dummy_pt_objects.DPTPreTrainedModel.__init__": 2148
        },
        {
            "transformers.utils.dummy_pt_objects.EfficientFormerForImageClassification.__init__": 2158
        },
        {
            "transformers.utils.dummy_pt_objects.EfficientFormerForImageClassificationWithTeacher.__init__": 2165
        },
        {
            "transformers.utils.dummy_pt_objects.EfficientFormerModel.__init__": 2172
        },
        {
            "transformers.utils.dummy_pt_objects.EfficientFormerPreTrainedModel.__init__": 2179
        },
        {
            "transformers.utils.dummy_pt_objects.ElectraForCausalLM.__init__": 2189
        },
        {
            "transformers.utils.dummy_pt_objects.ElectraForMaskedLM.__init__": 2196
        },
        {
            "transformers.utils.dummy_pt_objects.ElectraForMultipleChoice.__init__": 2203
        },
        {
            "transformers.utils.dummy_pt_objects.ElectraForPreTraining.__init__": 2210
        },
        {
            "transformers.utils.dummy_pt_objects.ElectraForQuestionAnswering.__init__": 2217
        },
        {
            "transformers.utils.dummy_pt_objects.ElectraForSequenceClassification.__init__": 2224
        },
        {
            "transformers.utils.dummy_pt_objects.ElectraForTokenClassification.__init__": 2231
        },
        {
            "transformers.utils.dummy_pt_objects.ElectraModel.__init__": 2238
        },
        {
            "transformers.utils.dummy_pt_objects.ElectraPreTrainedModel.__init__": 2245
        },
        {
            "transformers.utils.dummy_pt_objects.load_tf_weights_in_electra": 2249
        },
        {
            "transformers.utils.dummy_pt_objects.EncoderDecoderModel.__init__": 2256
        },
        {
            "transformers.utils.dummy_pt_objects.ErnieForCausalLM.__init__": 2266
        },
        {
            "transformers.utils.dummy_pt_objects.ErnieForMaskedLM.__init__": 2273
        },
        {
            "transformers.utils.dummy_pt_objects.ErnieForMultipleChoice.__init__": 2280
        },
        {
            "transformers.utils.dummy_pt_objects.ErnieForNextSentencePrediction.__init__": 2287
        },
        {
            "transformers.utils.dummy_pt_objects.ErnieForPreTraining.__init__": 2294
        },
        {
            "transformers.utils.dummy_pt_objects.ErnieForQuestionAnswering.__init__": 2301
        },
        {
            "transformers.utils.dummy_pt_objects.ErnieForSequenceClassification.__init__": 2308
        },
        {
            "transformers.utils.dummy_pt_objects.ErnieForTokenClassification.__init__": 2315
        },
        {
            "transformers.utils.dummy_pt_objects.ErnieModel.__init__": 2322
        },
        {
            "transformers.utils.dummy_pt_objects.ErniePreTrainedModel.__init__": 2329
        },
        {
            "transformers.utils.dummy_pt_objects.EsmFoldPreTrainedModel.__init__": 2339
        },
        {
            "transformers.utils.dummy_pt_objects.EsmForMaskedLM.__init__": 2346
        },
        {
            "transformers.utils.dummy_pt_objects.EsmForProteinFolding.__init__": 2353
        },
        {
            "transformers.utils.dummy_pt_objects.EsmForSequenceClassification.__init__": 2360
        },
        {
            "transformers.utils.dummy_pt_objects.EsmForTokenClassification.__init__": 2367
        },
        {
            "transformers.utils.dummy_pt_objects.EsmModel.__init__": 2374
        },
        {
            "transformers.utils.dummy_pt_objects.EsmPreTrainedModel.__init__": 2381
        },
        {
            "transformers.utils.dummy_pt_objects.FlaubertForMultipleChoice.__init__": 2391
        },
        {
            "transformers.utils.dummy_pt_objects.FlaubertForQuestionAnswering.__init__": 2398
        },
        {
            "transformers.utils.dummy_pt_objects.FlaubertForQuestionAnsweringSimple.__init__": 2405
        },
        {
            "transformers.utils.dummy_pt_objects.FlaubertForSequenceClassification.__init__": 2412
        },
        {
            "transformers.utils.dummy_pt_objects.FlaubertForTokenClassification.__init__": 2419
        },
        {
            "transformers.utils.dummy_pt_objects.FlaubertModel.__init__": 2426
        },
        {
            "transformers.utils.dummy_pt_objects.FlaubertPreTrainedModel.__init__": 2433
        },
        {
            "transformers.utils.dummy_pt_objects.FlaubertWithLMHeadModel.__init__": 2440
        },
        {
            "transformers.utils.dummy_pt_objects.FlavaForPreTraining.__init__": 2450
        },
        {
            "transformers.utils.dummy_pt_objects.FlavaImageCodebook.__init__": 2457
        },
        {
            "transformers.utils.dummy_pt_objects.FlavaImageModel.__init__": 2464
        },
        {
            "transformers.utils.dummy_pt_objects.FlavaModel.__init__": 2471
        },
        {
            "transformers.utils.dummy_pt_objects.FlavaMultimodalModel.__init__": 2478
        },
        {
            "transformers.utils.dummy_pt_objects.FlavaPreTrainedModel.__init__": 2485
        },
        {
            "transformers.utils.dummy_pt_objects.FlavaTextModel.__init__": 2492
        },
        {
            "transformers.utils.dummy_pt_objects.FNetForMaskedLM.__init__": 2502
        },
        {
            "transformers.utils.dummy_pt_objects.FNetForMultipleChoice.__init__": 2509
        },
        {
            "transformers.utils.dummy_pt_objects.FNetForNextSentencePrediction.__init__": 2516
        },
        {
            "transformers.utils.dummy_pt_objects.FNetForPreTraining.__init__": 2523
        },
        {
            "transformers.utils.dummy_pt_objects.FNetForQuestionAnswering.__init__": 2530
        },
        {
            "transformers.utils.dummy_pt_objects.FNetForSequenceClassification.__init__": 2537
        },
        {
            "transformers.utils.dummy_pt_objects.FNetForTokenClassification.__init__": 2544
        },
        {
            "transformers.utils.dummy_pt_objects.FNetLayer.__init__": 2551
        },
        {
            "transformers.utils.dummy_pt_objects.FNetModel.__init__": 2558
        },
        {
            "transformers.utils.dummy_pt_objects.FNetPreTrainedModel.__init__": 2565
        },
        {
            "transformers.utils.dummy_pt_objects.FSMTForConditionalGeneration.__init__": 2572
        },
        {
            "transformers.utils.dummy_pt_objects.FSMTModel.__init__": 2579
        },
        {
            "transformers.utils.dummy_pt_objects.PretrainedFSMTModel.__init__": 2586
        },
        {
            "transformers.utils.dummy_pt_objects.FunnelBaseModel.__init__": 2596
        },
        {
            "transformers.utils.dummy_pt_objects.FunnelForMaskedLM.__init__": 2603
        },
        {
            "transformers.utils.dummy_pt_objects.FunnelForMultipleChoice.__init__": 2610
        },
        {
            "transformers.utils.dummy_pt_objects.FunnelForPreTraining.__init__": 2617
        },
        {
            "transformers.utils.dummy_pt_objects.FunnelForQuestionAnswering.__init__": 2624
        },
        {
            "transformers.utils.dummy_pt_objects.FunnelForSequenceClassification.__init__": 2631
        },
        {
            "transformers.utils.dummy_pt_objects.FunnelForTokenClassification.__init__": 2638
        },
        {
            "transformers.utils.dummy_pt_objects.FunnelModel.__init__": 2645
        },
        {
            "transformers.utils.dummy_pt_objects.FunnelPreTrainedModel.__init__": 2652
        },
        {
            "transformers.utils.dummy_pt_objects.load_tf_weights_in_funnel": 2656
        },
        {
            "transformers.utils.dummy_pt_objects.GitForCausalLM.__init__": 2666
        },
        {
            "transformers.utils.dummy_pt_objects.GitModel.__init__": 2673
        },
        {
            "transformers.utils.dummy_pt_objects.GitPreTrainedModel.__init__": 2680
        },
        {
            "transformers.utils.dummy_pt_objects.GitVisionModel.__init__": 2687
        },
        {
            "transformers.utils.dummy_pt_objects.GLPNForDepthEstimation.__init__": 2697
        },
        {
            "transformers.utils.dummy_pt_objects.GLPNModel.__init__": 2704
        },
        {
            "transformers.utils.dummy_pt_objects.GLPNPreTrainedModel.__init__": 2711
        },
        {
            "transformers.utils.dummy_pt_objects.GPT2DoubleHeadsModel.__init__": 2721
        },
        {
            "transformers.utils.dummy_pt_objects.GPT2ForSequenceClassification.__init__": 2728
        },
        {
            "transformers.utils.dummy_pt_objects.GPT2ForTokenClassification.__init__": 2735
        },
        {
            "transformers.utils.dummy_pt_objects.GPT2LMHeadModel.__init__": 2742
        },
        {
            "transformers.utils.dummy_pt_objects.GPT2Model.__init__": 2749
        },
        {
            "transformers.utils.dummy_pt_objects.GPT2PreTrainedModel.__init__": 2756
        },
        {
            "transformers.utils.dummy_pt_objects.load_tf_weights_in_gpt2": 2760
        },
        {
            "transformers.utils.dummy_pt_objects.GPTNeoForCausalLM.__init__": 2770
        },
        {
            "transformers.utils.dummy_pt_objects.GPTNeoForSequenceClassification.__init__": 2777
        },
        {
            "transformers.utils.dummy_pt_objects.GPTNeoModel.__init__": 2784
        },
        {
            "transformers.utils.dummy_pt_objects.GPTNeoPreTrainedModel.__init__": 2791
        },
        {
            "transformers.utils.dummy_pt_objects.load_tf_weights_in_gpt_neo": 2795
        },
        {
            "transformers.utils.dummy_pt_objects.GPTNeoXForCausalLM.__init__": 2805
        },
        {
            "transformers.utils.dummy_pt_objects.GPTNeoXLayer.__init__": 2812
        },
        {
            "transformers.utils.dummy_pt_objects.GPTNeoXModel.__init__": 2819
        },
        {
            "transformers.utils.dummy_pt_objects.GPTNeoXPreTrainedModel.__init__": 2826
        },
        {
            "transformers.utils.dummy_pt_objects.GPTNeoXJapaneseForCausalLM.__init__": 2836
        },
        {
            "transformers.utils.dummy_pt_objects.GPTNeoXJapaneseLayer.__init__": 2843
        },
        {
            "transformers.utils.dummy_pt_objects.GPTNeoXJapaneseModel.__init__": 2850
        },
        {
            "transformers.utils.dummy_pt_objects.GPTNeoXJapanesePreTrainedModel.__init__": 2857
        },
        {
            "transformers.utils.dummy_pt_objects.GPTJForCausalLM.__init__": 2867
        },
        {
            "transformers.utils.dummy_pt_objects.GPTJForQuestionAnswering.__init__": 2874
        },
        {
            "transformers.utils.dummy_pt_objects.GPTJForSequenceClassification.__init__": 2881
        },
        {
            "transformers.utils.dummy_pt_objects.GPTJModel.__init__": 2888
        },
        {
            "transformers.utils.dummy_pt_objects.GPTJPreTrainedModel.__init__": 2895
        },
        {
            "transformers.utils.dummy_pt_objects.GraphormerForGraphClassification.__init__": 2905
        },
        {
            "transformers.utils.dummy_pt_objects.GraphormerModel.__init__": 2912
        },
        {
            "transformers.utils.dummy_pt_objects.GraphormerPreTrainedModel.__init__": 2919
        },
        {
            "transformers.utils.dummy_pt_objects.GroupViTModel.__init__": 2929
        },
        {
            "transformers.utils.dummy_pt_objects.GroupViTPreTrainedModel.__init__": 2936
        },
        {
            "transformers.utils.dummy_pt_objects.GroupViTTextModel.__init__": 2943
        },
        {
            "transformers.utils.dummy_pt_objects.GroupViTVisionModel.__init__": 2950
        },
        {
            "transformers.utils.dummy_pt_objects.HubertForCTC.__init__": 2960
        },
        {
            "transformers.utils.dummy_pt_objects.HubertForSequenceClassification.__init__": 2967
        },
        {
            "transformers.utils.dummy_pt_objects.HubertModel.__init__": 2974
        },
        {
            "transformers.utils.dummy_pt_objects.HubertPreTrainedModel.__init__": 2981
        },
        {
            "transformers.utils.dummy_pt_objects.IBertForMaskedLM.__init__": 2991
        },
        {
            "transformers.utils.dummy_pt_objects.IBertForMultipleChoice.__init__": 2998
        },
        {
            "transformers.utils.dummy_pt_objects.IBertForQuestionAnswering.__init__": 3005
        },
        {
            "transformers.utils.dummy_pt_objects.IBertForSequenceClassification.__init__": 3012
        },
        {
            "transformers.utils.dummy_pt_objects.IBertForTokenClassification.__init__": 3019
        },
        {
            "transformers.utils.dummy_pt_objects.IBertModel.__init__": 3026
        },
        {
            "transformers.utils.dummy_pt_objects.IBertPreTrainedModel.__init__": 3033
        },
        {
            "transformers.utils.dummy_pt_objects.ImageGPTForCausalImageModeling.__init__": 3043
        },
        {
            "transformers.utils.dummy_pt_objects.ImageGPTForImageClassification.__init__": 3050
        },
        {
            "transformers.utils.dummy_pt_objects.ImageGPTModel.__init__": 3057
        },
        {
            "transformers.utils.dummy_pt_objects.ImageGPTPreTrainedModel.__init__": 3064
        },
        {
            "transformers.utils.dummy_pt_objects.load_tf_weights_in_imagegpt": 3068
        },
        {
            "transformers.utils.dummy_pt_objects.JukeboxModel.__init__": 3078
        },
        {
            "transformers.utils.dummy_pt_objects.JukeboxPreTrainedModel.__init__": 3085
        },
        {
            "transformers.utils.dummy_pt_objects.JukeboxPrior.__init__": 3092
        },
        {
            "transformers.utils.dummy_pt_objects.JukeboxVQVAE.__init__": 3099
        },
        {
            "transformers.utils.dummy_pt_objects.LayoutLMForMaskedLM.__init__": 3109
        },
        {
            "transformers.utils.dummy_pt_objects.LayoutLMForQuestionAnswering.__init__": 3116
        },
        {
            "transformers.utils.dummy_pt_objects.LayoutLMForSequenceClassification.__init__": 3123
        },
        {
            "transformers.utils.dummy_pt_objects.LayoutLMForTokenClassification.__init__": 3130
        },
        {
            "transformers.utils.dummy_pt_objects.LayoutLMModel.__init__": 3137
        },
        {
            "transformers.utils.dummy_pt_objects.LayoutLMPreTrainedModel.__init__": 3144
        },
        {
            "transformers.utils.dummy_pt_objects.LayoutLMv2ForQuestionAnswering.__init__": 3154
        },
        {
            "transformers.utils.dummy_pt_objects.LayoutLMv2ForSequenceClassification.__init__": 3161
        },
        {
            "transformers.utils.dummy_pt_objects.LayoutLMv2ForTokenClassification.__init__": 3168
        },
        {
            "transformers.utils.dummy_pt_objects.LayoutLMv2Model.__init__": 3175
        },
        {
            "transformers.utils.dummy_pt_objects.LayoutLMv2PreTrainedModel.__init__": 3182
        },
        {
            "transformers.utils.dummy_pt_objects.LayoutLMv3ForQuestionAnswering.__init__": 3192
        },
        {
            "transformers.utils.dummy_pt_objects.LayoutLMv3ForSequenceClassification.__init__": 3199
        },
        {
            "transformers.utils.dummy_pt_objects.LayoutLMv3ForTokenClassification.__init__": 3206
        },
        {
            "transformers.utils.dummy_pt_objects.LayoutLMv3Model.__init__": 3213
        },
        {
            "transformers.utils.dummy_pt_objects.LayoutLMv3PreTrainedModel.__init__": 3220
        },
        {
            "transformers.utils.dummy_pt_objects.LEDForConditionalGeneration.__init__": 3230
        },
        {
            "transformers.utils.dummy_pt_objects.LEDForQuestionAnswering.__init__": 3237
        },
        {
            "transformers.utils.dummy_pt_objects.LEDForSequenceClassification.__init__": 3244
        },
        {
            "transformers.utils.dummy_pt_objects.LEDModel.__init__": 3251
        },
        {
            "transformers.utils.dummy_pt_objects.LEDPreTrainedModel.__init__": 3258
        },
        {
            "transformers.utils.dummy_pt_objects.LevitForImageClassification.__init__": 3268
        },
        {
            "transformers.utils.dummy_pt_objects.LevitForImageClassificationWithTeacher.__init__": 3275
        },
        {
            "transformers.utils.dummy_pt_objects.LevitModel.__init__": 3282
        },
        {
            "transformers.utils.dummy_pt_objects.LevitPreTrainedModel.__init__": 3289
        },
        {
            "transformers.utils.dummy_pt_objects.LiltForQuestionAnswering.__init__": 3299
        },
        {
            "transformers.utils.dummy_pt_objects.LiltForSequenceClassification.__init__": 3306
        },
        {
            "transformers.utils.dummy_pt_objects.LiltForTokenClassification.__init__": 3313
        },
        {
            "transformers.utils.dummy_pt_objects.LiltModel.__init__": 3320
        },
        {
            "transformers.utils.dummy_pt_objects.LiltPreTrainedModel.__init__": 3327
        },
        {
            "transformers.utils.dummy_pt_objects.LongformerForMaskedLM.__init__": 3337
        },
        {
            "transformers.utils.dummy_pt_objects.LongformerForMultipleChoice.__init__": 3344
        },
        {
            "transformers.utils.dummy_pt_objects.LongformerForQuestionAnswering.__init__": 3351
        },
        {
            "transformers.utils.dummy_pt_objects.LongformerForSequenceClassification.__init__": 3358
        },
        {
            "transformers.utils.dummy_pt_objects.LongformerForTokenClassification.__init__": 3365
        },
        {
            "transformers.utils.dummy_pt_objects.LongformerModel.__init__": 3372
        },
        {
            "transformers.utils.dummy_pt_objects.LongformerPreTrainedModel.__init__": 3379
        },
        {
            "transformers.utils.dummy_pt_objects.LongformerSelfAttention.__init__": 3386
        },
        {
            "transformers.utils.dummy_pt_objects.LongT5EncoderModel.__init__": 3396
        },
        {
            "transformers.utils.dummy_pt_objects.LongT5ForConditionalGeneration.__init__": 3403
        },
        {
            "transformers.utils.dummy_pt_objects.LongT5Model.__init__": 3410
        },
        {
            "transformers.utils.dummy_pt_objects.LongT5PreTrainedModel.__init__": 3417
        },
        {
            "transformers.utils.dummy_pt_objects.LukeForEntityClassification.__init__": 3427
        },
        {
            "transformers.utils.dummy_pt_objects.LukeForEntityPairClassification.__init__": 3434
        },
        {
            "transformers.utils.dummy_pt_objects.LukeForEntitySpanClassification.__init__": 3441
        },
        {
            "transformers.utils.dummy_pt_objects.LukeForMaskedLM.__init__": 3448
        },
        {
            "transformers.utils.dummy_pt_objects.LukeForMultipleChoice.__init__": 3455
        },
        {
            "transformers.utils.dummy_pt_objects.LukeForQuestionAnswering.__init__": 3462
        },
        {
            "transformers.utils.dummy_pt_objects.LukeForSequenceClassification.__init__": 3469
        },
        {
            "transformers.utils.dummy_pt_objects.LukeForTokenClassification.__init__": 3476
        },
        {
            "transformers.utils.dummy_pt_objects.LukeModel.__init__": 3483
        },
        {
            "transformers.utils.dummy_pt_objects.LukePreTrainedModel.__init__": 3490
        },
        {
            "transformers.utils.dummy_pt_objects.LxmertEncoder.__init__": 3497
        },
        {
            "transformers.utils.dummy_pt_objects.LxmertForPreTraining.__init__": 3504
        },
        {
            "transformers.utils.dummy_pt_objects.LxmertForQuestionAnswering.__init__": 3511
        },
        {
            "transformers.utils.dummy_pt_objects.LxmertModel.__init__": 3518
        },
        {
            "transformers.utils.dummy_pt_objects.LxmertPreTrainedModel.__init__": 3525
        },
        {
            "transformers.utils.dummy_pt_objects.LxmertVisualFeatureEncoder.__init__": 3532
        },
        {
            "transformers.utils.dummy_pt_objects.LxmertXLayer.__init__": 3539
        },
        {
            "transformers.utils.dummy_pt_objects.M2M100ForConditionalGeneration.__init__": 3549
        },
        {
            "transformers.utils.dummy_pt_objects.M2M100Model.__init__": 3556
        },
        {
            "transformers.utils.dummy_pt_objects.M2M100PreTrainedModel.__init__": 3563
        },
        {
            "transformers.utils.dummy_pt_objects.MarianForCausalLM.__init__": 3570
        },
        {
            "transformers.utils.dummy_pt_objects.MarianModel.__init__": 3577
        },
        {
            "transformers.utils.dummy_pt_objects.MarianMTModel.__init__": 3584
        },
        {
            "transformers.utils.dummy_pt_objects.MarkupLMForQuestionAnswering.__init__": 3594
        },
        {
            "transformers.utils.dummy_pt_objects.MarkupLMForSequenceClassification.__init__": 3601
        },
        {
            "transformers.utils.dummy_pt_objects.MarkupLMForTokenClassification.__init__": 3608
        },
        {
            "transformers.utils.dummy_pt_objects.MarkupLMModel.__init__": 3615
        },
        {
            "transformers.utils.dummy_pt_objects.MarkupLMPreTrainedModel.__init__": 3622
        },
        {
            "transformers.utils.dummy_pt_objects.Mask2FormerForUniversalSegmentation.__init__": 3632
        },
        {
            "transformers.utils.dummy_pt_objects.Mask2FormerModel.__init__": 3639
        },
        {
            "transformers.utils.dummy_pt_objects.Mask2FormerPreTrainedModel.__init__": 3646
        },
        {
            "transformers.utils.dummy_pt_objects.MaskFormerForInstanceSegmentation.__init__": 3656
        },
        {
            "transformers.utils.dummy_pt_objects.MaskFormerModel.__init__": 3663
        },
        {
            "transformers.utils.dummy_pt_objects.MaskFormerPreTrainedModel.__init__": 3670
        },
        {
            "transformers.utils.dummy_pt_objects.MaskFormerSwinBackbone.__init__": 3677
        },
        {
            "transformers.utils.dummy_pt_objects.MBartForCausalLM.__init__": 3684
        },
        {
            "transformers.utils.dummy_pt_objects.MBartForConditionalGeneration.__init__": 3691
        },
        {
            "transformers.utils.dummy_pt_objects.MBartForQuestionAnswering.__init__": 3698
        },
        {
            "transformers.utils.dummy_pt_objects.MBartForSequenceClassification.__init__": 3705
        },
        {
            "transformers.utils.dummy_pt_objects.MBartModel.__init__": 3712
        },
        {
            "transformers.utils.dummy_pt_objects.MBartPreTrainedModel.__init__": 3719
        },
        {
            "transformers.utils.dummy_pt_objects.MCTCTForCTC.__init__": 3729
        },
        {
            "transformers.utils.dummy_pt_objects.MCTCTModel.__init__": 3736
        },
        {
            "transformers.utils.dummy_pt_objects.MCTCTPreTrainedModel.__init__": 3743
        },
        {
            "transformers.utils.dummy_pt_objects.MegatronBertForCausalLM.__init__": 3753
        },
        {
            "transformers.utils.dummy_pt_objects.MegatronBertForMaskedLM.__init__": 3760
        },
        {
            "transformers.utils.dummy_pt_objects.MegatronBertForMultipleChoice.__init__": 3767
        },
        {
            "transformers.utils.dummy_pt_objects.MegatronBertForNextSentencePrediction.__init__": 3774
        },
        {
            "transformers.utils.dummy_pt_objects.MegatronBertForPreTraining.__init__": 3781
        },
        {
            "transformers.utils.dummy_pt_objects.MegatronBertForQuestionAnswering.__init__": 3788
        },
        {
            "transformers.utils.dummy_pt_objects.MegatronBertForSequenceClassification.__init__": 3795
        },
        {
            "transformers.utils.dummy_pt_objects.MegatronBertForTokenClassification.__init__": 3802
        },
        {
            "transformers.utils.dummy_pt_objects.MegatronBertModel.__init__": 3809
        },
        {
            "transformers.utils.dummy_pt_objects.MegatronBertPreTrainedModel.__init__": 3816
        },
        {
            "transformers.utils.dummy_pt_objects.MMBTForClassification.__init__": 3823
        },
        {
            "transformers.utils.dummy_pt_objects.MMBTModel.__init__": 3830
        },
        {
            "transformers.utils.dummy_pt_objects.ModalEmbeddings.__init__": 3837
        },
        {
            "transformers.utils.dummy_pt_objects.MobileBertForMaskedLM.__init__": 3847
        },
        {
            "transformers.utils.dummy_pt_objects.MobileBertForMultipleChoice.__init__": 3854
        },
        {
            "transformers.utils.dummy_pt_objects.MobileBertForNextSentencePrediction.__init__": 3861
        },
        {
            "transformers.utils.dummy_pt_objects.MobileBertForPreTraining.__init__": 3868
        },
        {
            "transformers.utils.dummy_pt_objects.MobileBertForQuestionAnswering.__init__": 3875
        },
        {
            "transformers.utils.dummy_pt_objects.MobileBertForSequenceClassification.__init__": 3882
        },
        {
            "transformers.utils.dummy_pt_objects.MobileBertForTokenClassification.__init__": 3889
        },
        {
            "transformers.utils.dummy_pt_objects.MobileBertLayer.__init__": 3896
        },
        {
            "transformers.utils.dummy_pt_objects.MobileBertModel.__init__": 3903
        },
        {
            "transformers.utils.dummy_pt_objects.MobileBertPreTrainedModel.__init__": 3910
        },
        {
            "transformers.utils.dummy_pt_objects.load_tf_weights_in_mobilebert": 3914
        },
        {
            "transformers.utils.dummy_pt_objects.MobileNetV1ForImageClassification.__init__": 3924
        },
        {
            "transformers.utils.dummy_pt_objects.MobileNetV1Model.__init__": 3931
        },
        {
            "transformers.utils.dummy_pt_objects.MobileNetV1PreTrainedModel.__init__": 3938
        },
        {
            "transformers.utils.dummy_pt_objects.load_tf_weights_in_mobilenet_v1": 3942
        },
        {
            "transformers.utils.dummy_pt_objects.MobileNetV2ForImageClassification.__init__": 3952
        },
        {
            "transformers.utils.dummy_pt_objects.MobileNetV2ForSemanticSegmentation.__init__": 3959
        },
        {
            "transformers.utils.dummy_pt_objects.MobileNetV2Model.__init__": 3966
        },
        {
            "transformers.utils.dummy_pt_objects.MobileNetV2PreTrainedModel.__init__": 3973
        },
        {
            "transformers.utils.dummy_pt_objects.load_tf_weights_in_mobilenet_v2": 3977
        },
        {
            "transformers.utils.dummy_pt_objects.MobileViTForImageClassification.__init__": 3987
        },
        {
            "transformers.utils.dummy_pt_objects.MobileViTForSemanticSegmentation.__init__": 3994
        },
        {
            "transformers.utils.dummy_pt_objects.MobileViTModel.__init__": 4001
        },
        {
            "transformers.utils.dummy_pt_objects.MobileViTPreTrainedModel.__init__": 4008
        },
        {
            "transformers.utils.dummy_pt_objects.MPNetForMaskedLM.__init__": 4018
        },
        {
            "transformers.utils.dummy_pt_objects.MPNetForMultipleChoice.__init__": 4025
        },
        {
            "transformers.utils.dummy_pt_objects.MPNetForQuestionAnswering.__init__": 4032
        },
        {
            "transformers.utils.dummy_pt_objects.MPNetForSequenceClassification.__init__": 4039
        },
        {
            "transformers.utils.dummy_pt_objects.MPNetForTokenClassification.__init__": 4046
        },
        {
            "transformers.utils.dummy_pt_objects.MPNetLayer.__init__": 4053
        },
        {
            "transformers.utils.dummy_pt_objects.MPNetModel.__init__": 4060
        },
        {
            "transformers.utils.dummy_pt_objects.MPNetPreTrainedModel.__init__": 4067
        },
        {
            "transformers.utils.dummy_pt_objects.MT5EncoderModel.__init__": 4074
        },
        {
            "transformers.utils.dummy_pt_objects.MT5ForConditionalGeneration.__init__": 4081
        },
        {
            "transformers.utils.dummy_pt_objects.MT5Model.__init__": 4088
        },
        {
            "transformers.utils.dummy_pt_objects.MT5PreTrainedModel.__init__": 4095
        },
        {
            "transformers.utils.dummy_pt_objects.MvpForCausalLM.__init__": 4105
        },
        {
            "transformers.utils.dummy_pt_objects.MvpForConditionalGeneration.__init__": 4112
        },
        {
            "transformers.utils.dummy_pt_objects.MvpForQuestionAnswering.__init__": 4119
        },
        {
            "transformers.utils.dummy_pt_objects.MvpForSequenceClassification.__init__": 4126
        },
        {
            "transformers.utils.dummy_pt_objects.MvpModel.__init__": 4133
        },
        {
            "transformers.utils.dummy_pt_objects.MvpPreTrainedModel.__init__": 4140
        },
        {
            "transformers.utils.dummy_pt_objects.NatBackbone.__init__": 4150
        },
        {
            "transformers.utils.dummy_pt_objects.NatForImageClassification.__init__": 4157
        },
        {
            "transformers.utils.dummy_pt_objects.NatModel.__init__": 4164
        },
        {
            "transformers.utils.dummy_pt_objects.NatPreTrainedModel.__init__": 4171
        },
        {
            "transformers.utils.dummy_pt_objects.NezhaForMaskedLM.__init__": 4181
        },
        {
            "transformers.utils.dummy_pt_objects.NezhaForMultipleChoice.__init__": 4188
        },
        {
            "transformers.utils.dummy_pt_objects.NezhaForNextSentencePrediction.__init__": 4195
        },
        {
            "transformers.utils.dummy_pt_objects.NezhaForPreTraining.__init__": 4202
        },
        {
            "transformers.utils.dummy_pt_objects.NezhaForQuestionAnswering.__init__": 4209
        },
        {
            "transformers.utils.dummy_pt_objects.NezhaForSequenceClassification.__init__": 4216
        },
        {
            "transformers.utils.dummy_pt_objects.NezhaForTokenClassification.__init__": 4223
        },
        {
            "transformers.utils.dummy_pt_objects.NezhaModel.__init__": 4230
        },
        {
            "transformers.utils.dummy_pt_objects.NezhaPreTrainedModel.__init__": 4237
        },
        {
            "transformers.utils.dummy_pt_objects.NystromformerForMaskedLM.__init__": 4247
        },
        {
            "transformers.utils.dummy_pt_objects.NystromformerForMultipleChoice.__init__": 4254
        },
        {
            "transformers.utils.dummy_pt_objects.NystromformerForQuestionAnswering.__init__": 4261
        },
        {
            "transformers.utils.dummy_pt_objects.NystromformerForSequenceClassification.__init__": 4268
        },
        {
            "transformers.utils.dummy_pt_objects.NystromformerForTokenClassification.__init__": 4275
        },
        {
            "transformers.utils.dummy_pt_objects.NystromformerLayer.__init__": 4282
        },
        {
            "transformers.utils.dummy_pt_objects.NystromformerModel.__init__": 4289
        },
        {
            "transformers.utils.dummy_pt_objects.NystromformerPreTrainedModel.__init__": 4296
        },
        {
            "transformers.utils.dummy_pt_objects.OneFormerForUniversalSegmentation.__init__": 4306
        },
        {
            "transformers.utils.dummy_pt_objects.OneFormerModel.__init__": 4313
        },
        {
            "transformers.utils.dummy_pt_objects.OneFormerPreTrainedModel.__init__": 4320
        },
        {
            "transformers.utils.dummy_pt_objects.OpenAIGPTDoubleHeadsModel.__init__": 4330
        },
        {
            "transformers.utils.dummy_pt_objects.OpenAIGPTForSequenceClassification.__init__": 4337
        },
        {
            "transformers.utils.dummy_pt_objects.OpenAIGPTLMHeadModel.__init__": 4344
        },
        {
            "transformers.utils.dummy_pt_objects.OpenAIGPTModel.__init__": 4351
        },
        {
            "transformers.utils.dummy_pt_objects.OpenAIGPTPreTrainedModel.__init__": 4358
        },
        {
            "transformers.utils.dummy_pt_objects.load_tf_weights_in_openai_gpt": 4362
        },
        {
            "transformers.utils.dummy_pt_objects.OPTForCausalLM.__init__": 4372
        },
        {
            "transformers.utils.dummy_pt_objects.OPTForQuestionAnswering.__init__": 4379
        },
        {
            "transformers.utils.dummy_pt_objects.OPTForSequenceClassification.__init__": 4386
        },
        {
            "transformers.utils.dummy_pt_objects.OPTModel.__init__": 4393
        },
        {
            "transformers.utils.dummy_pt_objects.OPTPreTrainedModel.__init__": 4400
        },
        {
            "transformers.utils.dummy_pt_objects.OwlViTForObjectDetection.__init__": 4410
        },
        {
            "transformers.utils.dummy_pt_objects.OwlViTModel.__init__": 4417
        },
        {
            "transformers.utils.dummy_pt_objects.OwlViTPreTrainedModel.__init__": 4424
        },
        {
            "transformers.utils.dummy_pt_objects.OwlViTTextModel.__init__": 4431
        },
        {
            "transformers.utils.dummy_pt_objects.OwlViTVisionModel.__init__": 4438
        },
        {
            "transformers.utils.dummy_pt_objects.PegasusForCausalLM.__init__": 4445
        },
        {
            "transformers.utils.dummy_pt_objects.PegasusForConditionalGeneration.__init__": 4452
        },
        {
            "transformers.utils.dummy_pt_objects.PegasusModel.__init__": 4459
        },
        {
            "transformers.utils.dummy_pt_objects.PegasusPreTrainedModel.__init__": 4466
        },
        {
            "transformers.utils.dummy_pt_objects.PegasusXForConditionalGeneration.__init__": 4476
        },
        {
            "transformers.utils.dummy_pt_objects.PegasusXModel.__init__": 4483
        },
        {
            "transformers.utils.dummy_pt_objects.PegasusXPreTrainedModel.__init__": 4490
        },
        {
            "transformers.utils.dummy_pt_objects.PerceiverForImageClassificationConvProcessing.__init__": 4500
        },
        {
            "transformers.utils.dummy_pt_objects.PerceiverForImageClassificationFourier.__init__": 4507
        },
        {
            "transformers.utils.dummy_pt_objects.PerceiverForImageClassificationLearned.__init__": 4514
        },
        {
            "transformers.utils.dummy_pt_objects.PerceiverForMaskedLM.__init__": 4521
        },
        {
            "transformers.utils.dummy_pt_objects.PerceiverForMultimodalAutoencoding.__init__": 4528
        },
        {
            "transformers.utils.dummy_pt_objects.PerceiverForOpticalFlow.__init__": 4535
        },
        {
            "transformers.utils.dummy_pt_objects.PerceiverForSequenceClassification.__init__": 4542
        },
        {
            "transformers.utils.dummy_pt_objects.PerceiverLayer.__init__": 4549
        },
        {
            "transformers.utils.dummy_pt_objects.PerceiverModel.__init__": 4556
        },
        {
            "transformers.utils.dummy_pt_objects.PerceiverPreTrainedModel.__init__": 4563
        },
        {
            "transformers.utils.dummy_pt_objects.PLBartForCausalLM.__init__": 4573
        },
        {
            "transformers.utils.dummy_pt_objects.PLBartForConditionalGeneration.__init__": 4580
        },
        {
            "transformers.utils.dummy_pt_objects.PLBartForSequenceClassification.__init__": 4587
        },
        {
            "transformers.utils.dummy_pt_objects.PLBartModel.__init__": 4594
        },
        {
            "transformers.utils.dummy_pt_objects.PLBartPreTrainedModel.__init__": 4601
        },
        {
            "transformers.utils.dummy_pt_objects.PoolFormerForImageClassification.__init__": 4611
        },
        {
            "transformers.utils.dummy_pt_objects.PoolFormerModel.__init__": 4618
        },
        {
            "transformers.utils.dummy_pt_objects.PoolFormerPreTrainedModel.__init__": 4625
        },
        {
            "transformers.utils.dummy_pt_objects.ProphetNetDecoder.__init__": 4635
        },
        {
            "transformers.utils.dummy_pt_objects.ProphetNetEncoder.__init__": 4642
        },
        {
            "transformers.utils.dummy_pt_objects.ProphetNetForCausalLM.__init__": 4649
        },
        {
            "transformers.utils.dummy_pt_objects.ProphetNetForConditionalGeneration.__init__": 4656
        },
        {
            "transformers.utils.dummy_pt_objects.ProphetNetModel.__init__": 4663
        },
        {
            "transformers.utils.dummy_pt_objects.ProphetNetPreTrainedModel.__init__": 4670
        },
        {
            "transformers.utils.dummy_pt_objects.QDQBertForMaskedLM.__init__": 4680
        },
        {
            "transformers.utils.dummy_pt_objects.QDQBertForMultipleChoice.__init__": 4687
        },
        {
            "transformers.utils.dummy_pt_objects.QDQBertForNextSentencePrediction.__init__": 4694
        },
        {
            "transformers.utils.dummy_pt_objects.QDQBertForQuestionAnswering.__init__": 4701
        },
        {
            "transformers.utils.dummy_pt_objects.QDQBertForSequenceClassification.__init__": 4708
        },
        {
            "transformers.utils.dummy_pt_objects.QDQBertForTokenClassification.__init__": 4715
        },
        {
            "transformers.utils.dummy_pt_objects.QDQBertLayer.__init__": 4722
        },
        {
            "transformers.utils.dummy_pt_objects.QDQBertLMHeadModel.__init__": 4729
        },
        {
            "transformers.utils.dummy_pt_objects.QDQBertModel.__init__": 4736
        },
        {
            "transformers.utils.dummy_pt_objects.QDQBertPreTrainedModel.__init__": 4743
        },
        {
            "transformers.utils.dummy_pt_objects.load_tf_weights_in_qdqbert": 4747
        },
        {
            "transformers.utils.dummy_pt_objects.RagModel.__init__": 4754
        },
        {
            "transformers.utils.dummy_pt_objects.RagPreTrainedModel.__init__": 4761
        },
        {
            "transformers.utils.dummy_pt_objects.RagSequenceForGeneration.__init__": 4768
        },
        {
            "transformers.utils.dummy_pt_objects.RagTokenForGeneration.__init__": 4775
        },
        {
            "transformers.utils.dummy_pt_objects.RealmEmbedder.__init__": 4785
        },
        {
            "transformers.utils.dummy_pt_objects.RealmForOpenQA.__init__": 4792
        },
        {
            "transformers.utils.dummy_pt_objects.RealmKnowledgeAugEncoder.__init__": 4799
        },
        {
            "transformers.utils.dummy_pt_objects.RealmPreTrainedModel.__init__": 4806
        },
        {
            "transformers.utils.dummy_pt_objects.RealmReader.__init__": 4813
        },
        {
            "transformers.utils.dummy_pt_objects.RealmRetriever.__init__": 4820
        },
        {
            "transformers.utils.dummy_pt_objects.RealmScorer.__init__": 4827
        },
        {
            "transformers.utils.dummy_pt_objects.load_tf_weights_in_realm": 4831
        },
        {
            "transformers.utils.dummy_pt_objects.ReformerAttention.__init__": 4841
        },
        {
            "transformers.utils.dummy_pt_objects.ReformerForMaskedLM.__init__": 4848
        },
        {
            "transformers.utils.dummy_pt_objects.ReformerForQuestionAnswering.__init__": 4855
        },
        {
            "transformers.utils.dummy_pt_objects.ReformerForSequenceClassification.__init__": 4862
        },
        {
            "transformers.utils.dummy_pt_objects.ReformerLayer.__init__": 4869
        },
        {
            "transformers.utils.dummy_pt_objects.ReformerModel.__init__": 4876
        },
        {
            "transformers.utils.dummy_pt_objects.ReformerModelWithLMHead.__init__": 4883
        },
        {
            "transformers.utils.dummy_pt_objects.ReformerPreTrainedModel.__init__": 4890
        },
        {
            "transformers.utils.dummy_pt_objects.RegNetForImageClassification.__init__": 4900
        },
        {
            "transformers.utils.dummy_pt_objects.RegNetModel.__init__": 4907
        },
        {
            "transformers.utils.dummy_pt_objects.RegNetPreTrainedModel.__init__": 4914
        },
        {
            "transformers.utils.dummy_pt_objects.RemBertForCausalLM.__init__": 4924
        },
        {
            "transformers.utils.dummy_pt_objects.RemBertForMaskedLM.__init__": 4931
        },
        {
            "transformers.utils.dummy_pt_objects.RemBertForMultipleChoice.__init__": 4938
        },
        {
            "transformers.utils.dummy_pt_objects.RemBertForQuestionAnswering.__init__": 4945
        },
        {
            "transformers.utils.dummy_pt_objects.RemBertForSequenceClassification.__init__": 4952
        },
        {
            "transformers.utils.dummy_pt_objects.RemBertForTokenClassification.__init__": 4959
        },
        {
            "transformers.utils.dummy_pt_objects.RemBertLayer.__init__": 4966
        },
        {
            "transformers.utils.dummy_pt_objects.RemBertModel.__init__": 4973
        },
        {
            "transformers.utils.dummy_pt_objects.RemBertPreTrainedModel.__init__": 4980
        },
        {
            "transformers.utils.dummy_pt_objects.load_tf_weights_in_rembert": 4984
        },
        {
            "transformers.utils.dummy_pt_objects.ResNetBackbone.__init__": 4994
        },
        {
            "transformers.utils.dummy_pt_objects.ResNetForImageClassification.__init__": 5001
        },
        {
            "transformers.utils.dummy_pt_objects.ResNetModel.__init__": 5008
        },
        {
            "transformers.utils.dummy_pt_objects.ResNetPreTrainedModel.__init__": 5015
        },
        {
            "transformers.utils.dummy_pt_objects.RetriBertModel.__init__": 5025
        },
        {
            "transformers.utils.dummy_pt_objects.RetriBertPreTrainedModel.__init__": 5032
        },
        {
            "transformers.utils.dummy_pt_objects.RobertaForCausalLM.__init__": 5042
        },
        {
            "transformers.utils.dummy_pt_objects.RobertaForMaskedLM.__init__": 5049
        },
        {
            "transformers.utils.dummy_pt_objects.RobertaForMultipleChoice.__init__": 5056
        },
        {
            "transformers.utils.dummy_pt_objects.RobertaForQuestionAnswering.__init__": 5063
        },
        {
            "transformers.utils.dummy_pt_objects.RobertaForSequenceClassification.__init__": 5070
        },
        {
            "transformers.utils.dummy_pt_objects.RobertaForTokenClassification.__init__": 5077
        },
        {
            "transformers.utils.dummy_pt_objects.RobertaModel.__init__": 5084
        },
        {
            "transformers.utils.dummy_pt_objects.RobertaPreTrainedModel.__init__": 5091
        },
        {
            "transformers.utils.dummy_pt_objects.RobertaPreLayerNormForCausalLM.__init__": 5101
        },
        {
            "transformers.utils.dummy_pt_objects.RobertaPreLayerNormForMaskedLM.__init__": 5108
        },
        {
            "transformers.utils.dummy_pt_objects.RobertaPreLayerNormForMultipleChoice.__init__": 5115
        },
        {
            "transformers.utils.dummy_pt_objects.RobertaPreLayerNormForQuestionAnswering.__init__": 5122
        },
        {
            "transformers.utils.dummy_pt_objects.RobertaPreLayerNormForSequenceClassification.__init__": 5129
        },
        {
            "transformers.utils.dummy_pt_objects.RobertaPreLayerNormForTokenClassification.__init__": 5136
        },
        {
            "transformers.utils.dummy_pt_objects.RobertaPreLayerNormModel.__init__": 5143
        },
        {
            "transformers.utils.dummy_pt_objects.RobertaPreLayerNormPreTrainedModel.__init__": 5150
        },
        {
            "transformers.utils.dummy_pt_objects.RoCBertForCausalLM.__init__": 5160
        },
        {
            "transformers.utils.dummy_pt_objects.RoCBertForMaskedLM.__init__": 5167
        },
        {
            "transformers.utils.dummy_pt_objects.RoCBertForMultipleChoice.__init__": 5174
        },
        {
            "transformers.utils.dummy_pt_objects.RoCBertForPreTraining.__init__": 5181
        },
        {
            "transformers.utils.dummy_pt_objects.RoCBertForQuestionAnswering.__init__": 5188
        },
        {
            "transformers.utils.dummy_pt_objects.RoCBertForSequenceClassification.__init__": 5195
        },
        {
            "transformers.utils.dummy_pt_objects.RoCBertForTokenClassification.__init__": 5202
        },
        {
            "transformers.utils.dummy_pt_objects.RoCBertLayer.__init__": 5209
        },
        {
            "transformers.utils.dummy_pt_objects.RoCBertModel.__init__": 5216
        },
        {
            "transformers.utils.dummy_pt_objects.RoCBertPreTrainedModel.__init__": 5223
        },
        {
            "transformers.utils.dummy_pt_objects.load_tf_weights_in_roc_bert": 5227
        },
        {
            "transformers.utils.dummy_pt_objects.RoFormerForCausalLM.__init__": 5237
        },
        {
            "transformers.utils.dummy_pt_objects.RoFormerForMaskedLM.__init__": 5244
        },
        {
            "transformers.utils.dummy_pt_objects.RoFormerForMultipleChoice.__init__": 5251
        },
        {
            "transformers.utils.dummy_pt_objects.RoFormerForQuestionAnswering.__init__": 5258
        },
        {
            "transformers.utils.dummy_pt_objects.RoFormerForSequenceClassification.__init__": 5265
        },
        {
            "transformers.utils.dummy_pt_objects.RoFormerForTokenClassification.__init__": 5272
        },
        {
            "transformers.utils.dummy_pt_objects.RoFormerLayer.__init__": 5279
        },
        {
            "transformers.utils.dummy_pt_objects.RoFormerModel.__init__": 5286
        },
        {
            "transformers.utils.dummy_pt_objects.RoFormerPreTrainedModel.__init__": 5293
        },
        {
            "transformers.utils.dummy_pt_objects.load_tf_weights_in_roformer": 5297
        },
        {
            "transformers.utils.dummy_pt_objects.SegformerDecodeHead.__init__": 5307
        },
        {
            "transformers.utils.dummy_pt_objects.SegformerForImageClassification.__init__": 5314
        },
        {
            "transformers.utils.dummy_pt_objects.SegformerForSemanticSegmentation.__init__": 5321
        },
        {
            "transformers.utils.dummy_pt_objects.SegformerLayer.__init__": 5328
        },
        {
            "transformers.utils.dummy_pt_objects.SegformerModel.__init__": 5335
        },
        {
            "transformers.utils.dummy_pt_objects.SegformerPreTrainedModel.__init__": 5342
        },
        {
            "transformers.utils.dummy_pt_objects.SEWForCTC.__init__": 5352
        },
        {
            "transformers.utils.dummy_pt_objects.SEWForSequenceClassification.__init__": 5359
        },
        {
            "transformers.utils.dummy_pt_objects.SEWModel.__init__": 5366
        },
        {
            "transformers.utils.dummy_pt_objects.SEWPreTrainedModel.__init__": 5373
        },
        {
            "transformers.utils.dummy_pt_objects.SEWDForCTC.__init__": 5383
        },
        {
            "transformers.utils.dummy_pt_objects.SEWDForSequenceClassification.__init__": 5390
        },
        {
            "transformers.utils.dummy_pt_objects.SEWDModel.__init__": 5397
        },
        {
            "transformers.utils.dummy_pt_objects.SEWDPreTrainedModel.__init__": 5404
        },
        {
            "transformers.utils.dummy_pt_objects.SpeechEncoderDecoderModel.__init__": 5411
        },
        {
            "transformers.utils.dummy_pt_objects.Speech2TextForConditionalGeneration.__init__": 5421
        },
        {
            "transformers.utils.dummy_pt_objects.Speech2TextModel.__init__": 5428
        },
        {
            "transformers.utils.dummy_pt_objects.Speech2TextPreTrainedModel.__init__": 5435
        },
        {
            "transformers.utils.dummy_pt_objects.Speech2Text2ForCausalLM.__init__": 5442
        },
        {
            "transformers.utils.dummy_pt_objects.Speech2Text2PreTrainedModel.__init__": 5449
        },
        {
            "transformers.utils.dummy_pt_objects.SplinterForPreTraining.__init__": 5459
        },
        {
            "transformers.utils.dummy_pt_objects.SplinterForQuestionAnswering.__init__": 5466
        },
        {
            "transformers.utils.dummy_pt_objects.SplinterLayer.__init__": 5473
        },
        {
            "transformers.utils.dummy_pt_objects.SplinterModel.__init__": 5480
        },
        {
            "transformers.utils.dummy_pt_objects.SplinterPreTrainedModel.__init__": 5487
        },
        {
            "transformers.utils.dummy_pt_objects.SqueezeBertForMaskedLM.__init__": 5497
        },
        {
            "transformers.utils.dummy_pt_objects.SqueezeBertForMultipleChoice.__init__": 5504
        },
        {
            "transformers.utils.dummy_pt_objects.SqueezeBertForQuestionAnswering.__init__": 5511
        },
        {
            "transformers.utils.dummy_pt_objects.SqueezeBertForSequenceClassification.__init__": 5518
        },
        {
            "transformers.utils.dummy_pt_objects.SqueezeBertForTokenClassification.__init__": 5525
        },
        {
            "transformers.utils.dummy_pt_objects.SqueezeBertModel.__init__": 5532
        },
        {
            "transformers.utils.dummy_pt_objects.SqueezeBertModule.__init__": 5539
        },
        {
            "transformers.utils.dummy_pt_objects.SqueezeBertPreTrainedModel.__init__": 5546
        },
        {
            "transformers.utils.dummy_pt_objects.SwinBackbone.__init__": 5556
        },
        {
            "transformers.utils.dummy_pt_objects.SwinForImageClassification.__init__": 5563
        },
        {
            "transformers.utils.dummy_pt_objects.SwinForMaskedImageModeling.__init__": 5570
        },
        {
            "transformers.utils.dummy_pt_objects.SwinModel.__init__": 5577
        },
        {
            "transformers.utils.dummy_pt_objects.SwinPreTrainedModel.__init__": 5584
        },
        {
            "transformers.utils.dummy_pt_objects.Swin2SRForImageSuperResolution.__init__": 5594
        },
        {
            "transformers.utils.dummy_pt_objects.Swin2SRModel.__init__": 5601
        },
        {
            "transformers.utils.dummy_pt_objects.Swin2SRPreTrainedModel.__init__": 5608
        },
        {
            "transformers.utils.dummy_pt_objects.Swinv2ForImageClassification.__init__": 5618
        },
        {
            "transformers.utils.dummy_pt_objects.Swinv2ForMaskedImageModeling.__init__": 5625
        },
        {
            "transformers.utils.dummy_pt_objects.Swinv2Model.__init__": 5632
        },
        {
            "transformers.utils.dummy_pt_objects.Swinv2PreTrainedModel.__init__": 5639
        },
        {
            "transformers.utils.dummy_pt_objects.SwitchTransformersEncoderModel.__init__": 5649
        },
        {
            "transformers.utils.dummy_pt_objects.SwitchTransformersForConditionalGeneration.__init__": 5656
        },
        {
            "transformers.utils.dummy_pt_objects.SwitchTransformersModel.__init__": 5663
        },
        {
            "transformers.utils.dummy_pt_objects.SwitchTransformersPreTrainedModel.__init__": 5670
        },
        {
            "transformers.utils.dummy_pt_objects.SwitchTransformersSparseMLP.__init__": 5677
        },
        {
            "transformers.utils.dummy_pt_objects.SwitchTransformersTop1Router.__init__": 5684
        },
        {
            "transformers.utils.dummy_pt_objects.T5EncoderModel.__init__": 5694
        },
        {
            "transformers.utils.dummy_pt_objects.T5ForConditionalGeneration.__init__": 5701
        },
        {
            "transformers.utils.dummy_pt_objects.T5Model.__init__": 5708
        },
        {
            "transformers.utils.dummy_pt_objects.T5PreTrainedModel.__init__": 5715
        },
        {
            "transformers.utils.dummy_pt_objects.load_tf_weights_in_t5": 5719
        },
        {
            "transformers.utils.dummy_pt_objects.TapasForMaskedLM.__init__": 5729
        },
        {
            "transformers.utils.dummy_pt_objects.TapasForQuestionAnswering.__init__": 5736
        },
        {
            "transformers.utils.dummy_pt_objects.TapasForSequenceClassification.__init__": 5743
        },
        {
            "transformers.utils.dummy_pt_objects.TapasModel.__init__": 5750
        },
        {
            "transformers.utils.dummy_pt_objects.TapasPreTrainedModel.__init__": 5757
        },
        {
            "transformers.utils.dummy_pt_objects.load_tf_weights_in_tapas": 5761
        },
        {
            "transformers.utils.dummy_pt_objects.TimeSeriesTransformerForPrediction.__init__": 5771
        },
        {
            "transformers.utils.dummy_pt_objects.TimeSeriesTransformerModel.__init__": 5778
        },
        {
            "transformers.utils.dummy_pt_objects.TimeSeriesTransformerPreTrainedModel.__init__": 5785
        },
        {
            "transformers.utils.dummy_pt_objects.TimesformerForVideoClassification.__init__": 5795
        },
        {
            "transformers.utils.dummy_pt_objects.TimesformerModel.__init__": 5802
        },
        {
            "transformers.utils.dummy_pt_objects.TimesformerPreTrainedModel.__init__": 5809
        },
        {
            "transformers.utils.dummy_pt_objects.TrajectoryTransformerModel.__init__": 5819
        },
        {
            "transformers.utils.dummy_pt_objects.TrajectoryTransformerPreTrainedModel.__init__": 5826
        },
        {
            "transformers.utils.dummy_pt_objects.AdaptiveEmbedding.__init__": 5836
        },
        {
            "transformers.utils.dummy_pt_objects.TransfoXLForSequenceClassification.__init__": 5843
        },
        {
            "transformers.utils.dummy_pt_objects.TransfoXLLMHeadModel.__init__": 5850
        },
        {
            "transformers.utils.dummy_pt_objects.TransfoXLModel.__init__": 5857
        },
        {
            "transformers.utils.dummy_pt_objects.TransfoXLPreTrainedModel.__init__": 5864
        },
        {
            "transformers.utils.dummy_pt_objects.load_tf_weights_in_transfo_xl": 5868
        },
        {
            "transformers.utils.dummy_pt_objects.TrOCRForCausalLM.__init__": 5878
        },
        {
            "transformers.utils.dummy_pt_objects.TrOCRPreTrainedModel.__init__": 5885
        },
        {
            "transformers.utils.dummy_pt_objects.UniSpeechForCTC.__init__": 5895
        },
        {
            "transformers.utils.dummy_pt_objects.UniSpeechForPreTraining.__init__": 5902
        },
        {
            "transformers.utils.dummy_pt_objects.UniSpeechForSequenceClassification.__init__": 5909
        },
        {
            "transformers.utils.dummy_pt_objects.UniSpeechModel.__init__": 5916
        },
        {
            "transformers.utils.dummy_pt_objects.UniSpeechPreTrainedModel.__init__": 5923
        },
        {
            "transformers.utils.dummy_pt_objects.UniSpeechSatForAudioFrameClassification.__init__": 5933
        },
        {
            "transformers.utils.dummy_pt_objects.UniSpeechSatForCTC.__init__": 5940
        },
        {
            "transformers.utils.dummy_pt_objects.UniSpeechSatForPreTraining.__init__": 5947
        },
        {
            "transformers.utils.dummy_pt_objects.UniSpeechSatForSequenceClassification.__init__": 5954
        },
        {
            "transformers.utils.dummy_pt_objects.UniSpeechSatForXVector.__init__": 5961
        },
        {
            "transformers.utils.dummy_pt_objects.UniSpeechSatModel.__init__": 5968
        },
        {
            "transformers.utils.dummy_pt_objects.UniSpeechSatPreTrainedModel.__init__": 5975
        },
        {
            "transformers.utils.dummy_pt_objects.UperNetForSemanticSegmentation.__init__": 5982
        },
        {
            "transformers.utils.dummy_pt_objects.UperNetPreTrainedModel.__init__": 5989
        },
        {
            "transformers.utils.dummy_pt_objects.VanForImageClassification.__init__": 5999
        },
        {
            "transformers.utils.dummy_pt_objects.VanModel.__init__": 6006
        },
        {
            "transformers.utils.dummy_pt_objects.VanPreTrainedModel.__init__": 6013
        },
        {
            "transformers.utils.dummy_pt_objects.VideoMAEForPreTraining.__init__": 6023
        },
        {
            "transformers.utils.dummy_pt_objects.VideoMAEForVideoClassification.__init__": 6030
        },
        {
            "transformers.utils.dummy_pt_objects.VideoMAEModel.__init__": 6037
        },
        {
            "transformers.utils.dummy_pt_objects.VideoMAEPreTrainedModel.__init__": 6044
        },
        {
            "transformers.utils.dummy_pt_objects.ViltForImageAndTextRetrieval.__init__": 6054
        },
        {
            "transformers.utils.dummy_pt_objects.ViltForImagesAndTextClassification.__init__": 6061
        },
        {
            "transformers.utils.dummy_pt_objects.ViltForMaskedLM.__init__": 6068
        },
        {
            "transformers.utils.dummy_pt_objects.ViltForQuestionAnswering.__init__": 6075
        },
        {
            "transformers.utils.dummy_pt_objects.ViltForTokenClassification.__init__": 6082
        },
        {
            "transformers.utils.dummy_pt_objects.ViltLayer.__init__": 6089
        },
        {
            "transformers.utils.dummy_pt_objects.ViltModel.__init__": 6096
        },
        {
            "transformers.utils.dummy_pt_objects.ViltPreTrainedModel.__init__": 6103
        },
        {
            "transformers.utils.dummy_pt_objects.VisionEncoderDecoderModel.__init__": 6110
        },
        {
            "transformers.utils.dummy_pt_objects.VisionTextDualEncoderModel.__init__": 6117
        },
        {
            "transformers.utils.dummy_pt_objects.VisualBertForMultipleChoice.__init__": 6127
        },
        {
            "transformers.utils.dummy_pt_objects.VisualBertForPreTraining.__init__": 6134
        },
        {
            "transformers.utils.dummy_pt_objects.VisualBertForQuestionAnswering.__init__": 6141
        },
        {
            "transformers.utils.dummy_pt_objects.VisualBertForRegionToPhraseAlignment.__init__": 6148
        },
        {
            "transformers.utils.dummy_pt_objects.VisualBertForVisualReasoning.__init__": 6155
        },
        {
            "transformers.utils.dummy_pt_objects.VisualBertLayer.__init__": 6162
        },
        {
            "transformers.utils.dummy_pt_objects.VisualBertModel.__init__": 6169
        },
        {
            "transformers.utils.dummy_pt_objects.VisualBertPreTrainedModel.__init__": 6176
        },
        {
            "transformers.utils.dummy_pt_objects.ViTForImageClassification.__init__": 6186
        },
        {
            "transformers.utils.dummy_pt_objects.ViTForMaskedImageModeling.__init__": 6193
        },
        {
            "transformers.utils.dummy_pt_objects.ViTModel.__init__": 6200
        },
        {
            "transformers.utils.dummy_pt_objects.ViTPreTrainedModel.__init__": 6207
        },
        {
            "transformers.utils.dummy_pt_objects.ViTHybridForImageClassification.__init__": 6217
        },
        {
            "transformers.utils.dummy_pt_objects.ViTHybridModel.__init__": 6224
        },
        {
            "transformers.utils.dummy_pt_objects.ViTHybridPreTrainedModel.__init__": 6231
        },
        {
            "transformers.utils.dummy_pt_objects.ViTMAEForPreTraining.__init__": 6241
        },
        {
            "transformers.utils.dummy_pt_objects.ViTMAELayer.__init__": 6248
        },
        {
            "transformers.utils.dummy_pt_objects.ViTMAEModel.__init__": 6255
        },
        {
            "transformers.utils.dummy_pt_objects.ViTMAEPreTrainedModel.__init__": 6262
        },
        {
            "transformers.utils.dummy_pt_objects.ViTMSNForImageClassification.__init__": 6272
        },
        {
            "transformers.utils.dummy_pt_objects.ViTMSNModel.__init__": 6279
        },
        {
            "transformers.utils.dummy_pt_objects.ViTMSNPreTrainedModel.__init__": 6286
        },
        {
            "transformers.utils.dummy_pt_objects.Wav2Vec2ForAudioFrameClassification.__init__": 6296
        },
        {
            "transformers.utils.dummy_pt_objects.Wav2Vec2ForCTC.__init__": 6303
        },
        {
            "transformers.utils.dummy_pt_objects.Wav2Vec2ForMaskedLM.__init__": 6310
        },
        {
            "transformers.utils.dummy_pt_objects.Wav2Vec2ForPreTraining.__init__": 6317
        },
        {
            "transformers.utils.dummy_pt_objects.Wav2Vec2ForSequenceClassification.__init__": 6324
        },
        {
            "transformers.utils.dummy_pt_objects.Wav2Vec2ForXVector.__init__": 6331
        },
        {
            "transformers.utils.dummy_pt_objects.Wav2Vec2Model.__init__": 6338
        },
        {
            "transformers.utils.dummy_pt_objects.Wav2Vec2PreTrainedModel.__init__": 6345
        },
        {
            "transformers.utils.dummy_pt_objects.Wav2Vec2ConformerForAudioFrameClassification.__init__": 6355
        },
        {
            "transformers.utils.dummy_pt_objects.Wav2Vec2ConformerForCTC.__init__": 6362
        },
        {
            "transformers.utils.dummy_pt_objects.Wav2Vec2ConformerForPreTraining.__init__": 6369
        },
        {
            "transformers.utils.dummy_pt_objects.Wav2Vec2ConformerForSequenceClassification.__init__": 6376
        },
        {
            "transformers.utils.dummy_pt_objects.Wav2Vec2ConformerForXVector.__init__": 6383
        },
        {
            "transformers.utils.dummy_pt_objects.Wav2Vec2ConformerModel.__init__": 6390
        },
        {
            "transformers.utils.dummy_pt_objects.Wav2Vec2ConformerPreTrainedModel.__init__": 6397
        },
        {
            "transformers.utils.dummy_pt_objects.WavLMForAudioFrameClassification.__init__": 6407
        },
        {
            "transformers.utils.dummy_pt_objects.WavLMForCTC.__init__": 6414
        },
        {
            "transformers.utils.dummy_pt_objects.WavLMForSequenceClassification.__init__": 6421
        },
        {
            "transformers.utils.dummy_pt_objects.WavLMForXVector.__init__": 6428
        },
        {
            "transformers.utils.dummy_pt_objects.WavLMModel.__init__": 6435
        },
        {
            "transformers.utils.dummy_pt_objects.WavLMPreTrainedModel.__init__": 6442
        },
        {
            "transformers.utils.dummy_pt_objects.WhisperForConditionalGeneration.__init__": 6452
        },
        {
            "transformers.utils.dummy_pt_objects.WhisperModel.__init__": 6459
        },
        {
            "transformers.utils.dummy_pt_objects.WhisperPreTrainedModel.__init__": 6466
        },
        {
            "transformers.utils.dummy_pt_objects.XCLIPModel.__init__": 6476
        },
        {
            "transformers.utils.dummy_pt_objects.XCLIPPreTrainedModel.__init__": 6483
        },
        {
            "transformers.utils.dummy_pt_objects.XCLIPTextModel.__init__": 6490
        },
        {
            "transformers.utils.dummy_pt_objects.XCLIPVisionModel.__init__": 6497
        },
        {
            "transformers.utils.dummy_pt_objects.XGLMForCausalLM.__init__": 6507
        },
        {
            "transformers.utils.dummy_pt_objects.XGLMModel.__init__": 6514
        },
        {
            "transformers.utils.dummy_pt_objects.XGLMPreTrainedModel.__init__": 6521
        },
        {
            "transformers.utils.dummy_pt_objects.XLMForMultipleChoice.__init__": 6531
        },
        {
            "transformers.utils.dummy_pt_objects.XLMForQuestionAnswering.__init__": 6538
        },
        {
            "transformers.utils.dummy_pt_objects.XLMForQuestionAnsweringSimple.__init__": 6545
        },
        {
            "transformers.utils.dummy_pt_objects.XLMForSequenceClassification.__init__": 6552
        },
        {
            "transformers.utils.dummy_pt_objects.XLMForTokenClassification.__init__": 6559
        },
        {
            "transformers.utils.dummy_pt_objects.XLMModel.__init__": 6566
        },
        {
            "transformers.utils.dummy_pt_objects.XLMPreTrainedModel.__init__": 6573
        },
        {
            "transformers.utils.dummy_pt_objects.XLMWithLMHeadModel.__init__": 6580
        },
        {
            "transformers.utils.dummy_pt_objects.XLMProphetNetDecoder.__init__": 6590
        },
        {
            "transformers.utils.dummy_pt_objects.XLMProphetNetEncoder.__init__": 6597
        },
        {
            "transformers.utils.dummy_pt_objects.XLMProphetNetForCausalLM.__init__": 6604
        },
        {
            "transformers.utils.dummy_pt_objects.XLMProphetNetForConditionalGeneration.__init__": 6611
        },
        {
            "transformers.utils.dummy_pt_objects.XLMProphetNetModel.__init__": 6618
        },
        {
            "transformers.utils.dummy_pt_objects.XLMProphetNetPreTrainedModel.__init__": 6625
        },
        {
            "transformers.utils.dummy_pt_objects.XLMRobertaForCausalLM.__init__": 6635
        },
        {
            "transformers.utils.dummy_pt_objects.XLMRobertaForMaskedLM.__init__": 6642
        },
        {
            "transformers.utils.dummy_pt_objects.XLMRobertaForMultipleChoice.__init__": 6649
        },
        {
            "transformers.utils.dummy_pt_objects.XLMRobertaForQuestionAnswering.__init__": 6656
        },
        {
            "transformers.utils.dummy_pt_objects.XLMRobertaForSequenceClassification.__init__": 6663
        },
        {
            "transformers.utils.dummy_pt_objects.XLMRobertaForTokenClassification.__init__": 6670
        },
        {
            "transformers.utils.dummy_pt_objects.XLMRobertaModel.__init__": 6677
        },
        {
            "transformers.utils.dummy_pt_objects.XLMRobertaPreTrainedModel.__init__": 6684
        },
        {
            "transformers.utils.dummy_pt_objects.XLMRobertaXLForCausalLM.__init__": 6694
        },
        {
            "transformers.utils.dummy_pt_objects.XLMRobertaXLForMaskedLM.__init__": 6701
        },
        {
            "transformers.utils.dummy_pt_objects.XLMRobertaXLForMultipleChoice.__init__": 6708
        },
        {
            "transformers.utils.dummy_pt_objects.XLMRobertaXLForQuestionAnswering.__init__": 6715
        },
        {
            "transformers.utils.dummy_pt_objects.XLMRobertaXLForSequenceClassification.__init__": 6722
        },
        {
            "transformers.utils.dummy_pt_objects.XLMRobertaXLForTokenClassification.__init__": 6729
        },
        {
            "transformers.utils.dummy_pt_objects.XLMRobertaXLModel.__init__": 6736
        },
        {
            "transformers.utils.dummy_pt_objects.XLMRobertaXLPreTrainedModel.__init__": 6743
        },
        {
            "transformers.utils.dummy_pt_objects.XLNetForMultipleChoice.__init__": 6753
        },
        {
            "transformers.utils.dummy_pt_objects.XLNetForQuestionAnswering.__init__": 6760
        },
        {
            "transformers.utils.dummy_pt_objects.XLNetForQuestionAnsweringSimple.__init__": 6767
        },
        {
            "transformers.utils.dummy_pt_objects.XLNetForSequenceClassification.__init__": 6774
        },
        {
            "transformers.utils.dummy_pt_objects.XLNetForTokenClassification.__init__": 6781
        },
        {
            "transformers.utils.dummy_pt_objects.XLNetLMHeadModel.__init__": 6788
        },
        {
            "transformers.utils.dummy_pt_objects.XLNetModel.__init__": 6795
        },
        {
            "transformers.utils.dummy_pt_objects.XLNetPreTrainedModel.__init__": 6802
        },
        {
            "transformers.utils.dummy_pt_objects.load_tf_weights_in_xlnet": 6806
        },
        {
            "transformers.utils.dummy_pt_objects.YolosForObjectDetection.__init__": 6816
        },
        {
            "transformers.utils.dummy_pt_objects.YolosModel.__init__": 6823
        },
        {
            "transformers.utils.dummy_pt_objects.YolosPreTrainedModel.__init__": 6830
        },
        {
            "transformers.utils.dummy_pt_objects.YosoForMaskedLM.__init__": 6840
        },
        {
            "transformers.utils.dummy_pt_objects.YosoForMultipleChoice.__init__": 6847
        },
        {
            "transformers.utils.dummy_pt_objects.YosoForQuestionAnswering.__init__": 6854
        },
        {
            "transformers.utils.dummy_pt_objects.YosoForSequenceClassification.__init__": 6861
        },
        {
            "transformers.utils.dummy_pt_objects.YosoForTokenClassification.__init__": 6868
        },
        {
            "transformers.utils.dummy_pt_objects.YosoLayer.__init__": 6875
        },
        {
            "transformers.utils.dummy_pt_objects.YosoModel.__init__": 6882
        },
        {
            "transformers.utils.dummy_pt_objects.YosoPreTrainedModel.__init__": 6889
        },
        {
            "transformers.utils.dummy_pt_objects.Adafactor.__init__": 6896
        },
        {
            "transformers.utils.dummy_pt_objects.AdamW.__init__": 6903
        },
        {
            "transformers.utils.dummy_pt_objects.get_constant_schedule": 6907
        },
        {
            "transformers.utils.dummy_pt_objects.get_constant_schedule_with_warmup": 6911
        },
        {
            "transformers.utils.dummy_pt_objects.get_cosine_schedule_with_warmup": 6915
        },
        {
            "transformers.utils.dummy_pt_objects.get_cosine_with_hard_restarts_schedule_with_warmup": 6919
        },
        {
            "transformers.utils.dummy_pt_objects.get_linear_schedule_with_warmup": 6923
        },
        {
            "transformers.utils.dummy_pt_objects.get_polynomial_decay_schedule_with_warmup": 6927
        },
        {
            "transformers.utils.dummy_pt_objects.get_scheduler": 6931
        },
        {
            "transformers.utils.dummy_pt_objects.Conv1D.__init__": 6938
        },
        {
            "transformers.utils.dummy_pt_objects.apply_chunking_to_forward": 6942
        },
        {
            "transformers.utils.dummy_pt_objects.prune_layer": 6946
        },
        {
            "transformers.utils.dummy_pt_objects.Trainer.__init__": 6953
        },
        {
            "transformers.utils.dummy_pt_objects.torch_distributed_zero_first": 6957
        },
        {
            "transformers.utils.dummy_pt_objects.Seq2SeqTrainer.__init__": 6964
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/utils/import_utils.py": [
        {
            "transformers.utils.import_utils.wrapper": 711
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/utils/generic.py": [
        {
            "transformers.utils.generic.ModelOutput.__delitem__": 274
        },
        {
            "transformers.utils.generic.ModelOutput.setdefault": 277
        },
        {
            "transformers.utils.generic.ModelOutput.pop": 280
        },
        {
            "transformers.utils.generic.ModelOutput.update": 283
        },
        {
            "transformers.utils.generic.ContextManagers.__exit__": 361
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/utils/dummy_vision_objects.py": [
        {
            "transformers.utils.dummy_vision_objects.ImageProcessingMixin.__init__": 9
        },
        {
            "transformers.utils.dummy_vision_objects.ImageFeatureExtractionMixin.__init__": 16
        },
        {
            "transformers.utils.dummy_vision_objects.BeitFeatureExtractor.__init__": 23
        },
        {
            "transformers.utils.dummy_vision_objects.BeitImageProcessor.__init__": 30
        },
        {
            "transformers.utils.dummy_vision_objects.BitImageProcessor.__init__": 37
        },
        {
            "transformers.utils.dummy_vision_objects.BlipImageProcessor.__init__": 44
        },
        {
            "transformers.utils.dummy_vision_objects.ChineseCLIPFeatureExtractor.__init__": 51
        },
        {
            "transformers.utils.dummy_vision_objects.ChineseCLIPImageProcessor.__init__": 58
        },
        {
            "transformers.utils.dummy_vision_objects.CLIPFeatureExtractor.__init__": 65
        },
        {
            "transformers.utils.dummy_vision_objects.CLIPImageProcessor.__init__": 72
        },
        {
            "transformers.utils.dummy_vision_objects.ConditionalDetrFeatureExtractor.__init__": 79
        },
        {
            "transformers.utils.dummy_vision_objects.ConditionalDetrImageProcessor.__init__": 86
        },
        {
            "transformers.utils.dummy_vision_objects.ConvNextFeatureExtractor.__init__": 93
        },
        {
            "transformers.utils.dummy_vision_objects.ConvNextImageProcessor.__init__": 100
        },
        {
            "transformers.utils.dummy_vision_objects.DeformableDetrFeatureExtractor.__init__": 107
        },
        {
            "transformers.utils.dummy_vision_objects.DeformableDetrImageProcessor.__init__": 114
        },
        {
            "transformers.utils.dummy_vision_objects.DeiTFeatureExtractor.__init__": 121
        },
        {
            "transformers.utils.dummy_vision_objects.DeiTImageProcessor.__init__": 128
        },
        {
            "transformers.utils.dummy_vision_objects.DetrFeatureExtractor.__init__": 135
        },
        {
            "transformers.utils.dummy_vision_objects.DetrImageProcessor.__init__": 142
        },
        {
            "transformers.utils.dummy_vision_objects.DonutFeatureExtractor.__init__": 149
        },
        {
            "transformers.utils.dummy_vision_objects.DonutImageProcessor.__init__": 156
        },
        {
            "transformers.utils.dummy_vision_objects.DPTFeatureExtractor.__init__": 163
        },
        {
            "transformers.utils.dummy_vision_objects.DPTImageProcessor.__init__": 170
        },
        {
            "transformers.utils.dummy_vision_objects.EfficientFormerImageProcessor.__init__": 177
        },
        {
            "transformers.utils.dummy_vision_objects.FlavaFeatureExtractor.__init__": 184
        },
        {
            "transformers.utils.dummy_vision_objects.FlavaImageProcessor.__init__": 191
        },
        {
            "transformers.utils.dummy_vision_objects.FlavaProcessor.__init__": 198
        },
        {
            "transformers.utils.dummy_vision_objects.GLPNFeatureExtractor.__init__": 205
        },
        {
            "transformers.utils.dummy_vision_objects.GLPNImageProcessor.__init__": 212
        },
        {
            "transformers.utils.dummy_vision_objects.ImageGPTFeatureExtractor.__init__": 219
        },
        {
            "transformers.utils.dummy_vision_objects.ImageGPTImageProcessor.__init__": 226
        },
        {
            "transformers.utils.dummy_vision_objects.LayoutLMv2FeatureExtractor.__init__": 233
        },
        {
            "transformers.utils.dummy_vision_objects.LayoutLMv2ImageProcessor.__init__": 240
        },
        {
            "transformers.utils.dummy_vision_objects.LayoutLMv3FeatureExtractor.__init__": 247
        },
        {
            "transformers.utils.dummy_vision_objects.LayoutLMv3ImageProcessor.__init__": 254
        },
        {
            "transformers.utils.dummy_vision_objects.LevitFeatureExtractor.__init__": 261
        },
        {
            "transformers.utils.dummy_vision_objects.LevitImageProcessor.__init__": 268
        },
        {
            "transformers.utils.dummy_vision_objects.Mask2FormerImageProcessor.__init__": 275
        },
        {
            "transformers.utils.dummy_vision_objects.MaskFormerFeatureExtractor.__init__": 282
        },
        {
            "transformers.utils.dummy_vision_objects.MaskFormerImageProcessor.__init__": 289
        },
        {
            "transformers.utils.dummy_vision_objects.MobileNetV1FeatureExtractor.__init__": 296
        },
        {
            "transformers.utils.dummy_vision_objects.MobileNetV1ImageProcessor.__init__": 303
        },
        {
            "transformers.utils.dummy_vision_objects.MobileNetV2FeatureExtractor.__init__": 310
        },
        {
            "transformers.utils.dummy_vision_objects.MobileNetV2ImageProcessor.__init__": 317
        },
        {
            "transformers.utils.dummy_vision_objects.MobileViTFeatureExtractor.__init__": 324
        },
        {
            "transformers.utils.dummy_vision_objects.MobileViTImageProcessor.__init__": 331
        },
        {
            "transformers.utils.dummy_vision_objects.OneFormerImageProcessor.__init__": 338
        },
        {
            "transformers.utils.dummy_vision_objects.OwlViTFeatureExtractor.__init__": 345
        },
        {
            "transformers.utils.dummy_vision_objects.OwlViTImageProcessor.__init__": 352
        },
        {
            "transformers.utils.dummy_vision_objects.PerceiverFeatureExtractor.__init__": 359
        },
        {
            "transformers.utils.dummy_vision_objects.PerceiverImageProcessor.__init__": 366
        },
        {
            "transformers.utils.dummy_vision_objects.PoolFormerFeatureExtractor.__init__": 373
        },
        {
            "transformers.utils.dummy_vision_objects.PoolFormerImageProcessor.__init__": 380
        },
        {
            "transformers.utils.dummy_vision_objects.SegformerFeatureExtractor.__init__": 387
        },
        {
            "transformers.utils.dummy_vision_objects.SegformerImageProcessor.__init__": 394
        },
        {
            "transformers.utils.dummy_vision_objects.Swin2SRImageProcessor.__init__": 401
        },
        {
            "transformers.utils.dummy_vision_objects.VideoMAEFeatureExtractor.__init__": 408
        },
        {
            "transformers.utils.dummy_vision_objects.VideoMAEImageProcessor.__init__": 415
        },
        {
            "transformers.utils.dummy_vision_objects.ViltFeatureExtractor.__init__": 422
        },
        {
            "transformers.utils.dummy_vision_objects.ViltImageProcessor.__init__": 429
        },
        {
            "transformers.utils.dummy_vision_objects.ViltProcessor.__init__": 436
        },
        {
            "transformers.utils.dummy_vision_objects.ViTFeatureExtractor.__init__": 443
        },
        {
            "transformers.utils.dummy_vision_objects.ViTImageProcessor.__init__": 450
        },
        {
            "transformers.utils.dummy_vision_objects.ViTHybridImageProcessor.__init__": 457
        },
        {
            "transformers.utils.dummy_vision_objects.YolosFeatureExtractor.__init__": 464
        },
        {
            "transformers.utils.dummy_vision_objects.YolosImageProcessor.__init__": 471
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/utils/dummy_sentencepiece_and_speech_objects.py": [
        {
            "transformers.utils.dummy_sentencepiece_and_speech_objects.Speech2TextProcessor.__init__": 9
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/utils/dummy_tf_objects.py": [
        {
            "transformers.utils.dummy_tf_objects.TensorFlowBenchmarkArguments.__init__": 9
        },
        {
            "transformers.utils.dummy_tf_objects.TensorFlowBenchmark.__init__": 16
        },
        {
            "transformers.utils.dummy_tf_objects.TFForcedBOSTokenLogitsProcessor.__init__": 23
        },
        {
            "transformers.utils.dummy_tf_objects.TFForcedEOSTokenLogitsProcessor.__init__": 30
        },
        {
            "transformers.utils.dummy_tf_objects.TFGenerationMixin.__init__": 37
        },
        {
            "transformers.utils.dummy_tf_objects.TFLogitsProcessor.__init__": 44
        },
        {
            "transformers.utils.dummy_tf_objects.TFLogitsProcessorList.__init__": 51
        },
        {
            "transformers.utils.dummy_tf_objects.TFLogitsWarper.__init__": 58
        },
        {
            "transformers.utils.dummy_tf_objects.TFMinLengthLogitsProcessor.__init__": 65
        },
        {
            "transformers.utils.dummy_tf_objects.TFNoBadWordsLogitsProcessor.__init__": 72
        },
        {
            "transformers.utils.dummy_tf_objects.TFNoRepeatNGramLogitsProcessor.__init__": 79
        },
        {
            "transformers.utils.dummy_tf_objects.TFRepetitionPenaltyLogitsProcessor.__init__": 86
        },
        {
            "transformers.utils.dummy_tf_objects.TFTemperatureLogitsWarper.__init__": 93
        },
        {
            "transformers.utils.dummy_tf_objects.TFTopKLogitsWarper.__init__": 100
        },
        {
            "transformers.utils.dummy_tf_objects.TFTopPLogitsWarper.__init__": 107
        },
        {
            "transformers.utils.dummy_tf_objects.tf_top_k_top_p_filtering": 111
        },
        {
            "transformers.utils.dummy_tf_objects.KerasMetricCallback.__init__": 118
        },
        {
            "transformers.utils.dummy_tf_objects.PushToHubCallback.__init__": 125
        },
        {
            "transformers.utils.dummy_tf_objects.TFLayoutLMForMaskedLM.__init__": 135
        },
        {
            "transformers.utils.dummy_tf_objects.TFLayoutLMForQuestionAnswering.__init__": 142
        },
        {
            "transformers.utils.dummy_tf_objects.TFLayoutLMForSequenceClassification.__init__": 149
        },
        {
            "transformers.utils.dummy_tf_objects.TFLayoutLMForTokenClassification.__init__": 156
        },
        {
            "transformers.utils.dummy_tf_objects.TFLayoutLMMainLayer.__init__": 163
        },
        {
            "transformers.utils.dummy_tf_objects.TFLayoutLMModel.__init__": 170
        },
        {
            "transformers.utils.dummy_tf_objects.TFLayoutLMPreTrainedModel.__init__": 177
        },
        {
            "transformers.utils.dummy_tf_objects.TFPreTrainedModel.__init__": 184
        },
        {
            "transformers.utils.dummy_tf_objects.TFSequenceSummary.__init__": 191
        },
        {
            "transformers.utils.dummy_tf_objects.TFSharedEmbeddings.__init__": 198
        },
        {
            "transformers.utils.dummy_tf_objects.shape_list": 202
        },
        {
            "transformers.utils.dummy_tf_objects.TFAlbertForMaskedLM.__init__": 212
        },
        {
            "transformers.utils.dummy_tf_objects.TFAlbertForMultipleChoice.__init__": 219
        },
        {
            "transformers.utils.dummy_tf_objects.TFAlbertForPreTraining.__init__": 226
        },
        {
            "transformers.utils.dummy_tf_objects.TFAlbertForQuestionAnswering.__init__": 233
        },
        {
            "transformers.utils.dummy_tf_objects.TFAlbertForSequenceClassification.__init__": 240
        },
        {
            "transformers.utils.dummy_tf_objects.TFAlbertForTokenClassification.__init__": 247
        },
        {
            "transformers.utils.dummy_tf_objects.TFAlbertMainLayer.__init__": 254
        },
        {
            "transformers.utils.dummy_tf_objects.TFAlbertModel.__init__": 261
        },
        {
            "transformers.utils.dummy_tf_objects.TFAlbertPreTrainedModel.__init__": 268
        },
        {
            "transformers.utils.dummy_tf_objects.TFAutoModel.__init__": 329
        },
        {
            "transformers.utils.dummy_tf_objects.TFAutoModelForCausalLM.__init__": 336
        },
        {
            "transformers.utils.dummy_tf_objects.TFAutoModelForDocumentQuestionAnswering.__init__": 343
        },
        {
            "transformers.utils.dummy_tf_objects.TFAutoModelForImageClassification.__init__": 350
        },
        {
            "transformers.utils.dummy_tf_objects.TFAutoModelForMaskedLM.__init__": 357
        },
        {
            "transformers.utils.dummy_tf_objects.TFAutoModelForMultipleChoice.__init__": 364
        },
        {
            "transformers.utils.dummy_tf_objects.TFAutoModelForNextSentencePrediction.__init__": 371
        },
        {
            "transformers.utils.dummy_tf_objects.TFAutoModelForPreTraining.__init__": 378
        },
        {
            "transformers.utils.dummy_tf_objects.TFAutoModelForQuestionAnswering.__init__": 385
        },
        {
            "transformers.utils.dummy_tf_objects.TFAutoModelForSemanticSegmentation.__init__": 392
        },
        {
            "transformers.utils.dummy_tf_objects.TFAutoModelForSeq2SeqLM.__init__": 399
        },
        {
            "transformers.utils.dummy_tf_objects.TFAutoModelForSequenceClassification.__init__": 406
        },
        {
            "transformers.utils.dummy_tf_objects.TFAutoModelForSpeechSeq2Seq.__init__": 413
        },
        {
            "transformers.utils.dummy_tf_objects.TFAutoModelForTableQuestionAnswering.__init__": 420
        },
        {
            "transformers.utils.dummy_tf_objects.TFAutoModelForTokenClassification.__init__": 427
        },
        {
            "transformers.utils.dummy_tf_objects.TFAutoModelForVision2Seq.__init__": 434
        },
        {
            "transformers.utils.dummy_tf_objects.TFAutoModelWithLMHead.__init__": 441
        },
        {
            "transformers.utils.dummy_tf_objects.TFBartForConditionalGeneration.__init__": 448
        },
        {
            "transformers.utils.dummy_tf_objects.TFBartForSequenceClassification.__init__": 455
        },
        {
            "transformers.utils.dummy_tf_objects.TFBartModel.__init__": 462
        },
        {
            "transformers.utils.dummy_tf_objects.TFBartPretrainedModel.__init__": 469
        },
        {
            "transformers.utils.dummy_tf_objects.TFBertEmbeddings.__init__": 479
        },
        {
            "transformers.utils.dummy_tf_objects.TFBertForMaskedLM.__init__": 486
        },
        {
            "transformers.utils.dummy_tf_objects.TFBertForMultipleChoice.__init__": 493
        },
        {
            "transformers.utils.dummy_tf_objects.TFBertForNextSentencePrediction.__init__": 500
        },
        {
            "transformers.utils.dummy_tf_objects.TFBertForPreTraining.__init__": 507
        },
        {
            "transformers.utils.dummy_tf_objects.TFBertForQuestionAnswering.__init__": 514
        },
        {
            "transformers.utils.dummy_tf_objects.TFBertForSequenceClassification.__init__": 521
        },
        {
            "transformers.utils.dummy_tf_objects.TFBertForTokenClassification.__init__": 528
        },
        {
            "transformers.utils.dummy_tf_objects.TFBertLMHeadModel.__init__": 535
        },
        {
            "transformers.utils.dummy_tf_objects.TFBertMainLayer.__init__": 542
        },
        {
            "transformers.utils.dummy_tf_objects.TFBertModel.__init__": 549
        },
        {
            "transformers.utils.dummy_tf_objects.TFBertPreTrainedModel.__init__": 556
        },
        {
            "transformers.utils.dummy_tf_objects.TFBlenderbotForConditionalGeneration.__init__": 563
        },
        {
            "transformers.utils.dummy_tf_objects.TFBlenderbotModel.__init__": 570
        },
        {
            "transformers.utils.dummy_tf_objects.TFBlenderbotPreTrainedModel.__init__": 577
        },
        {
            "transformers.utils.dummy_tf_objects.TFBlenderbotSmallForConditionalGeneration.__init__": 584
        },
        {
            "transformers.utils.dummy_tf_objects.TFBlenderbotSmallModel.__init__": 591
        },
        {
            "transformers.utils.dummy_tf_objects.TFBlenderbotSmallPreTrainedModel.__init__": 598
        },
        {
            "transformers.utils.dummy_tf_objects.TFCamembertForCausalLM.__init__": 608
        },
        {
            "transformers.utils.dummy_tf_objects.TFCamembertForMaskedLM.__init__": 615
        },
        {
            "transformers.utils.dummy_tf_objects.TFCamembertForMultipleChoice.__init__": 622
        },
        {
            "transformers.utils.dummy_tf_objects.TFCamembertForQuestionAnswering.__init__": 629
        },
        {
            "transformers.utils.dummy_tf_objects.TFCamembertForSequenceClassification.__init__": 636
        },
        {
            "transformers.utils.dummy_tf_objects.TFCamembertForTokenClassification.__init__": 643
        },
        {
            "transformers.utils.dummy_tf_objects.TFCamembertModel.__init__": 650
        },
        {
            "transformers.utils.dummy_tf_objects.TFCamembertPreTrainedModel.__init__": 657
        },
        {
            "transformers.utils.dummy_tf_objects.TFCLIPModel.__init__": 667
        },
        {
            "transformers.utils.dummy_tf_objects.TFCLIPPreTrainedModel.__init__": 674
        },
        {
            "transformers.utils.dummy_tf_objects.TFCLIPTextModel.__init__": 681
        },
        {
            "transformers.utils.dummy_tf_objects.TFCLIPVisionModel.__init__": 688
        },
        {
            "transformers.utils.dummy_tf_objects.TFConvBertForMaskedLM.__init__": 698
        },
        {
            "transformers.utils.dummy_tf_objects.TFConvBertForMultipleChoice.__init__": 705
        },
        {
            "transformers.utils.dummy_tf_objects.TFConvBertForQuestionAnswering.__init__": 712
        },
        {
            "transformers.utils.dummy_tf_objects.TFConvBertForSequenceClassification.__init__": 719
        },
        {
            "transformers.utils.dummy_tf_objects.TFConvBertForTokenClassification.__init__": 726
        },
        {
            "transformers.utils.dummy_tf_objects.TFConvBertLayer.__init__": 733
        },
        {
            "transformers.utils.dummy_tf_objects.TFConvBertModel.__init__": 740
        },
        {
            "transformers.utils.dummy_tf_objects.TFConvBertPreTrainedModel.__init__": 747
        },
        {
            "transformers.utils.dummy_tf_objects.TFConvNextForImageClassification.__init__": 754
        },
        {
            "transformers.utils.dummy_tf_objects.TFConvNextModel.__init__": 761
        },
        {
            "transformers.utils.dummy_tf_objects.TFConvNextPreTrainedModel.__init__": 768
        },
        {
            "transformers.utils.dummy_tf_objects.TFCTRLForSequenceClassification.__init__": 778
        },
        {
            "transformers.utils.dummy_tf_objects.TFCTRLLMHeadModel.__init__": 785
        },
        {
            "transformers.utils.dummy_tf_objects.TFCTRLModel.__init__": 792
        },
        {
            "transformers.utils.dummy_tf_objects.TFCTRLPreTrainedModel.__init__": 799
        },
        {
            "transformers.utils.dummy_tf_objects.TFCvtForImageClassification.__init__": 809
        },
        {
            "transformers.utils.dummy_tf_objects.TFCvtModel.__init__": 816
        },
        {
            "transformers.utils.dummy_tf_objects.TFCvtPreTrainedModel.__init__": 823
        },
        {
            "transformers.utils.dummy_tf_objects.TFData2VecVisionForImageClassification.__init__": 830
        },
        {
            "transformers.utils.dummy_tf_objects.TFData2VecVisionForSemanticSegmentation.__init__": 837
        },
        {
            "transformers.utils.dummy_tf_objects.TFData2VecVisionModel.__init__": 844
        },
        {
            "transformers.utils.dummy_tf_objects.TFData2VecVisionPreTrainedModel.__init__": 851
        },
        {
            "transformers.utils.dummy_tf_objects.TFDebertaForMaskedLM.__init__": 861
        },
        {
            "transformers.utils.dummy_tf_objects.TFDebertaForQuestionAnswering.__init__": 868
        },
        {
            "transformers.utils.dummy_tf_objects.TFDebertaForSequenceClassification.__init__": 875
        },
        {
            "transformers.utils.dummy_tf_objects.TFDebertaForTokenClassification.__init__": 882
        },
        {
            "transformers.utils.dummy_tf_objects.TFDebertaModel.__init__": 889
        },
        {
            "transformers.utils.dummy_tf_objects.TFDebertaPreTrainedModel.__init__": 896
        },
        {
            "transformers.utils.dummy_tf_objects.TFDebertaV2ForMaskedLM.__init__": 906
        },
        {
            "transformers.utils.dummy_tf_objects.TFDebertaV2ForQuestionAnswering.__init__": 913
        },
        {
            "transformers.utils.dummy_tf_objects.TFDebertaV2ForSequenceClassification.__init__": 920
        },
        {
            "transformers.utils.dummy_tf_objects.TFDebertaV2ForTokenClassification.__init__": 927
        },
        {
            "transformers.utils.dummy_tf_objects.TFDebertaV2Model.__init__": 934
        },
        {
            "transformers.utils.dummy_tf_objects.TFDebertaV2PreTrainedModel.__init__": 941
        },
        {
            "transformers.utils.dummy_tf_objects.TFDeiTForImageClassification.__init__": 951
        },
        {
            "transformers.utils.dummy_tf_objects.TFDeiTForImageClassificationWithTeacher.__init__": 958
        },
        {
            "transformers.utils.dummy_tf_objects.TFDeiTForMaskedImageModeling.__init__": 965
        },
        {
            "transformers.utils.dummy_tf_objects.TFDeiTModel.__init__": 972
        },
        {
            "transformers.utils.dummy_tf_objects.TFDeiTPreTrainedModel.__init__": 979
        },
        {
            "transformers.utils.dummy_tf_objects.TFDistilBertForMaskedLM.__init__": 989
        },
        {
            "transformers.utils.dummy_tf_objects.TFDistilBertForMultipleChoice.__init__": 996
        },
        {
            "transformers.utils.dummy_tf_objects.TFDistilBertForQuestionAnswering.__init__": 1003
        },
        {
            "transformers.utils.dummy_tf_objects.TFDistilBertForSequenceClassification.__init__": 1010
        },
        {
            "transformers.utils.dummy_tf_objects.TFDistilBertForTokenClassification.__init__": 1017
        },
        {
            "transformers.utils.dummy_tf_objects.TFDistilBertMainLayer.__init__": 1024
        },
        {
            "transformers.utils.dummy_tf_objects.TFDistilBertModel.__init__": 1031
        },
        {
            "transformers.utils.dummy_tf_objects.TFDistilBertPreTrainedModel.__init__": 1038
        },
        {
            "transformers.utils.dummy_tf_objects.TFDPRContextEncoder.__init__": 1054
        },
        {
            "transformers.utils.dummy_tf_objects.TFDPRPretrainedContextEncoder.__init__": 1061
        },
        {
            "transformers.utils.dummy_tf_objects.TFDPRPretrainedQuestionEncoder.__init__": 1068
        },
        {
            "transformers.utils.dummy_tf_objects.TFDPRPretrainedReader.__init__": 1075
        },
        {
            "transformers.utils.dummy_tf_objects.TFDPRQuestionEncoder.__init__": 1082
        },
        {
            "transformers.utils.dummy_tf_objects.TFDPRReader.__init__": 1089
        },
        {
            "transformers.utils.dummy_tf_objects.TFElectraForMaskedLM.__init__": 1099
        },
        {
            "transformers.utils.dummy_tf_objects.TFElectraForMultipleChoice.__init__": 1106
        },
        {
            "transformers.utils.dummy_tf_objects.TFElectraForPreTraining.__init__": 1113
        },
        {
            "transformers.utils.dummy_tf_objects.TFElectraForQuestionAnswering.__init__": 1120
        },
        {
            "transformers.utils.dummy_tf_objects.TFElectraForSequenceClassification.__init__": 1127
        },
        {
            "transformers.utils.dummy_tf_objects.TFElectraForTokenClassification.__init__": 1134
        },
        {
            "transformers.utils.dummy_tf_objects.TFElectraModel.__init__": 1141
        },
        {
            "transformers.utils.dummy_tf_objects.TFElectraPreTrainedModel.__init__": 1148
        },
        {
            "transformers.utils.dummy_tf_objects.TFEncoderDecoderModel.__init__": 1155
        },
        {
            "transformers.utils.dummy_tf_objects.TFEsmForMaskedLM.__init__": 1165
        },
        {
            "transformers.utils.dummy_tf_objects.TFEsmForSequenceClassification.__init__": 1172
        },
        {
            "transformers.utils.dummy_tf_objects.TFEsmForTokenClassification.__init__": 1179
        },
        {
            "transformers.utils.dummy_tf_objects.TFEsmModel.__init__": 1186
        },
        {
            "transformers.utils.dummy_tf_objects.TFEsmPreTrainedModel.__init__": 1193
        },
        {
            "transformers.utils.dummy_tf_objects.TFFlaubertForMultipleChoice.__init__": 1203
        },
        {
            "transformers.utils.dummy_tf_objects.TFFlaubertForQuestionAnsweringSimple.__init__": 1210
        },
        {
            "transformers.utils.dummy_tf_objects.TFFlaubertForSequenceClassification.__init__": 1217
        },
        {
            "transformers.utils.dummy_tf_objects.TFFlaubertForTokenClassification.__init__": 1224
        },
        {
            "transformers.utils.dummy_tf_objects.TFFlaubertModel.__init__": 1231
        },
        {
            "transformers.utils.dummy_tf_objects.TFFlaubertPreTrainedModel.__init__": 1238
        },
        {
            "transformers.utils.dummy_tf_objects.TFFlaubertWithLMHeadModel.__init__": 1245
        },
        {
            "transformers.utils.dummy_tf_objects.TFFunnelBaseModel.__init__": 1255
        },
        {
            "transformers.utils.dummy_tf_objects.TFFunnelForMaskedLM.__init__": 1262
        },
        {
            "transformers.utils.dummy_tf_objects.TFFunnelForMultipleChoice.__init__": 1269
        },
        {
            "transformers.utils.dummy_tf_objects.TFFunnelForPreTraining.__init__": 1276
        },
        {
            "transformers.utils.dummy_tf_objects.TFFunnelForQuestionAnswering.__init__": 1283
        },
        {
            "transformers.utils.dummy_tf_objects.TFFunnelForSequenceClassification.__init__": 1290
        },
        {
            "transformers.utils.dummy_tf_objects.TFFunnelForTokenClassification.__init__": 1297
        },
        {
            "transformers.utils.dummy_tf_objects.TFFunnelModel.__init__": 1304
        },
        {
            "transformers.utils.dummy_tf_objects.TFFunnelPreTrainedModel.__init__": 1311
        },
        {
            "transformers.utils.dummy_tf_objects.TFGPT2DoubleHeadsModel.__init__": 1321
        },
        {
            "transformers.utils.dummy_tf_objects.TFGPT2ForSequenceClassification.__init__": 1328
        },
        {
            "transformers.utils.dummy_tf_objects.TFGPT2LMHeadModel.__init__": 1335
        },
        {
            "transformers.utils.dummy_tf_objects.TFGPT2MainLayer.__init__": 1342
        },
        {
            "transformers.utils.dummy_tf_objects.TFGPT2Model.__init__": 1349
        },
        {
            "transformers.utils.dummy_tf_objects.TFGPT2PreTrainedModel.__init__": 1356
        },
        {
            "transformers.utils.dummy_tf_objects.TFGPTJForCausalLM.__init__": 1363
        },
        {
            "transformers.utils.dummy_tf_objects.TFGPTJForQuestionAnswering.__init__": 1370
        },
        {
            "transformers.utils.dummy_tf_objects.TFGPTJForSequenceClassification.__init__": 1377
        },
        {
            "transformers.utils.dummy_tf_objects.TFGPTJModel.__init__": 1384
        },
        {
            "transformers.utils.dummy_tf_objects.TFGPTJPreTrainedModel.__init__": 1391
        },
        {
            "transformers.utils.dummy_tf_objects.TFGroupViTModel.__init__": 1401
        },
        {
            "transformers.utils.dummy_tf_objects.TFGroupViTPreTrainedModel.__init__": 1408
        },
        {
            "transformers.utils.dummy_tf_objects.TFGroupViTTextModel.__init__": 1415
        },
        {
            "transformers.utils.dummy_tf_objects.TFGroupViTVisionModel.__init__": 1422
        },
        {
            "transformers.utils.dummy_tf_objects.TFHubertForCTC.__init__": 1432
        },
        {
            "transformers.utils.dummy_tf_objects.TFHubertModel.__init__": 1439
        },
        {
            "transformers.utils.dummy_tf_objects.TFHubertPreTrainedModel.__init__": 1446
        },
        {
            "transformers.utils.dummy_tf_objects.TFLayoutLMv3ForQuestionAnswering.__init__": 1456
        },
        {
            "transformers.utils.dummy_tf_objects.TFLayoutLMv3ForSequenceClassification.__init__": 1463
        },
        {
            "transformers.utils.dummy_tf_objects.TFLayoutLMv3ForTokenClassification.__init__": 1470
        },
        {
            "transformers.utils.dummy_tf_objects.TFLayoutLMv3Model.__init__": 1477
        },
        {
            "transformers.utils.dummy_tf_objects.TFLayoutLMv3PreTrainedModel.__init__": 1484
        },
        {
            "transformers.utils.dummy_tf_objects.TFLEDForConditionalGeneration.__init__": 1491
        },
        {
            "transformers.utils.dummy_tf_objects.TFLEDModel.__init__": 1498
        },
        {
            "transformers.utils.dummy_tf_objects.TFLEDPreTrainedModel.__init__": 1505
        },
        {
            "transformers.utils.dummy_tf_objects.TFLongformerForMaskedLM.__init__": 1515
        },
        {
            "transformers.utils.dummy_tf_objects.TFLongformerForMultipleChoice.__init__": 1522
        },
        {
            "transformers.utils.dummy_tf_objects.TFLongformerForQuestionAnswering.__init__": 1529
        },
        {
            "transformers.utils.dummy_tf_objects.TFLongformerForSequenceClassification.__init__": 1536
        },
        {
            "transformers.utils.dummy_tf_objects.TFLongformerForTokenClassification.__init__": 1543
        },
        {
            "transformers.utils.dummy_tf_objects.TFLongformerModel.__init__": 1550
        },
        {
            "transformers.utils.dummy_tf_objects.TFLongformerPreTrainedModel.__init__": 1557
        },
        {
            "transformers.utils.dummy_tf_objects.TFLongformerSelfAttention.__init__": 1564
        },
        {
            "transformers.utils.dummy_tf_objects.TFLxmertForPreTraining.__init__": 1574
        },
        {
            "transformers.utils.dummy_tf_objects.TFLxmertMainLayer.__init__": 1581
        },
        {
            "transformers.utils.dummy_tf_objects.TFLxmertModel.__init__": 1588
        },
        {
            "transformers.utils.dummy_tf_objects.TFLxmertPreTrainedModel.__init__": 1595
        },
        {
            "transformers.utils.dummy_tf_objects.TFLxmertVisualFeatureEncoder.__init__": 1602
        },
        {
            "transformers.utils.dummy_tf_objects.TFMarianModel.__init__": 1609
        },
        {
            "transformers.utils.dummy_tf_objects.TFMarianMTModel.__init__": 1616
        },
        {
            "transformers.utils.dummy_tf_objects.TFMarianPreTrainedModel.__init__": 1623
        },
        {
            "transformers.utils.dummy_tf_objects.TFMBartForConditionalGeneration.__init__": 1630
        },
        {
            "transformers.utils.dummy_tf_objects.TFMBartModel.__init__": 1637
        },
        {
            "transformers.utils.dummy_tf_objects.TFMBartPreTrainedModel.__init__": 1644
        },
        {
            "transformers.utils.dummy_tf_objects.TFMobileBertForMaskedLM.__init__": 1657
        },
        {
            "transformers.utils.dummy_tf_objects.TFMobileBertForMultipleChoice.__init__": 1664
        },
        {
            "transformers.utils.dummy_tf_objects.TFMobileBertForNextSentencePrediction.__init__": 1671
        },
        {
            "transformers.utils.dummy_tf_objects.TFMobileBertForPreTraining.__init__": 1678
        },
        {
            "transformers.utils.dummy_tf_objects.TFMobileBertForQuestionAnswering.__init__": 1685
        },
        {
            "transformers.utils.dummy_tf_objects.TFMobileBertForSequenceClassification.__init__": 1692
        },
        {
            "transformers.utils.dummy_tf_objects.TFMobileBertForTokenClassification.__init__": 1699
        },
        {
            "transformers.utils.dummy_tf_objects.TFMobileBertMainLayer.__init__": 1706
        },
        {
            "transformers.utils.dummy_tf_objects.TFMobileBertModel.__init__": 1713
        },
        {
            "transformers.utils.dummy_tf_objects.TFMobileBertPreTrainedModel.__init__": 1720
        },
        {
            "transformers.utils.dummy_tf_objects.TFMobileViTForImageClassification.__init__": 1727
        },
        {
            "transformers.utils.dummy_tf_objects.TFMobileViTForSemanticSegmentation.__init__": 1734
        },
        {
            "transformers.utils.dummy_tf_objects.TFMobileViTModel.__init__": 1741
        },
        {
            "transformers.utils.dummy_tf_objects.TFMobileViTPreTrainedModel.__init__": 1748
        },
        {
            "transformers.utils.dummy_tf_objects.TFMPNetForMaskedLM.__init__": 1758
        },
        {
            "transformers.utils.dummy_tf_objects.TFMPNetForMultipleChoice.__init__": 1765
        },
        {
            "transformers.utils.dummy_tf_objects.TFMPNetForQuestionAnswering.__init__": 1772
        },
        {
            "transformers.utils.dummy_tf_objects.TFMPNetForSequenceClassification.__init__": 1779
        },
        {
            "transformers.utils.dummy_tf_objects.TFMPNetForTokenClassification.__init__": 1786
        },
        {
            "transformers.utils.dummy_tf_objects.TFMPNetMainLayer.__init__": 1793
        },
        {
            "transformers.utils.dummy_tf_objects.TFMPNetModel.__init__": 1800
        },
        {
            "transformers.utils.dummy_tf_objects.TFMPNetPreTrainedModel.__init__": 1807
        },
        {
            "transformers.utils.dummy_tf_objects.TFMT5EncoderModel.__init__": 1814
        },
        {
            "transformers.utils.dummy_tf_objects.TFMT5ForConditionalGeneration.__init__": 1821
        },
        {
            "transformers.utils.dummy_tf_objects.TFMT5Model.__init__": 1828
        },
        {
            "transformers.utils.dummy_tf_objects.TFOpenAIGPTDoubleHeadsModel.__init__": 1838
        },
        {
            "transformers.utils.dummy_tf_objects.TFOpenAIGPTForSequenceClassification.__init__": 1845
        },
        {
            "transformers.utils.dummy_tf_objects.TFOpenAIGPTLMHeadModel.__init__": 1852
        },
        {
            "transformers.utils.dummy_tf_objects.TFOpenAIGPTMainLayer.__init__": 1859
        },
        {
            "transformers.utils.dummy_tf_objects.TFOpenAIGPTModel.__init__": 1866
        },
        {
            "transformers.utils.dummy_tf_objects.TFOpenAIGPTPreTrainedModel.__init__": 1873
        },
        {
            "transformers.utils.dummy_tf_objects.TFOPTForCausalLM.__init__": 1880
        },
        {
            "transformers.utils.dummy_tf_objects.TFOPTModel.__init__": 1887
        },
        {
            "transformers.utils.dummy_tf_objects.TFOPTPreTrainedModel.__init__": 1894
        },
        {
            "transformers.utils.dummy_tf_objects.TFPegasusForConditionalGeneration.__init__": 1901
        },
        {
            "transformers.utils.dummy_tf_objects.TFPegasusModel.__init__": 1908
        },
        {
            "transformers.utils.dummy_tf_objects.TFPegasusPreTrainedModel.__init__": 1915
        },
        {
            "transformers.utils.dummy_tf_objects.TFRagModel.__init__": 1922
        },
        {
            "transformers.utils.dummy_tf_objects.TFRagPreTrainedModel.__init__": 1929
        },
        {
            "transformers.utils.dummy_tf_objects.TFRagSequenceForGeneration.__init__": 1936
        },
        {
            "transformers.utils.dummy_tf_objects.TFRagTokenForGeneration.__init__": 1943
        },
        {
            "transformers.utils.dummy_tf_objects.TFRegNetForImageClassification.__init__": 1953
        },
        {
            "transformers.utils.dummy_tf_objects.TFRegNetModel.__init__": 1960
        },
        {
            "transformers.utils.dummy_tf_objects.TFRegNetPreTrainedModel.__init__": 1967
        },
        {
            "transformers.utils.dummy_tf_objects.TFRemBertForCausalLM.__init__": 1977
        },
        {
            "transformers.utils.dummy_tf_objects.TFRemBertForMaskedLM.__init__": 1984
        },
        {
            "transformers.utils.dummy_tf_objects.TFRemBertForMultipleChoice.__init__": 1991
        },
        {
            "transformers.utils.dummy_tf_objects.TFRemBertForQuestionAnswering.__init__": 1998
        },
        {
            "transformers.utils.dummy_tf_objects.TFRemBertForSequenceClassification.__init__": 2005
        },
        {
            "transformers.utils.dummy_tf_objects.TFRemBertForTokenClassification.__init__": 2012
        },
        {
            "transformers.utils.dummy_tf_objects.TFRemBertLayer.__init__": 2019
        },
        {
            "transformers.utils.dummy_tf_objects.TFRemBertModel.__init__": 2026
        },
        {
            "transformers.utils.dummy_tf_objects.TFRemBertPreTrainedModel.__init__": 2033
        },
        {
            "transformers.utils.dummy_tf_objects.TFResNetForImageClassification.__init__": 2043
        },
        {
            "transformers.utils.dummy_tf_objects.TFResNetModel.__init__": 2050
        },
        {
            "transformers.utils.dummy_tf_objects.TFResNetPreTrainedModel.__init__": 2057
        },
        {
            "transformers.utils.dummy_tf_objects.TFRobertaForCausalLM.__init__": 2067
        },
        {
            "transformers.utils.dummy_tf_objects.TFRobertaForMaskedLM.__init__": 2074
        },
        {
            "transformers.utils.dummy_tf_objects.TFRobertaForMultipleChoice.__init__": 2081
        },
        {
            "transformers.utils.dummy_tf_objects.TFRobertaForQuestionAnswering.__init__": 2088
        },
        {
            "transformers.utils.dummy_tf_objects.TFRobertaForSequenceClassification.__init__": 2095
        },
        {
            "transformers.utils.dummy_tf_objects.TFRobertaForTokenClassification.__init__": 2102
        },
        {
            "transformers.utils.dummy_tf_objects.TFRobertaMainLayer.__init__": 2109
        },
        {
            "transformers.utils.dummy_tf_objects.TFRobertaModel.__init__": 2116
        },
        {
            "transformers.utils.dummy_tf_objects.TFRobertaPreTrainedModel.__init__": 2123
        },
        {
            "transformers.utils.dummy_tf_objects.TFRobertaPreLayerNormForCausalLM.__init__": 2133
        },
        {
            "transformers.utils.dummy_tf_objects.TFRobertaPreLayerNormForMaskedLM.__init__": 2140
        },
        {
            "transformers.utils.dummy_tf_objects.TFRobertaPreLayerNormForMultipleChoice.__init__": 2147
        },
        {
            "transformers.utils.dummy_tf_objects.TFRobertaPreLayerNormForQuestionAnswering.__init__": 2154
        },
        {
            "transformers.utils.dummy_tf_objects.TFRobertaPreLayerNormForSequenceClassification.__init__": 2161
        },
        {
            "transformers.utils.dummy_tf_objects.TFRobertaPreLayerNormForTokenClassification.__init__": 2168
        },
        {
            "transformers.utils.dummy_tf_objects.TFRobertaPreLayerNormMainLayer.__init__": 2175
        },
        {
            "transformers.utils.dummy_tf_objects.TFRobertaPreLayerNormModel.__init__": 2182
        },
        {
            "transformers.utils.dummy_tf_objects.TFRobertaPreLayerNormPreTrainedModel.__init__": 2189
        },
        {
            "transformers.utils.dummy_tf_objects.TFRoFormerForCausalLM.__init__": 2199
        },
        {
            "transformers.utils.dummy_tf_objects.TFRoFormerForMaskedLM.__init__": 2206
        },
        {
            "transformers.utils.dummy_tf_objects.TFRoFormerForMultipleChoice.__init__": 2213
        },
        {
            "transformers.utils.dummy_tf_objects.TFRoFormerForQuestionAnswering.__init__": 2220
        },
        {
            "transformers.utils.dummy_tf_objects.TFRoFormerForSequenceClassification.__init__": 2227
        },
        {
            "transformers.utils.dummy_tf_objects.TFRoFormerForTokenClassification.__init__": 2234
        },
        {
            "transformers.utils.dummy_tf_objects.TFRoFormerLayer.__init__": 2241
        },
        {
            "transformers.utils.dummy_tf_objects.TFRoFormerModel.__init__": 2248
        },
        {
            "transformers.utils.dummy_tf_objects.TFRoFormerPreTrainedModel.__init__": 2255
        },
        {
            "transformers.utils.dummy_tf_objects.TFSegformerDecodeHead.__init__": 2265
        },
        {
            "transformers.utils.dummy_tf_objects.TFSegformerForImageClassification.__init__": 2272
        },
        {
            "transformers.utils.dummy_tf_objects.TFSegformerForSemanticSegmentation.__init__": 2279
        },
        {
            "transformers.utils.dummy_tf_objects.TFSegformerModel.__init__": 2286
        },
        {
            "transformers.utils.dummy_tf_objects.TFSegformerPreTrainedModel.__init__": 2293
        },
        {
            "transformers.utils.dummy_tf_objects.TFSpeech2TextForConditionalGeneration.__init__": 2303
        },
        {
            "transformers.utils.dummy_tf_objects.TFSpeech2TextModel.__init__": 2310
        },
        {
            "transformers.utils.dummy_tf_objects.TFSpeech2TextPreTrainedModel.__init__": 2317
        },
        {
            "transformers.utils.dummy_tf_objects.TFSwinForImageClassification.__init__": 2327
        },
        {
            "transformers.utils.dummy_tf_objects.TFSwinForMaskedImageModeling.__init__": 2334
        },
        {
            "transformers.utils.dummy_tf_objects.TFSwinModel.__init__": 2341
        },
        {
            "transformers.utils.dummy_tf_objects.TFSwinPreTrainedModel.__init__": 2348
        },
        {
            "transformers.utils.dummy_tf_objects.TFT5EncoderModel.__init__": 2358
        },
        {
            "transformers.utils.dummy_tf_objects.TFT5ForConditionalGeneration.__init__": 2365
        },
        {
            "transformers.utils.dummy_tf_objects.TFT5Model.__init__": 2372
        },
        {
            "transformers.utils.dummy_tf_objects.TFT5PreTrainedModel.__init__": 2379
        },
        {
            "transformers.utils.dummy_tf_objects.TFTapasForMaskedLM.__init__": 2389
        },
        {
            "transformers.utils.dummy_tf_objects.TFTapasForQuestionAnswering.__init__": 2396
        },
        {
            "transformers.utils.dummy_tf_objects.TFTapasForSequenceClassification.__init__": 2403
        },
        {
            "transformers.utils.dummy_tf_objects.TFTapasModel.__init__": 2410
        },
        {
            "transformers.utils.dummy_tf_objects.TFTapasPreTrainedModel.__init__": 2417
        },
        {
            "transformers.utils.dummy_tf_objects.TFAdaptiveEmbedding.__init__": 2427
        },
        {
            "transformers.utils.dummy_tf_objects.TFTransfoXLForSequenceClassification.__init__": 2434
        },
        {
            "transformers.utils.dummy_tf_objects.TFTransfoXLLMHeadModel.__init__": 2441
        },
        {
            "transformers.utils.dummy_tf_objects.TFTransfoXLMainLayer.__init__": 2448
        },
        {
            "transformers.utils.dummy_tf_objects.TFTransfoXLModel.__init__": 2455
        },
        {
            "transformers.utils.dummy_tf_objects.TFTransfoXLPreTrainedModel.__init__": 2462
        },
        {
            "transformers.utils.dummy_tf_objects.TFVisionEncoderDecoderModel.__init__": 2469
        },
        {
            "transformers.utils.dummy_tf_objects.TFViTForImageClassification.__init__": 2476
        },
        {
            "transformers.utils.dummy_tf_objects.TFViTModel.__init__": 2483
        },
        {
            "transformers.utils.dummy_tf_objects.TFViTPreTrainedModel.__init__": 2490
        },
        {
            "transformers.utils.dummy_tf_objects.TFViTMAEForPreTraining.__init__": 2497
        },
        {
            "transformers.utils.dummy_tf_objects.TFViTMAEModel.__init__": 2504
        },
        {
            "transformers.utils.dummy_tf_objects.TFViTMAEPreTrainedModel.__init__": 2511
        },
        {
            "transformers.utils.dummy_tf_objects.TFWav2Vec2ForCTC.__init__": 2521
        },
        {
            "transformers.utils.dummy_tf_objects.TFWav2Vec2Model.__init__": 2528
        },
        {
            "transformers.utils.dummy_tf_objects.TFWav2Vec2PreTrainedModel.__init__": 2535
        },
        {
            "transformers.utils.dummy_tf_objects.TFWhisperForConditionalGeneration.__init__": 2545
        },
        {
            "transformers.utils.dummy_tf_objects.TFWhisperModel.__init__": 2552
        },
        {
            "transformers.utils.dummy_tf_objects.TFWhisperPreTrainedModel.__init__": 2559
        },
        {
            "transformers.utils.dummy_tf_objects.TFXGLMForCausalLM.__init__": 2569
        },
        {
            "transformers.utils.dummy_tf_objects.TFXGLMModel.__init__": 2576
        },
        {
            "transformers.utils.dummy_tf_objects.TFXGLMPreTrainedModel.__init__": 2583
        },
        {
            "transformers.utils.dummy_tf_objects.TFXLMForMultipleChoice.__init__": 2593
        },
        {
            "transformers.utils.dummy_tf_objects.TFXLMForQuestionAnsweringSimple.__init__": 2600
        },
        {
            "transformers.utils.dummy_tf_objects.TFXLMForSequenceClassification.__init__": 2607
        },
        {
            "transformers.utils.dummy_tf_objects.TFXLMForTokenClassification.__init__": 2614
        },
        {
            "transformers.utils.dummy_tf_objects.TFXLMMainLayer.__init__": 2621
        },
        {
            "transformers.utils.dummy_tf_objects.TFXLMModel.__init__": 2628
        },
        {
            "transformers.utils.dummy_tf_objects.TFXLMPreTrainedModel.__init__": 2635
        },
        {
            "transformers.utils.dummy_tf_objects.TFXLMWithLMHeadModel.__init__": 2642
        },
        {
            "transformers.utils.dummy_tf_objects.TFXLMRobertaForCausalLM.__init__": 2652
        },
        {
            "transformers.utils.dummy_tf_objects.TFXLMRobertaForMaskedLM.__init__": 2659
        },
        {
            "transformers.utils.dummy_tf_objects.TFXLMRobertaForMultipleChoice.__init__": 2666
        },
        {
            "transformers.utils.dummy_tf_objects.TFXLMRobertaForQuestionAnswering.__init__": 2673
        },
        {
            "transformers.utils.dummy_tf_objects.TFXLMRobertaForSequenceClassification.__init__": 2680
        },
        {
            "transformers.utils.dummy_tf_objects.TFXLMRobertaForTokenClassification.__init__": 2687
        },
        {
            "transformers.utils.dummy_tf_objects.TFXLMRobertaModel.__init__": 2694
        },
        {
            "transformers.utils.dummy_tf_objects.TFXLMRobertaPreTrainedModel.__init__": 2701
        },
        {
            "transformers.utils.dummy_tf_objects.TFXLNetForMultipleChoice.__init__": 2711
        },
        {
            "transformers.utils.dummy_tf_objects.TFXLNetForQuestionAnsweringSimple.__init__": 2718
        },
        {
            "transformers.utils.dummy_tf_objects.TFXLNetForSequenceClassification.__init__": 2725
        },
        {
            "transformers.utils.dummy_tf_objects.TFXLNetForTokenClassification.__init__": 2732
        },
        {
            "transformers.utils.dummy_tf_objects.TFXLNetLMHeadModel.__init__": 2739
        },
        {
            "transformers.utils.dummy_tf_objects.TFXLNetMainLayer.__init__": 2746
        },
        {
            "transformers.utils.dummy_tf_objects.TFXLNetModel.__init__": 2753
        },
        {
            "transformers.utils.dummy_tf_objects.TFXLNetPreTrainedModel.__init__": 2760
        },
        {
            "transformers.utils.dummy_tf_objects.AdamWeightDecay.__init__": 2767
        },
        {
            "transformers.utils.dummy_tf_objects.GradientAccumulator.__init__": 2774
        },
        {
            "transformers.utils.dummy_tf_objects.WarmUp.__init__": 2781
        },
        {
            "transformers.utils.dummy_tf_objects.create_optimizer": 2785
        },
        {
            "transformers.utils.dummy_tf_objects.TFTrainer.__init__": 2792
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/utils/hub.py": [
        {
            "transformers.utils.hub.PushToHubMixin.push_to_hub": 712
        },
        {
            "transformers.utils.hub.send_example_telemetry": 807
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/utils/dummy_tokenizers_objects.py": [
        {
            "transformers.utils.dummy_tokenizers_objects.AlbertTokenizerFast.__init__": 9
        },
        {
            "transformers.utils.dummy_tokenizers_objects.BartTokenizerFast.__init__": 16
        },
        {
            "transformers.utils.dummy_tokenizers_objects.BarthezTokenizerFast.__init__": 23
        },
        {
            "transformers.utils.dummy_tokenizers_objects.BertTokenizerFast.__init__": 30
        },
        {
            "transformers.utils.dummy_tokenizers_objects.BigBirdTokenizerFast.__init__": 37
        },
        {
            "transformers.utils.dummy_tokenizers_objects.BlenderbotTokenizerFast.__init__": 44
        },
        {
            "transformers.utils.dummy_tokenizers_objects.BlenderbotSmallTokenizerFast.__init__": 51
        },
        {
            "transformers.utils.dummy_tokenizers_objects.BloomTokenizerFast.__init__": 58
        },
        {
            "transformers.utils.dummy_tokenizers_objects.CamembertTokenizerFast.__init__": 65
        },
        {
            "transformers.utils.dummy_tokenizers_objects.CLIPTokenizerFast.__init__": 72
        },
        {
            "transformers.utils.dummy_tokenizers_objects.CodeGenTokenizerFast.__init__": 79
        },
        {
            "transformers.utils.dummy_tokenizers_objects.ConvBertTokenizerFast.__init__": 86
        },
        {
            "transformers.utils.dummy_tokenizers_objects.CpmTokenizerFast.__init__": 93
        },
        {
            "transformers.utils.dummy_tokenizers_objects.DebertaTokenizerFast.__init__": 100
        },
        {
            "transformers.utils.dummy_tokenizers_objects.DebertaV2TokenizerFast.__init__": 107
        },
        {
            "transformers.utils.dummy_tokenizers_objects.DistilBertTokenizerFast.__init__": 114
        },
        {
            "transformers.utils.dummy_tokenizers_objects.DPRContextEncoderTokenizerFast.__init__": 121
        },
        {
            "transformers.utils.dummy_tokenizers_objects.DPRQuestionEncoderTokenizerFast.__init__": 128
        },
        {
            "transformers.utils.dummy_tokenizers_objects.DPRReaderTokenizerFast.__init__": 135
        },
        {
            "transformers.utils.dummy_tokenizers_objects.ElectraTokenizerFast.__init__": 142
        },
        {
            "transformers.utils.dummy_tokenizers_objects.FNetTokenizerFast.__init__": 149
        },
        {
            "transformers.utils.dummy_tokenizers_objects.FunnelTokenizerFast.__init__": 156
        },
        {
            "transformers.utils.dummy_tokenizers_objects.GPT2TokenizerFast.__init__": 163
        },
        {
            "transformers.utils.dummy_tokenizers_objects.GPTNeoXTokenizerFast.__init__": 170
        },
        {
            "transformers.utils.dummy_tokenizers_objects.GPTNeoXJapaneseTokenizer.__init__": 177
        },
        {
            "transformers.utils.dummy_tokenizers_objects.HerbertTokenizerFast.__init__": 184
        },
        {
            "transformers.utils.dummy_tokenizers_objects.LayoutLMTokenizerFast.__init__": 191
        },
        {
            "transformers.utils.dummy_tokenizers_objects.LayoutLMv2TokenizerFast.__init__": 198
        },
        {
            "transformers.utils.dummy_tokenizers_objects.LayoutLMv3TokenizerFast.__init__": 205
        },
        {
            "transformers.utils.dummy_tokenizers_objects.LayoutXLMTokenizerFast.__init__": 212
        },
        {
            "transformers.utils.dummy_tokenizers_objects.LEDTokenizerFast.__init__": 219
        },
        {
            "transformers.utils.dummy_tokenizers_objects.LongformerTokenizerFast.__init__": 226
        },
        {
            "transformers.utils.dummy_tokenizers_objects.LxmertTokenizerFast.__init__": 233
        },
        {
            "transformers.utils.dummy_tokenizers_objects.MarkupLMTokenizerFast.__init__": 240
        },
        {
            "transformers.utils.dummy_tokenizers_objects.MBartTokenizerFast.__init__": 247
        },
        {
            "transformers.utils.dummy_tokenizers_objects.MBart50TokenizerFast.__init__": 254
        },
        {
            "transformers.utils.dummy_tokenizers_objects.MobileBertTokenizerFast.__init__": 261
        },
        {
            "transformers.utils.dummy_tokenizers_objects.MPNetTokenizerFast.__init__": 268
        },
        {
            "transformers.utils.dummy_tokenizers_objects.MT5TokenizerFast.__init__": 275
        },
        {
            "transformers.utils.dummy_tokenizers_objects.MvpTokenizerFast.__init__": 282
        },
        {
            "transformers.utils.dummy_tokenizers_objects.NllbTokenizerFast.__init__": 289
        },
        {
            "transformers.utils.dummy_tokenizers_objects.OpenAIGPTTokenizerFast.__init__": 296
        },
        {
            "transformers.utils.dummy_tokenizers_objects.PegasusTokenizerFast.__init__": 303
        },
        {
            "transformers.utils.dummy_tokenizers_objects.RealmTokenizerFast.__init__": 310
        },
        {
            "transformers.utils.dummy_tokenizers_objects.ReformerTokenizerFast.__init__": 317
        },
        {
            "transformers.utils.dummy_tokenizers_objects.RemBertTokenizerFast.__init__": 324
        },
        {
            "transformers.utils.dummy_tokenizers_objects.RetriBertTokenizerFast.__init__": 331
        },
        {
            "transformers.utils.dummy_tokenizers_objects.RobertaTokenizerFast.__init__": 338
        },
        {
            "transformers.utils.dummy_tokenizers_objects.RoFormerTokenizerFast.__init__": 345
        },
        {
            "transformers.utils.dummy_tokenizers_objects.SplinterTokenizerFast.__init__": 352
        },
        {
            "transformers.utils.dummy_tokenizers_objects.SqueezeBertTokenizerFast.__init__": 359
        },
        {
            "transformers.utils.dummy_tokenizers_objects.T5TokenizerFast.__init__": 366
        },
        {
            "transformers.utils.dummy_tokenizers_objects.XGLMTokenizerFast.__init__": 373
        },
        {
            "transformers.utils.dummy_tokenizers_objects.XLMRobertaTokenizerFast.__init__": 380
        },
        {
            "transformers.utils.dummy_tokenizers_objects.XLNetTokenizerFast.__init__": 387
        },
        {
            "transformers.utils.dummy_tokenizers_objects.PreTrainedTokenizerFast.__init__": 394
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/sagemaker/trainer_sm.py": [
        {
            "transformers.sagemaker.trainer_sm.SageMakerTrainer.__init__": 24
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/commands/add_new_model.py": [
        {
            "transformers.commands.add_new_model.AddNewModelCommand.__init__": 52
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/commands/serving.py": [
        {
            "transformers.commands.serving.Body": 34
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/commands/add_new_model_like.py": [
        {
            "transformers.commands.add_new_model_like.AddNewModelLikeCommand.__init__": 1366
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/commands/pt_to_tf.py": [
        {
            "transformers.commands.pt_to_tf.PTtoTFCommand.__init__": 171
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/commands/lfs.py": [
        {
            "transformers.commands.lfs.FileSlice.__exit__": 153
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/commands/convert.py": [
        {
            "transformers.commands.convert.ConvertCommand.__init__": 67
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/benchmark/benchmark_tf.py": [
        {
            "transformers.benchmark.benchmark_tf.run_in_eager_mode": 54
        },
        {
            "transformers.benchmark.benchmark_tf.run_in_graph_mode": 59
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/benchmark/benchmark_args.py": [
        {
            "transformers.benchmark.benchmark_args.PyTorchBenchmarkArguments.__init__": 47
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/benchmark/benchmark_args_tf.py": [
        {
            "transformers.benchmark.benchmark_args_tf.TensorFlowBenchmarkArguments.__init__": 44
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/onnx/features.py": [
        {
            "transformers.onnx.features.supported_features_mapping": 55
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/mobilevit/modeling_tf_mobilevit.py": [
        {
            "transformers.models.mobilevit.modeling_tf_mobilevit.TFMobileViTConvLayer.__init__": 83
        },
        {
            "transformers.models.mobilevit.modeling_tf_mobilevit.TFMobileViTInvertedResidual.__init__": 149
        },
        {
            "transformers.models.mobilevit.modeling_tf_mobilevit.TFMobileViTMobileNetLayer.__init__": 193
        },
        {
            "transformers.models.mobilevit.modeling_tf_mobilevit.TFMobileViTSelfAttention.__init__": 223
        },
        {
            "transformers.models.mobilevit.modeling_tf_mobilevit.TFMobileViTSelfOutput.__init__": 275
        },
        {
            "transformers.models.mobilevit.modeling_tf_mobilevit.TFMobileViTAttention.__init__": 287
        },
        {
            "transformers.models.mobilevit.modeling_tf_mobilevit.TFMobileViTIntermediate.__init__": 302
        },
        {
            "transformers.models.mobilevit.modeling_tf_mobilevit.TFMobileViTOutput.__init__": 317
        },
        {
            "transformers.models.mobilevit.modeling_tf_mobilevit.TFMobileViTTransformerLayer.__init__": 330
        },
        {
            "transformers.models.mobilevit.modeling_tf_mobilevit.TFMobileViTTransformer.__init__": 353
        },
        {
            "transformers.models.mobilevit.modeling_tf_mobilevit.TFMobileViTLayer.__init__": 377
        },
        {
            "transformers.models.mobilevit.modeling_tf_mobilevit.TFMobileViTEncoder.__init__": 531
        },
        {
            "transformers.models.mobilevit.modeling_tf_mobilevit.TFMobileViTMainLayer.__init__": 634
        },
        {
            "transformers.models.mobilevit.modeling_tf_mobilevit.TFMobileViTModel.__init__": 831
        },
        {
            "transformers.models.mobilevit.modeling_tf_mobilevit.TFMobileViTForImageClassification.__init__": 875
        },
        {
            "transformers.models.mobilevit.modeling_tf_mobilevit.TFMobileViTASPPPooling.__init__": 932
        },
        {
            "transformers.models.mobilevit.modeling_tf_mobilevit.TFMobileViTASPP.__init__": 960
        },
        {
            "transformers.models.mobilevit.modeling_tf_mobilevit.TFMobileViTDeepLabV3.__init__": 1025
        },
        {
            "transformers.models.mobilevit.modeling_tf_mobilevit.TFMobileViTForSemanticSegmentation.__init__": 1055
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/mobilevit/image_processing_mobilevit.py": [
        {
            "transformers.models.mobilevit.image_processing_mobilevit.MobileViTImageProcessor.__init__": 110
        },
        {
            "transformers.models.mobilevit.image_processing_mobilevit.MobileViTImageProcessor.resize": 137
        },
        {
            "transformers.models.mobilevit.image_processing_mobilevit.MobileViTImageProcessor.center_crop": 165
        },
        {
            "transformers.models.mobilevit.image_processing_mobilevit.MobileViTImageProcessor.rescale": 189
        },
        {
            "transformers.models.mobilevit.image_processing_mobilevit.MobileViTImageProcessor.preprocess": 223
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/mobilevit/feature_extraction_mobilevit.py": [
        {
            "transformers.models.mobilevit.feature_extraction_mobilevit.MobileViTFeatureExtractor.__init__": 27
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/mobilevit/modeling_mobilevit.py": [
        {
            "transformers.models.mobilevit.modeling_mobilevit.MobileViTEncoder.custom_forward": 631
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/mobilevit/configuration_mobilevit.py": [
        {
            "transformers.models.mobilevit.configuration_mobilevit.MobileViTConfig.__init__": 116
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/distilbert/modeling_flax_distilbert.py": [
        {
            "transformers.models.distilbert.modeling_flax_distilbert.FlaxDistilBertPreTrainedModel.__init__": 425
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/distilbert/tokenization_distilbert_fast.py": [
        {
            "transformers.models.distilbert.tokenization_distilbert_fast.DistilBertTokenizerFast.__init__": 131
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/distilbert/configuration_distilbert.py": [
        {
            "transformers.models.distilbert.configuration_distilbert.DistilBertConfig.__init__": 108
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/distilbert/tokenization_distilbert.py": [
        {
            "transformers.models.distilbert.tokenization_distilbert.DistilBertTokenizer.__init__": 137
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/distilbert/modeling_tf_distilbert.py": [
        {
            "transformers.models.distilbert.modeling_tf_distilbert.TFEmbeddings.__init__": 76
        },
        {
            "transformers.models.distilbert.modeling_tf_distilbert.TFMultiHeadSelfAttention.__init__": 138
        },
        {
            "transformers.models.distilbert.modeling_tf_distilbert.TFFFN.__init__": 224
        },
        {
            "transformers.models.distilbert.modeling_tf_distilbert.TFTransformerBlock.__init__": 244
        },
        {
            "transformers.models.distilbert.modeling_tf_distilbert.TFTransformer.__init__": 293
        },
        {
            "transformers.models.distilbert.modeling_tf_distilbert.TFDistilBertMainLayer.__init__": 351
        },
        {
            "transformers.models.distilbert.modeling_tf_distilbert.TFDistilBertModel.__init__": 537
        },
        {
            "transformers.models.distilbert.modeling_tf_distilbert.TFDistilBertLMHead.__init__": 579
        },
        {
            "transformers.models.distilbert.modeling_tf_distilbert.TFDistilBertForMaskedLM.__init__": 623
        },
        {
            "transformers.models.distilbert.modeling_tf_distilbert.TFDistilBertForSequenceClassification.__init__": 712
        },
        {
            "transformers.models.distilbert.modeling_tf_distilbert.TFDistilBertForTokenClassification.__init__": 798
        },
        {
            "transformers.models.distilbert.modeling_tf_distilbert.TFDistilBertForMultipleChoice.__init__": 873
        },
        {
            "transformers.models.distilbert.modeling_tf_distilbert.TFDistilBertForQuestionAnswering.__init__": 997
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/dpt/feature_extraction_dpt.py": [
        {
            "transformers.models.dpt.feature_extraction_dpt.DPTFeatureExtractor.__init__": 27
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/dpt/image_processing_dpt.py": [
        {
            "transformers.models.dpt.image_processing_dpt.DPTImageProcessor.__init__": 126
        },
        {
            "transformers.models.dpt.image_processing_dpt.DPTImageProcessor.resize": 154
        },
        {
            "transformers.models.dpt.image_processing_dpt.DPTImageProcessor.rescale": 197
        },
        {
            "transformers.models.dpt.image_processing_dpt.DPTImageProcessor.normalize": 217
        },
        {
            "transformers.models.dpt.image_processing_dpt.DPTImageProcessor.preprocess": 240
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/dpt/modeling_dpt.py": [
        {
            "transformers.models.dpt.modeling_dpt.DPTViTEncoder.custom_forward": 535
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/dpt/configuration_dpt.py": [
        {
            "transformers.models.dpt.configuration_dpt.DPTConfig.__init__": 125
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/git/configuration_git.py": [
        {
            "transformers.models.git.configuration_git.GitVisionConfig.__init__": 86
        },
        {
            "transformers.models.git.configuration_git.GitVisionConfig.from_pretrained": 122
        },
        {
            "transformers.models.git.configuration_git.GitConfig.__init__": 206
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/git/modeling_git.py": [
        {
            "transformers.models.git.modeling_git.GitEncoder.custom_forward": 454
        },
        {
            "transformers.models.git.modeling_git.GitVisionEncoder.custom_forward": 880
        },
        {
            "transformers.models.git.modeling_git.GitForCausalLM.prepare_inputs_for_generation": 1515
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/git/processing_git.py": [
        {
            "transformers.models.git.processing_git.GitProcessor.__call__": 44
        },
        {
            "transformers.models.git.processing_git.GitProcessor.batch_decode": 97
        },
        {
            "transformers.models.git.processing_git.GitProcessor.decode": 104
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/efficientformer/image_processing_efficientformer.py": [
        {
            "transformers.models.efficientformer.image_processing_efficientformer.EfficientFormerImageProcessor.__init__": 87
        },
        {
            "transformers.models.efficientformer.image_processing_efficientformer.EfficientFormerImageProcessor.resize": 118
        },
        {
            "transformers.models.efficientformer.image_processing_efficientformer.EfficientFormerImageProcessor.center_crop": 156
        },
        {
            "transformers.models.efficientformer.image_processing_efficientformer.EfficientFormerImageProcessor.rescale": 180
        },
        {
            "transformers.models.efficientformer.image_processing_efficientformer.EfficientFormerImageProcessor.normalize": 202
        },
        {
            "transformers.models.efficientformer.image_processing_efficientformer.EfficientFormerImageProcessor.preprocess": 231
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/efficientformer/configuration_efficientformer.py": [
        {
            "transformers.models.efficientformer.configuration_efficientformer.EfficientFormerConfig.__init__": 112
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/blip/configuration_blip.py": [
        {
            "transformers.models.blip.configuration_blip.BlipTextConfig.__init__": 117
        },
        {
            "transformers.models.blip.configuration_blip.BlipTextConfig.from_pretrained": 167
        },
        {
            "transformers.models.blip.configuration_blip.BlipVisionConfig.__init__": 239
        },
        {
            "transformers.models.blip.configuration_blip.BlipVisionConfig.from_pretrained": 275
        },
        {
            "transformers.models.blip.configuration_blip.BlipConfig.__init__": 342
        },
        {
            "transformers.models.blip.configuration_blip.BlipConfig.from_text_vision_configs": 381
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/blip/image_processing_blip.py": [
        {
            "transformers.models.blip.image_processing_blip.BlipImageProcessor.__init__": 83
        },
        {
            "transformers.models.blip.image_processing_blip.BlipImageProcessor.resize": 111
        },
        {
            "transformers.models.blip.image_processing_blip.BlipImageProcessor.rescale": 140
        },
        {
            "transformers.models.blip.image_processing_blip.BlipImageProcessor.normalize": 160
        },
        {
            "transformers.models.blip.image_processing_blip.BlipImageProcessor.preprocess": 183
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/blip/modeling_blip_text.py": [
        {
            "transformers.models.blip.modeling_blip_text.BlipTextEncoder.custom_forward": 420
        },
        {
            "transformers.models.blip.modeling_blip_text.BlipTextLMHeadModel.prepare_inputs_for_generation": 911
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/blip/processing_blip.py": [
        {
            "transformers.models.blip.processing_blip.BlipProcessor.__call__": 48
        },
        {
            "transformers.models.blip.processing_blip.BlipProcessor.batch_decode": 131
        },
        {
            "transformers.models.blip.processing_blip.BlipProcessor.decode": 138
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/blip/modeling_blip.py": [
        {
            "transformers.models.blip.modeling_blip.BlipEncoder.custom_forward": 625
        },
        {
            "transformers.models.blip.modeling_blip.BlipForConditionalGeneration.generate": 1034
        },
        {
            "transformers.models.blip.modeling_blip.BlipForQuestionAnswering.generate": 1261
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/layoutlmv3/configuration_layoutlmv3.py": [
        {
            "transformers.models.layoutlmv3.configuration_layoutlmv3.LayoutLMv3Config.__init__": 124
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/layoutlmv3/tokenization_layoutlmv3_fast.py": [
        {
            "transformers.models.layoutlmv3.tokenization_layoutlmv3_fast.LayoutLMv3TokenizerFast.__init__": 139
        },
        {
            "transformers.models.layoutlmv3.tokenization_layoutlmv3_fast.LayoutLMv3TokenizerFast.__call__": 226
        },
        {
            "transformers.models.layoutlmv3.tokenization_layoutlmv3_fast.LayoutLMv3TokenizerFast.batch_encode_plus": 375
        },
        {
            "transformers.models.layoutlmv3.tokenization_layoutlmv3_fast.LayoutLMv3TokenizerFast.tokenize": 435
        },
        {
            "transformers.models.layoutlmv3.tokenization_layoutlmv3_fast.LayoutLMv3TokenizerFast.encode_plus": 445
        },
        {
            "transformers.models.layoutlmv3.tokenization_layoutlmv3_fast.LayoutLMv3TokenizerFast._encode_plus": 670
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/layoutlmv3/image_processing_layoutlmv3.py": [
        {
            "transformers.models.layoutlmv3.image_processing_layoutlmv3.LayoutLMv3ImageProcessor.__init__": 147
        },
        {
            "transformers.models.layoutlmv3.image_processing_layoutlmv3.LayoutLMv3ImageProcessor.resize": 178
        },
        {
            "transformers.models.layoutlmv3.image_processing_layoutlmv3.LayoutLMv3ImageProcessor.rescale": 205
        },
        {
            "transformers.models.layoutlmv3.image_processing_layoutlmv3.LayoutLMv3ImageProcessor.normalize": 225
        },
        {
            "transformers.models.layoutlmv3.image_processing_layoutlmv3.LayoutLMv3ImageProcessor.preprocess": 248
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/layoutlmv3/feature_extraction_layoutlmv3.py": [
        {
            "transformers.models.layoutlmv3.feature_extraction_layoutlmv3.LayoutLMv3FeatureExtractor.__init__": 29
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/layoutlmv3/tokenization_layoutlmv3.py": [
        {
            "transformers.models.layoutlmv3.tokenization_layoutlmv3.LayoutLMv3Tokenizer.__init__": 276
        },
        {
            "transformers.models.layoutlmv3.tokenization_layoutlmv3.LayoutLMv3Tokenizer.prepare_for_tokenization": 535
        },
        {
            "transformers.models.layoutlmv3.tokenization_layoutlmv3.LayoutLMv3Tokenizer.__call__": 549
        },
        {
            "transformers.models.layoutlmv3.tokenization_layoutlmv3.LayoutLMv3Tokenizer.batch_encode_plus": 698
        },
        {
            "transformers.models.layoutlmv3.tokenization_layoutlmv3.LayoutLMv3Tokenizer._batch_encode_plus": 758
        },
        {
            "transformers.models.layoutlmv3.tokenization_layoutlmv3.LayoutLMv3Tokenizer.encode": 888
        },
        {
            "transformers.models.layoutlmv3.tokenization_layoutlmv3.LayoutLMv3Tokenizer.encode_plus": 936
        },
        {
            "transformers.models.layoutlmv3.tokenization_layoutlmv3.LayoutLMv3Tokenizer._encode_plus": 1003
        },
        {
            "transformers.models.layoutlmv3.tokenization_layoutlmv3.LayoutLMv3Tokenizer.prepare_for_model": 1056
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/layoutlmv3/modeling_layoutlmv3.py": [
        {
            "transformers.models.layoutlmv3.modeling_layoutlmv3.LayoutLMv3Encoder.custom_forward": 667
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/layoutlmv3/modeling_tf_layoutlmv3.py": [
        {
            "transformers.models.layoutlmv3.modeling_tf_layoutlmv3.TFLayoutLMv3PatchEmbeddings.__init__": 67
        },
        {
            "transformers.models.layoutlmv3.modeling_tf_layoutlmv3.TFLayoutLMv3TextEmbeddings.__init__": 102
        },
        {
            "transformers.models.layoutlmv3.modeling_tf_layoutlmv3.TFLayoutLMv3SelfAttention.__init__": 270
        },
        {
            "transformers.models.layoutlmv3.modeling_tf_layoutlmv3.TFLayoutLMv3SelfOutput.__init__": 383
        },
        {
            "transformers.models.layoutlmv3.modeling_tf_layoutlmv3.TFLayoutLMv3Attention.__init__": 401
        },
        {
            "transformers.models.layoutlmv3.modeling_tf_layoutlmv3.TFLayoutLMv3Intermediate.__init__": 432
        },
        {
            "transformers.models.layoutlmv3.modeling_tf_layoutlmv3.TFLayoutLMv3Output.__init__": 453
        },
        {
            "transformers.models.layoutlmv3.modeling_tf_layoutlmv3.TFLayoutLMv3Layer.__init__": 471
        },
        {
            "transformers.models.layoutlmv3.modeling_tf_layoutlmv3.TFLayoutLMv3Encoder.__init__": 505
        },
        {
            "transformers.models.layoutlmv3.modeling_tf_layoutlmv3.TFLayoutLMv3MainLayer.__init__": 663
        },
        {
            "transformers.models.layoutlmv3.modeling_tf_layoutlmv3.TFLayoutLMv3Model.__init__": 1147
        },
        {
            "transformers.models.layoutlmv3.modeling_tf_layoutlmv3.TFLayoutLMv3ClassificationHead.__init__": 1231
        },
        {
            "transformers.models.layoutlmv3.modeling_tf_layoutlmv3.TFLayoutLMv3ForSequenceClassification.__init__": 1272
        },
        {
            "transformers.models.layoutlmv3.modeling_tf_layoutlmv3.TFLayoutLMv3ForTokenClassification.__init__": 1383
        },
        {
            "transformers.models.layoutlmv3.modeling_tf_layoutlmv3.TFLayoutLMv3ForQuestionAnswering.__init__": 1512
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/layoutlmv3/processing_layoutlmv3.py": [
        {
            "transformers.models.layoutlmv3.processing_layoutlmv3.LayoutLMv3Processor.__init__": 50
        },
        {
            "transformers.models.layoutlmv3.processing_layoutlmv3.LayoutLMv3Processor.__call__": 67
        },
        {
            "transformers.models.layoutlmv3.processing_layoutlmv3.LayoutLMv3Processor.batch_decode": 165
        },
        {
            "transformers.models.layoutlmv3.processing_layoutlmv3.LayoutLMv3Processor.decode": 172
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/openai/modeling_openai.py": [
        {
            "transformers.models.openai.modeling_openai.OpenAIGPTLMHeadModel.prepare_inputs_for_generation": 609
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/openai/tokenization_openai_fast.py": [
        {
            "transformers.models.openai.tokenization_openai_fast.OpenAIGPTTokenizerFast.__init__": 67
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/openai/tokenization_openai.py": [
        {
            "transformers.models.openai.tokenization_openai.OpenAIGPTTokenizer.__init__": 259
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/openai/configuration_openai.py": [
        {
            "transformers.models.openai.configuration_openai.OpenAIGPTConfig.__init__": 121
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/openai/modeling_tf_openai.py": [
        {
            "transformers.models.openai.modeling_tf_openai.TFAttention.__init__": 62
        },
        {
            "transformers.models.openai.modeling_tf_openai.TFMLP.__init__": 156
        },
        {
            "transformers.models.openai.modeling_tf_openai.TFBlock.__init__": 172
        },
        {
            "transformers.models.openai.modeling_tf_openai.TFOpenAIGPTMainLayer.__init__": 196
        },
        {
            "transformers.models.openai.modeling_tf_openai.TFOpenAIGPTModel.__init__": 523
        },
        {
            "transformers.models.openai.modeling_tf_openai.TFOpenAIGPTLMHeadModel.__init__": 578
        },
        {
            "transformers.models.openai.modeling_tf_openai.TFOpenAIGPTLMHeadModel.prepare_inputs_for_generation": 657
        },
        {
            "transformers.models.openai.modeling_tf_openai.TFOpenAIGPTDoubleHeadsModel.__init__": 671
        },
        {
            "transformers.models.openai.modeling_tf_openai.TFOpenAIGPTForSequenceClassification.__init__": 806
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/sew/configuration_sew.py": [
        {
            "transformers.models.sew.configuration_sew.SEWConfig.__init__": 154
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/sew/modeling_sew.py": [
        {
            "transformers.models.sew.modeling_sew.SEWFeatureEncoder.custom_forward": 367
        },
        {
            "transformers.models.sew.modeling_sew.SEWEncoder.custom_forward": 680
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/vit_hybrid/configuration_vit_hybrid.py": [
        {
            "transformers.models.vit_hybrid.configuration_vit_hybrid.ViTHybridConfig.__init__": 93
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/vit_hybrid/image_processing_vit_hybrid.py": [
        {
            "transformers.models.vit_hybrid.image_processing_vit_hybrid.ViTHybridImageProcessor.__init__": 85
        },
        {
            "transformers.models.vit_hybrid.image_processing_vit_hybrid.ViTHybridImageProcessor.resize": 118
        },
        {
            "transformers.models.vit_hybrid.image_processing_vit_hybrid.ViTHybridImageProcessor.center_crop": 146
        },
        {
            "transformers.models.vit_hybrid.image_processing_vit_hybrid.ViTHybridImageProcessor.rescale": 170
        },
        {
            "transformers.models.vit_hybrid.image_processing_vit_hybrid.ViTHybridImageProcessor.normalize": 190
        },
        {
            "transformers.models.vit_hybrid.image_processing_vit_hybrid.ViTHybridImageProcessor.preprocess": 213
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/vit_hybrid/modeling_vit_hybrid.py": [
        {
            "transformers.models.vit_hybrid.modeling_vit_hybrid.ViTHybridEncoder.custom_forward": 422
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/swin2sr/configuration_swin2sr.py": [
        {
            "transformers.models.swin2sr.configuration_swin2sr.Swin2SRConfig.__init__": 108
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/swin2sr/image_processing_swin2sr.py": [
        {
            "transformers.models.swin2sr.image_processing_swin2sr.Swin2SRImageProcessor.__init__": 47
        },
        {
            "transformers.models.swin2sr.image_processing_swin2sr.Swin2SRImageProcessor.rescale": 62
        },
        {
            "transformers.models.swin2sr.image_processing_swin2sr.Swin2SRImageProcessor.preprocess": 108
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/swin2sr/modeling_swin2sr.py": [
        {
            "transformers.models.swin2sr.modeling_swin2sr.Swin2SREncoder.custom_forward": 752
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/canine/configuration_canine.py": [
        {
            "transformers.models.canine.configuration_canine.CanineConfig.__init__": 94
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/canine/tokenization_canine.py": [
        {
            "transformers.models.canine.tokenization_canine.CanineTokenizer.__init__": 79
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/canine/modeling_canine.py": [
        {
            "transformers.models.canine.modeling_canine.CanineEncoder.custom_forward": 799
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/gpt_neox/modeling_gpt_neox.py": [
        {
            "transformers.models.gpt_neox.modeling_gpt_neox.GPTNeoXModel.custom_forward": 533
        },
        {
            "transformers.models.gpt_neox.modeling_gpt_neox.GPTNeoXForCausalLM.prepare_inputs_for_generation": 689
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/gpt_neox/configuration_gpt_neox.py": [
        {
            "transformers.models.gpt_neox.configuration_gpt_neox.GPTNeoXConfig.__init__": 88
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/gpt_neox/tokenization_gpt_neox_fast.py": [
        {
            "transformers.models.gpt_neox.tokenization_gpt_neox_fast.GPTNeoXTokenizerFast.__init__": 100
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/mobilenet_v2/configuration_mobilenet_v2.py": [
        {
            "transformers.models.mobilenet_v2.configuration_mobilenet_v2.MobileNetV2Config.__init__": 101
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/mobilenet_v2/image_processing_mobilenet_v2.py": [
        {
            "transformers.models.mobilenet_v2.image_processing_mobilenet_v2.MobileNetV2ImageProcessor.__init__": 94
        },
        {
            "transformers.models.mobilenet_v2.image_processing_mobilenet_v2.MobileNetV2ImageProcessor.resize": 124
        },
        {
            "transformers.models.mobilenet_v2.image_processing_mobilenet_v2.MobileNetV2ImageProcessor.center_crop": 152
        },
        {
            "transformers.models.mobilenet_v2.image_processing_mobilenet_v2.MobileNetV2ImageProcessor.rescale": 176
        },
        {
            "transformers.models.mobilenet_v2.image_processing_mobilenet_v2.MobileNetV2ImageProcessor.normalize": 198
        },
        {
            "transformers.models.mobilenet_v2.image_processing_mobilenet_v2.MobileNetV2ImageProcessor.preprocess": 227
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/mobilenet_v2/feature_extraction_mobilenet_v2.py": [
        {
            "transformers.models.mobilenet_v2.feature_extraction_mobilenet_v2.MobileNetV2FeatureExtractor.__init__": 27
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/bertweet/tokenization_bertweet.py": [
        {
            "transformers.models.bertweet.tokenization_bertweet.BertweetTokenizer.__init__": 123
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/blenderbot/tokenization_blenderbot.py": [
        {
            "transformers.models.blenderbot.tokenization_blenderbot.BlenderbotTokenizer.__init__": 175
        },
        {
            "transformers.models.blenderbot.tokenization_blenderbot.BlenderbotTokenizer.prepare_for_tokenization": 392
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/blenderbot/configuration_blenderbot.py": [
        {
            "transformers.models.blenderbot.configuration_blenderbot.BlenderbotConfig.__init__": 111
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/blenderbot/modeling_tf_blenderbot.py": [
        {
            "transformers.models.blenderbot.modeling_tf_blenderbot.TFBlenderbotLearnedPositionalEmbedding.__init__": 125
        },
        {
            "transformers.models.blenderbot.modeling_tf_blenderbot.TFBlenderbotAttention.__init__": 144
        },
        {
            "transformers.models.blenderbot.modeling_tf_blenderbot.TFBlenderbotEncoderLayer.__init__": 296
        },
        {
            "transformers.models.blenderbot.modeling_tf_blenderbot.TFBlenderbotDecoderLayer.__init__": 353
        },
        {
            "transformers.models.blenderbot.modeling_tf_blenderbot.TFBlenderbotEncoder.__init__": 653
        },
        {
            "transformers.models.blenderbot.modeling_tf_blenderbot.TFBlenderbotDecoder.__init__": 828
        },
        {
            "transformers.models.blenderbot.modeling_tf_blenderbot.TFBlenderbotMainLayer.__init__": 1060
        },
        {
            "transformers.models.blenderbot.modeling_tf_blenderbot.TFBlenderbotMainLayer.call": 1085
        },
        {
            "transformers.models.blenderbot.modeling_tf_blenderbot.TFBlenderbotModel.__init__": 1169
        },
        {
            "transformers.models.blenderbot.modeling_tf_blenderbot.TFBlenderbotModel.from_pretrained": 1181
        },
        {
            "transformers.models.blenderbot.modeling_tf_blenderbot.TFBlenderbotModel.call": 1203
        },
        {
            "transformers.models.blenderbot.modeling_tf_blenderbot.BiasLayer.__init__": 1274
        },
        {
            "transformers.models.blenderbot.modeling_tf_blenderbot.TFBlenderbotForConditionalGeneration.__init__": 1295
        },
        {
            "transformers.models.blenderbot.modeling_tf_blenderbot.TFBlenderbotForConditionalGeneration.from_pretrained": 1328
        },
        {
            "transformers.models.blenderbot.modeling_tf_blenderbot.TFBlenderbotForConditionalGeneration.prepare_inputs_for_generation": 1448
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/blenderbot/tokenization_blenderbot_fast.py": [
        {
            "transformers.models.blenderbot.tokenization_blenderbot_fast.BlenderbotTokenizerFast.__init__": 136
        },
        {
            "transformers.models.blenderbot.tokenization_blenderbot_fast.BlenderbotTokenizerFast._batch_encode_plus": 233
        },
        {
            "transformers.models.blenderbot.tokenization_blenderbot_fast.BlenderbotTokenizerFast._encode_plus": 243
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/blenderbot/modeling_flax_blenderbot.py": [
        {
            "transformers.models.blenderbot.modeling_flax_blenderbot.FlaxBlenderbotPreTrainedModel.__init__": 885
        },
        {
            "transformers.models.blenderbot.modeling_flax_blenderbot.FlaxBlenderbotPreTrainedModel._decoder_forward": 954
        },
        {
            "transformers.models.blenderbot.modeling_flax_blenderbot.FlaxBlenderbotPreTrainedModel._encoder_forward": 1020
        },
        {
            "transformers.models.blenderbot.modeling_flax_blenderbot.FlaxBlenderbotPreTrainedModel._decoder_forward": 1117
        },
        {
            "transformers.models.blenderbot.modeling_flax_blenderbot.FlaxBlenderbotForConditionalGeneration._decoder_forward": 1385
        },
        {
            "transformers.models.blenderbot.modeling_flax_blenderbot.FlaxBlenderbotForConditionalGeneration.prepare_inputs_for_generation": 1444
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/blenderbot/modeling_blenderbot.py": [
        {
            "transformers.models.blenderbot.modeling_blenderbot.BlenderbotEncoder.custom_forward": 775
        },
        {
            "transformers.models.blenderbot.modeling_blenderbot.BlenderbotDecoder.custom_forward": 1026
        },
        {
            "transformers.models.blenderbot.modeling_blenderbot.BlenderbotModel.from_pretrained": 1111
        },
        {
            "transformers.models.blenderbot.modeling_blenderbot.BlenderbotForConditionalGeneration.from_pretrained": 1256
        },
        {
            "transformers.models.blenderbot.modeling_blenderbot.BlenderbotForConditionalGeneration.prepare_inputs_for_generation": 1377
        },
        {
            "transformers.models.blenderbot.modeling_blenderbot.BlenderbotDecoderWrapper.forward": 1427
        },
        {
            "transformers.models.blenderbot.modeling_blenderbot.BlenderbotForCausalLM.prepare_inputs_for_generation": 1611
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/imagegpt/feature_extraction_imagegpt.py": [
        {
            "transformers.models.imagegpt.feature_extraction_imagegpt.ImageGPTFeatureExtractor.__init__": 27
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/imagegpt/configuration_imagegpt.py": [
        {
            "transformers.models.imagegpt.configuration_imagegpt.ImageGPTConfig.__init__": 110
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/imagegpt/image_processing_imagegpt.py": [
        {
            "transformers.models.imagegpt.image_processing_imagegpt.ImageGPTImageProcessor.__init__": 78
        },
        {
            "transformers.models.imagegpt.image_processing_imagegpt.ImageGPTImageProcessor.resize": 99
        },
        {
            "transformers.models.imagegpt.image_processing_imagegpt.ImageGPTImageProcessor.preprocess": 145
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/imagegpt/modeling_imagegpt.py": [
        {
            "transformers.models.imagegpt.modeling_imagegpt.ImageGPTPreTrainedModel.__init__": 498
        },
        {
            "transformers.models.imagegpt.modeling_imagegpt.ImageGPTModel.forward": 652
        },
        {
            "transformers.models.imagegpt.modeling_imagegpt.ImageGPTModel.custom_forward": 823
        },
        {
            "transformers.models.imagegpt.modeling_imagegpt.ImageGPTForCausalImageModeling.prepare_inputs_for_generation": 915
        },
        {
            "transformers.models.imagegpt.modeling_imagegpt.ImageGPTForCausalImageModeling.forward": 945
        },
        {
            "transformers.models.imagegpt.modeling_imagegpt.ImageGPTForImageClassification.forward": 1098
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/byt5/tokenization_byt5.py": [
        {
            "transformers.models.byt5.tokenization_byt5.ByT5Tokenizer.__init__": 63
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/chinese_clip/modeling_chinese_clip.py": [
        {
            "transformers.models.chinese_clip.modeling_chinese_clip.ChineseCLIPTextEncoder.custom_forward": 911
        },
        {
            "transformers.models.chinese_clip.modeling_chinese_clip.ChineseCLIPVisionEncoder.custom_forward": 1020
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/chinese_clip/image_processing_chinese_clip.py": [
        {
            "transformers.models.chinese_clip.image_processing_chinese_clip.ChineseCLIPImageProcessor.__init__": 85
        },
        {
            "transformers.models.chinese_clip.image_processing_chinese_clip.ChineseCLIPImageProcessor.resize": 118
        },
        {
            "transformers.models.chinese_clip.image_processing_chinese_clip.ChineseCLIPImageProcessor.center_crop": 146
        },
        {
            "transformers.models.chinese_clip.image_processing_chinese_clip.ChineseCLIPImageProcessor.rescale": 168
        },
        {
            "transformers.models.chinese_clip.image_processing_chinese_clip.ChineseCLIPImageProcessor.normalize": 188
        },
        {
            "transformers.models.chinese_clip.image_processing_chinese_clip.ChineseCLIPImageProcessor.preprocess": 211
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/chinese_clip/configuration_chinese_clip.py": [
        {
            "transformers.models.chinese_clip.configuration_chinese_clip.ChineseCLIPTextConfig.__init__": 107
        },
        {
            "transformers.models.chinese_clip.configuration_chinese_clip.ChineseCLIPTextConfig.from_pretrained": 146
        },
        {
            "transformers.models.chinese_clip.configuration_chinese_clip.ChineseCLIPVisionConfig.__init__": 217
        },
        {
            "transformers.models.chinese_clip.configuration_chinese_clip.ChineseCLIPVisionConfig.from_pretrained": 253
        },
        {
            "transformers.models.chinese_clip.configuration_chinese_clip.ChineseCLIPConfig.__init__": 320
        },
        {
            "transformers.models.chinese_clip.configuration_chinese_clip.ChineseCLIPConfig.from_text_vision_configs": 350
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/chinese_clip/feature_extraction_chinese_clip.py": [
        {
            "transformers.models.chinese_clip.feature_extraction_chinese_clip.ChineseCLIPFeatureExtractor.__init__": 27
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/chinese_clip/processing_chinese_clip.py": [
        {
            "transformers.models.chinese_clip.processing_chinese_clip.ChineseCLIPProcessor.__init__": 43
        },
        {
            "transformers.models.chinese_clip.processing_chinese_clip.ChineseCLIPProcessor.__call__": 61
        },
        {
            "transformers.models.chinese_clip.processing_chinese_clip.ChineseCLIPProcessor.batch_decode": 114
        },
        {
            "transformers.models.chinese_clip.processing_chinese_clip.ChineseCLIPProcessor.decode": 121
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/esm/modeling_esm.py": [
        {
            "transformers.models.esm.modeling_esm.EsmEncoder.custom_forward": 609
        },
        {
            "transformers.models.esm.modeling_esm.EsmLMHead.forward": 1064
        },
        {
            "transformers.models.esm.modeling_esm.EsmClassificationHead.forward": 1264
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/esm/tokenization_esm.py": [
        {
            "transformers.models.esm.tokenization_esm.EsmTokenizer.__init__": 57
        },
        {
            "transformers.models.esm.tokenization_esm.EsmTokenizer._tokenize": 76
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/esm/modeling_tf_esm.py": [
        {
            "transformers.models.esm.modeling_tf_esm.TFEsmIntermediate.__init__": 481
        },
        {
            "transformers.models.esm.modeling_tf_esm.TFEsmPooler.__init__": 683
        },
        {
            "transformers.models.esm.modeling_tf_esm.TFEsmMainLayer.__init__": 788
        },
        {
            "transformers.models.esm.modeling_tf_esm.TFEsmModel.__init__": 989
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/esm/configuration_esm.py": [
        {
            "transformers.models.esm.configuration_esm.EsmConfig.__init__": 104
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/esm/modeling_esmfold.py": [
        {
            "transformers.models.esm.modeling_esmfold.EsmFoldTriangularSelfAttentionBlock.forward": 1186
        },
        {
            "transformers.models.esm.modeling_esmfold.EsmForProteinFolding.infer_pdb": 2311
        },
        {
            "transformers.models.esm.modeling_esmfold.EsmForProteinFolding.infer_pdbs": 2317
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/esm/openfold_utils/loss.py": [
        {
            "transformers.models.esm.openfold_utils.loss.compute_predicted_aligned_error": 39
        },
        {
            "transformers.models.esm.openfold_utils.loss.compute_tm": 74
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/regnet/configuration_regnet.py": [
        {
            "transformers.models.regnet.configuration_regnet.RegNetConfig.__init__": 72
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/regnet/modeling_tf_regnet.py": [
        {
            "transformers.models.regnet.modeling_tf_regnet.TFRegNetConvLayer.__init__": 54
        },
        {
            "transformers.models.regnet.modeling_tf_regnet.TFRegNetEmbeddings.__init__": 91
        },
        {
            "transformers.models.regnet.modeling_tf_regnet.TFRegNetShortCut.__init__": 123
        },
        {
            "transformers.models.regnet.modeling_tf_regnet.TFRegNetSELayer.__init__": 139
        },
        {
            "transformers.models.regnet.modeling_tf_regnet.TFRegNetXLayer.__init__": 161
        },
        {
            "transformers.models.regnet.modeling_tf_regnet.TFRegNetYLayer.__init__": 195
        },
        {
            "transformers.models.regnet.modeling_tf_regnet.TFRegNetStage.__init__": 229
        },
        {
            "transformers.models.regnet.modeling_tf_regnet.TFRegNetEncoder.__init__": 248
        },
        {
            "transformers.models.regnet.modeling_tf_regnet.TFRegNetMainLayer.__init__": 290
        },
        {
            "transformers.models.regnet.modeling_tf_regnet.TFRegNetModel.__init__": 406
        },
        {
            "transformers.models.regnet.modeling_tf_regnet.TFRegNetForImageClassification.__init__": 465
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/swin/modeling_tf_swin.py": [
        {
            "transformers.models.swin.modeling_tf_swin.TFSwinEmbeddings.__init__": 263
        },
        {
            "transformers.models.swin.modeling_tf_swin.TFSwinPatchEmbeddings.__init__": 318
        },
        {
            "transformers.models.swin.modeling_tf_swin.TFSwinPatchMerging.__init__": 386
        },
        {
            "transformers.models.swin.modeling_tf_swin.TFSwinDropPath.__init__": 438
        },
        {
            "transformers.models.swin.modeling_tf_swin.TFSwinSelfAttention.__init__": 448
        },
        {
            "transformers.models.swin.modeling_tf_swin.TFSwinSelfOutput.__init__": 584
        },
        {
            "transformers.models.swin.modeling_tf_swin.TFSwinAttention.__init__": 596
        },
        {
            "transformers.models.swin.modeling_tf_swin.TFSwinIntermediate.__init__": 624
        },
        {
            "transformers.models.swin.modeling_tf_swin.TFSwinOutput.__init__": 639
        },
        {
            "transformers.models.swin.modeling_tf_swin.TFSwinLayer.__init__": 651
        },
        {
            "transformers.models.swin.modeling_tf_swin.TFSwinStage.__init__": 782
        },
        {
            "transformers.models.swin.modeling_tf_swin.TFSwinEncoder.__init__": 854
        },
        {
            "transformers.models.swin.modeling_tf_swin.AdaptiveAveragePooling1D.__init__": 1043
        },
        {
            "transformers.models.swin.modeling_tf_swin.AdaptiveAveragePooling1D.call": 1055
        },
        {
            "transformers.models.swin.modeling_tf_swin.TFSwinMainLayer.__init__": 1088
        },
        {
            "transformers.models.swin.modeling_tf_swin.TFSwinModel.__init__": 1185
        },
        {
            "transformers.models.swin.modeling_tf_swin.TFSwinPixelShuffle.__init__": 1246
        },
        {
            "transformers.models.swin.modeling_tf_swin.TFSwinDecoder.__init__": 1270
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/swin/modeling_swin.py": [
        {
            "transformers.models.swin.modeling_swin.SwinEncoder.custom_forward": 820
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/swin/configuration_swin.py": [
        {
            "transformers.models.swin.configuration_swin.SwinConfig.__init__": 111
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/t5/modeling_t5.py": [
        {
            "transformers.models.t5.modeling_t5.T5Stack.custom_forward": 1037
        },
        {
            "transformers.models.t5.modeling_t5.T5ForConditionalGeneration.prepare_inputs_for_generation": 1715
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/t5/configuration_t5.py": [
        {
            "transformers.models.t5.configuration_t5.T5Config.__init__": 82
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/t5/tokenization_t5.py": [
        {
            "transformers.models.t5.tokenization_t5.T5Tokenizer.__init__": 114
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/t5/tokenization_t5_fast.py": [
        {
            "transformers.models.t5.tokenization_t5_fast.T5TokenizerFast.__init__": 109
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/t5/modeling_tf_t5.py": [
        {
            "transformers.models.t5.modeling_tf_t5.TFT5LayerNorm.__init__": 77
        },
        {
            "transformers.models.t5.modeling_tf_t5.TFT5DenseActDense.__init__": 96
        },
        {
            "transformers.models.t5.modeling_tf_t5.TFT5DenseGatedActDense.__init__": 122
        },
        {
            "transformers.models.t5.modeling_tf_t5.TFT5LayerFF.__init__": 152
        },
        {
            "transformers.models.t5.modeling_tf_t5.TFT5Attention.__init__": 172
        },
        {
            "transformers.models.t5.modeling_tf_t5.TFT5LayerSelfAttention.__init__": 434
        },
        {
            "transformers.models.t5.modeling_tf_t5.TFT5LayerCrossAttention.__init__": 472
        },
        {
            "transformers.models.t5.modeling_tf_t5.TFT5Block.__init__": 514
        },
        {
            "transformers.models.t5.modeling_tf_t5.TFT5MainLayer.__init__": 625
        },
        {
            "transformers.models.t5.modeling_tf_t5.TFT5Model.__init__": 1130
        },
        {
            "transformers.models.t5.modeling_tf_t5.TFT5ForConditionalGeneration.__init__": 1282
        },
        {
            "transformers.models.t5.modeling_tf_t5.TFT5ForConditionalGeneration.prepare_inputs_for_generation": 1498
        },
        {
            "transformers.models.t5.modeling_tf_t5.TFT5EncoderModel.__init__": 1536
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/t5/modeling_flax_t5.py": [
        {
            "transformers.models.t5.modeling_flax_t5.FlaxT5PreTrainedModel.__init__": 938
        },
        {
            "transformers.models.t5.modeling_flax_t5.FlaxT5PreTrainedModel._decoder_forward": 1055
        },
        {
            "transformers.models.t5.modeling_flax_t5.FlaxT5PreTrainedModel._encoder_forward": 1115
        },
        {
            "transformers.models.t5.modeling_flax_t5.FlaxT5PreTrainedModel._decoder_forward": 1200
        },
        {
            "transformers.models.t5.modeling_flax_t5.FlaxT5ForConditionalGeneration._decoder_forward": 1679
        },
        {
            "transformers.models.t5.modeling_flax_t5.FlaxT5ForConditionalGeneration.prepare_inputs_for_generation": 1741
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/fnet/tokenization_fnet_fast.py": [
        {
            "transformers.models.fnet.tokenization_fnet_fast.FNetTokenizerFast.__init__": 95
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/fnet/tokenization_fnet.py": [
        {
            "transformers.models.fnet.tokenization_fnet.FNetTokenizer.__init__": 104
        },
        {
            "transformers.models.fnet.tokenization_fnet.FNetTokenizer._decode": 235
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/fnet/configuration_fnet.py": [
        {
            "transformers.models.fnet.configuration_fnet.FNetConfig.__init__": 89
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/fnet/modeling_fnet.py": [
        {
            "transformers.models.fnet.modeling_fnet.FNetEncoder.custom_forward": 296
        },
        {
            "transformers.models.fnet.modeling_fnet.FNetForNextSentencePrediction.forward": 800
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/splinter/configuration_splinter.py": [
        {
            "transformers.models.splinter.configuration_splinter.SplinterConfig.__init__": 93
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/splinter/tokenization_splinter.py": [
        {
            "transformers.models.splinter.tokenization_splinter.SplinterTokenizer.__init__": 124
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/splinter/modeling_splinter.py": [
        {
            "transformers.models.splinter.modeling_splinter.SplinterEncoder.custom_forward": 461
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/splinter/tokenization_splinter_fast.py": [
        {
            "transformers.models.splinter.tokenization_splinter_fast.SplinterTokenizerFast.__init__": 103
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/albert/modeling_flax_albert.py": [
        {
            "transformers.models.albert.modeling_flax_albert.FlaxAlbertPreTrainedModel.__init__": 519
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/albert/configuration_albert.py": [
        {
            "transformers.models.albert.configuration_albert.AlbertConfig.__init__": 113
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/albert/modeling_tf_albert.py": [
        {
            "transformers.models.albert.modeling_tf_albert.TFAlbertEmbeddings.__init__": 137
        },
        {
            "transformers.models.albert.modeling_tf_albert.TFAlbertAttention.__init__": 225
        },
        {
            "transformers.models.albert.modeling_tf_albert.TFAlbertLayer.__init__": 319
        },
        {
            "transformers.models.albert.modeling_tf_albert.TFAlbertLayerGroup.__init__": 368
        },
        {
            "transformers.models.albert.modeling_tf_albert.TFAlbertTransformer.__init__": 411
        },
        {
            "transformers.models.albert.modeling_tf_albert.TFAlbertMLMHead.__init__": 479
        },
        {
            "transformers.models.albert.modeling_tf_albert.TFAlbertMainLayer.__init__": 538
        },
        {
            "transformers.models.albert.modeling_tf_albert.TFAlbertModel.__init__": 796
        },
        {
            "transformers.models.albert.modeling_tf_albert.TFAlbertForPreTraining.__init__": 859
        },
        {
            "transformers.models.albert.modeling_tf_albert.TFAlbertSOPHead.__init__": 956
        },
        {
            "transformers.models.albert.modeling_tf_albert.TFAlbertForMaskedLM.__init__": 978
        },
        {
            "transformers.models.albert.modeling_tf_albert.TFAlbertForSequenceClassification.__init__": 1088
        },
        {
            "transformers.models.albert.modeling_tf_albert.TFAlbertForTokenClassification.__init__": 1177
        },
        {
            "transformers.models.albert.modeling_tf_albert.TFAlbertForQuestionAnswering.__init__": 1266
        },
        {
            "transformers.models.albert.modeling_tf_albert.TFAlbertForMultipleChoice.__init__": 1371
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/albert/tokenization_albert.py": [
        {
            "transformers.models.albert.tokenization_albert.AlbertTokenizer.__init__": 136
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/albert/tokenization_albert_fast.py": [
        {
            "transformers.models.albert.tokenization_albert_fast.AlbertTokenizerFast.__init__": 124
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/xlm_roberta_xl/configuration_xlm_roberta_xl.py": [
        {
            "transformers.models.xlm_roberta_xl.configuration_xlm_roberta_xl.XLMRobertaXLConfig.__init__": 102
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/xlm_roberta_xl/modeling_xlm_roberta_xl.py": [
        {
            "transformers.models.xlm_roberta_xl.modeling_xlm_roberta_xl.XLMRobertaXLEncoder.custom_forward": 502
        },
        {
            "transformers.models.xlm_roberta_xl.modeling_xlm_roberta_xl.XLMRobertaXLForCausalLM.prepare_inputs_for_generation": 980
        },
        {
            "transformers.models.xlm_roberta_xl.modeling_xlm_roberta_xl.XLMRobertaXLLMHead.forward": 1107
        },
        {
            "transformers.models.xlm_roberta_xl.modeling_xlm_roberta_xl.XLMRobertaXLClassificationHead.forward": 1415
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/nezha/modeling_nezha.py": [
        {
            "transformers.models.nezha.modeling_nezha.NezhaEncoder.custom_forward": 581
        },
        {
            "transformers.models.nezha.modeling_nezha.NezhaForMaskedLM.prepare_inputs_for_generation": 1227
        },
        {
            "transformers.models.nezha.modeling_nezha.NezhaForNextSentencePrediction.forward": 1260
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/nezha/configuration_nezha.py": [
        {
            "transformers.models.nezha.configuration_nezha.NezhaConfig.__init__": 71
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/squeezebert/configuration_squeezebert.py": [
        {
            "transformers.models.squeezebert.configuration_squeezebert.SqueezeBertConfig.__init__": 115
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/squeezebert/tokenization_squeezebert.py": [
        {
            "transformers.models.squeezebert.tokenization_squeezebert.SqueezeBertTokenizer.__init__": 126
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/squeezebert/tokenization_squeezebert_fast.py": [
        {
            "transformers.models.squeezebert.tokenization_squeezebert_fast.SqueezeBertTokenizerFast.__init__": 115
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/lilt/modeling_lilt.py": [
        {
            "transformers.models.lilt.modeling_lilt.LiltEncoder.custom_forward": 518
        },
        {
            "transformers.models.lilt.modeling_lilt.LiltClassificationHead.forward": 1078
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/lilt/configuration_lilt.py": [
        {
            "transformers.models.lilt.configuration_lilt.LiltConfig.__init__": 95
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/vit_msn/modeling_vit_msn.py": [
        {
            "transformers.models.vit_msn.modeling_vit_msn.ViTMSNEncoder.custom_forward": 393
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/vit_msn/configuration_vit_msn.py": [
        {
            "transformers.models.vit_msn.configuration_vit_msn.ViTMSNConfig.__init__": 86
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/videomae/configuration_videomae.py": [
        {
            "transformers.models.videomae.configuration_videomae.VideoMAEConfig.__init__": 99
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/videomae/feature_extraction_videomae.py": [
        {
            "transformers.models.videomae.feature_extraction_videomae.VideoMAEFeatureExtractor.__init__": 27
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/videomae/modeling_videomae.py": [
        {
            "transformers.models.videomae.modeling_videomae.VideoMAEEncoder.custom_forward": 441
        },
        {
            "transformers.models.videomae.modeling_videomae.VideoMAEDecoder.custom_forward": 697
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/videomae/image_processing_videomae.py": [
        {
            "transformers.models.videomae.image_processing_videomae.VideoMAEImageProcessor.__init__": 106
        },
        {
            "transformers.models.videomae.image_processing_videomae.VideoMAEImageProcessor.resize": 137
        },
        {
            "transformers.models.videomae.image_processing_videomae.VideoMAEImageProcessor.center_crop": 169
        },
        {
            "transformers.models.videomae.image_processing_videomae.VideoMAEImageProcessor.rescale": 193
        },
        {
            "transformers.models.videomae.image_processing_videomae.VideoMAEImageProcessor.normalize": 213
        },
        {
            "transformers.models.videomae.image_processing_videomae.VideoMAEImageProcessor.preprocess": 282
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/mbart/modeling_mbart.py": [
        {
            "transformers.models.mbart.modeling_mbart.MBartEncoder.custom_forward": 826
        },
        {
            "transformers.models.mbart.modeling_mbart.MBartDecoder.custom_forward": 1079
        },
        {
            "transformers.models.mbart.modeling_mbart.MBartForConditionalGeneration.prepare_inputs_for_generation": 1391
        },
        {
            "transformers.models.mbart.modeling_mbart.MBartForSequenceClassification.__init__": 1443
        },
        {
            "transformers.models.mbart.modeling_mbart.MBartDecoderWrapper.forward": 1694
        },
        {
            "transformers.models.mbart.modeling_mbart.MBartForCausalLM.prepare_inputs_for_generation": 1876
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/mbart/configuration_mbart.py": [
        {
            "transformers.models.mbart.configuration_mbart.MBartConfig.__init__": 111
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/mbart/tokenization_mbart_fast.py": [
        {
            "transformers.models.mbart.tokenization_mbart_fast.MBartTokenizerFast.__init__": 96
        },
        {
            "transformers.models.mbart.tokenization_mbart_fast.MBartTokenizerFast._build_translation_inputs": 215
        },
        {
            "transformers.models.mbart.tokenization_mbart_fast.MBartTokenizerFast.prepare_seq2seq_batch": 227
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/mbart/tokenization_mbart.py": [
        {
            "transformers.models.mbart.tokenization_mbart.MBartTokenizer.__init__": 82
        },
        {
            "transformers.models.mbart.tokenization_mbart.MBartTokenizer._build_translation_inputs": 270
        },
        {
            "transformers.models.mbart.tokenization_mbart.MBartTokenizer.prepare_seq2seq_batch": 327
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/mbart/modeling_tf_mbart.py": [
        {
            "transformers.models.mbart.modeling_tf_mbart.TFMBartLearnedPositionalEmbedding.__init__": 124
        },
        {
            "transformers.models.mbart.modeling_tf_mbart.TFMBartAttention.__init__": 150
        },
        {
            "transformers.models.mbart.modeling_tf_mbart.TFMBartEncoderLayer.__init__": 301
        },
        {
            "transformers.models.mbart.modeling_tf_mbart.TFMBartDecoderLayer.__init__": 357
        },
        {
            "transformers.models.mbart.modeling_tf_mbart.TFMBartEncoder.__init__": 668
        },
        {
            "transformers.models.mbart.modeling_tf_mbart.TFMBartDecoder.__init__": 846
        },
        {
            "transformers.models.mbart.modeling_tf_mbart.TFMBartMainLayer.__init__": 1087
        },
        {
            "transformers.models.mbart.modeling_tf_mbart.TFMBartMainLayer.call": 1112
        },
        {
            "transformers.models.mbart.modeling_tf_mbart.TFMBartModel.__init__": 1203
        },
        {
            "transformers.models.mbart.modeling_tf_mbart.TFMBartModel.call": 1221
        },
        {
            "transformers.models.mbart.modeling_tf_mbart.BiasLayer.__init__": 1293
        },
        {
            "transformers.models.mbart.modeling_tf_mbart.TFMBartForConditionalGeneration.__init__": 1314
        },
        {
            "transformers.models.mbart.modeling_tf_mbart.TFMBartForConditionalGeneration.prepare_inputs_for_generation": 1450
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/mbart/modeling_flax_mbart.py": [
        {
            "transformers.models.mbart.modeling_flax_mbart.FlaxMBartPreTrainedModel.__init__": 949
        },
        {
            "transformers.models.mbart.modeling_flax_mbart.FlaxMBartPreTrainedModel._decoder_forward": 1019
        },
        {
            "transformers.models.mbart.modeling_flax_mbart.FlaxMBartPreTrainedModel._encoder_forward": 1085
        },
        {
            "transformers.models.mbart.modeling_flax_mbart.FlaxMBartPreTrainedModel._decoder_forward": 1179
        },
        {
            "transformers.models.mbart.modeling_flax_mbart.FlaxMBartForConditionalGeneration._decoder_forward": 1444
        },
        {
            "transformers.models.mbart.modeling_flax_mbart.FlaxMBartForConditionalGeneration.prepare_inputs_for_generation": 1503
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/led/modeling_tf_led.py": [
        {
            "transformers.models.led.modeling_tf_led.TFLEDLearnedPositionalEmbedding.__init__": 120
        },
        {
            "transformers.models.led.modeling_tf_led.TFLEDEncoderSelfAttention.__init__": 134
        },
        {
            "transformers.models.led.modeling_tf_led.TFLEDEncoderAttention.__init__": 974
        },
        {
            "transformers.models.led.modeling_tf_led.TFLEDDecoderAttention.__init__": 1003
        },
        {
            "transformers.models.led.modeling_tf_led.TFLEDEncoderLayer.__init__": 1152
        },
        {
            "transformers.models.led.modeling_tf_led.TFLEDDecoderLayer.__init__": 1211
        },
        {
            "transformers.models.led.modeling_tf_led.TFLEDEncoder.__init__": 1652
        },
        {
            "transformers.models.led.modeling_tf_led.TFLEDDecoder.__init__": 1927
        },
        {
            "transformers.models.led.modeling_tf_led.TFLEDMainLayer.__init__": 2149
        },
        {
            "transformers.models.led.modeling_tf_led.TFLEDMainLayer.call": 2173
        },
        {
            "transformers.models.led.modeling_tf_led.TFLEDModel.__init__": 2257
        },
        {
            "transformers.models.led.modeling_tf_led.TFLEDModel.call": 2275
        },
        {
            "transformers.models.led.modeling_tf_led.BiasLayer.__init__": 2346
        },
        {
            "transformers.models.led.modeling_tf_led.TFLEDForConditionalGeneration.__init__": 2367
        },
        {
            "transformers.models.led.modeling_tf_led.TFLEDForConditionalGeneration.prepare_inputs_for_generation": 2510
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/led/tokenization_led.py": [
        {
            "transformers.models.led.tokenization_led.LEDTokenizer.__init__": 175
        },
        {
            "transformers.models.led.tokenization_led.LEDTokenizer.prepare_for_tokenization": 418
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/led/modeling_led.py": [
        {
            "transformers.models.led.modeling_led.LEDEncoder.custom_forward": 1882
        },
        {
            "transformers.models.led.modeling_led.LEDDecoder.custom_forward": 2146
        },
        {
            "transformers.models.led.modeling_led.LEDForConditionalGeneration.prepare_inputs_for_generation": 2478
        },
        {
            "transformers.models.led.modeling_led.LEDForSequenceClassification.__init__": 2532
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/led/configuration_led.py": [
        {
            "transformers.models.led.configuration_led.LEDConfig.__init__": 108
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/led/tokenization_led_fast.py": [
        {
            "transformers.models.led.tokenization_led_fast.LEDTokenizerFast.__init__": 136
        },
        {
            "transformers.models.led.tokenization_led_fast.LEDTokenizerFast._batch_encode_plus": 234
        },
        {
            "transformers.models.led.tokenization_led_fast.LEDTokenizerFast._encode_plus": 246
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/realm/tokenization_realm_fast.py": [
        {
            "transformers.models.realm.tokenization_realm_fast.RealmTokenizerFast.__init__": 151
        },
        {
            "transformers.models.realm.tokenization_realm_fast.RealmTokenizerFast.batch_encode_candidates": 193
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/realm/configuration_realm.py": [
        {
            "transformers.models.realm.configuration_realm.RealmConfig.__init__": 130
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/realm/retrieval_realm.py": [
        {
            "transformers.models.realm.retrieval_realm.RealmRetriever.from_pretrained": 111
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/realm/tokenization_realm.py": [
        {
            "transformers.models.realm.tokenization_realm.RealmTokenizer.__init__": 145
        },
        {
            "transformers.models.realm.tokenization_realm.RealmTokenizer.batch_encode_candidates": 229
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/realm/modeling_realm.py": [
        {
            "transformers.models.realm.modeling_realm.RealmEncoder.custom_forward": 588
        },
        {
            "transformers.models.realm.modeling_realm.RealmPreTrainedModel._flatten_inputs": 988
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/timesformer/modeling_timesformer.py": [
        {
            "transformers.models.timesformer.modeling_timesformer.TimesformerEncoder.custom_forward": 446
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/timesformer/configuration_timesformer.py": [
        {
            "transformers.models.timesformer.configuration_timesformer.TimesformerConfig.__init__": 89
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/donut/processing_donut.py": [
        {
            "transformers.models.donut.processing_donut.DonutProcessor.__init__": 44
        },
        {
            "transformers.models.donut.processing_donut.DonutProcessor.__call__": 63
        },
        {
            "transformers.models.donut.processing_donut.DonutProcessor.batch_decode": 96
        },
        {
            "transformers.models.donut.processing_donut.DonutProcessor.decode": 103
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/donut/image_processing_donut.py": [
        {
            "transformers.models.donut.image_processing_donut.DonutImageProcessor.__init__": 92
        },
        {
            "transformers.models.donut.image_processing_donut.DonutImageProcessor.rotate_image": 155
        },
        {
            "transformers.models.donut.image_processing_donut.DonutImageProcessor.pad": 200
        },
        {
            "transformers.models.donut.image_processing_donut.DonutImageProcessor.thumbnail": 204
        },
        {
            "transformers.models.donut.image_processing_donut.DonutImageProcessor.resize": 245
        },
        {
            "transformers.models.donut.image_processing_donut.DonutImageProcessor.rescale": 273
        },
        {
            "transformers.models.donut.image_processing_donut.DonutImageProcessor.normalize": 293
        },
        {
            "transformers.models.donut.image_processing_donut.DonutImageProcessor.preprocess": 316
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/donut/modeling_donut_swin.py": [
        {
            "transformers.models.donut.modeling_donut_swin.DonutSwinEncoder.custom_forward": 755
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/donut/feature_extraction_donut.py": [
        {
            "transformers.models.donut.feature_extraction_donut.DonutFeatureExtractor.__init__": 27
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/donut/configuration_donut_swin.py": [
        {
            "transformers.models.donut.configuration_donut_swin.DonutSwinConfig.__init__": 97
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/wavlm/modeling_wavlm.py": [
        {
            "transformers.models.wavlm.modeling_wavlm.WavLMFeatureEncoder.custom_forward": 356
        },
        {
            "transformers.models.wavlm.modeling_wavlm.WavLMEncoder.custom_forward": 715
        },
        {
            "transformers.models.wavlm.modeling_wavlm.WavLMEncoderStableLayerNorm.custom_forward": 806
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/wavlm/configuration_wavlm.py": [
        {
            "transformers.models.wavlm.configuration_wavlm.WavLMConfig.__init__": 192
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/upernet/configuration_upernet.py": [
        {
            "transformers.models.upernet.configuration_upernet.UperNetConfig.__init__": 75
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/mbart50/tokenization_mbart50_fast.py": [
        {
            "transformers.models.mbart50.tokenization_mbart50_fast.MBart50TokenizerFast.__init__": 113
        },
        {
            "transformers.models.mbart50.tokenization_mbart50_fast.MBart50TokenizerFast.prepare_seq2seq_batch": 199
        },
        {
            "transformers.models.mbart50.tokenization_mbart50_fast.MBart50TokenizerFast._build_translation_inputs": 247
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/mbart50/tokenization_mbart50.py": [
        {
            "transformers.models.mbart50.tokenization_mbart50.MBart50Tokenizer.__init__": 116
        },
        {
            "transformers.models.mbart50.tokenization_mbart50.MBart50Tokenizer._build_translation_inputs": 328
        },
        {
            "transformers.models.mbart50.tokenization_mbart50.MBart50Tokenizer.prepare_seq2seq_batch": 340
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/time_series_transformer/configuration_time_series_transformer.py": [
        {
            "transformers.models.time_series_transformer.configuration_time_series_transformer.TimeSeriesTransformerConfig.__init__": 133
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/time_series_transformer/modeling_time_series_transformer.py": [
        {
            "transformers.models.time_series_transformer.modeling_time_series_transformer.ParameterProjection.__init__": 82
        },
        {
            "transformers.models.time_series_transformer.modeling_time_series_transformer.LambdaLayer.forward": 101
        },
        {
            "transformers.models.time_series_transformer.modeling_time_series_transformer.DistributionOutput.domain_map": 165
        },
        {
            "transformers.models.time_series_transformer.modeling_time_series_transformer.TimeSeriesTransformerEncoder.custom_forward": 1148
        },
        {
            "transformers.models.time_series_transformer.modeling_time_series_transformer.TimeSeriesTransformerDecoder.custom_forward": 1358
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/segformer/image_processing_segformer.py": [
        {
            "transformers.models.segformer.image_processing_segformer.SegformerImageProcessor.__init__": 88
        },
        {
            "transformers.models.segformer.image_processing_segformer.SegformerImageProcessor.from_dict": 132
        },
        {
            "transformers.models.segformer.image_processing_segformer.SegformerImageProcessor.resize": 143
        },
        {
            "transformers.models.segformer.image_processing_segformer.SegformerImageProcessor.rescale": 171
        },
        {
            "transformers.models.segformer.image_processing_segformer.SegformerImageProcessor.normalize": 191
        },
        {
            "transformers.models.segformer.image_processing_segformer.SegformerImageProcessor.__call__": 311
        },
        {
            "transformers.models.segformer.image_processing_segformer.SegformerImageProcessor.preprocess": 320
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/segformer/modeling_tf_segformer.py": [
        {
            "transformers.models.segformer.modeling_tf_segformer.TFSegformerDropPath.__init__": 62
        },
        {
            "transformers.models.segformer.modeling_tf_segformer.TFSegformerOverlapPatchEmbeddings.__init__": 79
        },
        {
            "transformers.models.segformer.modeling_tf_segformer.TFSegformerEfficientSelfAttention.__init__": 104
        },
        {
            "transformers.models.segformer.modeling_tf_segformer.TFSegformerSelfOutput.__init__": 198
        },
        {
            "transformers.models.segformer.modeling_tf_segformer.TFSegformerAttention.__init__": 210
        },
        {
            "transformers.models.segformer.modeling_tf_segformer.TFSegformerDWConv.__init__": 239
        },
        {
            "transformers.models.segformer.modeling_tf_segformer.TFSegformerMixFFN.__init__": 259
        },
        {
            "transformers.models.segformer.modeling_tf_segformer.TFSegformerLayer.__init__": 291
        },
        {
            "transformers.models.segformer.modeling_tf_segformer.TFSegformerEncoder.__init__": 349
        },
        {
            "transformers.models.segformer.modeling_tf_segformer.TFSegformerMainLayer.__init__": 454
        },
        {
            "transformers.models.segformer.modeling_tf_segformer.TFSegformerModel.__init__": 598
        },
        {
            "transformers.models.segformer.modeling_tf_segformer.TFSegformerForImageClassification.__init__": 648
        },
        {
            "transformers.models.segformer.modeling_tf_segformer.TFSegformerMLP.__init__": 714
        },
        {
            "transformers.models.segformer.modeling_tf_segformer.TFSegformerDecodeHead.__init__": 728
        },
        {
            "transformers.models.segformer.modeling_tf_segformer.TFSegformerForSemanticSegmentation.__init__": 788
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/segformer/configuration_segformer.py": [
        {
            "transformers.models.segformer.configuration_segformer.SegformerConfig.__init__": 105
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/segformer/feature_extraction_segformer.py": [
        {
            "transformers.models.segformer.feature_extraction_segformer.SegformerFeatureExtractor.__init__": 27
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/layoutlmv2/image_processing_layoutlmv2.py": [
        {
            "transformers.models.layoutlmv2.image_processing_layoutlmv2.LayoutLMv2ImageProcessor.__init__": 131
        },
        {
            "transformers.models.layoutlmv2.image_processing_layoutlmv2.LayoutLMv2ImageProcessor.resize": 152
        },
        {
            "transformers.models.layoutlmv2.image_processing_layoutlmv2.LayoutLMv2ImageProcessor.preprocess": 179
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/layoutlmv2/processing_layoutlmv2.py": [
        {
            "transformers.models.layoutlmv2.processing_layoutlmv2.LayoutLMv2Processor.__init__": 50
        },
        {
            "transformers.models.layoutlmv2.processing_layoutlmv2.LayoutLMv2Processor.__call__": 67
        },
        {
            "transformers.models.layoutlmv2.processing_layoutlmv2.LayoutLMv2Processor.batch_decode": 167
        },
        {
            "transformers.models.layoutlmv2.processing_layoutlmv2.LayoutLMv2Processor.decode": 174
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/layoutlmv2/modeling_layoutlmv2.py": [
        {
            "transformers.models.layoutlmv2.modeling_layoutlmv2.LayoutLMv2Encoder.custom_forward": 453
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/layoutlmv2/tokenization_layoutlmv2.py": [
        {
            "transformers.models.layoutlmv2.tokenization_layoutlmv2.LayoutLMv2Tokenizer.__init__": 225
        },
        {
            "transformers.models.layoutlmv2.tokenization_layoutlmv2.LayoutLMv2Tokenizer.__call__": 427
        },
        {
            "transformers.models.layoutlmv2.tokenization_layoutlmv2.LayoutLMv2Tokenizer.batch_encode_plus": 575
        },
        {
            "transformers.models.layoutlmv2.tokenization_layoutlmv2.LayoutLMv2Tokenizer._batch_encode_plus": 634
        },
        {
            "transformers.models.layoutlmv2.tokenization_layoutlmv2.LayoutLMv2Tokenizer.encode": 762
        },
        {
            "transformers.models.layoutlmv2.tokenization_layoutlmv2.LayoutLMv2Tokenizer.encode_plus": 809
        },
        {
            "transformers.models.layoutlmv2.tokenization_layoutlmv2.LayoutLMv2Tokenizer._encode_plus": 875
        },
        {
            "transformers.models.layoutlmv2.tokenization_layoutlmv2.LayoutLMv2Tokenizer.prepare_for_model": 928
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/layoutlmv2/feature_extraction_layoutlmv2.py": [
        {
            "transformers.models.layoutlmv2.feature_extraction_layoutlmv2.LayoutLMv2FeatureExtractor.__init__": 29
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/layoutlmv2/tokenization_layoutlmv2_fast.py": [
        {
            "transformers.models.layoutlmv2.tokenization_layoutlmv2_fast.LayoutLMv2TokenizerFast.__init__": 122
        },
        {
            "transformers.models.layoutlmv2.tokenization_layoutlmv2_fast.LayoutLMv2TokenizerFast.__call__": 180
        },
        {
            "transformers.models.layoutlmv2.tokenization_layoutlmv2_fast.LayoutLMv2TokenizerFast.batch_encode_plus": 328
        },
        {
            "transformers.models.layoutlmv2.tokenization_layoutlmv2_fast.LayoutLMv2TokenizerFast.tokenize": 387
        },
        {
            "transformers.models.layoutlmv2.tokenization_layoutlmv2_fast.LayoutLMv2TokenizerFast.encode_plus": 396
        },
        {
            "transformers.models.layoutlmv2.tokenization_layoutlmv2_fast.LayoutLMv2TokenizerFast._encode_plus": 619
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/layoutlmv2/configuration_layoutlmv2.py": [
        {
            "transformers.models.layoutlmv2.configuration_layoutlmv2.LayoutLMv2Config.__init__": 119
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/xlm/configuration_xlm.py": [
        {
            "transformers.models.xlm.configuration_xlm.XLMConfig.__init__": 160
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/xlm/modeling_tf_xlm.py": [
        {
            "transformers.models.xlm.modeling_tf_xlm.TFXLMMultiHeadAttention.__init__": 118
        },
        {
            "transformers.models.xlm.modeling_tf_xlm.TFXLMTransformerFFN.__init__": 208
        },
        {
            "transformers.models.xlm.modeling_tf_xlm.TFXLMMainLayer.__init__": 229
        },
        {
            "transformers.models.xlm.modeling_tf_xlm.TFXLMModel.__init__": 696
        },
        {
            "transformers.models.xlm.modeling_tf_xlm.TFXLMPredLayer.__init__": 754
        },
        {
            "transformers.models.xlm.modeling_tf_xlm.TFXLMWithLMHeadModel.__init__": 808
        },
        {
            "transformers.models.xlm.modeling_tf_xlm.TFXLMWithLMHeadModel.prepare_inputs_for_generation": 822
        },
        {
            "transformers.models.xlm.modeling_tf_xlm.TFXLMForSequenceClassification.__init__": 900
        },
        {
            "transformers.models.xlm.modeling_tf_xlm.TFXLMForMultipleChoice.__init__": 985
        },
        {
            "transformers.models.xlm.modeling_tf_xlm.TFXLMForTokenClassification.__init__": 1126
        },
        {
            "transformers.models.xlm.modeling_tf_xlm.TFXLMForQuestionAnsweringSimple.__init__": 1213
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/xlm/tokenization_xlm.py": [
        {
            "transformers.models.xlm.tokenization_xlm.XLMTokenizer.__init__": 589
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/xlm/modeling_xlm.py": [
        {
            "transformers.models.xlm.modeling_xlm.XLMPreTrainedModel.__init__": 232
        },
        {
            "transformers.models.xlm.modeling_xlm.XLMWithLMHeadModel.prepare_inputs_for_generation": 690
        },
        {
            "transformers.models.xlm.modeling_xlm.XLMForMultipleChoice.__init__": 1182
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/retribert/modeling_retribert.py": [
        {
            "transformers.models.retribert.modeling_retribert.RetriBertModel.partial_encode": 125
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/retribert/tokenization_retribert.py": [
        {
            "transformers.models.retribert.tokenization_retribert.RetriBertTokenizer.__init__": 121
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/retribert/configuration_retribert.py": [
        {
            "transformers.models.retribert.configuration_retribert.RetriBertConfig.__init__": 77
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/retribert/tokenization_retribert_fast.py": [
        {
            "transformers.models.retribert.tokenization_retribert_fast.RetriBertTokenizerFast.__init__": 105
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/dinat/configuration_dinat.py": [
        {
            "transformers.models.dinat.configuration_dinat.DinatConfig.__init__": 100
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/dinat/modeling_dinat.py": [
        {
            "transformers.models.dinat.modeling_dinat.natten2dqkrpb": 49
        },
        {
            "transformers.models.dinat.modeling_dinat.natten2dav": 52
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/mobilenet_v1/image_processing_mobilenet_v1.py": [
        {
            "transformers.models.mobilenet_v1.image_processing_mobilenet_v1.MobileNetV1ImageProcessor.__init__": 89
        },
        {
            "transformers.models.mobilenet_v1.image_processing_mobilenet_v1.MobileNetV1ImageProcessor.resize": 119
        },
        {
            "transformers.models.mobilenet_v1.image_processing_mobilenet_v1.MobileNetV1ImageProcessor.center_crop": 147
        },
        {
            "transformers.models.mobilenet_v1.image_processing_mobilenet_v1.MobileNetV1ImageProcessor.rescale": 169
        },
        {
            "transformers.models.mobilenet_v1.image_processing_mobilenet_v1.MobileNetV1ImageProcessor.normalize": 191
        },
        {
            "transformers.models.mobilenet_v1.image_processing_mobilenet_v1.MobileNetV1ImageProcessor.preprocess": 220
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/mobilenet_v1/configuration_mobilenet_v1.py": [
        {
            "transformers.models.mobilenet_v1.configuration_mobilenet_v1.MobileNetV1Config.__init__": 83
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/mobilenet_v1/feature_extraction_mobilenet_v1.py": [
        {
            "transformers.models.mobilenet_v1.feature_extraction_mobilenet_v1.MobileNetV1FeatureExtractor.__init__": 27
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/roberta_prelayernorm/modeling_tf_roberta_prelayernorm.py": [
        {
            "transformers.models.roberta_prelayernorm.modeling_tf_roberta_prelayernorm.TFRobertaPreLayerNormEmbeddings.__init__": 85
        },
        {
            "transformers.models.roberta_prelayernorm.modeling_tf_roberta_prelayernorm.TFRobertaPreLayerNormPooler.__init__": 191
        },
        {
            "transformers.models.roberta_prelayernorm.modeling_tf_roberta_prelayernorm.TFRobertaPreLayerNormSelfAttention.__init__": 212
        },
        {
            "transformers.models.roberta_prelayernorm.modeling_tf_roberta_prelayernorm.TFRobertaPreLayerNormSelfOutput.__init__": 329
        },
        {
            "transformers.models.roberta_prelayernorm.modeling_tf_roberta_prelayernorm.TFRobertaPreLayerNormAttention.__init__": 346
        },
        {
            "transformers.models.roberta_prelayernorm.modeling_tf_roberta_prelayernorm.TFRobertaPreLayerNormIntermediate.__init__": 389
        },
        {
            "transformers.models.roberta_prelayernorm.modeling_tf_roberta_prelayernorm.TFRobertaPreLayerNormOutput.__init__": 411
        },
        {
            "transformers.models.roberta_prelayernorm.modeling_tf_roberta_prelayernorm.TFRobertaPreLayerNormLayer.__init__": 429
        },
        {
            "transformers.models.roberta_prelayernorm.modeling_tf_roberta_prelayernorm.TFRobertaPreLayerNormEncoder.__init__": 516
        },
        {
            "transformers.models.roberta_prelayernorm.modeling_tf_roberta_prelayernorm.TFRobertaPreLayerNormMainLayer.__init__": 588
        },
        {
            "transformers.models.roberta_prelayernorm.modeling_tf_roberta_prelayernorm.TFRobertaPreLayerNormModel.__init__": 925
        },
        {
            "transformers.models.roberta_prelayernorm.modeling_tf_roberta_prelayernorm.TFRobertaPreLayerNormLMHead.__init__": 1018
        },
        {
            "transformers.models.roberta_prelayernorm.modeling_tf_roberta_prelayernorm.TFRobertaPreLayerNormForMaskedLM.__init__": 1075
        },
        {
            "transformers.models.roberta_prelayernorm.modeling_tf_roberta_prelayernorm.TFRobertaPreLayerNormForCausalLM.__init__": 1162
        },
        {
            "transformers.models.roberta_prelayernorm.modeling_tf_roberta_prelayernorm.TFRobertaPreLayerNormForCausalLM.prepare_inputs_for_generation": 1185
        },
        {
            "transformers.models.roberta_prelayernorm.modeling_tf_roberta_prelayernorm.TFRobertaPreLayerNormClassificationHead.__init__": 1304
        },
        {
            "transformers.models.roberta_prelayernorm.modeling_tf_roberta_prelayernorm.TFRobertaPreLayerNormForSequenceClassification.__init__": 1342
        },
        {
            "transformers.models.roberta_prelayernorm.modeling_tf_roberta_prelayernorm.TFRobertaPreLayerNormForMultipleChoice.__init__": 1430
        },
        {
            "transformers.models.roberta_prelayernorm.modeling_tf_roberta_prelayernorm.TFRobertaPreLayerNormForTokenClassification.__init__": 1552
        },
        {
            "transformers.models.roberta_prelayernorm.modeling_tf_roberta_prelayernorm.TFRobertaPreLayerNormForQuestionAnswering.__init__": 1644
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/roberta_prelayernorm/modeling_flax_roberta_prelayernorm.py": [
        {
            "transformers.models.roberta_prelayernorm.modeling_flax_roberta_prelayernorm.FlaxRobertaPreLayerNormPreTrainedModel.__init__": 737
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/roberta_prelayernorm/modeling_roberta_prelayernorm.py": [
        {
            "transformers.models.roberta_prelayernorm.modeling_roberta_prelayernorm.RobertaPreLayerNormEncoder.custom_forward": 514
        },
        {
            "transformers.models.roberta_prelayernorm.modeling_roberta_prelayernorm.RobertaPreLayerNormForCausalLM.prepare_inputs_for_generation": 1021
        },
        {
            "transformers.models.roberta_prelayernorm.modeling_roberta_prelayernorm.RobertaPreLayerNormLMHead.forward": 1151
        },
        {
            "transformers.models.roberta_prelayernorm.modeling_roberta_prelayernorm.RobertaPreLayerNormClassificationHead.forward": 1461
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/roberta_prelayernorm/configuration_roberta_prelayernorm.py": [
        {
            "transformers.models.roberta_prelayernorm.configuration_roberta_prelayernorm.RobertaPreLayerNormConfig.__init__": 107
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/opt/configuration_opt.py": [
        {
            "transformers.models.opt.configuration_opt.OPTConfig.__init__": 99
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/opt/modeling_opt.py": [
        {
            "transformers.models.opt.modeling_opt.OPTDecoder.custom_forward": 682
        },
        {
            "transformers.models.opt.modeling_opt.OPTForCausalLM.prepare_inputs_for_generation": 967
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/opt/modeling_flax_opt.py": [
        {
            "transformers.models.opt.modeling_flax_opt.FlaxOPTPreTrainedModel.__init__": 523
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/opt/modeling_tf_opt.py": [
        {
            "transformers.models.opt.modeling_tf_opt.TFOPTLearnedPositionalEmbedding.__init__": 98
        },
        {
            "transformers.models.opt.modeling_tf_opt.TFOPTAttention.__init__": 121
        },
        {
            "transformers.models.opt.modeling_tf_opt.TFOPTDecoderLayer.__init__": 272
        },
        {
            "transformers.models.opt.modeling_tf_opt.TFOPTDecoder.__init__": 489
        },
        {
            "transformers.models.opt.modeling_tf_opt.TFOPTMainLayer.__init__": 721
        },
        {
            "transformers.models.opt.modeling_tf_opt.TFOPTMainLayer.call": 733
        },
        {
            "transformers.models.opt.modeling_tf_opt.TFOPTModel.__init__": 787
        },
        {
            "transformers.models.opt.modeling_tf_opt.TFOPTModel.call": 806
        },
        {
            "transformers.models.opt.modeling_tf_opt.TFOPTForCausalLM.__init__": 874
        },
        {
            "transformers.models.opt.modeling_tf_opt.TFOPTForCausalLM.prepare_inputs_for_generation": 882
        },
        {
            "transformers.models.opt.modeling_tf_opt.TFOPTForCausalLM.call": 904
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/blenderbot_small/modeling_blenderbot_small.py": [
        {
            "transformers.models.blenderbot_small.modeling_blenderbot_small.BlenderbotSmallEncoder.custom_forward": 773
        },
        {
            "transformers.models.blenderbot_small.modeling_blenderbot_small.BlenderbotSmallDecoder.custom_forward": 1022
        },
        {
            "transformers.models.blenderbot_small.modeling_blenderbot_small.BlenderbotSmallForConditionalGeneration.prepare_inputs_for_generation": 1343
        },
        {
            "transformers.models.blenderbot_small.modeling_blenderbot_small.BlenderbotSmallDecoderWrapper.forward": 1393
        },
        {
            "transformers.models.blenderbot_small.modeling_blenderbot_small.BlenderbotSmallForCausalLM.prepare_inputs_for_generation": 1577
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/blenderbot_small/tokenization_blenderbot_small_fast.py": [
        {
            "transformers.models.blenderbot_small.tokenization_blenderbot_small_fast.BlenderbotSmallTokenizerFast.__init__": 66
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/blenderbot_small/configuration_blenderbot_small.py": [
        {
            "transformers.models.blenderbot_small.configuration_blenderbot_small.BlenderbotSmallConfig.__init__": 111
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/blenderbot_small/modeling_flax_blenderbot_small.py": [
        {
            "transformers.models.blenderbot_small.modeling_flax_blenderbot_small.FlaxBlenderbotSmallPreTrainedModel.__init__": 883
        },
        {
            "transformers.models.blenderbot_small.modeling_flax_blenderbot_small.FlaxBlenderbotSmallPreTrainedModel._decoder_forward": 952
        },
        {
            "transformers.models.blenderbot_small.modeling_flax_blenderbot_small.FlaxBlenderbotSmallPreTrainedModel._encoder_forward": 1018
        },
        {
            "transformers.models.blenderbot_small.modeling_flax_blenderbot_small.FlaxBlenderbotSmallPreTrainedModel._decoder_forward": 1115
        },
        {
            "transformers.models.blenderbot_small.modeling_flax_blenderbot_small.FlaxBlenderbotSmallForConditionalGeneration._decoder_forward": 1383
        },
        {
            "transformers.models.blenderbot_small.modeling_flax_blenderbot_small.FlaxBlenderbotSmallForConditionalGeneration.prepare_inputs_for_generation": 1442
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/blenderbot_small/modeling_tf_blenderbot_small.py": [
        {
            "transformers.models.blenderbot_small.modeling_tf_blenderbot_small.TFBlenderbotSmallLearnedPositionalEmbedding.__init__": 125
        },
        {
            "transformers.models.blenderbot_small.modeling_tf_blenderbot_small.TFBlenderbotSmallAttention.__init__": 144
        },
        {
            "transformers.models.blenderbot_small.modeling_tf_blenderbot_small.TFBlenderbotSmallEncoderLayer.__init__": 296
        },
        {
            "transformers.models.blenderbot_small.modeling_tf_blenderbot_small.TFBlenderbotSmallDecoderLayer.__init__": 353
        },
        {
            "transformers.models.blenderbot_small.modeling_tf_blenderbot_small.TFBlenderbotSmallEncoder.__init__": 657
        },
        {
            "transformers.models.blenderbot_small.modeling_tf_blenderbot_small.TFBlenderbotSmallDecoder.__init__": 833
        },
        {
            "transformers.models.blenderbot_small.modeling_tf_blenderbot_small.TFBlenderbotSmallMainLayer.__init__": 1068
        },
        {
            "transformers.models.blenderbot_small.modeling_tf_blenderbot_small.TFBlenderbotSmallMainLayer.call": 1093
        },
        {
            "transformers.models.blenderbot_small.modeling_tf_blenderbot_small.TFBlenderbotSmallModel.__init__": 1178
        },
        {
            "transformers.models.blenderbot_small.modeling_tf_blenderbot_small.TFBlenderbotSmallModel.call": 1196
        },
        {
            "transformers.models.blenderbot_small.modeling_tf_blenderbot_small.BiasLayer.__init__": 1268
        },
        {
            "transformers.models.blenderbot_small.modeling_tf_blenderbot_small.TFBlenderbotSmallForConditionalGeneration.__init__": 1289
        },
        {
            "transformers.models.blenderbot_small.modeling_tf_blenderbot_small.TFBlenderbotSmallForConditionalGeneration.prepare_inputs_for_generation": 1427
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/blenderbot_small/tokenization_blenderbot_small.py": [
        {
            "transformers.models.blenderbot_small.tokenization_blenderbot_small.BlenderbotSmallTokenizer.__init__": 99
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/yolos/image_processing_yolos.py": [
        {
            "transformers.models.yolos.image_processing_yolos.YolosImageProcessor.__init__": 686
        },
        {
            "transformers.models.yolos.image_processing_yolos.YolosImageProcessor.from_dict": 740
        },
        {
            "transformers.models.yolos.image_processing_yolos.YolosImageProcessor.convert_coco_poly_to_mask": 790
        },
        {
            "transformers.models.yolos.image_processing_yolos.YolosImageProcessor.prepare_coco_detection": 795
        },
        {
            "transformers.models.yolos.image_processing_yolos.YolosImageProcessor.prepare_coco_panoptic": 800
        },
        {
            "transformers.models.yolos.image_processing_yolos.YolosImageProcessor.resize": 805
        },
        {
            "transformers.models.yolos.image_processing_yolos.YolosImageProcessor.preprocess": 937
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/yolos/feature_extraction_yolos.py": [
        {
            "transformers.models.yolos.feature_extraction_yolos.YolosFeatureExtractor.__init__": 27
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/yolos/modeling_yolos.py": [
        {
            "transformers.models.yolos.modeling_yolos.YolosEncoder.custom_forward": 499
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/yolos/configuration_yolos.py": [
        {
            "transformers.models.yolos.configuration_yolos.YolosConfig.__init__": 108
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/x_clip/processing_x_clip.py": [
        {
            "transformers.models.x_clip.processing_x_clip.XCLIPProcessor.__init__": 42
        },
        {
            "transformers.models.x_clip.processing_x_clip.XCLIPProcessor.__call__": 60
        },
        {
            "transformers.models.x_clip.processing_x_clip.XCLIPProcessor.batch_decode": 114
        },
        {
            "transformers.models.x_clip.processing_x_clip.XCLIPProcessor.decode": 121
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/x_clip/configuration_x_clip.py": [
        {
            "transformers.models.x_clip.configuration_x_clip.XCLIPTextConfig.__init__": 89
        },
        {
            "transformers.models.x_clip.configuration_x_clip.XCLIPTextConfig.from_pretrained": 124
        },
        {
            "transformers.models.x_clip.configuration_x_clip.XCLIPVisionConfig.__init__": 208
        },
        {
            "transformers.models.x_clip.configuration_x_clip.XCLIPVisionConfig.from_pretrained": 254
        },
        {
            "transformers.models.x_clip.configuration_x_clip.XCLIPConfig.__init__": 310
        },
        {
            "transformers.models.x_clip.configuration_x_clip.XCLIPConfig.from_text_vision_configs": 356
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/x_clip/modeling_x_clip.py": [
        {
            "transformers.models.x_clip.modeling_x_clip.XCLIPEncoder.custom_forward": 706
        },
        {
            "transformers.models.x_clip.modeling_x_clip.XCLIPVisionEncoder.custom_forward": 947
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/biogpt/tokenization_biogpt.py": [
        {
            "transformers.models.biogpt.tokenization_biogpt.BioGptTokenizer.__init__": 104
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/biogpt/modeling_biogpt.py": [
        {
            "transformers.models.biogpt.modeling_biogpt.BioGptModel.custom_forward": 567
        },
        {
            "transformers.models.biogpt.modeling_biogpt.BioGptForCausalLM.prepare_inputs_for_generation": 706
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/biogpt/configuration_biogpt.py": [
        {
            "transformers.models.biogpt.configuration_biogpt.BioGptConfig.__init__": 99
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/swinv2/configuration_swinv2.py": [
        {
            "transformers.models.swinv2.configuration_swinv2.Swinv2Config.__init__": 101
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/swinv2/modeling_swinv2.py": [
        {
            "transformers.models.swinv2.modeling_swinv2.Swinv2Encoder.custom_forward": 898
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/poolformer/modeling_poolformer.py": [
        {
            "transformers.models.poolformer.modeling_poolformer.PoolFormerGroupNorm.__init__": 113
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/poolformer/image_processing_poolformer.py": [
        {
            "transformers.models.poolformer.image_processing_poolformer.PoolFormerImageProcessor.__init__": 106
        },
        {
            "transformers.models.poolformer.image_processing_poolformer.PoolFormerImageProcessor.resize": 139
        },
        {
            "transformers.models.poolformer.image_processing_poolformer.PoolFormerImageProcessor.center_crop": 201
        },
        {
            "transformers.models.poolformer.image_processing_poolformer.PoolFormerImageProcessor.rescale": 225
        },
        {
            "transformers.models.poolformer.image_processing_poolformer.PoolFormerImageProcessor.normalize": 245
        },
        {
            "transformers.models.poolformer.image_processing_poolformer.PoolFormerImageProcessor.preprocess": 268
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/poolformer/configuration_poolformer.py": [
        {
            "transformers.models.poolformer.configuration_poolformer.PoolFormerConfig.__init__": 96
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/poolformer/feature_extraction_poolformer.py": [
        {
            "transformers.models.poolformer.feature_extraction_poolformer.PoolFormerFeatureExtractor.__init__": 27
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/clipseg/processing_clipseg.py": [
        {
            "transformers.models.clipseg.processing_clipseg.CLIPSegProcessor.__init__": 42
        },
        {
            "transformers.models.clipseg.processing_clipseg.CLIPSegProcessor.__call__": 59
        },
        {
            "transformers.models.clipseg.processing_clipseg.CLIPSegProcessor.batch_decode": 132
        },
        {
            "transformers.models.clipseg.processing_clipseg.CLIPSegProcessor.decode": 139
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/clipseg/configuration_clipseg.py": [
        {
            "transformers.models.clipseg.configuration_clipseg.CLIPSegTextConfig.__init__": 87
        },
        {
            "transformers.models.clipseg.configuration_clipseg.CLIPSegTextConfig.from_pretrained": 122
        },
        {
            "transformers.models.clipseg.configuration_clipseg.CLIPSegVisionConfig.__init__": 193
        },
        {
            "transformers.models.clipseg.configuration_clipseg.CLIPSegVisionConfig.from_pretrained": 227
        },
        {
            "transformers.models.clipseg.configuration_clipseg.CLIPSegConfig.__init__": 312
        },
        {
            "transformers.models.clipseg.configuration_clipseg.CLIPSegConfig.from_text_vision_configs": 361
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/clipseg/modeling_clipseg.py": [
        {
            "transformers.models.clipseg.modeling_clipseg.CLIPSegEncoder.custom_forward": 652
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/tapex/tokenization_tapex.py": [
        {
            "transformers.models.tapex.tokenization_tapex.TapexTokenizer.__init__": 272
        },
        {
            "transformers.models.tapex.tokenization_tapex.TapexTokenizer.prepare_for_tokenization": 406
        },
        {
            "transformers.models.tapex.tokenization_tapex.TapexTokenizer.__call__": 515
        },
        {
            "transformers.models.tapex.tokenization_tapex.TapexTokenizer.source_call_func": 592
        },
        {
            "transformers.models.tapex.tokenization_tapex.TapexTokenizer.batch_encode_plus": 680
        },
        {
            "transformers.models.tapex.tokenization_tapex.TapexTokenizer._batch_encode_plus": 737
        },
        {
            "transformers.models.tapex.tokenization_tapex.TapexTokenizer.encode": 868
        },
        {
            "transformers.models.tapex.tokenization_tapex.TapexTokenizer.encode_plus": 900
        },
        {
            "transformers.models.tapex.tokenization_tapex.TapexTokenizer._encode_plus": 948
        },
        {
            "transformers.models.tapex.tokenization_tapex.TapexTokenizer.target_call_func": 1006
        },
        {
            "transformers.models.tapex.tokenization_tapex.TapexTokenizer.target_batch_encode_plus": 1071
        },
        {
            "transformers.models.tapex.tokenization_tapex.TapexTokenizer._target_batch_encode_plus": 1124
        },
        {
            "transformers.models.tapex.tokenization_tapex.TapexTokenizer.target_encode": 1186
        },
        {
            "transformers.models.tapex.tokenization_tapex.TapexTokenizer.target_encode_plus": 1217
        },
        {
            "transformers.models.tapex.tokenization_tapex.TapexTokenizer._target_encode_plus": 1268
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/bigbird_pegasus/modeling_bigbird_pegasus.py": [
        {
            "transformers.models.bigbird_pegasus.modeling_bigbird_pegasus.BigBirdPegasusEncoder.custom_forward": 1935
        },
        {
            "transformers.models.bigbird_pegasus.modeling_bigbird_pegasus.BigBirdPegasusDecoder.custom_forward": 2277
        },
        {
            "transformers.models.bigbird_pegasus.modeling_bigbird_pegasus.BigBirdPegasusForConditionalGeneration.prepare_inputs_for_generation": 2603
        },
        {
            "transformers.models.bigbird_pegasus.modeling_bigbird_pegasus.BigBirdPegasusForSequenceClassification.__init__": 2657
        },
        {
            "transformers.models.bigbird_pegasus.modeling_bigbird_pegasus.BigBirdPegasusDecoderWrapper.forward": 2908
        },
        {
            "transformers.models.bigbird_pegasus.modeling_bigbird_pegasus.BigBirdPegasusForCausalLM.prepare_inputs_for_generation": 3088
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/bigbird_pegasus/configuration_bigbird_pegasus.py": [
        {
            "transformers.models.bigbird_pegasus.configuration_bigbird_pegasus.BigBirdPegasusConfig.__init__": 131
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/detr/image_processing_detr.py": [
        {
            "transformers.models.detr.image_processing_detr.DetrImageProcessor.__init__": 758
        },
        {
            "transformers.models.detr.image_processing_detr.DetrImageProcessor.from_dict": 810
        },
        {
            "transformers.models.detr.image_processing_detr.DetrImageProcessor.convert_coco_poly_to_mask": 857
        },
        {
            "transformers.models.detr.image_processing_detr.DetrImageProcessor.prepare_coco_detection": 861
        },
        {
            "transformers.models.detr.image_processing_detr.DetrImageProcessor.prepare_coco_panoptic": 865
        },
        {
            "transformers.models.detr.image_processing_detr.DetrImageProcessor.resize": 869
        },
        {
            "transformers.models.detr.image_processing_detr.DetrImageProcessor.preprocess": 1037
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/detr/modeling_detr.py": [
        {
            "transformers.models.detr.modeling_detr.DetrDecoder.custom_forward": 1132
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/detr/configuration_detr.py": [
        {
            "transformers.models.detr.configuration_detr.DetrConfig.__init__": 142
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/detr/feature_extraction_detr.py": [
        {
            "transformers.models.detr.feature_extraction_detr.DetrFeatureExtractor.__init__": 27
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/gpt_neox_japanese/configuration_gpt_neox_japanese.py": [
        {
            "transformers.models.gpt_neox_japanese.configuration_gpt_neox_japanese.GPTNeoXJapaneseConfig.__init__": 88
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/perceiver/image_processing_perceiver.py": [
        {
            "transformers.models.perceiver.image_processing_perceiver.PerceiverImageProcessor.__init__": 86
        },
        {
            "transformers.models.perceiver.image_processing_perceiver.PerceiverImageProcessor.center_crop": 117
        },
        {
            "transformers.models.perceiver.image_processing_perceiver.PerceiverImageProcessor.resize": 152
        },
        {
            "transformers.models.perceiver.image_processing_perceiver.PerceiverImageProcessor.rescale": 180
        },
        {
            "transformers.models.perceiver.image_processing_perceiver.PerceiverImageProcessor.normalize": 200
        },
        {
            "transformers.models.perceiver.image_processing_perceiver.PerceiverImageProcessor.preprocess": 223
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/perceiver/configuration_perceiver.py": [
        {
            "transformers.models.perceiver.configuration_perceiver.PerceiverConfig.__init__": 120
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/perceiver/tokenization_perceiver.py": [
        {
            "transformers.models.perceiver.tokenization_perceiver.PerceiverTokenizer.__init__": 60
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/perceiver/modeling_perceiver.py": [
        {
            "transformers.models.perceiver.modeling_perceiver.PerceiverBasicDecoder.__init__": 2103
        },
        {
            "transformers.models.perceiver.modeling_perceiver.PerceiverClassificationDecoder.__init__": 2264
        },
        {
            "transformers.models.perceiver.modeling_perceiver.PerceiverOpticalFlowDecoder.__init__": 2302
        },
        {
            "transformers.models.perceiver.modeling_perceiver.PerceiverBasicVideoAutoencodingDecoder.__init__": 2348
        },
        {
            "transformers.models.perceiver.modeling_perceiver.PerceiverMultimodalDecoder.__init__": 2437
        },
        {
            "transformers.models.perceiver.modeling_perceiver.Conv2dSamePadding.__init__": 2588
        },
        {
            "transformers.models.perceiver.modeling_perceiver.PerceiverAbstractPositionEncoding.output_size": 2720
        },
        {
            "transformers.models.perceiver.modeling_perceiver.PerceiverTrainablePositionEncoding.output_size": 2744
        },
        {
            "transformers.models.perceiver.modeling_perceiver.PerceiverImagePreprocessor.__init__": 3025
        },
        {
            "transformers.models.perceiver.modeling_perceiver.PerceiverAudioPreprocessor.__init__": 3266
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/perceiver/feature_extraction_perceiver.py": [
        {
            "transformers.models.perceiver.feature_extraction_perceiver.PerceiverFeatureExtractor.__init__": 27
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/graphormer/configuration_graphormer.py": [
        {
            "transformers.models.graphormer.configuration_graphormer.GraphormerConfig.__init__": 135
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/graphormer/modeling_graphormer.py": [
        {
            "transformers.models.graphormer.modeling_graphormer.GraphormerDecoderHead.forward": 686
        },
        {
            "transformers.models.graphormer.modeling_graphormer.GraphormerModel.forward": 790
        },
        {
            "transformers.models.graphormer.modeling_graphormer.GraphormerForGraphClassification.forward": 853
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/jukebox/configuration_jukebox.py": [
        {
            "transformers.models.jukebox.configuration_jukebox.JukeboxPriorConfig.__init__": 260
        },
        {
            "transformers.models.jukebox.configuration_jukebox.JukeboxPriorConfig.from_pretrained": 353
        },
        {
            "transformers.models.jukebox.configuration_jukebox.JukeboxVQVAEConfig.__init__": 440
        },
        {
            "transformers.models.jukebox.configuration_jukebox.JukeboxVQVAEConfig.from_pretrained": 488
        },
        {
            "transformers.models.jukebox.configuration_jukebox.JukeboxConfig.__init__": 565
        },
        {
            "transformers.models.jukebox.configuration_jukebox.JukeboxConfig.from_configs": 615
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/jukebox/tokenization_jukebox.py": [
        {
            "transformers.models.jukebox.tokenization_jukebox.JukeboxTokenizer.__init__": 120
        },
        {
            "transformers.models.jukebox.tokenization_jukebox.JukeboxTokenizer.tokenize": 192
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/jukebox/modeling_jukebox.py": [
        {
            "transformers.models.jukebox.modeling_jukebox.JukeboxPreTrainedModel.__init__": 2281
        },
        {
            "transformers.models.jukebox.modeling_jukebox.JukeboxModel.ancestral_sample": 2592
        },
        {
            "transformers.models.jukebox.modeling_jukebox.JukeboxModel.continue_sample": 2633
        },
        {
            "transformers.models.jukebox.modeling_jukebox.JukeboxModel.upsample": 2648
        },
        {
            "transformers.models.jukebox.modeling_jukebox.JukeboxModel.primed_sample": 2665
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/nllb/tokenization_nllb.py": [
        {
            "transformers.models.nllb.tokenization_nllb.NllbTokenizer.__init__": 128
        },
        {
            "transformers.models.nllb.tokenization_nllb.NllbTokenizer._build_translation_inputs": 316
        },
        {
            "transformers.models.nllb.tokenization_nllb.NllbTokenizer.prepare_seq2seq_batch": 373
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/nllb/tokenization_nllb_fast.py": [
        {
            "transformers.models.nllb.tokenization_nllb_fast.NllbTokenizerFast.__init__": 140
        },
        {
            "transformers.models.nllb.tokenization_nllb_fast.NllbTokenizerFast._build_translation_inputs": 259
        },
        {
            "transformers.models.nllb.tokenization_nllb_fast.NllbTokenizerFast.prepare_seq2seq_batch": 271
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/clip/modeling_flax_clip.py": [
        {
            "transformers.models.clip.modeling_flax_clip.FlaxCLIPTextPreTrainedModel.__init__": 589
        },
        {
            "transformers.models.clip.modeling_flax_clip.FlaxCLIPVisionPreTrainedModel.__init__": 669
        },
        {
            "transformers.models.clip.modeling_flax_clip.FlaxCLIPPreTrainedModel.__init__": 740
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/clip/modeling_tf_clip.py": [
        {
            "transformers.models.clip.modeling_tf_clip.TFCLIPVisionEmbeddings.__init__": 130
        },
        {
            "transformers.models.clip.modeling_tf_clip.TFCLIPTextEmbeddings.__init__": 200
        },
        {
            "transformers.models.clip.modeling_tf_clip.TFCLIPAttention.__init__": 270
        },
        {
            "transformers.models.clip.modeling_tf_clip.TFCLIPMLP.__init__": 367
        },
        {
            "transformers.models.clip.modeling_tf_clip.TFCLIPEncoderLayer.__init__": 392
        },
        {
            "transformers.models.clip.modeling_tf_clip.TFCLIPEncoder.__init__": 452
        },
        {
            "transformers.models.clip.modeling_tf_clip.TFCLIPTextTransformer.__init__": 499
        },
        {
            "transformers.models.clip.modeling_tf_clip.TFCLIPTextMainLayer.__init__": 586
        },
        {
            "transformers.models.clip.modeling_tf_clip.TFCLIPVisionTransformer.__init__": 631
        },
        {
            "transformers.models.clip.modeling_tf_clip.TFCLIPVisionMainLayer.__init__": 680
        },
        {
            "transformers.models.clip.modeling_tf_clip.TFCLIPMainLayer.__init__": 716
        },
        {
            "transformers.models.clip.modeling_tf_clip.TFCLIPTextModel.__init__": 1058
        },
        {
            "transformers.models.clip.modeling_tf_clip.TFCLIPVisionModel.__init__": 1134
        },
        {
            "transformers.models.clip.modeling_tf_clip.TFCLIPModel.__init__": 1231
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/clip/feature_extraction_clip.py": [
        {
            "transformers.models.clip.feature_extraction_clip.CLIPFeatureExtractor.__init__": 27
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/clip/tokenization_clip.py": [
        {
            "transformers.models.clip.tokenization_clip.CLIPTokenizer.__init__": 289
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/clip/configuration_clip.py": [
        {
            "transformers.models.clip.configuration_clip.CLIPTextConfig.__init__": 95
        },
        {
            "transformers.models.clip.configuration_clip.CLIPTextConfig.from_pretrained": 132
        },
        {
            "transformers.models.clip.configuration_clip.CLIPVisionConfig.__init__": 203
        },
        {
            "transformers.models.clip.configuration_clip.CLIPVisionConfig.from_pretrained": 239
        },
        {
            "transformers.models.clip.configuration_clip.CLIPConfig.__init__": 305
        },
        {
            "transformers.models.clip.configuration_clip.CLIPConfig.from_text_vision_configs": 334
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/clip/image_processing_clip.py": [
        {
            "transformers.models.clip.image_processing_clip.CLIPImageProcessor.__init__": 85
        },
        {
            "transformers.models.clip.image_processing_clip.CLIPImageProcessor.resize": 118
        },
        {
            "transformers.models.clip.image_processing_clip.CLIPImageProcessor.center_crop": 146
        },
        {
            "transformers.models.clip.image_processing_clip.CLIPImageProcessor.rescale": 170
        },
        {
            "transformers.models.clip.image_processing_clip.CLIPImageProcessor.normalize": 190
        },
        {
            "transformers.models.clip.image_processing_clip.CLIPImageProcessor.preprocess": 213
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/clip/tokenization_clip_fast.py": [
        {
            "transformers.models.clip.tokenization_clip_fast.CLIPTokenizerFast.__init__": 78
        },
        {
            "transformers.models.clip.tokenization_clip_fast.CLIPTokenizerFast.new_decode_method": 116
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/clip/processing_clip.py": [
        {
            "transformers.models.clip.processing_clip.CLIPProcessor.__init__": 42
        },
        {
            "transformers.models.clip.processing_clip.CLIPProcessor.__call__": 59
        },
        {
            "transformers.models.clip.processing_clip.CLIPProcessor.batch_decode": 112
        },
        {
            "transformers.models.clip.processing_clip.CLIPProcessor.decode": 119
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/clip/modeling_clip.py": [
        {
            "transformers.models.clip.modeling_clip.CLIPEncoder.custom_forward": 642
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/dpr/tokenization_dpr.py": [
        {
            "transformers.models.dpr.tokenization_dpr.CustomDPRReaderTokenizerMixin.__call__": 223
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/dpr/convert_dpr_original_checkpoint_to_pytorch.py": [
        {
            "transformers.models.dpr.convert_dpr_original_checkpoint_to_pytorch.DPRState.from_type": 44
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/dpr/configuration_dpr.py": [
        {
            "transformers.models.dpr.configuration_dpr.DPRConfig.__init__": 112
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/dpr/tokenization_dpr_fast.py": [
        {
            "transformers.models.dpr.tokenization_dpr_fast.CustomDPRReaderTokenizerMixin.__call__": 224
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/dpr/modeling_tf_dpr.py": [
        {
            "transformers.models.dpr.modeling_tf_dpr.TFDPREncoderLayer.__init__": 152
        },
        {
            "transformers.models.dpr.modeling_tf_dpr.TFDPRSpanPredictorLayer.__init__": 216
        },
        {
            "transformers.models.dpr.modeling_tf_dpr.TFDPRSpanPredictor.__init__": 281
        },
        {
            "transformers.models.dpr.modeling_tf_dpr.TFDPREncoder.__init__": 313
        },
        {
            "transformers.models.dpr.modeling_tf_dpr.TFDPRContextEncoder.__init__": 541
        },
        {
            "transformers.models.dpr.modeling_tf_dpr.TFDPRQuestionEncoder.__init__": 628
        },
        {
            "transformers.models.dpr.modeling_tf_dpr.TFDPRReader.__init__": 714
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/resnet/modeling_tf_resnet.py": [
        {
            "transformers.models.resnet.modeling_tf_resnet.TFResNetConvLayer.__init__": 53
        },
        {
            "transformers.models.resnet.modeling_tf_resnet.TFResNetEmbeddings.__init__": 84
        },
        {
            "transformers.models.resnet.modeling_tf_resnet.TFResNetShortCut.__init__": 115
        },
        {
            "transformers.models.resnet.modeling_tf_resnet.TFResNetBasicLayer.__init__": 135
        },
        {
            "transformers.models.resnet.modeling_tf_resnet.TFResNetBottleNeckLayer.__init__": 167
        },
        {
            "transformers.models.resnet.modeling_tf_resnet.TFResNetStage.__init__": 205
        },
        {
            "transformers.models.resnet.modeling_tf_resnet.TFResNetEncoder.__init__": 226
        },
        {
            "transformers.models.resnet.modeling_tf_resnet.TFResNetMainLayer.__init__": 330
        },
        {
            "transformers.models.resnet.modeling_tf_resnet.TFResNetModel.__init__": 389
        },
        {
            "transformers.models.resnet.modeling_tf_resnet.TFResNetForImageClassification.__init__": 441
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/resnet/configuration_resnet.py": [
        {
            "transformers.models.resnet.configuration_resnet.ResNetConfig.__init__": 82
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/longt5/modeling_longt5.py": [
        {
            "transformers.models.longt5.modeling_longt5.LongT5LayerLocalSelfAttention.forward": 1055
        },
        {
            "transformers.models.longt5.modeling_longt5.LongT5LayerTransientGlobalSelfAttention.forward": 1088
        },
        {
            "transformers.models.longt5.modeling_longt5.LongT5Stack.custom_forward": 1505
        },
        {
            "transformers.models.longt5.modeling_longt5.LongT5ForConditionalGeneration.prepare_inputs_for_generation": 2089
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/longt5/modeling_flax_longt5.py": [
        {
            "transformers.models.longt5.modeling_flax_longt5.FlaxLongT5LayerLocalSelfAttention.__call__": 1120
        },
        {
            "transformers.models.longt5.modeling_flax_longt5.FlaxLongT5LayerTransientGlobalSelfAttention.__call__": 1158
        },
        {
            "transformers.models.longt5.modeling_flax_longt5.FlaxLongT5PreTrainedModel.__init__": 1677
        },
        {
            "transformers.models.longt5.modeling_flax_longt5.FlaxLongT5PreTrainedModel._decoder_forward": 1793
        },
        {
            "transformers.models.longt5.modeling_flax_longt5.FlaxLongT5PreTrainedModel._encoder_forward": 1853
        },
        {
            "transformers.models.longt5.modeling_flax_longt5.FlaxLongT5PreTrainedModel._decoder_forward": 1938
        },
        {
            "transformers.models.longt5.modeling_flax_longt5.FlaxLongT5ForConditionalGeneration._decoder_forward": 2326
        },
        {
            "transformers.models.longt5.modeling_flax_longt5.FlaxLongT5ForConditionalGeneration.prepare_inputs_for_generation": 2388
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/longt5/configuration_longt5.py": [
        {
            "transformers.models.longt5.configuration_longt5.LongT5Config.__init__": 89
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/reformer/tokenization_reformer_fast.py": [
        {
            "transformers.models.reformer.tokenization_reformer_fast.ReformerTokenizerFast.__init__": 94
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/reformer/tokenization_reformer.py": [
        {
            "transformers.models.reformer.tokenization_reformer.ReformerTokenizer.__init__": 98
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/reformer/configuration_reformer.py": [
        {
            "transformers.models.reformer.configuration_reformer.ReformerConfig.__init__": 165
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/mt5/modeling_mt5.py": [
        {
            "transformers.models.mt5.modeling_mt5.MT5Stack.custom_forward": 1008
        },
        {
            "transformers.models.mt5.modeling_mt5.MT5ForConditionalGeneration.prepare_inputs_for_generation": 1748
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/mt5/configuration_mt5.py": [
        {
            "transformers.models.mt5.configuration_mt5.MT5Config.__init__": 72
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/auto/auto_factory.py": [
        {
            "transformers.models.auto.auto_factory._BaseAutoModelClass.__init__": 382
        },
        {
            "transformers.models.auto.auto_factory._BaseAutoModelClass.from_config": 390
        },
        {
            "transformers.models.auto.auto_factory._BaseAutoModelClass.from_pretrained": 418
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/auto/modeling_auto.py": [
        {
            "transformers.models.auto.modeling_auto.AutoModelWithLMHead.from_pretrained": 1247
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/auto/processing_auto.py": [
        {
            "transformers.models.auto.processing_auto.AutoProcessor.from_pretrained": 119
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/auto/feature_extraction_auto.py": [
        {
            "transformers.models.auto.feature_extraction_auto.get_feature_extractor_config": 127
        },
        {
            "transformers.models.auto.feature_extraction_auto.AutoFeatureExtractor.from_pretrained": 233
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/auto/configuration_auto.py": [
        {
            "transformers.models.auto.configuration_auto.AutoConfig.for_model": 756
        },
        {
            "transformers.models.auto.configuration_auto.AutoConfig.from_pretrained": 766
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/auto/image_processing_auto.py": [
        {
            "transformers.models.auto.image_processing_auto.get_image_processor_config": 125
        },
        {
            "transformers.models.auto.image_processing_auto.AutoImageProcessor.from_pretrained": 231
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/auto/modeling_tf_auto.py": [
        {
            "transformers.models.auto.modeling_tf_auto.TFAutoModelWithLMHead.from_pretrained": 623
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/auto/tokenization_auto.py": [
        {
            "transformers.models.auto.tokenization_auto.get_tokenizer_config": 368
        },
        {
            "transformers.models.auto.tokenization_auto.AutoTokenizer.from_pretrained": 484
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/electra/configuration_electra.py": [
        {
            "transformers.models.electra.configuration_electra.ElectraConfig.__init__": 135
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/electra/modeling_flax_electra.py": [
        {
            "transformers.models.electra.modeling_flax_electra.FlaxElectraPreTrainedModel.__init__": 687
        },
        {
            "transformers.models.electra.modeling_flax_electra.identity": 1180
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/electra/modeling_tf_electra.py": [
        {
            "transformers.models.electra.modeling_tf_electra.TFElectraSelfAttention.__init__": 79
        },
        {
            "transformers.models.electra.modeling_tf_electra.TFElectraSelfOutput.__init__": 197
        },
        {
            "transformers.models.electra.modeling_tf_electra.TFElectraAttention.__init__": 216
        },
        {
            "transformers.models.electra.modeling_tf_electra.TFElectraIntermediate.__init__": 257
        },
        {
            "transformers.models.electra.modeling_tf_electra.TFElectraOutput.__init__": 278
        },
        {
            "transformers.models.electra.modeling_tf_electra.TFElectraLayer.__init__": 297
        },
        {
            "transformers.models.electra.modeling_tf_electra.TFElectraEncoder.__init__": 384
        },
        {
            "transformers.models.electra.modeling_tf_electra.TFElectraPooler.__init__": 454
        },
        {
            "transformers.models.electra.modeling_tf_electra.TFElectraEmbeddings.__init__": 477
        },
        {
            "transformers.models.electra.modeling_tf_electra.TFElectraDiscriminatorPredictions.__init__": 563
        },
        {
            "transformers.models.electra.modeling_tf_electra.TFElectraGeneratorPredictions.__init__": 579
        },
        {
            "transformers.models.electra.modeling_tf_electra.TFElectraMainLayer.__init__": 629
        },
        {
            "transformers.models.electra.modeling_tf_electra.TFElectraModel.__init__": 939
        },
        {
            "transformers.models.electra.modeling_tf_electra.TFElectraForPreTraining.__init__": 1035
        },
        {
            "transformers.models.electra.modeling_tf_electra.TFElectraMaskedLMHead.__init__": 1104
        },
        {
            "transformers.models.electra.modeling_tf_electra.TFElectraForMaskedLM.__init__": 1150
        },
        {
            "transformers.models.electra.modeling_tf_electra.TFElectraClassificationHead.__init__": 1241
        },
        {
            "transformers.models.electra.modeling_tf_electra.TFElectraClassificationHead.call": 1257
        },
        {
            "transformers.models.electra.modeling_tf_electra.TFElectraForSequenceClassification.__init__": 1276
        },
        {
            "transformers.models.electra.modeling_tf_electra.TFElectraForMultipleChoice.__init__": 1354
        },
        {
            "transformers.models.electra.modeling_tf_electra.TFElectraForTokenClassification.__init__": 1479
        },
        {
            "transformers.models.electra.modeling_tf_electra.TFElectraForQuestionAnswering.__init__": 1563
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/electra/modeling_electra.py": [
        {
            "transformers.models.electra.modeling_electra.ElectraEncoder.custom_forward": 573
        },
        {
            "transformers.models.electra.modeling_electra.ElectraClassificationHead.forward": 946
        },
        {
            "transformers.models.electra.modeling_electra.ElectraForCausalLM.prepare_inputs_for_generation": 1662
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/electra/tokenization_electra.py": [
        {
            "transformers.models.electra.tokenization_electra.ElectraTokenizer.__init__": 140
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/electra/tokenization_electra_fast.py": [
        {
            "transformers.models.electra.tokenization_electra_fast.ElectraTokenizerFast.__init__": 134
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/m2m_100/configuration_m2m_100.py": [
        {
            "transformers.models.m2m_100.configuration_m2m_100.M2M100Config.__init__": 106
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/m2m_100/modeling_m2m_100.py": [
        {
            "transformers.models.m2m_100.modeling_m2m_100.M2M100Encoder.custom_forward": 823
        },
        {
            "transformers.models.m2m_100.modeling_m2m_100.M2M100Decoder.custom_forward": 1066
        },
        {
            "transformers.models.m2m_100.modeling_m2m_100.M2M100ForConditionalGeneration.prepare_inputs_for_generation": 1371
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/m2m_100/tokenization_m2m_100.py": [
        {
            "transformers.models.m2m_100.tokenization_m2m_100.M2M100Tokenizer.__init__": 130
        },
        {
            "transformers.models.m2m_100.tokenization_m2m_100.M2M100Tokenizer.prepare_seq2seq_batch": 333
        },
        {
            "transformers.models.m2m_100.tokenization_m2m_100.M2M100Tokenizer._build_translation_inputs": 346
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/herbert/tokenization_herbert_fast.py": [
        {
            "transformers.models.herbert.tokenization_herbert_fast.HerbertTokenizerFast.__init__": 65
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/herbert/tokenization_herbert.py": [
        {
            "transformers.models.herbert.tokenization_herbert.HerbertTokenizer.__init__": 297
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/bit/configuration_bit.py": [
        {
            "transformers.models.bit.configuration_bit.BitConfig.__init__": 86
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/bit/image_processing_bit.py": [
        {
            "transformers.models.bit.image_processing_bit.BitImageProcessor.__init__": 85
        },
        {
            "transformers.models.bit.image_processing_bit.BitImageProcessor.resize": 118
        },
        {
            "transformers.models.bit.image_processing_bit.BitImageProcessor.center_crop": 146
        },
        {
            "transformers.models.bit.image_processing_bit.BitImageProcessor.rescale": 170
        },
        {
            "transformers.models.bit.image_processing_bit.BitImageProcessor.normalize": 190
        },
        {
            "transformers.models.bit.image_processing_bit.BitImageProcessor.preprocess": 213
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/mluke/tokenization_mluke.py": [
        {
            "transformers.models.mluke.tokenization_mluke.MLukeTokenizer.__init__": 238
        },
        {
            "transformers.models.mluke.tokenization_mluke.MLukeTokenizer.__call__": 367
        },
        {
            "transformers.models.mluke.tokenization_mluke.MLukeTokenizer._encode_plus": 513
        },
        {
            "transformers.models.mluke.tokenization_mluke.MLukeTokenizer._batch_encode_plus": 595
        },
        {
            "transformers.models.mluke.tokenization_mluke.MLukeTokenizer._create_input_sequence": 724
        },
        {
            "transformers.models.mluke.tokenization_mluke.MLukeTokenizer.prepare_for_model": 963
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/vit_mae/modeling_tf_vit_mae.py": [
        {
            "transformers.models.vit_mae.modeling_tf_vit_mae.TFViTMAEEmbeddings.__init__": 205
        },
        {
            "transformers.models.vit_mae.modeling_tf_vit_mae.TFViTMAEPatchEmbeddings.__init__": 300
        },
        {
            "transformers.models.vit_mae.modeling_tf_vit_mae.TFViTMAESelfAttention.__init__": 355
        },
        {
            "transformers.models.vit_mae.modeling_tf_vit_mae.TFViTMAESelfOutput.__init__": 436
        },
        {
            "transformers.models.vit_mae.modeling_tf_vit_mae.TFViTMAEAttention.__init__": 453
        },
        {
            "transformers.models.vit_mae.modeling_tf_vit_mae.TFViTMAEIntermediate.__init__": 482
        },
        {
            "transformers.models.vit_mae.modeling_tf_vit_mae.TFViTMAEOutput.__init__": 503
        },
        {
            "transformers.models.vit_mae.modeling_tf_vit_mae.TFViTMAELayer.__init__": 523
        },
        {
            "transformers.models.vit_mae.modeling_tf_vit_mae.TFViTMAEEncoder.__init__": 572
        },
        {
            "transformers.models.vit_mae.modeling_tf_vit_mae.TFViTMAEMainLayer.__init__": 620
        },
        {
            "transformers.models.vit_mae.modeling_tf_vit_mae.TFViTMAEModel.__init__": 806
        },
        {
            "transformers.models.vit_mae.modeling_tf_vit_mae.TFViTMAEDecoder.__init__": 873
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/vit_mae/modeling_vit_mae.py": [
        {
            "transformers.models.vit_mae.modeling_vit_mae.ViTMAEEncoder.custom_forward": 543
        },
        {
            "transformers.models.vit_mae.modeling_vit_mae.ViTMAEDecoder.custom_forward": 800
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/vit_mae/configuration_vit_mae.py": [
        {
            "transformers.models.vit_mae.configuration_vit_mae.ViTMAEConfig.__init__": 98
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/convbert/configuration_convbert.py": [
        {
            "transformers.models.convbert.configuration_convbert.ConvBertConfig.__init__": 101
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/convbert/modeling_tf_convbert.py": [
        {
            "transformers.models.convbert.modeling_tf_convbert.TFConvBertEmbeddings.__init__": 73
        },
        {
            "transformers.models.convbert.modeling_tf_convbert.TFConvBertSelfAttention.__init__": 159
        },
        {
            "transformers.models.convbert.modeling_tf_convbert.TFConvBertSelfOutput.__init__": 310
        },
        {
            "transformers.models.convbert.modeling_tf_convbert.TFConvBertAttention.__init__": 328
        },
        {
            "transformers.models.convbert.modeling_tf_convbert.GroupedLinearLayer.__init__": 348
        },
        {
            "transformers.models.convbert.modeling_tf_convbert.TFConvBertIntermediate.__init__": 380
        },
        {
            "transformers.models.convbert.modeling_tf_convbert.TFConvBertOutput.__init__": 408
        },
        {
            "transformers.models.convbert.modeling_tf_convbert.TFConvBertLayer.__init__": 435
        },
        {
            "transformers.models.convbert.modeling_tf_convbert.TFConvBertEncoder.__init__": 455
        },
        {
            "transformers.models.convbert.modeling_tf_convbert.TFConvBertPredictionHeadTransform.__init__": 498
        },
        {
            "transformers.models.convbert.modeling_tf_convbert.TFConvBertMainLayer.__init__": 524
        },
        {
            "transformers.models.convbert.modeling_tf_convbert.TFConvBertModel.__init__": 740
        },
        {
            "transformers.models.convbert.modeling_tf_convbert.TFConvBertMaskedLMHead.__init__": 788
        },
        {
            "transformers.models.convbert.modeling_tf_convbert.TFConvBertGeneratorPredictions.__init__": 825
        },
        {
            "transformers.models.convbert.modeling_tf_convbert.TFConvBertForMaskedLM.__init__": 841
        },
        {
            "transformers.models.convbert.modeling_tf_convbert.TFConvBertClassificationHead.__init__": 928
        },
        {
            "transformers.models.convbert.modeling_tf_convbert.TFConvBertClassificationHead.call": 944
        },
        {
            "transformers.models.convbert.modeling_tf_convbert.TFConvBertForSequenceClassification.__init__": 962
        },
        {
            "transformers.models.convbert.modeling_tf_convbert.TFConvBertForMultipleChoice.__init__": 1037
        },
        {
            "transformers.models.convbert.modeling_tf_convbert.TFConvBertForTokenClassification.__init__": 1160
        },
        {
            "transformers.models.convbert.modeling_tf_convbert.TFConvBertForQuestionAnswering.__init__": 1241
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/convbert/tokenization_convbert.py": [
        {
            "transformers.models.convbert.tokenization_convbert.ConvBertTokenizer.__init__": 123
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/convbert/tokenization_convbert_fast.py": [
        {
            "transformers.models.convbert.tokenization_convbert_fast.ConvBertTokenizerFast.__init__": 101
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/convbert/modeling_convbert.py": [
        {
            "transformers.models.convbert.modeling_convbert.SeparableConv1D.__init__": 275
        },
        {
            "transformers.models.convbert.modeling_convbert.ConvBertEncoder.custom_forward": 634
        },
        {
            "transformers.models.convbert.modeling_convbert.ConvBertClassificationHead.forward": 973
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/flava/processing_flava.py": [
        {
            "transformers.models.flava.processing_flava.FlavaProcessor.__init__": 43
        },
        {
            "transformers.models.flava.processing_flava.FlavaProcessor.__call__": 61
        },
        {
            "transformers.models.flava.processing_flava.FlavaProcessor.batch_decode": 129
        },
        {
            "transformers.models.flava.processing_flava.FlavaProcessor.decode": 136
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/flava/feature_extraction_flava.py": [
        {
            "transformers.models.flava.feature_extraction_flava.FlavaFeatureExtractor.__init__": 27
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/flava/image_processing_flava.py": [
        {
            "transformers.models.flava.image_processing_flava.FlavaImageProcessor.__init__": 217
        },
        {
            "transformers.models.flava.image_processing_flava.FlavaImageProcessor.from_dict": 297
        },
        {
            "transformers.models.flava.image_processing_flava.FlavaImageProcessor.resize": 328
        },
        {
            "transformers.models.flava.image_processing_flava.FlavaImageProcessor.center_crop": 356
        },
        {
            "transformers.models.flava.image_processing_flava.FlavaImageProcessor.rescale": 380
        },
        {
            "transformers.models.flava.image_processing_flava.FlavaImageProcessor.normalize": 400
        },
        {
            "transformers.models.flava.image_processing_flava.FlavaImageProcessor.preprocess": 474
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/flava/modeling_flava.py": [
        {
            "transformers.models.flava.modeling_flava.FlavaEncoder.custom_forward": 669
        },
        {
            "transformers.models.flava.modeling_flava.FlavaImageCodebookResPath.__init__": 1447
        },
        {
            "transformers.models.flava.modeling_flava.FlavaImageCodebookBlock.__init__": 1468
        },
        {
            "transformers.models.flava.modeling_flava.FlavaImageCodebook.__init__": 1518
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/flava/configuration_flava.py": [
        {
            "transformers.models.flava.configuration_flava.FlavaImageConfig.__init__": 95
        },
        {
            "transformers.models.flava.configuration_flava.FlavaImageConfig.from_pretrained": 133
        },
        {
            "transformers.models.flava.configuration_flava.FlavaTextConfig.__init__": 223
        },
        {
            "transformers.models.flava.configuration_flava.FlavaTextConfig.from_pretrained": 261
        },
        {
            "transformers.models.flava.configuration_flava.FlavaMultimodalConfig.__init__": 333
        },
        {
            "transformers.models.flava.configuration_flava.FlavaMultimodalConfig.from_pretrained": 363
        },
        {
            "transformers.models.flava.configuration_flava.FlavaImageCodebookConfig.__init__": 425
        },
        {
            "transformers.models.flava.configuration_flava.FlavaImageCodebookConfig.from_pretrained": 446
        },
        {
            "transformers.models.flava.configuration_flava.FlavaConfig.__init__": 536
        },
        {
            "transformers.models.flava.configuration_flava.FlavaConfig.from_configs": 618
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/visual_bert/configuration_visual_bert.py": [
        {
            "transformers.models.visual_bert.configuration_visual_bert.VisualBertConfig.__init__": 113
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/visual_bert/modeling_visual_bert.py": [
        {
            "transformers.models.visual_bert.modeling_visual_bert.VisualBertEncoder.custom_forward": 421
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/transfo_xl/configuration_transfo_xl.py": [
        {
            "transformers.models.transfo_xl.configuration_transfo_xl.TransfoXLConfig.__init__": 116
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/transfo_xl/modeling_tf_transfo_xl.py": [
        {
            "transformers.models.transfo_xl.modeling_tf_transfo_xl.TFPositionalEmbedding.__init__": 58
        },
        {
            "transformers.models.transfo_xl.modeling_tf_transfo_xl.TFPositionwiseFF.__init__": 75
        },
        {
            "transformers.models.transfo_xl.modeling_tf_transfo_xl.TFRelPartialLearnableMultiHeadAttn.__init__": 118
        },
        {
            "transformers.models.transfo_xl.modeling_tf_transfo_xl.TFRelPartialLearnableDecoderLayer.__init__": 270
        },
        {
            "transformers.models.transfo_xl.modeling_tf_transfo_xl.TFTransfoEmbeddings.__init__": 322
        },
        {
            "transformers.models.transfo_xl.modeling_tf_transfo_xl.TFAdaptiveEmbedding.__init__": 343
        },
        {
            "transformers.models.transfo_xl.modeling_tf_transfo_xl.TFTransfoXLMainLayer.__init__": 422
        },
        {
            "transformers.models.transfo_xl.modeling_tf_transfo_xl.TFTransfoXLModel.__init__": 883
        },
        {
            "transformers.models.transfo_xl.modeling_tf_transfo_xl.TFTransfoXLLMHeadModel.prepare_inputs_for_generation": 1028
        },
        {
            "transformers.models.transfo_xl.modeling_tf_transfo_xl.TFTransfoXLForSequenceClassification.__init__": 1056
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/transfo_xl/modeling_tf_transfo_xl_utilities.py": [
        {
            "transformers.models.transfo_xl.modeling_tf_transfo_xl_utilities.TFAdaptiveSoftmaxMask.__init__": 27
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/transfo_xl/modeling_transfo_xl.py": [
        {
            "transformers.models.transfo_xl.modeling_transfo_xl.RelPartialLearnableDecoderLayer.__init__": 373
        },
        {
            "transformers.models.transfo_xl.modeling_transfo_xl.TransfoXLLMHeadModel.prepare_inputs_for_generation": 1150
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/transfo_xl/tokenization_transfo_xl.py": [
        {
            "transformers.models.transfo_xl.tokenization_transfo_xl.TransfoXLTokenizer.__init__": 168
        },
        {
            "transformers.models.transfo_xl.tokenization_transfo_xl.TransfoXLCorpus.from_pretrained": 679
        },
        {
            "transformers.models.transfo_xl.tokenization_transfo_xl.TransfoXLCorpus.__init__": 714
        },
        {
            "transformers.models.transfo_xl.tokenization_transfo_xl.TransfoXLCorpus.get_iterator": 755
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/sew_d/configuration_sew_d.py": [
        {
            "transformers.models.sew_d.configuration_sew_d.SEWDConfig.__init__": 172
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/sew_d/modeling_sew_d.py": [
        {
            "transformers.models.sew_d.modeling_sew_d.SEWDFeatureEncoder.custom_forward": 459
        },
        {
            "transformers.models.sew_d.modeling_sew_d.SEWDTransformerEncoder.custom_forward": 1142
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/ctrl/configuration_ctrl.py": [
        {
            "transformers.models.ctrl.configuration_ctrl.CTRLConfig.__init__": 87
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/ctrl/modeling_ctrl.py": [
        {
            "transformers.models.ctrl.modeling_ctrl.CTRLLMHeadModel.prepare_inputs_for_generation": 528
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/ctrl/tokenization_ctrl.py": [
        {
            "transformers.models.ctrl.tokenization_ctrl.CTRLTokenizer.__init__": 141
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/ctrl/modeling_tf_ctrl.py": [
        {
            "transformers.models.ctrl.modeling_tf_ctrl.TFMultiHeadAttention.__init__": 94
        },
        {
            "transformers.models.ctrl.modeling_tf_ctrl.TFPointWiseFeedForwardLayer.__init__": 147
        },
        {
            "transformers.models.ctrl.modeling_tf_ctrl.TFEncoderLayer.__init__": 161
        },
        {
            "transformers.models.ctrl.modeling_tf_ctrl.TFCTRLMainLayer.__init__": 210
        },
        {
            "transformers.models.ctrl.modeling_tf_ctrl.TFCTRLModel.__init__": 532
        },
        {
            "transformers.models.ctrl.modeling_tf_ctrl.TFCTRLLMHead.__init__": 585
        },
        {
            "transformers.models.ctrl.modeling_tf_ctrl.TFCTRLLMHeadModel.__init__": 627
        },
        {
            "transformers.models.ctrl.modeling_tf_ctrl.TFCTRLLMHeadModel.prepare_inputs_for_generation": 642
        },
        {
            "transformers.models.ctrl.modeling_tf_ctrl.TFCTRLForSequenceClassification.__init__": 739
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/yoso/configuration_yoso.py": [
        {
            "transformers.models.yoso.configuration_yoso.YosoConfig.__init__": 99
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/yoso/modeling_yoso.py": [
        {
            "transformers.models.yoso.modeling_yoso.YosoEncoder.custom_forward": 565
        },
        {
            "transformers.models.yoso.modeling_yoso.YosoClassificationHead.forward": 944
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/xlm_roberta/tokenization_xlm_roberta.py": [
        {
            "transformers.models.xlm_roberta.tokenization_xlm_roberta.XLMRobertaTokenizer.__init__": 137
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/xlm_roberta/modeling_tf_xlm_roberta.py": [
        {
            "transformers.models.xlm_roberta.modeling_tf_xlm_roberta.TFXLMRobertaEmbeddings.__init__": 169
        },
        {
            "transformers.models.xlm_roberta.modeling_tf_xlm_roberta.TFXLMRobertaPooler.__init__": 275
        },
        {
            "transformers.models.xlm_roberta.modeling_tf_xlm_roberta.TFXLMRobertaSelfAttention.__init__": 296
        },
        {
            "transformers.models.xlm_roberta.modeling_tf_xlm_roberta.TFXLMRobertaSelfOutput.__init__": 414
        },
        {
            "transformers.models.xlm_roberta.modeling_tf_xlm_roberta.TFXLMRobertaAttention.__init__": 433
        },
        {
            "transformers.models.xlm_roberta.modeling_tf_xlm_roberta.TFXLMRobertaIntermediate.__init__": 474
        },
        {
            "transformers.models.xlm_roberta.modeling_tf_xlm_roberta.TFXLMRobertaOutput.__init__": 495
        },
        {
            "transformers.models.xlm_roberta.modeling_tf_xlm_roberta.TFXLMRobertaLayer.__init__": 514
        },
        {
            "transformers.models.xlm_roberta.modeling_tf_xlm_roberta.TFXLMRobertaEncoder.__init__": 601
        },
        {
            "transformers.models.xlm_roberta.modeling_tf_xlm_roberta.TFXLMRobertaMainLayer.__init__": 674
        },
        {
            "transformers.models.xlm_roberta.modeling_tf_xlm_roberta.TFXLMRobertaModel.__init__": 917
        },
        {
            "transformers.models.xlm_roberta.modeling_tf_xlm_roberta.TFXLMRobertaLMHead.__init__": 1010
        },
        {
            "transformers.models.xlm_roberta.modeling_tf_xlm_roberta.TFXLMRobertaForMaskedLM.__init__": 1065
        },
        {
            "transformers.models.xlm_roberta.modeling_tf_xlm_roberta.TFXLMRobertaForCausalLM.__init__": 1154
        },
        {
            "transformers.models.xlm_roberta.modeling_tf_xlm_roberta.TFXLMRobertaForCausalLM.prepare_inputs_for_generation": 1171
        },
        {
            "transformers.models.xlm_roberta.modeling_tf_xlm_roberta.TFXLMRobertaClassificationHead.__init__": 1290
        },
        {
            "transformers.models.xlm_roberta.modeling_tf_xlm_roberta.TFXLMRobertaForSequenceClassification.__init__": 1327
        },
        {
            "transformers.models.xlm_roberta.modeling_tf_xlm_roberta.TFXLMRobertaForMultipleChoice.__init__": 1412
        },
        {
            "transformers.models.xlm_roberta.modeling_tf_xlm_roberta.TFXLMRobertaForTokenClassification.__init__": 1535
        },
        {
            "transformers.models.xlm_roberta.modeling_tf_xlm_roberta.TFXLMRobertaForQuestionAnswering.__init__": 1625
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/xlm_roberta/modeling_xlm_roberta.py": [
        {
            "transformers.models.xlm_roberta.modeling_xlm_roberta.XLMRobertaEncoder.custom_forward": 513
        },
        {
            "transformers.models.xlm_roberta.modeling_xlm_roberta.XLMRobertaForCausalLM.prepare_inputs_for_generation": 1018
        },
        {
            "transformers.models.xlm_roberta.modeling_xlm_roberta.XLMRobertaLMHead.forward": 1151
        },
        {
            "transformers.models.xlm_roberta.modeling_xlm_roberta.XLMRobertaClassificationHead.forward": 1465
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/xlm_roberta/configuration_xlm_roberta.py": [
        {
            "transformers.models.xlm_roberta.configuration_xlm_roberta.XLMRobertaConfig.__init__": 115
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/xlm_roberta/modeling_flax_xlm_roberta.py": [
        {
            "transformers.models.xlm_roberta.modeling_flax_xlm_roberta.FlaxXLMRobertaPreTrainedModel.__init__": 747
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/xlm_roberta/tokenization_xlm_roberta_fast.py": [
        {
            "transformers.models.xlm_roberta.tokenization_xlm_roberta_fast.XLMRobertaTokenizerFast.__init__": 139
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/gpt2/configuration_gpt2.py": [
        {
            "transformers.models.gpt2.configuration_gpt2.GPT2Config.__init__": 141
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/gpt2/tokenization_gpt2.py": [
        {
            "transformers.models.gpt2.tokenization_gpt2.GPT2Tokenizer.__init__": 157
        },
        {
            "transformers.models.gpt2.tokenization_gpt2.GPT2Tokenizer.prepare_for_tokenization": 349
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/gpt2/tokenization_gpt2_fast.py": [
        {
            "transformers.models.gpt2.tokenization_gpt2_fast.GPT2TokenizerFast.__init__": 127
        },
        {
            "transformers.models.gpt2.tokenization_gpt2_fast.GPT2TokenizerFast._batch_encode_plus": 159
        },
        {
            "transformers.models.gpt2.tokenization_gpt2_fast.GPT2TokenizerFast._encode_plus": 168
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/gpt2/modeling_tf_gpt2.py": [
        {
            "transformers.models.gpt2.modeling_tf_gpt2.TFAttention.__init__": 71
        },
        {
            "transformers.models.gpt2.modeling_tf_gpt2.TFMLP.__init__": 208
        },
        {
            "transformers.models.gpt2.modeling_tf_gpt2.TFBlock.__init__": 224
        },
        {
            "transformers.models.gpt2.modeling_tf_gpt2.TFGPT2MainLayer.__init__": 306
        },
        {
            "transformers.models.gpt2.modeling_tf_gpt2.TFGPT2Model.__init__": 721
        },
        {
            "transformers.models.gpt2.modeling_tf_gpt2.TFGPT2LMHeadModel.__init__": 818
        },
        {
            "transformers.models.gpt2.modeling_tf_gpt2.TFGPT2LMHeadModel.prepare_inputs_for_generation": 828
        },
        {
            "transformers.models.gpt2.modeling_tf_gpt2.TFGPT2DoubleHeadsModel.__init__": 968
        },
        {
            "transformers.models.gpt2.modeling_tf_gpt2.TFGPT2ForSequenceClassification.__init__": 1116
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/gpt2/modeling_flax_gpt2.py": [
        {
            "transformers.models.gpt2.modeling_flax_gpt2.FlaxGPT2PreTrainedModel.__init__": 391
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/gpt2/modeling_gpt2.py": [
        {
            "transformers.models.gpt2.modeling_gpt2.GPT2PreTrainedModel.__init__": 450
        },
        {
            "transformers.models.gpt2.modeling_gpt2.GPT2Model.custom_forward": 871
        },
        {
            "transformers.models.gpt2.modeling_gpt2.GPT2LMHeadModel.prepare_inputs_for_generation": 984
        },
        {
            "transformers.models.gpt2.modeling_gpt2.GPT2DoubleHeadsModel.prepare_inputs_for_generation": 1156
        },
        {
            "transformers.models.gpt2.modeling_gpt2.GPT2DoubleHeadsModel.forward": 1187
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/gpt2/tokenization_gpt2_tf.py": [
        {
            "transformers.models.gpt2.tokenization_gpt2_tf.TFGPT2Tokenizer.from_tokenizer": 37
        },
        {
            "transformers.models.gpt2.tokenization_gpt2_tf.TFGPT2Tokenizer.from_pretrained": 57
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/funnel/modeling_tf_funnel.py": [
        {
            "transformers.models.funnel.modeling_tf_funnel.TFFunnelEmbeddings.__init__": 81
        },
        {
            "transformers.models.funnel.modeling_tf_funnel.TFFunnelRelMultiheadAttention.__init__": 392
        },
        {
            "transformers.models.funnel.modeling_tf_funnel.TFFunnelPositionwiseFFN.__init__": 557
        },
        {
            "transformers.models.funnel.modeling_tf_funnel.TFFunnelLayer.__init__": 577
        },
        {
            "transformers.models.funnel.modeling_tf_funnel.TFFunnelEncoder.__init__": 591
        },
        {
            "transformers.models.funnel.modeling_tf_funnel.TFFunnelDecoder.__init__": 681
        },
        {
            "transformers.models.funnel.modeling_tf_funnel.TFFunnelBaseLayer.__init__": 741
        },
        {
            "transformers.models.funnel.modeling_tf_funnel.TFFunnelMainLayer.__init__": 812
        },
        {
            "transformers.models.funnel.modeling_tf_funnel.TFFunnelDiscriminatorPredictions.__init__": 909
        },
        {
            "transformers.models.funnel.modeling_tf_funnel.TFFunnelMaskedLMHead.__init__": 924
        },
        {
            "transformers.models.funnel.modeling_tf_funnel.TFFunnelClassificationHead.__init__": 960
        },
        {
            "transformers.models.funnel.modeling_tf_funnel.TFFunnelBaseModel.__init__": 1110
        },
        {
            "transformers.models.funnel.modeling_tf_funnel.TFFunnelModel.__init__": 1158
        },
        {
            "transformers.models.funnel.modeling_tf_funnel.TFFunnelForPreTraining.__init__": 1209
        },
        {
            "transformers.models.funnel.modeling_tf_funnel.TFFunnelForPreTraining.call": 1218
        },
        {
            "transformers.models.funnel.modeling_tf_funnel.TFFunnelForMaskedLM.__init__": 1277
        },
        {
            "transformers.models.funnel.modeling_tf_funnel.TFFunnelForSequenceClassification.__init__": 1355
        },
        {
            "transformers.models.funnel.modeling_tf_funnel.TFFunnelForMultipleChoice.__init__": 1430
        },
        {
            "transformers.models.funnel.modeling_tf_funnel.TFFunnelForTokenClassification.__init__": 1545
        },
        {
            "transformers.models.funnel.modeling_tf_funnel.TFFunnelForQuestionAnswering.__init__": 1622
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/funnel/tokenization_funnel_fast.py": [
        {
            "transformers.models.funnel.tokenization_funnel_fast.FunnelTokenizerFast.__init__": 145
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/funnel/configuration_funnel.py": [
        {
            "transformers.models.funnel.configuration_funnel.FunnelConfig.__init__": 107
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/funnel/tokenization_funnel.py": [
        {
            "transformers.models.funnel.tokenization_funnel.FunnelTokenizer.__init__": 143
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/pegasus_x/configuration_pegasus_x.py": [
        {
            "transformers.models.pegasus_x.configuration_pegasus_x.PegasusXConfig.__init__": 112
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/pegasus_x/modeling_pegasus_x.py": [
        {
            "transformers.models.pegasus_x.modeling_pegasus_x.PegasusXEncoder.custom_forward": 1068
        },
        {
            "transformers.models.pegasus_x.modeling_pegasus_x.PegasusXDecoder.custom_forward": 1321
        },
        {
            "transformers.models.pegasus_x.modeling_pegasus_x.PegasusXForConditionalGeneration.prepare_inputs_for_generation": 1660
        },
        {
            "transformers.models.pegasus_x.modeling_pegasus_x.PegasusXDecoderWrapper.forward": 1707
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/deberta/configuration_deberta.py": [
        {
            "transformers.models.deberta.configuration_deberta.DebertaConfig.__init__": 110
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/deberta/tokenization_deberta_fast.py": [
        {
            "transformers.models.deberta.tokenization_deberta_fast.DebertaTokenizerFast.__init__": 143
        },
        {
            "transformers.models.deberta.tokenization_deberta_fast.DebertaTokenizerFast._batch_encode_plus": 266
        },
        {
            "transformers.models.deberta.tokenization_deberta_fast.DebertaTokenizerFast._encode_plus": 276
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/deberta/tokenization_deberta.py": [
        {
            "transformers.models.deberta.tokenization_deberta.DebertaTokenizer.__init__": 180
        },
        {
            "transformers.models.deberta.tokenization_deberta.DebertaTokenizer.prepare_for_tokenization": 429
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/deberta/modeling_deberta.py": [
        {
            "transformers.models.deberta.modeling_deberta.DebertaEncoder.custom_forward": 464
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/deberta/modeling_tf_deberta.py": [
        {
            "transformers.models.deberta.modeling_tf_deberta.TFDebertaContextPooler.__init__": 60
        },
        {
            "transformers.models.deberta.modeling_tf_deberta.TFDebertaXSoftmax.__init__": 90
        },
        {
            "transformers.models.deberta.modeling_tf_deberta.TFDebertaStableDropout.__init__": 111
        },
        {
            "transformers.models.deberta.modeling_tf_deberta.TFDebertaLayerNorm.__init__": 146
        },
        {
            "transformers.models.deberta.modeling_tf_deberta.TFDebertaSelfOutput.__init__": 164
        },
        {
            "transformers.models.deberta.modeling_tf_deberta.TFDebertaAttention.__init__": 178
        },
        {
            "transformers.models.deberta.modeling_tf_deberta.TFDebertaIntermediate.__init__": 215
        },
        {
            "transformers.models.deberta.modeling_tf_deberta.TFDebertaOutput.__init__": 235
        },
        {
            "transformers.models.deberta.modeling_tf_deberta.TFDebertaLayer.__init__": 253
        },
        {
            "transformers.models.deberta.modeling_tf_deberta.TFDebertaEncoder.__init__": 290
        },
        {
            "transformers.models.deberta.modeling_tf_deberta.TFDebertaDisentangledSelfAttention.__init__": 476
        },
        {
            "transformers.models.deberta.modeling_tf_deberta.TFDebertaEmbeddings.__init__": 721
        },
        {
            "transformers.models.deberta.modeling_tf_deberta.TFDebertaPredictionHeadTransform.__init__": 831
        },
        {
            "transformers.models.deberta.modeling_tf_deberta.TFDebertaLMPredictionHead.__init__": 855
        },
        {
            "transformers.models.deberta.modeling_tf_deberta.TFDebertaOnlyMLMHead.__init__": 898
        },
        {
            "transformers.models.deberta.modeling_tf_deberta.TFDebertaMainLayer.__init__": 912
        },
        {
            "transformers.models.deberta.modeling_tf_deberta.TFDebertaModel.__init__": 1094
        },
        {
            "transformers.models.deberta.modeling_tf_deberta.TFDebertaForMaskedLM.__init__": 1141
        },
        {
            "transformers.models.deberta.modeling_tf_deberta.TFDebertaForSequenceClassification.__init__": 1223
        },
        {
            "transformers.models.deberta.modeling_tf_deberta.TFDebertaForTokenClassification.__init__": 1310
        },
        {
            "transformers.models.deberta.modeling_tf_deberta.TFDebertaForQuestionAnswering.__init__": 1387
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/qdqbert/configuration_qdqbert.py": [
        {
            "transformers.models.qdqbert.configuration_qdqbert.QDQBertConfig.__init__": 90
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/qdqbert/modeling_qdqbert.py": [
        {
            "transformers.models.qdqbert.modeling_qdqbert.QDQBertEncoder.custom_forward": 585
        },
        {
            "transformers.models.qdqbert.modeling_qdqbert.QDQBertLMHeadModel.prepare_inputs_for_generation": 1143
        },
        {
            "transformers.models.qdqbert.modeling_qdqbert.QDQBertForMaskedLM.prepare_inputs_for_generation": 1258
        },
        {
            "transformers.models.qdqbert.modeling_qdqbert.QDQBertForNextSentencePrediction.forward": 1293
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/mvp/tokenization_mvp_fast.py": [
        {
            "transformers.models.mvp.tokenization_mvp_fast.MvpTokenizerFast.__init__": 137
        },
        {
            "transformers.models.mvp.tokenization_mvp_fast.MvpTokenizerFast._batch_encode_plus": 233
        },
        {
            "transformers.models.mvp.tokenization_mvp_fast.MvpTokenizerFast._encode_plus": 244
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/mvp/modeling_mvp.py": [
        {
            "transformers.models.mvp.modeling_mvp.MvpEncoder.custom_forward": 949
        },
        {
            "transformers.models.mvp.modeling_mvp.MvpDecoder.custom_forward": 1222
        },
        {
            "transformers.models.mvp.modeling_mvp.MvpForConditionalGeneration.prepare_inputs_for_generation": 1553
        },
        {
            "transformers.models.mvp.modeling_mvp.MvpForSequenceClassification.__init__": 1606
        },
        {
            "transformers.models.mvp.modeling_mvp.MvpDecoderWrapper.forward": 1857
        },
        {
            "transformers.models.mvp.modeling_mvp.MvpForCausalLM.prepare_inputs_for_generation": 2041
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/mvp/tokenization_mvp.py": [
        {
            "transformers.models.mvp.tokenization_mvp.MvpTokenizer.__init__": 170
        },
        {
            "transformers.models.mvp.tokenization_mvp.MvpTokenizer.prepare_for_tokenization": 400
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/mvp/configuration_mvp.py": [
        {
            "transformers.models.mvp.configuration_mvp.MvpConfig.__init__": 111
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/layoutxlm/processing_layoutxlm.py": [
        {
            "transformers.models.layoutxlm.processing_layoutxlm.LayoutXLMProcessor.__call__": 47
        },
        {
            "transformers.models.layoutxlm.processing_layoutxlm.LayoutXLMProcessor.batch_decode": 148
        },
        {
            "transformers.models.layoutxlm.processing_layoutxlm.LayoutXLMProcessor.decode": 155
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/layoutxlm/tokenization_layoutxlm_fast.py": [
        {
            "transformers.models.layoutxlm.tokenization_layoutxlm_fast.LayoutXLMTokenizerFast.__init__": 220
        },
        {
            "transformers.models.layoutxlm.tokenization_layoutxlm_fast.LayoutXLMTokenizerFast.__call__": 270
        },
        {
            "transformers.models.layoutxlm.tokenization_layoutxlm_fast.LayoutXLMTokenizerFast.tokenize": 417
        },
        {
            "transformers.models.layoutxlm.tokenization_layoutxlm_fast.LayoutXLMTokenizerFast._batch_encode_plus": 425
        },
        {
            "transformers.models.layoutxlm.tokenization_layoutxlm_fast.LayoutXLMTokenizerFast._encode_plus": 583
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/layoutxlm/tokenization_layoutxlm.py": [
        {
            "transformers.models.layoutxlm.tokenization_layoutxlm.LayoutXLMTokenizer.__init__": 234
        },
        {
            "transformers.models.layoutxlm.tokenization_layoutxlm.LayoutXLMTokenizer.__call__": 445
        },
        {
            "transformers.models.layoutxlm.tokenization_layoutxlm.LayoutXLMTokenizer._batch_encode_plus": 592
        },
        {
            "transformers.models.layoutxlm.tokenization_layoutxlm.LayoutXLMTokenizer._encode_plus": 719
        },
        {
            "transformers.models.layoutxlm.tokenization_layoutxlm.LayoutXLMTokenizer.prepare_for_model": 772
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/maskformer/configuration_maskformer.py": [
        {
            "transformers.models.maskformer.configuration_maskformer.MaskFormerConfig.__init__": 103
        },
        {
            "transformers.models.maskformer.configuration_maskformer.MaskFormerConfig.from_backbone_and_decoder_configs": 184
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/maskformer/modeling_maskformer.py": [
        {
            "transformers.models.maskformer.modeling_maskformer.DetrDecoder.custom_forward": 778
        },
        {
            "transformers.models.maskformer.modeling_maskformer.MaskFormerPixelDecoder.__init__": 1244
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/maskformer/feature_extraction_maskformer.py": [
        {
            "transformers.models.maskformer.feature_extraction_maskformer.MaskFormerFeatureExtractor.__init__": 28
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/maskformer/modeling_maskformer_swin.py": [
        {
            "transformers.models.maskformer.modeling_maskformer_swin.MaskFormerSwinEncoder.custom_forward": 692
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/maskformer/configuration_maskformer_swin.py": [
        {
            "transformers.models.maskformer.configuration_maskformer_swin.MaskFormerSwinConfig.__init__": 96
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/maskformer/image_processing_maskformer.py": [
        {
            "transformers.models.maskformer.image_processing_maskformer.MaskFormerImageProcessor.__init__": 385
        },
        {
            "transformers.models.maskformer.image_processing_maskformer.MaskFormerImageProcessor.from_dict": 443
        },
        {
            "transformers.models.maskformer.image_processing_maskformer.MaskFormerImageProcessor.resize": 482
        },
        {
            "transformers.models.maskformer.image_processing_maskformer.MaskFormerImageProcessor.convert_segmentation_map_to_binary_masks": 545
        },
        {
            "transformers.models.maskformer.image_processing_maskformer.MaskFormerImageProcessor.__call__": 562
        },
        {
            "transformers.models.maskformer.image_processing_maskformer.MaskFormerImageProcessor.preprocess": 650
        },
        {
            "transformers.models.maskformer.image_processing_maskformer.MaskFormerImageProcessor.encode_inputs": 815
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/vision_text_dual_encoder/modeling_flax_vision_text_dual_encoder.py": [
        {
            "transformers.models.vision_text_dual_encoder.modeling_flax_vision_text_dual_encoder.FlaxVisionTextDualEncoderModel.__init__": 223
        },
        {
            "transformers.models.vision_text_dual_encoder.modeling_flax_vision_text_dual_encoder.FlaxVisionTextDualEncoderModel.from_vision_text_pretrained": 416
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/vision_text_dual_encoder/modeling_vision_text_dual_encoder.py": [
        {
            "transformers.models.vision_text_dual_encoder.modeling_vision_text_dual_encoder.VisionTextDualEncoderModel.from_pretrained": 409
        },
        {
            "transformers.models.vision_text_dual_encoder.modeling_vision_text_dual_encoder.VisionTextDualEncoderModel.from_vision_text_pretrained": 416
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/vision_text_dual_encoder/processing_vision_text_dual_encoder.py": [
        {
            "transformers.models.vision_text_dual_encoder.processing_vision_text_dual_encoder.VisionTextDualEncoderProcessor.__init__": 44
        },
        {
            "transformers.models.vision_text_dual_encoder.processing_vision_text_dual_encoder.VisionTextDualEncoderProcessor.__call__": 62
        },
        {
            "transformers.models.vision_text_dual_encoder.processing_vision_text_dual_encoder.VisionTextDualEncoderProcessor.batch_decode": 115
        },
        {
            "transformers.models.vision_text_dual_encoder.processing_vision_text_dual_encoder.VisionTextDualEncoderProcessor.decode": 122
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/vision_text_dual_encoder/configuration_vision_text_dual_encoder.py": [
        {
            "transformers.models.vision_text_dual_encoder.configuration_vision_text_dual_encoder.VisionTextDualEncoderConfig.__init__": 78
        },
        {
            "transformers.models.vision_text_dual_encoder.configuration_vision_text_dual_encoder.VisionTextDualEncoderConfig.from_vision_text_configs": 106
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/prophetnet/configuration_prophetnet.py": [
        {
            "transformers.models.prophetnet.configuration_prophetnet.ProphetNetConfig.__init__": 107
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/prophetnet/modeling_prophetnet.py": [
        {
            "transformers.models.prophetnet.modeling_prophetnet.ProphetNetEncoder.custom_forward": 1362
        },
        {
            "transformers.models.prophetnet.modeling_prophetnet.ProphetNetDecoder.custom_forward": 1600
        },
        {
            "transformers.models.prophetnet.modeling_prophetnet.ProphetNetForConditionalGeneration.prepare_inputs_for_generation": 2061
        },
        {
            "transformers.models.prophetnet.modeling_prophetnet.ProphetNetForCausalLM.prepare_inputs_for_generation": 2315
        },
        {
            "transformers.models.prophetnet.modeling_prophetnet.ProphetNetDecoderWrapper.forward": 2358
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/prophetnet/tokenization_prophetnet.py": [
        {
            "transformers.models.prophetnet.tokenization_prophetnet.ProphetNetTokenizer.__init__": 330
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/mobilebert/modeling_tf_mobilebert.py": [
        {
            "transformers.models.mobilebert.modeling_tf_mobilebert.TFMobileBertIntermediate.__init__": 122
        },
        {
            "transformers.models.mobilebert.modeling_tf_mobilebert.TFLayerNorm.__init__": 140
        },
        {
            "transformers.models.mobilebert.modeling_tf_mobilebert.TFNoNorm.__init__": 145
        },
        {
            "transformers.models.mobilebert.modeling_tf_mobilebert.TFMobileBertEmbeddings.__init__": 163
        },
        {
            "transformers.models.mobilebert.modeling_tf_mobilebert.TFMobileBertSelfAttention.__init__": 265
        },
        {
            "transformers.models.mobilebert.modeling_tf_mobilebert.TFMobileBertSelfOutput.__init__": 343
        },
        {
            "transformers.models.mobilebert.modeling_tf_mobilebert.TFMobileBertAttention.__init__": 364
        },
        {
            "transformers.models.mobilebert.modeling_tf_mobilebert.TFOutputBottleneck.__init__": 393
        },
        {
            "transformers.models.mobilebert.modeling_tf_mobilebert.TFMobileBertOutput.__init__": 409
        },
        {
            "transformers.models.mobilebert.modeling_tf_mobilebert.TFBottleneckLayer.__init__": 435
        },
        {
            "transformers.models.mobilebert.modeling_tf_mobilebert.TFBottleneck.__init__": 449
        },
        {
            "transformers.models.mobilebert.modeling_tf_mobilebert.TFFFNOutput.__init__": 485
        },
        {
            "transformers.models.mobilebert.modeling_tf_mobilebert.TFFFNLayer.__init__": 499
        },
        {
            "transformers.models.mobilebert.modeling_tf_mobilebert.TFMobileBertLayer.__init__": 511
        },
        {
            "transformers.models.mobilebert.modeling_tf_mobilebert.TFMobileBertEncoder.__init__": 571
        },
        {
            "transformers.models.mobilebert.modeling_tf_mobilebert.TFMobileBertPooler.__init__": 614
        },
        {
            "transformers.models.mobilebert.modeling_tf_mobilebert.TFMobileBertPredictionHeadTransform.__init__": 637
        },
        {
            "transformers.models.mobilebert.modeling_tf_mobilebert.TFMobileBertLMPredictionHead.__init__": 656
        },
        {
            "transformers.models.mobilebert.modeling_tf_mobilebert.TFMobileBertMLMHead.__init__": 699
        },
        {
            "transformers.models.mobilebert.modeling_tf_mobilebert.TFMobileBertMainLayer.__init__": 712
        },
        {
            "transformers.models.mobilebert.modeling_tf_mobilebert.TFMobileBertModel.__init__": 968
        },
        {
            "transformers.models.mobilebert.modeling_tf_mobilebert.TFMobileBertForPreTraining.__init__": 1027
        },
        {
            "transformers.models.mobilebert.modeling_tf_mobilebert.TFMobileBertForMaskedLM.__init__": 1129
        },
        {
            "transformers.models.mobilebert.modeling_tf_mobilebert.TFMobileBertOnlyNSPHead.__init__": 1208
        },
        {
            "transformers.models.mobilebert.modeling_tf_mobilebert.TFMobileBertForNextSentencePrediction.__init__": 1225
        },
        {
            "transformers.models.mobilebert.modeling_tf_mobilebert.TFMobileBertForSequenceClassification.__init__": 1323
        },
        {
            "transformers.models.mobilebert.modeling_tf_mobilebert.TFMobileBertForQuestionAnswering.__init__": 1420
        },
        {
            "transformers.models.mobilebert.modeling_tf_mobilebert.TFMobileBertForMultipleChoice.__init__": 1528
        },
        {
            "transformers.models.mobilebert.modeling_tf_mobilebert.TFMobileBertForTokenClassification.__init__": 1662
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/mobilebert/tokenization_mobilebert_fast.py": [
        {
            "transformers.models.mobilebert.tokenization_mobilebert_fast.MobileBertTokenizerFast.__init__": 92
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/mobilebert/modeling_mobilebert.py": [
        {
            "transformers.models.mobilebert.modeling_mobilebert.MobileBertForNextSentencePrediction.forward": 1155
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/mobilebert/configuration_mobilebert.py": [
        {
            "transformers.models.mobilebert.configuration_mobilebert.MobileBertConfig.__init__": 114
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/mobilebert/tokenization_mobilebert.py": [
        {
            "transformers.models.mobilebert.tokenization_mobilebert.MobileBertTokenizer.__init__": 112
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/mpnet/configuration_mpnet.py": [
        {
            "transformers.models.mpnet.configuration_mpnet.MPNetConfig.__init__": 84
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/mpnet/modeling_mpnet.py": [
        {
            "transformers.models.mpnet.modeling_mpnet.MPNetEmbeddings.forward": 88
        },
        {
            "transformers.models.mpnet.modeling_mpnet.MPNetSelfAttention.forward": 157
        },
        {
            "transformers.models.mpnet.modeling_mpnet.MPNetAttention.forward": 231
        },
        {
            "transformers.models.mpnet.modeling_mpnet.MPNetLayer.forward": 290
        },
        {
            "transformers.models.mpnet.modeling_mpnet.MPNetEncoder.forward": 323
        },
        {
            "transformers.models.mpnet.modeling_mpnet.MPNetModel.forward": 517
        },
        {
            "transformers.models.mpnet.modeling_mpnet.MPNetLMHead.forward": 664
        },
        {
            "transformers.models.mpnet.modeling_mpnet.MPNetClassificationHead.forward": 948
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/mpnet/tokenization_mpnet_fast.py": [
        {
            "transformers.models.mpnet.tokenization_mpnet_fast.MPNetTokenizerFast.__init__": 113
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/mpnet/modeling_tf_mpnet.py": [
        {
            "transformers.models.mpnet.modeling_tf_mpnet.TFMPNetEmbeddings.__init__": 95
        },
        {
            "transformers.models.mpnet.modeling_tf_mpnet.TFMPNetPooler.__init__": 180
        },
        {
            "transformers.models.mpnet.modeling_tf_mpnet.TFMPNetSelfAttention.__init__": 200
        },
        {
            "transformers.models.mpnet.modeling_tf_mpnet.TFMPNetAttention.__init__": 273
        },
        {
            "transformers.models.mpnet.modeling_tf_mpnet.TFMPNetIntermediate.__init__": 294
        },
        {
            "transformers.models.mpnet.modeling_tf_mpnet.TFMPNetOutput.__init__": 315
        },
        {
            "transformers.models.mpnet.modeling_tf_mpnet.TFMPNetLayer.__init__": 333
        },
        {
            "transformers.models.mpnet.modeling_tf_mpnet.TFMPNetEncoder.__init__": 355
        },
        {
            "transformers.models.mpnet.modeling_tf_mpnet.TFMPNetMainLayer.__init__": 469
        },
        {
            "transformers.models.mpnet.modeling_tf_mpnet.TFMPNetModel.__init__": 682
        },
        {
            "transformers.models.mpnet.modeling_tf_mpnet.TFMPNetLMHead.__init__": 733
        },
        {
            "transformers.models.mpnet.modeling_tf_mpnet.TFMPNetForMaskedLM.__init__": 787
        },
        {
            "transformers.models.mpnet.modeling_tf_mpnet.TFMPNetClassificationHead.__init__": 864
        },
        {
            "transformers.models.mpnet.modeling_tf_mpnet.TFMPNetForSequenceClassification.__init__": 897
        },
        {
            "transformers.models.mpnet.modeling_tf_mpnet.TFMPNetForMultipleChoice.__init__": 974
        },
        {
            "transformers.models.mpnet.modeling_tf_mpnet.TFMPNetForTokenClassification.__init__": 1093
        },
        {
            "transformers.models.mpnet.modeling_tf_mpnet.TFMPNetForQuestionAnswering.__init__": 1175
        },
        {
            "transformers.models.mpnet.modeling_tf_mpnet.TFMPNetForQuestionAnswering.call": 1191
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/mpnet/tokenization_mpnet.py": [
        {
            "transformers.models.mpnet.tokenization_mpnet.MPNetTokenizer.__init__": 133
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/camembert/modeling_tf_camembert.py": [
        {
            "transformers.models.camembert.modeling_tf_camembert.TFCamembertEmbeddings.__init__": 175
        },
        {
            "transformers.models.camembert.modeling_tf_camembert.TFCamembertPooler.__init__": 281
        },
        {
            "transformers.models.camembert.modeling_tf_camembert.TFCamembertSelfAttention.__init__": 302
        },
        {
            "transformers.models.camembert.modeling_tf_camembert.TFCamembertSelfOutput.__init__": 420
        },
        {
            "transformers.models.camembert.modeling_tf_camembert.TFCamembertAttention.__init__": 439
        },
        {
            "transformers.models.camembert.modeling_tf_camembert.TFCamembertIntermediate.__init__": 480
        },
        {
            "transformers.models.camembert.modeling_tf_camembert.TFCamembertOutput.__init__": 501
        },
        {
            "transformers.models.camembert.modeling_tf_camembert.TFCamembertLayer.__init__": 520
        },
        {
            "transformers.models.camembert.modeling_tf_camembert.TFCamembertEncoder.__init__": 607
        },
        {
            "transformers.models.camembert.modeling_tf_camembert.TFCamembertMainLayer.__init__": 680
        },
        {
            "transformers.models.camembert.modeling_tf_camembert.TFCamembertModel.__init__": 922
        },
        {
            "transformers.models.camembert.modeling_tf_camembert.TFCamembertLMHead.__init__": 1015
        },
        {
            "transformers.models.camembert.modeling_tf_camembert.TFCamembertForMaskedLM.__init__": 1073
        },
        {
            "transformers.models.camembert.modeling_tf_camembert.TFCamembertClassificationHead.__init__": 1157
        },
        {
            "transformers.models.camembert.modeling_tf_camembert.TFCamembertForSequenceClassification.__init__": 1194
        },
        {
            "transformers.models.camembert.modeling_tf_camembert.TFCamembertForTokenClassification.__init__": 1279
        },
        {
            "transformers.models.camembert.modeling_tf_camembert.TFCamembertForMultipleChoice.__init__": 1370
        },
        {
            "transformers.models.camembert.modeling_tf_camembert.TFCamembertForQuestionAnswering.__init__": 1492
        },
        {
            "transformers.models.camembert.modeling_tf_camembert.TFCamembertForCausalLM.__init__": 1590
        },
        {
            "transformers.models.camembert.modeling_tf_camembert.TFCamembertForCausalLM.prepare_inputs_for_generation": 1607
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/camembert/modeling_camembert.py": [
        {
            "transformers.models.camembert.modeling_camembert.CamembertEncoder.custom_forward": 526
        },
        {
            "transformers.models.camembert.modeling_camembert.CamembertClassificationHead.forward": 702
        },
        {
            "transformers.models.camembert.modeling_camembert.CamembertLMHead.forward": 725
        },
        {
            "transformers.models.camembert.modeling_camembert.CamembertForCausalLM.prepare_inputs_for_generation": 1555
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/camembert/configuration_camembert.py": [
        {
            "transformers.models.camembert.configuration_camembert.CamembertConfig.__init__": 109
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/camembert/tokenization_camembert_fast.py": [
        {
            "transformers.models.camembert.tokenization_camembert_fast.CamembertTokenizerFast.__init__": 111
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/camembert/tokenization_camembert.py": [
        {
            "transformers.models.camembert.tokenization_camembert.CamembertTokenizer.__init__": 120
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/ibert/configuration_ibert.py": [
        {
            "transformers.models.ibert.configuration_ibert.IBertConfig.__init__": 94
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/ibert/modeling_ibert.py": [
        {
            "transformers.models.ibert.modeling_ibert.IBertLMHead.forward": 948
        },
        {
            "transformers.models.ibert.modeling_ibert.IBertClassificationHead.forward": 1240
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/xglm/modeling_flax_xglm.py": [
        {
            "transformers.models.xglm.modeling_flax_xglm.FlaxXGLMPreTrainedModel.__init__": 558
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/xglm/modeling_tf_xglm.py": [
        {
            "transformers.models.xglm.modeling_tf_xglm.TFXGLMAttention.__init__": 154
        },
        {
            "transformers.models.xglm.modeling_tf_xglm.TFXGLMDecoderLayer.__init__": 305
        },
        {
            "transformers.models.xglm.modeling_tf_xglm.TFXGLMMainLayer.__init__": 422
        },
        {
            "transformers.models.xglm.modeling_tf_xglm.TFXGLMMainLayer.call": 496
        },
        {
            "transformers.models.xglm.modeling_tf_xglm.TFXGLMModel.__init__": 781
        },
        {
            "transformers.models.xglm.modeling_tf_xglm.TFXGLMModel.call": 795
        },
        {
            "transformers.models.xglm.modeling_tf_xglm.TFXGLMForCausalLM.__init__": 867
        },
        {
            "transformers.models.xglm.modeling_tf_xglm.TFXGLMForCausalLM.prepare_inputs_for_generation": 889
        },
        {
            "transformers.models.xglm.modeling_tf_xglm.TFXGLMForCausalLM.call": 911
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/xglm/configuration_xglm.py": [
        {
            "transformers.models.xglm.configuration_xglm.XGLMConfig.__init__": 97
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/xglm/tokenization_xglm.py": [
        {
            "transformers.models.xglm.tokenization_xglm.XGLMTokenizer.__init__": 117
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/xglm/tokenization_xglm_fast.py": [
        {
            "transformers.models.xglm.tokenization_xglm_fast.XGLMTokenizerFast.__init__": 103
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/xglm/modeling_xglm.py": [
        {
            "transformers.models.xglm.modeling_xglm.XGLMModel.custom_forward": 751
        },
        {
            "transformers.models.xglm.modeling_xglm.XGLMForCausalLM.prepare_inputs_for_generation": 929
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/audio_spectrogram_transformer/configuration_audio_spectrogram_transformer.py": [
        {
            "transformers.models.audio_spectrogram_transformer.configuration_audio_spectrogram_transformer.ASTConfig.__init__": 91
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/audio_spectrogram_transformer/feature_extraction_audio_spectrogram_transformer.py": [
        {
            "transformers.models.audio_spectrogram_transformer.feature_extraction_audio_spectrogram_transformer.ASTFeatureExtractor.__init__": 65
        },
        {
            "transformers.models.audio_spectrogram_transformer.feature_extraction_audio_spectrogram_transformer.ASTFeatureExtractor.__call__": 125
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/audio_spectrogram_transformer/modeling_audio_spectrogram_transformer.py": [
        {
            "transformers.models.audio_spectrogram_transformer.modeling_audio_spectrogram_transformer.ASTEncoder.custom_forward": 343
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/tapas/configuration_tapas.py": [
        {
            "transformers.models.tapas.configuration_tapas.TapasConfig.__init__": 157
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/tapas/tokenization_tapas.py": [
        {
            "transformers.models.tapas.tokenization_tapas.TapasTokenizer.__init__": 320
        },
        {
            "transformers.models.tapas.tokenization_tapas.TapasTokenizer.__call__": 577
        },
        {
            "transformers.models.tapas.tokenization_tapas.TapasTokenizer.batch_encode_plus": 694
        },
        {
            "transformers.models.tapas.tokenization_tapas.TapasTokenizer._batch_encode_plus": 803
        },
        {
            "transformers.models.tapas.tokenization_tapas.TapasTokenizer._batch_prepare_for_model": 860
        },
        {
            "transformers.models.tapas.tokenization_tapas.TapasTokenizer.encode": 932
        },
        {
            "transformers.models.tapas.tokenization_tapas.TapasTokenizer.encode_plus": 975
        },
        {
            "transformers.models.tapas.tokenization_tapas.TapasTokenizer._encode_plus": 1058
        },
        {
            "transformers.models.tapas.tokenization_tapas.TapasTokenizer.prepare_for_model": 1114
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/tapas/modeling_tf_tapas.py": [
        {
            "transformers.models.tapas.modeling_tf_tapas.TFTapasEmbeddings.__init__": 148
        },
        {
            "transformers.models.tapas.modeling_tf_tapas.TFTapasSelfAttention.__init__": 263
        },
        {
            "transformers.models.tapas.modeling_tf_tapas.TFTapasSelfOutput.__init__": 381
        },
        {
            "transformers.models.tapas.modeling_tf_tapas.TFTapasAttention.__init__": 400
        },
        {
            "transformers.models.tapas.modeling_tf_tapas.TFTapasIntermediate.__init__": 441
        },
        {
            "transformers.models.tapas.modeling_tf_tapas.TFTapasOutput.__init__": 462
        },
        {
            "transformers.models.tapas.modeling_tf_tapas.TFTapasLayer.__init__": 481
        },
        {
            "transformers.models.tapas.modeling_tf_tapas.TFTapasEncoder.__init__": 568
        },
        {
            "transformers.models.tapas.modeling_tf_tapas.TFTapasPooler.__init__": 638
        },
        {
            "transformers.models.tapas.modeling_tf_tapas.TFTapasPredictionHeadTransform.__init__": 659
        },
        {
            "transformers.models.tapas.modeling_tf_tapas.TFTapasLMPredictionHead.__init__": 685
        },
        {
            "transformers.models.tapas.modeling_tf_tapas.TFTapasMLMHead.__init__": 729
        },
        {
            "transformers.models.tapas.modeling_tf_tapas.TFTapasMainLayer.__init__": 744
        },
        {
            "transformers.models.tapas.modeling_tf_tapas.TFTapasModel.__init__": 988
        },
        {
            "transformers.models.tapas.modeling_tf_tapas.TFTapasForMaskedLM.__init__": 1063
        },
        {
            "transformers.models.tapas.modeling_tf_tapas.TFTapasComputeTokenLogits.__init__": 1164
        },
        {
            "transformers.models.tapas.modeling_tf_tapas.TFTapasComputeColumnLogits.__init__": 1200
        },
        {
            "transformers.models.tapas.modeling_tf_tapas.TFTapasForQuestionAnswering.__init__": 1269
        },
        {
            "transformers.models.tapas.modeling_tf_tapas.TFTapasForSequenceClassification.__init__": 1605
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/tapas/modeling_tapas.py": [
        {
            "transformers.models.tapas.modeling_tapas.TapasEncoder.custom_forward": 641
        },
        {
            "transformers.models.tapas.modeling_tapas.TapasForMaskedLM.forward": 1012
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/plbart/modeling_plbart.py": [
        {
            "transformers.models.plbart.modeling_plbart.PLBartEncoder.custom_forward": 806
        },
        {
            "transformers.models.plbart.modeling_plbart.PLBartDecoder.custom_forward": 1058
        },
        {
            "transformers.models.plbart.modeling_plbart.PLBartForConditionalGeneration.prepare_inputs_for_generation": 1364
        },
        {
            "transformers.models.plbart.modeling_plbart.PLBartForSequenceClassification.__init__": 1416
        },
        {
            "transformers.models.plbart.modeling_plbart.PLBartDecoderWrapper.forward": 1544
        },
        {
            "transformers.models.plbart.modeling_plbart.PLBartForCausalLM.prepare_inputs_for_generation": 1726
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/plbart/tokenization_plbart.py": [
        {
            "transformers.models.plbart.tokenization_plbart.PLBartTokenizer.__init__": 176
        },
        {
            "transformers.models.plbart.tokenization_plbart.PLBartTokenizer._build_translation_inputs": 384
        },
        {
            "transformers.models.plbart.tokenization_plbart.PLBartTokenizer.prepare_seq2seq_batch": 442
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/plbart/configuration_plbart.py": [
        {
            "transformers.models.plbart.configuration_plbart.PLBartConfig.__init__": 109
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/cvt/configuration_cvt.py": [
        {
            "transformers.models.cvt.configuration_cvt.CvtConfig.__init__": 101
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/cvt/modeling_tf_cvt.py": [
        {
            "transformers.models.cvt.modeling_tf_cvt.TFCvtDropPath.__init__": 87
        },
        {
            "transformers.models.cvt.modeling_tf_cvt.TFCvtEmbeddings.__init__": 104
        },
        {
            "transformers.models.cvt.modeling_tf_cvt.TFCvtConvEmbeddings.__init__": 134
        },
        {
            "transformers.models.cvt.modeling_tf_cvt.TFCvtSelfAttentionConvProjection.__init__": 170
        },
        {
            "transformers.models.cvt.modeling_tf_cvt.TFCvtSelfAttentionProjection.__init__": 206
        },
        {
            "transformers.models.cvt.modeling_tf_cvt.TFCvtSelfAttention.__init__": 235
        },
        {
            "transformers.models.cvt.modeling_tf_cvt.TFCvtSelfOutput.__init__": 353
        },
        {
            "transformers.models.cvt.modeling_tf_cvt.TFCvtAttention.__init__": 369
        },
        {
            "transformers.models.cvt.modeling_tf_cvt.TFCvtIntermediate.__init__": 416
        },
        {
            "transformers.models.cvt.modeling_tf_cvt.TFCvtOutput.__init__": 435
        },
        {
            "transformers.models.cvt.modeling_tf_cvt.TFCvtLayer.__init__": 456
        },
        {
            "transformers.models.cvt.modeling_tf_cvt.TFCvtStage.__init__": 534
        },
        {
            "transformers.models.cvt.modeling_tf_cvt.TFCvtEncoder.__init__": 616
        },
        {
            "transformers.models.cvt.modeling_tf_cvt.TFCvtMainLayer.__init__": 663
        },
        {
            "transformers.models.cvt.modeling_tf_cvt.TFCvtModel.__init__": 790
        },
        {
            "transformers.models.cvt.modeling_tf_cvt.TFCvtForImageClassification.__init__": 861
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/cvt/modeling_cvt.py": [
        {
            "transformers.models.cvt.modeling_cvt.CvtSelfAttention.__init__": 202
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/unispeech/modeling_unispeech.py": [
        {
            "transformers.models.unispeech.modeling_unispeech.UniSpeechFeatureEncoder.custom_forward": 386
        },
        {
            "transformers.models.unispeech.modeling_unispeech.UniSpeechEncoder.custom_forward": 735
        },
        {
            "transformers.models.unispeech.modeling_unispeech.UniSpeechEncoderStableLayerNorm.custom_forward": 825
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/unispeech/configuration_unispeech.py": [
        {
            "transformers.models.unispeech.configuration_unispeech.UniSpeechConfig.__init__": 180
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/oneformer/modeling_oneformer.py": [
        {
            "transformers.models.oneformer.modeling_oneformer.sample_point": 207
        },
        {
            "transformers.models.oneformer.modeling_oneformer.OneFormerTextContextDecoder.__init__": 2482
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/oneformer/image_processing_oneformer.py": [
        {
            "transformers.models.oneformer.image_processing_oneformer.OneFormerImageProcessor.__init__": 391
        },
        {
            "transformers.models.oneformer.image_processing_oneformer.OneFormerImageProcessor.resize": 440
        },
        {
            "transformers.models.oneformer.image_processing_oneformer.OneFormerImageProcessor.convert_segmentation_map_to_binary_masks": 504
        },
        {
            "transformers.models.oneformer.image_processing_oneformer.OneFormerImageProcessor.__call__": 521
        },
        {
            "transformers.models.oneformer.image_processing_oneformer.OneFormerImageProcessor.preprocess": 604
        },
        {
            "transformers.models.oneformer.image_processing_oneformer.OneFormerImageProcessor.encode_inputs": 871
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/oneformer/configuration_oneformer.py": [
        {
            "transformers.models.oneformer.configuration_oneformer.OneFormerConfig.__init__": 146
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/oneformer/processing_oneformer.py": [
        {
            "transformers.models.oneformer.processing_oneformer.OneFormerProcessor.__init__": 50
        },
        {
            "transformers.models.oneformer.processing_oneformer.OneFormerProcessor.__call__": 79
        },
        {
            "transformers.models.oneformer.processing_oneformer.OneFormerProcessor.encode_inputs": 146
        },
        {
            "transformers.models.oneformer.processing_oneformer.OneFormerProcessor.post_process_semantic_segmentation": 186
        },
        {
            "transformers.models.oneformer.processing_oneformer.OneFormerProcessor.post_process_instance_segmentation": 193
        },
        {
            "transformers.models.oneformer.processing_oneformer.OneFormerProcessor.post_process_panoptic_segmentation": 200
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/trajectory_transformer/configuration_trajectory_transformer.py": [
        {
            "transformers.models.trajectory_transformer.configuration_trajectory_transformer.TrajectoryTransformerConfig.__init__": 113
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/trajectory_transformer/modeling_trajectory_transformer.py": [
        {
            "transformers.models.trajectory_transformer.modeling_trajectory_transformer.TrajectoryTransformerModel.custom_forward": 553
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/levit/image_processing_levit.py": [
        {
            "transformers.models.levit.image_processing_levit.LevitImageProcessor.__init__": 90
        },
        {
            "transformers.models.levit.image_processing_levit.LevitImageProcessor.resize": 121
        },
        {
            "transformers.models.levit.image_processing_levit.LevitImageProcessor.center_crop": 166
        },
        {
            "transformers.models.levit.image_processing_levit.LevitImageProcessor.rescale": 189
        },
        {
            "transformers.models.levit.image_processing_levit.LevitImageProcessor.normalize": 209
        },
        {
            "transformers.models.levit.image_processing_levit.LevitImageProcessor.preprocess": 232
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/levit/configuration_levit.py": [
        {
            "transformers.models.levit.configuration_levit.LevitConfig.__init__": 92
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/levit/feature_extraction_levit.py": [
        {
            "transformers.models.levit.feature_extraction_levit.LevitFeatureExtractor.__init__": 27
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/whisper/modeling_whisper.py": [
        {
            "transformers.models.whisper.modeling_whisper.WhisperEncoder.custom_forward": 682
        },
        {
            "transformers.models.whisper.modeling_whisper.WhisperDecoder.custom_forward": 908
        },
        {
            "transformers.models.whisper.modeling_whisper.WhisperForConditionalGeneration.prepare_inputs_for_generation": 1234
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/whisper/feature_extraction_whisper.py": [
        {
            "transformers.models.whisper.feature_extraction_whisper.WhisperFeatureExtractor.__init__": 60
        },
        {
            "transformers.models.whisper.feature_extraction_whisper.WhisperFeatureExtractor.__call__": 218
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/whisper/modeling_tf_whisper.py": [
        {
            "transformers.models.whisper.modeling_tf_whisper.TFWhisperPositionalEmbedding.__init__": 115
        },
        {
            "transformers.models.whisper.modeling_tf_whisper.TFWhisperAttention.__init__": 138
        },
        {
            "transformers.models.whisper.modeling_tf_whisper.TFWhisperEncoderLayer.__init__": 292
        },
        {
            "transformers.models.whisper.modeling_tf_whisper.TFWhisperDecoderLayer.__init__": 348
        },
        {
            "transformers.models.whisper.modeling_tf_whisper.TFWhisperEncoder.__init__": 607
        },
        {
            "transformers.models.whisper.modeling_tf_whisper.TFWhisperDecoder.__init__": 737
        },
        {
            "transformers.models.whisper.modeling_tf_whisper.TFWhisperMainLayer.__init__": 983
        },
        {
            "transformers.models.whisper.modeling_tf_whisper.TFWhisperModel.__init__": 1103
        },
        {
            "transformers.models.whisper.modeling_tf_whisper.TFWhisperForConditionalGeneration.__init__": 1221
        },
        {
            "transformers.models.whisper.modeling_tf_whisper.TFWhisperForConditionalGeneration.prepare_inputs_for_generation": 1358
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/whisper/tokenization_whisper.py": [
        {
            "transformers.models.whisper.tokenization_whisper.WhisperTokenizer.__init__": 258
        },
        {
            "transformers.models.whisper.tokenization_whisper.WhisperTokenizer.decode": 540
        },
        {
            "transformers.models.whisper.tokenization_whisper.WhisperTokenizer._decode": 581
        },
        {
            "transformers.models.whisper.tokenization_whisper.WhisperTokenizer.prepare_for_tokenization": 660
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/whisper/configuration_whisper.py": [
        {
            "transformers.models.whisper.configuration_whisper.WhisperConfig.__init__": 161
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/whisper/processing_whisper.py": [
        {
            "transformers.models.whisper.processing_whisper.WhisperProcessor.__call__": 47
        },
        {
            "transformers.models.whisper.processing_whisper.WhisperProcessor.batch_decode": 81
        },
        {
            "transformers.models.whisper.processing_whisper.WhisperProcessor.decode": 88
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/gpt_sw3/tokenization_gpt_sw3.py": [
        {
            "transformers.models.gpt_sw3.tokenization_gpt_sw3.GPTSw3Tokenizer.__init__": 107
        },
        {
            "transformers.models.gpt_sw3.tokenization_gpt_sw3.GPTSw3Tokenizer._tokenize": 208
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/speech_to_text_2/processing_speech_to_text_2.py": [
        {
            "transformers.models.speech_to_text_2.processing_speech_to_text_2.Speech2Text2Processor.__call__": 46
        },
        {
            "transformers.models.speech_to_text_2.processing_speech_to_text_2.Speech2Text2Processor.batch_decode": 85
        },
        {
            "transformers.models.speech_to_text_2.processing_speech_to_text_2.Speech2Text2Processor.decode": 92
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/speech_to_text_2/modeling_speech_to_text_2.py": [
        {
            "transformers.models.speech_to_text_2.modeling_speech_to_text_2.Speech2Text2Decoder.custom_forward": 669
        },
        {
            "transformers.models.speech_to_text_2.modeling_speech_to_text_2.Speech2Text2DecoderWrapper.forward": 745
        },
        {
            "transformers.models.speech_to_text_2.modeling_speech_to_text_2.Speech2Text2ForCausalLM.prepare_inputs_for_generation": 954
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/speech_to_text_2/configuration_speech_to_text_2.py": [
        {
            "transformers.models.speech_to_text_2.configuration_speech_to_text_2.Speech2Text2Config.__init__": 93
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/speech_to_text_2/tokenization_speech_to_text_2.py": [
        {
            "transformers.models.speech_to_text_2.tokenization_speech_to_text_2.Speech2Text2Tokenizer.__init__": 102
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/convnext/configuration_convnext.py": [
        {
            "transformers.models.convnext.configuration_convnext.ConvNextConfig.__init__": 86
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/convnext/feature_extraction_convnext.py": [
        {
            "transformers.models.convnext.feature_extraction_convnext.ConvNextFeatureExtractor.__init__": 27
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/convnext/modeling_tf_convnext.py": [
        {
            "transformers.models.convnext.modeling_tf_convnext.TFConvNextDropPath.__init__": 52
        },
        {
            "transformers.models.convnext.modeling_tf_convnext.TFConvNextEmbeddings.__init__": 71
        },
        {
            "transformers.models.convnext.modeling_tf_convnext.TFConvNextLayer.__init__": 119
        },
        {
            "transformers.models.convnext.modeling_tf_convnext.TFConvNextStage.__init__": 197
        },
        {
            "transformers.models.convnext.modeling_tf_convnext.TFConvNextEncoder.__init__": 244
        },
        {
            "transformers.models.convnext.modeling_tf_convnext.TFConvNextMainLayer.__init__": 287
        },
        {
            "transformers.models.convnext.modeling_tf_convnext.TFConvNextModel.__init__": 453
        },
        {
            "transformers.models.convnext.modeling_tf_convnext.TFConvNextForImageClassification.__init__": 528
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/convnext/image_processing_convnext.py": [
        {
            "transformers.models.convnext.image_processing_convnext.ConvNextImageProcessor.__init__": 91
        },
        {
            "transformers.models.convnext.image_processing_convnext.ConvNextImageProcessor.resize": 119
        },
        {
            "transformers.models.convnext.image_processing_convnext.ConvNextImageProcessor.rescale": 164
        },
        {
            "transformers.models.convnext.image_processing_convnext.ConvNextImageProcessor.normalize": 184
        },
        {
            "transformers.models.convnext.image_processing_convnext.ConvNextImageProcessor.preprocess": 207
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/deberta_v2/configuration_deberta_v2.py": [
        {
            "transformers.models.deberta_v2.configuration_deberta_v2.DebertaV2Config.__init__": 112
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/deberta_v2/modeling_tf_deberta_v2.py": [
        {
            "transformers.models.deberta_v2.modeling_tf_deberta_v2.TFDebertaV2ContextPooler.__init__": 60
        },
        {
            "transformers.models.deberta_v2.modeling_tf_deberta_v2.TFDebertaV2XSoftmax.__init__": 91
        },
        {
            "transformers.models.deberta_v2.modeling_tf_deberta_v2.TFDebertaV2StableDropout.__init__": 113
        },
        {
            "transformers.models.deberta_v2.modeling_tf_deberta_v2.TFDebertaV2SelfOutput.__init__": 147
        },
        {
            "transformers.models.deberta_v2.modeling_tf_deberta_v2.TFDebertaV2Attention.__init__": 162
        },
        {
            "transformers.models.deberta_v2.modeling_tf_deberta_v2.TFDebertaV2Intermediate.__init__": 200
        },
        {
            "transformers.models.deberta_v2.modeling_tf_deberta_v2.TFDebertaV2Output.__init__": 221
        },
        {
            "transformers.models.deberta_v2.modeling_tf_deberta_v2.TFDebertaV2Layer.__init__": 240
        },
        {
            "transformers.models.deberta_v2.modeling_tf_deberta_v2.TFDebertaV2ConvLayer.__init__": 277
        },
        {
            "transformers.models.deberta_v2.modeling_tf_deberta_v2.TFDebertaV2Encoder.__init__": 332
        },
        {
            "transformers.models.deberta_v2.modeling_tf_deberta_v2.TFDebertaV2DisentangledSelfAttention.__init__": 553
        },
        {
            "transformers.models.deberta_v2.modeling_tf_deberta_v2.TFDebertaV2Embeddings.__init__": 810
        },
        {
            "transformers.models.deberta_v2.modeling_tf_deberta_v2.TFDebertaV2PredictionHeadTransform.__init__": 921
        },
        {
            "transformers.models.deberta_v2.modeling_tf_deberta_v2.TFDebertaV2LMPredictionHead.__init__": 946
        },
        {
            "transformers.models.deberta_v2.modeling_tf_deberta_v2.TFDebertaV2OnlyMLMHead.__init__": 990
        },
        {
            "transformers.models.deberta_v2.modeling_tf_deberta_v2.TFDebertaV2MainLayer.__init__": 1004
        },
        {
            "transformers.models.deberta_v2.modeling_tf_deberta_v2.TFDebertaV2Model.__init__": 1188
        },
        {
            "transformers.models.deberta_v2.modeling_tf_deberta_v2.TFDebertaV2ForMaskedLM.__init__": 1236
        },
        {
            "transformers.models.deberta_v2.modeling_tf_deberta_v2.TFDebertaV2ForSequenceClassification.__init__": 1319
        },
        {
            "transformers.models.deberta_v2.modeling_tf_deberta_v2.TFDebertaV2ForTokenClassification.__init__": 1407
        },
        {
            "transformers.models.deberta_v2.modeling_tf_deberta_v2.TFDebertaV2ForQuestionAnswering.__init__": 1485
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/deberta_v2/tokenization_deberta_v2.py": [
        {
            "transformers.models.deberta_v2.tokenization_deberta_v2.DebertaV2Tokenizer.__init__": 110
        },
        {
            "transformers.models.deberta_v2.tokenization_deberta_v2.DebertaV2Tokenizer.prepare_for_tokenization": 261
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/deberta_v2/tokenization_deberta_v2_fast.py": [
        {
            "transformers.models.deberta_v2.tokenization_deberta_v2_fast.DebertaV2TokenizerFast.__init__": 118
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/deberta_v2/modeling_deberta_v2.py": [
        {
            "transformers.models.deberta_v2.modeling_deberta_v2.DebertaV2Encoder.custom_forward": 508
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/data2vec/configuration_data2vec_audio.py": [
        {
            "transformers.models.data2vec.configuration_data2vec_audio.Data2VecAudioConfig.__init__": 168
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/data2vec/modeling_tf_data2vec_vision.py": [
        {
            "transformers.models.data2vec.modeling_tf_data2vec_vision.TFData2VecVisionDropPath.__init__": 108
        },
        {
            "transformers.models.data2vec.modeling_tf_data2vec_vision.TFData2VecVisionEmbeddings.__init__": 128
        },
        {
            "transformers.models.data2vec.modeling_tf_data2vec_vision.TFData2VecVisionPatchEmbeddings.__init__": 195
        },
        {
            "transformers.models.data2vec.modeling_tf_data2vec_vision.TFData2VecVisionSelfAttention.__init__": 252
        },
        {
            "transformers.models.data2vec.modeling_tf_data2vec_vision.TFData2VecVisionSelfOutput.__init__": 353
        },
        {
            "transformers.models.data2vec.modeling_tf_data2vec_vision.TFData2VecVisionAttention.__init__": 369
        },
        {
            "transformers.models.data2vec.modeling_tf_data2vec_vision.TFData2VecVisionIntermediate.__init__": 403
        },
        {
            "transformers.models.data2vec.modeling_tf_data2vec_vision.TFData2VecVisionOutput.__init__": 423
        },
        {
            "transformers.models.data2vec.modeling_tf_data2vec_vision.TFData2VecVisionLayer.__init__": 441
        },
        {
            "transformers.models.data2vec.modeling_tf_data2vec_vision.TFData2VecVisionRelativePositionBias.__init__": 533
        },
        {
            "transformers.models.data2vec.modeling_tf_data2vec_vision.TFData2VecVisionEncoder.__init__": 589
        },
        {
            "transformers.models.data2vec.modeling_tf_data2vec_vision.TFData2VecVisionMainLayer.__init__": 657
        },
        {
            "transformers.models.data2vec.modeling_tf_data2vec_vision.TFData2VecVisionPooler.__init__": 745
        },
        {
            "transformers.models.data2vec.modeling_tf_data2vec_vision.TFData2VecVisionModel.__init__": 882
        },
        {
            "transformers.models.data2vec.modeling_tf_data2vec_vision.TFData2VecVisionForImageClassification.__init__": 945
        },
        {
            "transformers.models.data2vec.modeling_tf_data2vec_vision.TFData2VecVisionConvModule.__init__": 1023
        },
        {
            "transformers.models.data2vec.modeling_tf_data2vec_vision.TFAdaptiveAvgPool1D.__init__": 1054
        },
        {
            "transformers.models.data2vec.modeling_tf_data2vec_vision.TFAdaptiveAvgPool2D.__init__": 1109
        },
        {
            "transformers.models.data2vec.modeling_tf_data2vec_vision.TFData2VecVisionPyramidPoolingModule.__init__": 1146
        },
        {
            "transformers.models.data2vec.modeling_tf_data2vec_vision.TFData2VecVisionUperHead.__init__": 1183
        },
        {
            "transformers.models.data2vec.modeling_tf_data2vec_vision.TFData2VecVisionFCNHead.__init__": 1258
        },
        {
            "transformers.models.data2vec.modeling_tf_data2vec_vision.TFData2VecVisionForSemanticSegmentation.__init__": 1323
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/data2vec/modeling_data2vec_text.py": [
        {
            "transformers.models.data2vec.modeling_data2vec_text.Data2VecTextEncoder.custom_forward": 512
        },
        {
            "transformers.models.data2vec.modeling_data2vec_text.Data2VecTextForCausalLM.prepare_inputs_for_generation": 1016
        },
        {
            "transformers.models.data2vec.modeling_data2vec_text.Data2VecTextLMHead.forward": 1143
        },
        {
            "transformers.models.data2vec.modeling_data2vec_text.Data2VecTextClassificationHead.forward": 1450
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/data2vec/configuration_data2vec_text.py": [
        {
            "transformers.models.data2vec.configuration_data2vec_text.Data2VecTextConfig.__init__": 100
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/data2vec/modeling_data2vec_vision.py": [
        {
            "transformers.models.data2vec.modeling_data2vec_vision.Data2VecVisionEncoder.custom_forward": 528
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/data2vec/modeling_data2vec_audio.py": [
        {
            "transformers.models.data2vec.modeling_data2vec_audio.Data2VecAudioFeatureEncoder.custom_forward": 299
        },
        {
            "transformers.models.data2vec.modeling_data2vec_audio.Data2VecAudioEncoder.custom_forward": 599
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/data2vec/configuration_data2vec_vision.py": [
        {
            "transformers.models.data2vec.configuration_data2vec_vision.Data2VecVisionConfig.__init__": 116
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/roformer/configuration_roformer.py": [
        {
            "transformers.models.roformer.configuration_roformer.RoFormerConfig.__init__": 111
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/roformer/tokenization_roformer_fast.py": [
        {
            "transformers.models.roformer.tokenization_roformer_fast.RoFormerTokenizerFast.__init__": 97
        },
        {
            "transformers.models.roformer.tokenization_roformer_fast.RoFormerTokenizerFast.save_pretrained": 204
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/roformer/tokenization_roformer.py": [
        {
            "transformers.models.roformer.tokenization_roformer.RoFormerTokenizer.__init__": 354
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/roformer/modeling_flax_roformer.py": [
        {
            "transformers.models.roformer.modeling_flax_roformer.FlaxRoFormerPreTrainedModel.__init__": 618
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/roformer/modeling_tf_roformer.py": [
        {
            "transformers.models.roformer.modeling_tf_roformer.TFRoFormerSinusoidalPositionalEmbedding.__init__": 79
        },
        {
            "transformers.models.roformer.modeling_tf_roformer.TFRoFormerEmbeddings.__init__": 135
        },
        {
            "transformers.models.roformer.modeling_tf_roformer.TFRoFormerSelfAttention.__init__": 204
        },
        {
            "transformers.models.roformer.modeling_tf_roformer.TFRoFormerSelfOutput.__init__": 321
        },
        {
            "transformers.models.roformer.modeling_tf_roformer.TFRoFormerAttention.__init__": 339
        },
        {
            "transformers.models.roformer.modeling_tf_roformer.TFRoFormerIntermediate.__init__": 375
        },
        {
            "transformers.models.roformer.modeling_tf_roformer.TFRoFormerOutput.__init__": 396
        },
        {
            "transformers.models.roformer.modeling_tf_roformer.TFRoFormerLayer.__init__": 414
        },
        {
            "transformers.models.roformer.modeling_tf_roformer.TFRoFormerEncoder.__init__": 449
        },
        {
            "transformers.models.roformer.modeling_tf_roformer.TFRoFormerPredictionHeadTransform.__init__": 504
        },
        {
            "transformers.models.roformer.modeling_tf_roformer.TFRoFormerLMPredictionHead.__init__": 529
        },
        {
            "transformers.models.roformer.modeling_tf_roformer.TFRoFormerMLMHead.__init__": 573
        },
        {
            "transformers.models.roformer.modeling_tf_roformer.TFRoFormerMainLayer.__init__": 588
        },
        {
            "transformers.models.roformer.modeling_tf_roformer.TFRoFormerModel.__init__": 808
        },
        {
            "transformers.models.roformer.modeling_tf_roformer.TFRoFormerForMaskedLM.__init__": 855
        },
        {
            "transformers.models.roformer.modeling_tf_roformer.TFRoFormerForCausalLM.__init__": 933
        },
        {
            "transformers.models.roformer.modeling_tf_roformer.TFRoFormerClassificationHead.__init__": 1011
        },
        {
            "transformers.models.roformer.modeling_tf_roformer.TFRoFormerForSequenceClassification.__init__": 1045
        },
        {
            "transformers.models.roformer.modeling_tf_roformer.TFRoFormerForMultipleChoice.__init__": 1120
        },
        {
            "transformers.models.roformer.modeling_tf_roformer.TFRoFormerForTokenClassification.__init__": 1243
        },
        {
            "transformers.models.roformer.modeling_tf_roformer.TFRoFormerForQuestionAnswering.__init__": 1320
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/roformer/modeling_roformer.py": [
        {
            "transformers.models.roformer.modeling_roformer.RoFormerEncoder.custom_forward": 583
        },
        {
            "transformers.models.roformer.modeling_roformer.RoFormerForMaskedLM.prepare_inputs_for_generation": 1038
        },
        {
            "transformers.models.roformer.modeling_roformer.RoFormerForCausalLM.prepare_inputs_for_generation": 1178
        },
        {
            "transformers.models.roformer.modeling_roformer.RoFormerClassificationHead.forward": 1211
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/rag/tokenization_rag.py": [
        {
            "transformers.models.rag.tokenization_rag.RagTokenizer.from_pretrained": 44
        },
        {
            "transformers.models.rag.tokenization_rag.RagTokenizer.__call__": 61
        },
        {
            "transformers.models.rag.tokenization_rag.RagTokenizer.batch_decode": 64
        },
        {
            "transformers.models.rag.tokenization_rag.RagTokenizer.decode": 67
        },
        {
            "transformers.models.rag.tokenization_rag.RagTokenizer.prepare_seq2seq_batch": 76
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/rag/retrieval_rag.py": [
        {
            "transformers.models.rag.retrieval_rag.RagRetriever.from_pretrained": 419
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/rag/modeling_tf_rag.py": [
        {
            "transformers.models.rag.modeling_tf_rag.TFRagPreTrainedModel.from_pretrained_question_encoder_generator": 228
        },
        {
            "transformers.models.rag.modeling_tf_rag.TFRagModel.__init__": 496
        },
        {
            "transformers.models.rag.modeling_tf_rag.TFRagModel.call": 546
        },
        {
            "transformers.models.rag.modeling_tf_rag.TFRagTokenForGeneration.__init__": 731
        },
        {
            "transformers.models.rag.modeling_tf_rag.TFRagTokenForGeneration.prepare_inputs_for_generation": 764
        },
        {
            "transformers.models.rag.modeling_tf_rag.TFRagTokenForGeneration.call": 844
        },
        {
            "transformers.models.rag.modeling_tf_rag.TFRagTokenForGeneration.generate": 996
        },
        {
            "transformers.models.rag.modeling_tf_rag.TFRagSequenceForGeneration.__init__": 1298
        },
        {
            "transformers.models.rag.modeling_tf_rag.TFRagSequenceForGeneration.call": 1345
        },
        {
            "transformers.models.rag.modeling_tf_rag.TFRagSequenceForGeneration.generate": 1577
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/rag/configuration_rag.py": [
        {
            "transformers.models.rag.configuration_rag.RagConfig.__init__": 86
        },
        {
            "transformers.models.rag.configuration_rag.RagConfig.from_question_encoder_generator_configs": 171
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/rag/modeling_rag.py": [
        {
            "transformers.models.rag.modeling_rag.RagPreTrainedModel.from_pretrained": 237
        },
        {
            "transformers.models.rag.modeling_rag.RagPreTrainedModel.from_pretrained_question_encoder_generator": 244
        },
        {
            "transformers.models.rag.modeling_rag.RagModel.__init__": 495
        },
        {
            "transformers.models.rag.modeling_rag.RagSequenceForGeneration.__init__": 743
        },
        {
            "transformers.models.rag.modeling_rag.RagSequenceForGeneration.forward": 773
        },
        {
            "transformers.models.rag.modeling_rag.RagSequenceForGeneration.generate": 913
        },
        {
            "transformers.models.rag.modeling_rag.RagTokenForGeneration.__init__": 1141
        },
        {
            "transformers.models.rag.modeling_rag.RagTokenForGeneration.prepare_inputs_for_generation": 1170
        },
        {
            "transformers.models.rag.modeling_rag.RagTokenForGeneration.forward": 1241
        },
        {
            "transformers.models.rag.modeling_rag.RagTokenForGeneration.generate": 1381
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/luke/modeling_luke.py": [
        {
            "transformers.models.luke.modeling_luke.LukeEncoder.custom_forward": 793
        },
        {
            "transformers.models.luke.modeling_luke.LukeLMHead.forward": 1255
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/luke/tokenization_luke.py": [
        {
            "transformers.models.luke.tokenization_luke.LukeTokenizer.__init__": 293
        },
        {
            "transformers.models.luke.tokenization_luke.LukeTokenizer.prepare_for_tokenization": 569
        },
        {
            "transformers.models.luke.tokenization_luke.LukeTokenizer.__call__": 576
        },
        {
            "transformers.models.luke.tokenization_luke.LukeTokenizer._encode_plus": 721
        },
        {
            "transformers.models.luke.tokenization_luke.LukeTokenizer._batch_encode_plus": 802
        },
        {
            "transformers.models.luke.tokenization_luke.LukeTokenizer._create_input_sequence": 929
        },
        {
            "transformers.models.luke.tokenization_luke.LukeTokenizer.prepare_for_model": 1166
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/luke/configuration_luke.py": [
        {
            "transformers.models.luke.configuration_luke.LukeConfig.__init__": 96
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/decision_transformer/modeling_decision_transformer.py": [
        {
            "transformers.models.decision_transformer.modeling_decision_transformer.DecisionTransformerGPT2PreTrainedModel.__init__": 442
        },
        {
            "transformers.models.decision_transformer.modeling_decision_transformer.DecisionTransformerGPT2Model.custom_forward": 639
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/decision_transformer/configuration_decision_transformer.py": [
        {
            "transformers.models.decision_transformer.configuration_decision_transformer.DecisionTransformerConfig.__init__": 113
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/encoder_decoder/configuration_encoder_decoder.py": [
        {
            "transformers.models.encoder_decoder.configuration_encoder_decoder.EncoderDecoderConfig.__init__": 75
        },
        {
            "transformers.models.encoder_decoder.configuration_encoder_decoder.EncoderDecoderConfig.from_encoder_decoder_configs": 92
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/encoder_decoder/modeling_flax_encoder_decoder.py": [
        {
            "transformers.models.encoder_decoder.modeling_flax_encoder_decoder.FlaxEncoderDecoderModel.__init__": 313
        },
        {
            "transformers.models.encoder_decoder.modeling_flax_encoder_decoder.FlaxEncoderDecoderModel._decoder_forward": 408
        },
        {
            "transformers.models.encoder_decoder.modeling_flax_encoder_decoder.FlaxEncoderDecoderModel._encoder_forward": 476
        },
        {
            "transformers.models.encoder_decoder.modeling_flax_encoder_decoder.FlaxEncoderDecoderModel._decoder_forward": 582
        },
        {
            "transformers.models.encoder_decoder.modeling_flax_encoder_decoder.FlaxEncoderDecoderModel.prepare_inputs_for_generation": 722
        },
        {
            "transformers.models.encoder_decoder.modeling_flax_encoder_decoder.FlaxEncoderDecoderModel.from_encoder_decoder_pretrained": 761
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/encoder_decoder/modeling_tf_encoder_decoder.py": [
        {
            "transformers.models.encoder_decoder.modeling_tf_encoder_decoder.TFEncoderDecoderModel.from_pretrained": 294
        },
        {
            "transformers.models.encoder_decoder.modeling_tf_encoder_decoder.TFEncoderDecoderModel.from_encoder_decoder_pretrained": 346
        },
        {
            "transformers.models.encoder_decoder.modeling_tf_encoder_decoder.TFEncoderDecoderModel.call": 511
        },
        {
            "transformers.models.encoder_decoder.modeling_tf_encoder_decoder.TFEncoderDecoderModel.prepare_inputs_for_generation": 694
        },
        {
            "transformers.models.encoder_decoder.modeling_tf_encoder_decoder.TFEncoderDecoderModel.resize_token_embeddings": 717
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/encoder_decoder/modeling_encoder_decoder.py": [
        {
            "transformers.models.encoder_decoder.modeling_encoder_decoder.EncoderDecoderModel.from_pretrained": 281
        },
        {
            "transformers.models.encoder_decoder.modeling_encoder_decoder.EncoderDecoderModel.from_encoder_decoder_pretrained": 382
        },
        {
            "transformers.models.encoder_decoder.modeling_encoder_decoder.EncoderDecoderModel.forward": 533
        },
        {
            "transformers.models.encoder_decoder.modeling_encoder_decoder.EncoderDecoderModel.prepare_inputs_for_generation": 660
        },
        {
            "transformers.models.encoder_decoder.modeling_encoder_decoder.EncoderDecoderModel.resize_token_embeddings": 675
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/bert_generation/tokenization_bert_generation.py": [
        {
            "transformers.models.bert_generation.tokenization_bert_generation.BertGenerationTokenizer.__init__": 86
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/bert_generation/modeling_bert_generation.py": [
        {
            "transformers.models.bert_generation.modeling_bert_generation.BertEncoder.custom_forward": 405
        },
        {
            "transformers.models.bert_generation.modeling_bert_generation.BertGenerationDecoder.prepare_inputs_for_generation": 988
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/bert_generation/configuration_bert_generation.py": [
        {
            "transformers.models.bert_generation.configuration_bert_generation.BertGenerationConfig.__init__": 85
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/bert/tokenization_bert_fast.py": [
        {
            "transformers.models.bert.tokenization_bert_fast.BertTokenizerFast.__init__": 207
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/bert/tokenization_bert.py": [
        {
            "transformers.models.bert.tokenization_bert.BertTokenizer.__init__": 184
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/bert/configuration_bert.py": [
        {
            "transformers.models.bert.configuration_bert.BertConfig.__init__": 141
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/bert/modeling_flax_bert.py": [
        {
            "transformers.models.bert.modeling_flax_bert.FlaxBertPreTrainedModel.__init__": 770
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/bert/modeling_bert.py": [
        {
            "transformers.models.bert.modeling_bert.BertEncoder.custom_forward": 595
        },
        {
            "transformers.models.bert.modeling_bert.BertLMHeadModel.prepare_inputs_for_generation": 1274
        },
        {
            "transformers.models.bert.modeling_bert.BertForMaskedLM.prepare_inputs_for_generation": 1392
        },
        {
            "transformers.models.bert.modeling_bert.BertForNextSentencePrediction.forward": 1425
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/bert/tokenization_bert_tf.py": [
        {
            "transformers.models.bert.tokenization_bert_tf.TFBertTokenizer.from_tokenizer": 101
        },
        {
            "transformers.models.bert.tokenization_bert_tf.TFBertTokenizer.from_pretrained": 131
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/bert/modeling_tf_bert.py": [
        {
            "transformers.models.bert.modeling_tf_bert.TFBertEmbeddings.__init__": 148
        },
        {
            "transformers.models.bert.modeling_tf_bert.TFBertSelfAttention.__init__": 233
        },
        {
            "transformers.models.bert.modeling_tf_bert.TFBertSelfOutput.__init__": 350
        },
        {
            "transformers.models.bert.modeling_tf_bert.TFBertAttention.__init__": 368
        },
        {
            "transformers.models.bert.modeling_tf_bert.TFBertIntermediate.__init__": 408
        },
        {
            "transformers.models.bert.modeling_tf_bert.TFBertOutput.__init__": 428
        },
        {
            "transformers.models.bert.modeling_tf_bert.TFBertLayer.__init__": 446
        },
        {
            "transformers.models.bert.modeling_tf_bert.TFBertEncoder.__init__": 532
        },
        {
            "transformers.models.bert.modeling_tf_bert.TFBertPooler.__init__": 601
        },
        {
            "transformers.models.bert.modeling_tf_bert.TFBertPredictionHeadTransform.__init__": 621
        },
        {
            "transformers.models.bert.modeling_tf_bert.TFBertLMPredictionHead.__init__": 646
        },
        {
            "transformers.models.bert.modeling_tf_bert.TFBertMLMHead.__init__": 689
        },
        {
            "transformers.models.bert.modeling_tf_bert.TFBertNSPHead.__init__": 701
        },
        {
            "transformers.models.bert.modeling_tf_bert.TFBertMainLayer.__init__": 720
        },
        {
            "transformers.models.bert.modeling_tf_bert.TFBertModel.__init__": 1066
        },
        {
            "transformers.models.bert.modeling_tf_bert.TFBertForPreTraining.__init__": 1169
        },
        {
            "transformers.models.bert.modeling_tf_bert.TFBertForMaskedLM.__init__": 1287
        },
        {
            "transformers.models.bert.modeling_tf_bert.TFBertLMHeadModel.__init__": 1378
        },
        {
            "transformers.models.bert.modeling_tf_bert.TFBertLMHeadModel.prepare_inputs_for_generation": 1394
        },
        {
            "transformers.models.bert.modeling_tf_bert.TFBertLMHeadModel.call": 1412
        },
        {
            "transformers.models.bert.modeling_tf_bert.TFBertForNextSentencePrediction.__init__": 1515
        },
        {
            "transformers.models.bert.modeling_tf_bert.TFBertForSequenceClassification.__init__": 1607
        },
        {
            "transformers.models.bert.modeling_tf_bert.TFBertForMultipleChoice.__init__": 1699
        },
        {
            "transformers.models.bert.modeling_tf_bert.TFBertForTokenClassification.__init__": 1834
        },
        {
            "transformers.models.bert.modeling_tf_bert.TFBertForQuestionAnswering.__init__": 1929
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/speech_to_text/configuration_speech_to_text.py": [
        {
            "transformers.models.speech_to_text.configuration_speech_to_text.Speech2TextConfig.__init__": 118
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/speech_to_text/modeling_tf_speech_to_text.py": [
        {
            "transformers.models.speech_to_text.modeling_tf_speech_to_text.TFConv1dSubsampler.__init__": 129
        },
        {
            "transformers.models.speech_to_text.modeling_tf_speech_to_text.TFSpeech2TextSinusoidalPositionalEmbedding.__init__": 172
        },
        {
            "transformers.models.speech_to_text.modeling_tf_speech_to_text.TFSpeech2TextAttention.__init__": 243
        },
        {
            "transformers.models.speech_to_text.modeling_tf_speech_to_text.TFSpeech2TextEncoderLayer.__init__": 394
        },
        {
            "transformers.models.speech_to_text.modeling_tf_speech_to_text.TFSpeech2TextDecoderLayer.__init__": 449
        },
        {
            "transformers.models.speech_to_text.modeling_tf_speech_to_text.TFSpeech2TextEncoder.__init__": 747
        },
        {
            "transformers.models.speech_to_text.modeling_tf_speech_to_text.TFSpeech2TextDecoder.__init__": 915
        },
        {
            "transformers.models.speech_to_text.modeling_tf_speech_to_text.TFSpeech2TextMainLayer.__init__": 1140
        },
        {
            "transformers.models.speech_to_text.modeling_tf_speech_to_text.TFSpeech2TextMainLayer.call": 1154
        },
        {
            "transformers.models.speech_to_text.modeling_tf_speech_to_text.TFSpeech2TextModel.__init__": 1246
        },
        {
            "transformers.models.speech_to_text.modeling_tf_speech_to_text.TFSpeech2TextModel.call": 1265
        },
        {
            "transformers.models.speech_to_text.modeling_tf_speech_to_text.TFSpeech2TextForConditionalGeneration.call": 1355
        },
        {
            "transformers.models.speech_to_text.modeling_tf_speech_to_text.TFSpeech2TextForConditionalGeneration.prepare_inputs_for_generation": 1477
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/speech_to_text/processing_speech_to_text.py": [
        {
            "transformers.models.speech_to_text.processing_speech_to_text.Speech2TextProcessor.__call__": 47
        },
        {
            "transformers.models.speech_to_text.processing_speech_to_text.Speech2TextProcessor.batch_decode": 86
        },
        {
            "transformers.models.speech_to_text.processing_speech_to_text.Speech2TextProcessor.decode": 93
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/speech_to_text/tokenization_speech_to_text.py": [
        {
            "transformers.models.speech_to_text.tokenization_speech_to_text.Speech2TextTokenizer.__init__": 113
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/speech_to_text/modeling_speech_to_text.py": [
        {
            "transformers.models.speech_to_text.modeling_speech_to_text.Speech2TextEncoder.custom_forward": 816
        },
        {
            "transformers.models.speech_to_text.modeling_speech_to_text.Speech2TextDecoder.custom_forward": 1060
        },
        {
            "transformers.models.speech_to_text.modeling_speech_to_text.Speech2TextForConditionalGeneration.prepare_inputs_for_generation": 1395
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/speech_to_text/feature_extraction_speech_to_text.py": [
        {
            "transformers.models.speech_to_text.feature_extraction_speech_to_text.Speech2TextFeatureExtractor.__init__": 62
        },
        {
            "transformers.models.speech_to_text.feature_extraction_speech_to_text.Speech2TextFeatureExtractor.__call__": 126
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/nat/configuration_nat.py": [
        {
            "transformers.models.nat.configuration_nat.NatConfig.__init__": 98
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/nat/modeling_nat.py": [
        {
            "transformers.models.nat.modeling_nat.natten2dqkrpb": 49
        },
        {
            "transformers.models.nat.modeling_nat.natten2dav": 52
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/roberta/modeling_flax_roberta.py": [
        {
            "transformers.models.roberta.modeling_flax_roberta.FlaxRobertaPreTrainedModel.__init__": 734
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/roberta/modeling_roberta.py": [
        {
            "transformers.models.roberta.modeling_roberta.RobertaEncoder.custom_forward": 512
        },
        {
            "transformers.models.roberta.modeling_roberta.RobertaForCausalLM.prepare_inputs_for_generation": 1014
        },
        {
            "transformers.models.roberta.modeling_roberta.RobertaLMHead.forward": 1142
        },
        {
            "transformers.models.roberta.modeling_roberta.RobertaClassificationHead.forward": 1450
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/roberta/tokenization_roberta_fast.py": [
        {
            "transformers.models.roberta.tokenization_roberta_fast.RobertaTokenizerFast.__init__": 161
        },
        {
            "transformers.models.roberta.tokenization_roberta_fast.RobertaTokenizerFast._batch_encode_plus": 256
        },
        {
            "transformers.models.roberta.tokenization_roberta_fast.RobertaTokenizerFast._encode_plus": 265
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/roberta/modeling_tf_roberta.py": [
        {
            "transformers.models.roberta.modeling_tf_roberta.TFRobertaEmbeddings.__init__": 80
        },
        {
            "transformers.models.roberta.modeling_tf_roberta.TFRobertaPooler.__init__": 186
        },
        {
            "transformers.models.roberta.modeling_tf_roberta.TFRobertaSelfAttention.__init__": 207
        },
        {
            "transformers.models.roberta.modeling_tf_roberta.TFRobertaSelfOutput.__init__": 325
        },
        {
            "transformers.models.roberta.modeling_tf_roberta.TFRobertaAttention.__init__": 344
        },
        {
            "transformers.models.roberta.modeling_tf_roberta.TFRobertaIntermediate.__init__": 385
        },
        {
            "transformers.models.roberta.modeling_tf_roberta.TFRobertaOutput.__init__": 406
        },
        {
            "transformers.models.roberta.modeling_tf_roberta.TFRobertaLayer.__init__": 425
        },
        {
            "transformers.models.roberta.modeling_tf_roberta.TFRobertaEncoder.__init__": 512
        },
        {
            "transformers.models.roberta.modeling_tf_roberta.TFRobertaMainLayer.__init__": 584
        },
        {
            "transformers.models.roberta.modeling_tf_roberta.TFRobertaModel.__init__": 923
        },
        {
            "transformers.models.roberta.modeling_tf_roberta.TFRobertaLMHead.__init__": 1015
        },
        {
            "transformers.models.roberta.modeling_tf_roberta.TFRobertaForMaskedLM.__init__": 1069
        },
        {
            "transformers.models.roberta.modeling_tf_roberta.TFRobertaForCausalLM.__init__": 1153
        },
        {
            "transformers.models.roberta.modeling_tf_roberta.TFRobertaForCausalLM.prepare_inputs_for_generation": 1170
        },
        {
            "transformers.models.roberta.modeling_tf_roberta.TFRobertaClassificationHead.__init__": 1288
        },
        {
            "transformers.models.roberta.modeling_tf_roberta.TFRobertaForSequenceClassification.__init__": 1324
        },
        {
            "transformers.models.roberta.modeling_tf_roberta.TFRobertaForMultipleChoice.__init__": 1408
        },
        {
            "transformers.models.roberta.modeling_tf_roberta.TFRobertaForTokenClassification.__init__": 1528
        },
        {
            "transformers.models.roberta.modeling_tf_roberta.TFRobertaForQuestionAnswering.__init__": 1617
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/roberta/tokenization_roberta.py": [
        {
            "transformers.models.roberta.tokenization_roberta.RobertaTokenizer.__init__": 188
        },
        {
            "transformers.models.roberta.tokenization_roberta.RobertaTokenizer.prepare_for_tokenization": 419
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/roberta/configuration_roberta.py": [
        {
            "transformers.models.roberta.configuration_roberta.RobertaConfig.__init__": 106
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/marian/modeling_tf_marian.py": [
        {
            "transformers.models.marian.modeling_tf_marian.TFMarianSinusoidalPositionalEmbedding.__init__": 122
        },
        {
            "transformers.models.marian.modeling_tf_marian.TFMarianAttention.__init__": 181
        },
        {
            "transformers.models.marian.modeling_tf_marian.TFMarianEncoderLayer.__init__": 333
        },
        {
            "transformers.models.marian.modeling_tf_marian.TFMarianDecoderLayer.__init__": 390
        },
        {
            "transformers.models.marian.modeling_tf_marian.TFMarianEncoder.__init__": 685
        },
        {
            "transformers.models.marian.modeling_tf_marian.TFMarianDecoder.__init__": 858
        },
        {
            "transformers.models.marian.modeling_tf_marian.TFMarianMainLayer.__init__": 1092
        },
        {
            "transformers.models.marian.modeling_tf_marian.TFMarianMainLayer.call": 1117
        },
        {
            "transformers.models.marian.modeling_tf_marian.TFMarianModel.__init__": 1205
        },
        {
            "transformers.models.marian.modeling_tf_marian.TFMarianModel.call": 1223
        },
        {
            "transformers.models.marian.modeling_tf_marian.BiasLayer.__init__": 1294
        },
        {
            "transformers.models.marian.modeling_tf_marian.TFMarianMTModel.__init__": 1315
        },
        {
            "transformers.models.marian.modeling_tf_marian.TFMarianMTModel.prepare_inputs_for_generation": 1453
        },
        {
            "transformers.models.marian.modeling_tf_marian.TFMarianMTModel.adjust_logits_during_generation": 1495
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/marian/tokenization_marian.py": [
        {
            "transformers.models.marian.tokenization_marian.MarianTokenizer.__init__": 127
        },
        {
            "transformers.models.marian.tokenization_marian.MarianTokenizer.batch_decode": 219
        },
        {
            "transformers.models.marian.tokenization_marian.MarianTokenizer.decode": 241
        },
        {
            "transformers.models.marian.tokenization_marian.MarianTokenizer.num_special_tokens_to_add": 373
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/marian/modeling_marian.py": [
        {
            "transformers.models.marian.modeling_marian.MarianEncoder.custom_forward": 786
        },
        {
            "transformers.models.marian.modeling_marian.MarianDecoder.custom_forward": 1030
        },
        {
            "transformers.models.marian.modeling_marian.MarianMTModel.prepare_inputs_for_generation": 1490
        },
        {
            "transformers.models.marian.modeling_marian.MarianDecoderWrapper.forward": 1547
        },
        {
            "transformers.models.marian.modeling_marian.MarianForCausalLM.prepare_inputs_for_generation": 1729
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/marian/modeling_flax_marian.py": [
        {
            "transformers.models.marian.modeling_flax_marian.FlaxMarianPreTrainedModel.__init__": 879
        },
        {
            "transformers.models.marian.modeling_flax_marian.FlaxMarianPreTrainedModel._decoder_forward": 948
        },
        {
            "transformers.models.marian.modeling_flax_marian.FlaxMarianPreTrainedModel._encoder_forward": 1010
        },
        {
            "transformers.models.marian.modeling_flax_marian.FlaxMarianPreTrainedModel._decoder_forward": 1105
        },
        {
            "transformers.models.marian.modeling_flax_marian.FlaxMarianMTModel._decoder_forward": 1372
        },
        {
            "transformers.models.marian.modeling_flax_marian.FlaxMarianMTModel.prepare_inputs_for_generation": 1436
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/marian/configuration_marian.py": [
        {
            "transformers.models.marian.configuration_marian.MarianConfig.__init__": 109
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/pegasus/modeling_flax_pegasus.py": [
        {
            "transformers.models.pegasus.modeling_flax_pegasus.FlaxPegasusPreTrainedModel.__init__": 899
        },
        {
            "transformers.models.pegasus.modeling_flax_pegasus.FlaxPegasusPreTrainedModel._decoder_forward": 966
        },
        {
            "transformers.models.pegasus.modeling_flax_pegasus.FlaxPegasusPreTrainedModel._encoder_forward": 1032
        },
        {
            "transformers.models.pegasus.modeling_flax_pegasus.FlaxPegasusPreTrainedModel._decoder_forward": 1127
        },
        {
            "transformers.models.pegasus.modeling_flax_pegasus.FlaxPegasusForConditionalGeneration._decoder_forward": 1395
        },
        {
            "transformers.models.pegasus.modeling_flax_pegasus.FlaxPegasusForConditionalGeneration.prepare_inputs_for_generation": 1454
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/pegasus/configuration_pegasus.py": [
        {
            "transformers.models.pegasus.configuration_pegasus.PegasusConfig.__init__": 104
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/pegasus/modeling_pegasus.py": [
        {
            "transformers.models.pegasus.modeling_pegasus.PegasusEncoder.custom_forward": 801
        },
        {
            "transformers.models.pegasus.modeling_pegasus.PegasusDecoder.custom_forward": 1080
        },
        {
            "transformers.models.pegasus.modeling_pegasus.PegasusForConditionalGeneration.prepare_inputs_for_generation": 1451
        },
        {
            "transformers.models.pegasus.modeling_pegasus.PegasusDecoderWrapper.forward": 1504
        },
        {
            "transformers.models.pegasus.modeling_pegasus.PegasusForCausalLM.prepare_inputs_for_generation": 1708
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/pegasus/tokenization_pegasus_fast.py": [
        {
            "transformers.models.pegasus.tokenization_pegasus_fast.PegasusTokenizerFast.__init__": 100
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/pegasus/modeling_tf_pegasus.py": [
        {
            "transformers.models.pegasus.modeling_tf_pegasus.TFPegasusSinusoidalPositionalEmbedding.__init__": 124
        },
        {
            "transformers.models.pegasus.modeling_tf_pegasus.TFPegasusAttention.__init__": 183
        },
        {
            "transformers.models.pegasus.modeling_tf_pegasus.TFPegasusEncoderLayer.__init__": 335
        },
        {
            "transformers.models.pegasus.modeling_tf_pegasus.TFPegasusDecoderLayer.__init__": 392
        },
        {
            "transformers.models.pegasus.modeling_tf_pegasus.TFPegasusEncoder.__init__": 688
        },
        {
            "transformers.models.pegasus.modeling_tf_pegasus.TFPegasusDecoder.__init__": 864
        },
        {
            "transformers.models.pegasus.modeling_tf_pegasus.TFPegasusMainLayer.__init__": 1101
        },
        {
            "transformers.models.pegasus.modeling_tf_pegasus.TFPegasusMainLayer.call": 1126
        },
        {
            "transformers.models.pegasus.modeling_tf_pegasus.TFPegasusModel.__init__": 1214
        },
        {
            "transformers.models.pegasus.modeling_tf_pegasus.TFPegasusModel.call": 1232
        },
        {
            "transformers.models.pegasus.modeling_tf_pegasus.BiasLayer.__init__": 1304
        },
        {
            "transformers.models.pegasus.modeling_tf_pegasus.TFPegasusForConditionalGeneration.__init__": 1325
        },
        {
            "transformers.models.pegasus.modeling_tf_pegasus.TFPegasusForConditionalGeneration.prepare_inputs_for_generation": 1463
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/pegasus/tokenization_pegasus.py": [
        {
            "transformers.models.pegasus.tokenization_pegasus.PegasusTokenizer.__init__": 105
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/wav2vec2_conformer/configuration_wav2vec2_conformer.py": [
        {
            "transformers.models.wav2vec2_conformer.configuration_wav2vec2_conformer.Wav2Vec2ConformerConfig.__init__": 209
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/wav2vec2_conformer/modeling_wav2vec2_conformer.py": [
        {
            "transformers.models.wav2vec2_conformer.modeling_wav2vec2_conformer.Wav2Vec2ConformerFeatureEncoder.custom_forward": 518
        },
        {
            "transformers.models.wav2vec2_conformer.modeling_wav2vec2_conformer.Wav2Vec2ConformerEncoder.custom_forward": 911
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/barthez/tokenization_barthez.py": [
        {
            "transformers.models.barthez.tokenization_barthez.BarthezTokenizer.__init__": 126
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/barthez/tokenization_barthez_fast.py": [
        {
            "transformers.models.barthez.tokenization_barthez_fast.BarthezTokenizerFast.__init__": 119
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/speech_encoder_decoder/modeling_flax_speech_encoder_decoder.py": [
        {
            "transformers.models.speech_encoder_decoder.modeling_flax_speech_encoder_decoder.FlaxSpeechEncoderDecoderModel.__init__": 341
        },
        {
            "transformers.models.speech_encoder_decoder.modeling_flax_speech_encoder_decoder.FlaxSpeechEncoderDecoderModel._decoder_forward": 442
        },
        {
            "transformers.models.speech_encoder_decoder.modeling_flax_speech_encoder_decoder.FlaxSpeechEncoderDecoderModel._encoder_forward": 511
        },
        {
            "transformers.models.speech_encoder_decoder.modeling_flax_speech_encoder_decoder.FlaxSpeechEncoderDecoderModel._decoder_forward": 616
        },
        {
            "transformers.models.speech_encoder_decoder.modeling_flax_speech_encoder_decoder.FlaxSpeechEncoderDecoderModel.prepare_inputs_for_generation": 746
        },
        {
            "transformers.models.speech_encoder_decoder.modeling_flax_speech_encoder_decoder.FlaxSpeechEncoderDecoderModel.from_encoder_decoder_pretrained": 785
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/speech_encoder_decoder/configuration_speech_encoder_decoder.py": [
        {
            "transformers.models.speech_encoder_decoder.configuration_speech_encoder_decoder.SpeechEncoderDecoderConfig.__init__": 76
        },
        {
            "transformers.models.speech_encoder_decoder.configuration_speech_encoder_decoder.SpeechEncoderDecoderConfig.from_encoder_decoder_configs": 94
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/speech_encoder_decoder/modeling_speech_encoder_decoder.py": [
        {
            "transformers.models.speech_encoder_decoder.modeling_speech_encoder_decoder.SpeechEncoderDecoderModel.from_pretrained": 277
        },
        {
            "transformers.models.speech_encoder_decoder.modeling_speech_encoder_decoder.SpeechEncoderDecoderModel.from_encoder_decoder_pretrained": 288
        },
        {
            "transformers.models.speech_encoder_decoder.modeling_speech_encoder_decoder.SpeechEncoderDecoderModel.forward": 444
        },
        {
            "transformers.models.speech_encoder_decoder.modeling_speech_encoder_decoder.SpeechEncoderDecoderModel.prepare_inputs_for_generation": 585
        },
        {
            "transformers.models.speech_encoder_decoder.modeling_speech_encoder_decoder.SpeechEncoderDecoderModel.resize_token_embeddings": 600
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/wav2vec2_phoneme/tokenization_wav2vec2_phoneme.py": [
        {
            "transformers.models.wav2vec2_phoneme.tokenization_wav2vec2_phoneme.Wav2Vec2PhonemeCTCTokenizer.__init__": 132
        },
        {
            "transformers.models.wav2vec2_phoneme.tokenization_wav2vec2_phoneme.Wav2Vec2PhonemeCTCTokenizer._tokenize": 235
        },
        {
            "transformers.models.wav2vec2_phoneme.tokenization_wav2vec2_phoneme.Wav2Vec2PhonemeCTCTokenizer.decode": 450
        },
        {
            "transformers.models.wav2vec2_phoneme.tokenization_wav2vec2_phoneme.Wav2Vec2PhonemeCTCTokenizer.batch_decode": 506
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/big_bird/configuration_big_bird.py": [
        {
            "transformers.models.big_bird.configuration_big_bird.BigBirdConfig.__init__": 109
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/big_bird/tokenization_big_bird.py": [
        {
            "transformers.models.big_bird.tokenization_big_bird.BigBirdTokenizer.__init__": 105
        },
        {
            "transformers.models.big_bird.tokenization_big_bird.BigBirdTokenizer._decode": 203
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/big_bird/modeling_big_bird.py": [
        {
            "transformers.models.big_bird.modeling_big_bird.BigBirdEncoder.custom_forward": 1617
        },
        {
            "transformers.models.big_bird.modeling_big_bird.BigBirdForMaskedLM.prepare_inputs_for_generation": 2493
        },
        {
            "transformers.models.big_bird.modeling_big_bird.BigBirdForCausalLM.prepare_inputs_for_generation": 2626
        },
        {
            "transformers.models.big_bird.modeling_big_bird.BigBirdClassificationHead.forward": 2662
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/big_bird/tokenization_big_bird_fast.py": [
        {
            "transformers.models.big_bird.tokenization_big_bird_fast.BigBirdTokenizerFast.__init__": 116
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/big_bird/modeling_flax_big_bird.py": [
        {
            "transformers.models.big_bird.modeling_flax_big_bird.FlaxBigBirdPreTrainedModel.__init__": 1573
        },
        {
            "transformers.models.big_bird.modeling_flax_big_bird.FlaxBigBirdForMultipleChoice.__init__": 2177
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/groupvit/modeling_tf_groupvit.py": [
        {
            "transformers.models.groupvit.modeling_tf_groupvit.TFGroupViTCrossAttentionLayer.__init__": 267
        },
        {
            "transformers.models.groupvit.modeling_tf_groupvit.TFGroupViTAssignAttention.__init__": 283
        },
        {
            "transformers.models.groupvit.modeling_tf_groupvit.TFGroupViTTokenAssign.__init__": 332
        },
        {
            "transformers.models.groupvit.modeling_tf_groupvit.TFGroupViTPatchEmbeddings.__init__": 398
        },
        {
            "transformers.models.groupvit.modeling_tf_groupvit.TFGroupViTVisionEmbeddings.__init__": 468
        },
        {
            "transformers.models.groupvit.modeling_tf_groupvit.TFGroupViTTextEmbeddings.__init__": 535
        },
        {
            "transformers.models.groupvit.modeling_tf_groupvit.TFGroupViTStage.__init__": 605
        },
        {
            "transformers.models.groupvit.modeling_tf_groupvit.TFGroupViTMLP.__init__": 718
        },
        {
            "transformers.models.groupvit.modeling_tf_groupvit.TFGroupViTAttention.__init__": 752
        },
        {
            "transformers.models.groupvit.modeling_tf_groupvit.TFGroupViTEncoderLayer.__init__": 858
        },
        {
            "transformers.models.groupvit.modeling_tf_groupvit.TFGroupViTTextEncoder.__init__": 911
        },
        {
            "transformers.models.groupvit.modeling_tf_groupvit.TFGroupViTVisionEncoder.__init__": 955
        },
        {
            "transformers.models.groupvit.modeling_tf_groupvit.TFGroupViTTextTransformer.__init__": 1007
        },
        {
            "transformers.models.groupvit.modeling_tf_groupvit.TFGroupViTVisionTransformer.__init__": 1092
        },
        {
            "transformers.models.groupvit.modeling_tf_groupvit.TFGroupViTTextMainLayer.__init__": 1139
        },
        {
            "transformers.models.groupvit.modeling_tf_groupvit.TFGroupViTVisionMainLayer.__init__": 1188
        },
        {
            "transformers.models.groupvit.modeling_tf_groupvit.TFGroupViTMainLayer.__init__": 1225
        },
        {
            "transformers.models.groupvit.modeling_tf_groupvit.TFGroupViTTextModel.__init__": 1622
        },
        {
            "transformers.models.groupvit.modeling_tf_groupvit.TFGroupViTVisionModel.__init__": 1710
        },
        {
            "transformers.models.groupvit.modeling_tf_groupvit.TFGroupViTModel.__init__": 1805
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/groupvit/configuration_groupvit.py": [
        {
            "transformers.models.groupvit.configuration_groupvit.GroupViTTextConfig.__init__": 94
        },
        {
            "transformers.models.groupvit.configuration_groupvit.GroupViTTextConfig.from_pretrained": 129
        },
        {
            "transformers.models.groupvit.configuration_groupvit.GroupViTVisionConfig.__init__": 204
        },
        {
            "transformers.models.groupvit.configuration_groupvit.GroupViTVisionConfig.from_pretrained": 253
        },
        {
            "transformers.models.groupvit.configuration_groupvit.GroupViTConfig.__init__": 299
        },
        {
            "transformers.models.groupvit.configuration_groupvit.GroupViTConfig.from_text_vision_configs": 337
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/groupvit/modeling_groupvit.py": [
        {
            "transformers.models.groupvit.modeling_groupvit.GroupViTTextEncoder.custom_forward": 1037
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/trocr/processing_trocr.py": [
        {
            "transformers.models.trocr.processing_trocr.TrOCRProcessor.__init__": 42
        },
        {
            "transformers.models.trocr.processing_trocr.TrOCRProcessor.__call__": 61
        },
        {
            "transformers.models.trocr.processing_trocr.TrOCRProcessor.batch_decode": 94
        },
        {
            "transformers.models.trocr.processing_trocr.TrOCRProcessor.decode": 101
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/trocr/modeling_trocr.py": [
        {
            "transformers.models.trocr.modeling_trocr.TrOCRDecoder.custom_forward": 701
        },
        {
            "transformers.models.trocr.modeling_trocr.TrOCRDecoderWrapper.forward": 777
        },
        {
            "transformers.models.trocr.modeling_trocr.TrOCRForCausalLM.prepare_inputs_for_generation": 994
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/trocr/configuration_trocr.py": [
        {
            "transformers.models.trocr.configuration_trocr.TrOCRConfig.__init__": 104
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/markuplm/processing_markuplm.py": [
        {
            "transformers.models.markuplm.processing_markuplm.MarkupLMProcessor.__call__": 48
        },
        {
            "transformers.models.markuplm.processing_markuplm.MarkupLMProcessor.batch_decode": 128
        },
        {
            "transformers.models.markuplm.processing_markuplm.MarkupLMProcessor.decode": 135
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/markuplm/modeling_markuplm.py": [
        {
            "transformers.models.markuplm.modeling_markuplm.MarkupLMEncoder.custom_forward": 651
        },
        {
            "transformers.models.markuplm.modeling_markuplm.MarkupLMPreTrainedModel.from_pretrained": 736
        },
        {
            "transformers.models.markuplm.modeling_markuplm.MarkupLMModel.prepare_inputs_for_generation": 939
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/markuplm/tokenization_markuplm_fast.py": [
        {
            "transformers.models.markuplm.tokenization_markuplm_fast.MarkupLMTokenizerFast.__init__": 162
        },
        {
            "transformers.models.markuplm.tokenization_markuplm_fast.MarkupLMTokenizerFast.__call__": 285
        },
        {
            "transformers.models.markuplm.tokenization_markuplm_fast.MarkupLMTokenizerFast.batch_encode_plus": 429
        },
        {
            "transformers.models.markuplm.tokenization_markuplm_fast.MarkupLMTokenizerFast.tokenize": 487
        },
        {
            "transformers.models.markuplm.tokenization_markuplm_fast.MarkupLMTokenizerFast.encode_plus": 496
        },
        {
            "transformers.models.markuplm.tokenization_markuplm_fast.MarkupLMTokenizerFast._encode_plus": 719
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/markuplm/tokenization_markuplm.py": [
        {
            "transformers.models.markuplm.tokenization_markuplm.MarkupLMTokenizer.__init__": 204
        },
        {
            "transformers.models.markuplm.tokenization_markuplm.MarkupLMTokenizer.prepare_for_tokenization": 417
        },
        {
            "transformers.models.markuplm.tokenization_markuplm.MarkupLMTokenizer.__call__": 510
        },
        {
            "transformers.models.markuplm.tokenization_markuplm.MarkupLMTokenizer.batch_encode_plus": 655
        },
        {
            "transformers.models.markuplm.tokenization_markuplm.MarkupLMTokenizer._batch_encode_plus": 713
        },
        {
            "transformers.models.markuplm.tokenization_markuplm.MarkupLMTokenizer.encode": 840
        },
        {
            "transformers.models.markuplm.tokenization_markuplm.MarkupLMTokenizer.encode_plus": 887
        },
        {
            "transformers.models.markuplm.tokenization_markuplm.MarkupLMTokenizer._encode_plus": 953
        },
        {
            "transformers.models.markuplm.tokenization_markuplm.MarkupLMTokenizer.prepare_for_model": 1006
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/markuplm/feature_extraction_markuplm.py": [
        {
            "transformers.models.markuplm.feature_extraction_markuplm.MarkupLMFeatureExtractor.__init__": 43
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/markuplm/configuration_markuplm.py": [
        {
            "transformers.models.markuplm.configuration_markuplm.MarkupLMConfig.__init__": 103
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/deit/feature_extraction_deit.py": [
        {
            "transformers.models.deit.feature_extraction_deit.DeiTFeatureExtractor.__init__": 27
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/deit/image_processing_deit.py": [
        {
            "transformers.models.deit.image_processing_deit.DeiTImageProcessor.__init__": 82
        },
        {
            "transformers.models.deit.image_processing_deit.DeiTImageProcessor.resize": 113
        },
        {
            "transformers.models.deit.image_processing_deit.DeiTImageProcessor.center_crop": 141
        },
        {
            "transformers.models.deit.image_processing_deit.DeiTImageProcessor.rescale": 165
        },
        {
            "transformers.models.deit.image_processing_deit.DeiTImageProcessor.normalize": 185
        },
        {
            "transformers.models.deit.image_processing_deit.DeiTImageProcessor.preprocess": 208
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/deit/configuration_deit.py": [
        {
            "transformers.models.deit.configuration_deit.DeiTConfig.__init__": 96
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/deit/modeling_tf_deit.py": [
        {
            "transformers.models.deit.modeling_tf_deit.TFDeiTEmbeddings.__init__": 107
        },
        {
            "transformers.models.deit.modeling_tf_deit.TFDeiTPatchEmbeddings.__init__": 172
        },
        {
            "transformers.models.deit.modeling_tf_deit.TFDeiTSelfAttention.__init__": 207
        },
        {
            "transformers.models.deit.modeling_tf_deit.TFDeiTSelfOutput.__init__": 288
        },
        {
            "transformers.models.deit.modeling_tf_deit.TFDeiTAttention.__init__": 305
        },
        {
            "transformers.models.deit.modeling_tf_deit.TFDeiTIntermediate.__init__": 334
        },
        {
            "transformers.models.deit.modeling_tf_deit.TFDeiTOutput.__init__": 355
        },
        {
            "transformers.models.deit.modeling_tf_deit.TFDeiTLayer.__init__": 374
        },
        {
            "transformers.models.deit.modeling_tf_deit.TFDeiTEncoder.__init__": 423
        },
        {
            "transformers.models.deit.modeling_tf_deit.TFDeiTMainLayer.__init__": 471
        },
        {
            "transformers.models.deit.modeling_tf_deit.TFDeiTModel.__init__": 641
        },
        {
            "transformers.models.deit.modeling_tf_deit.TFDeiTPooler.__init__": 694
        },
        {
            "transformers.models.deit.modeling_tf_deit.TFDeitPixelShuffle.__init__": 716
        },
        {
            "transformers.models.deit.modeling_tf_deit.TFDeitDecoder.__init__": 740
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/deit/modeling_deit.py": [
        {
            "transformers.models.deit.modeling_deit.DeiTEncoder.custom_forward": 359
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/deformable_detr/modeling_deformable_detr.py": [
        {
            "transformers.models.deformable_detr.modeling_deformable_detr.DeformableDetrDecoder.custom_forward": 1361
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/deformable_detr/image_processing_deformable_detr.py": [
        {
            "transformers.models.deformable_detr.image_processing_deformable_detr.DeformableDetrImageProcessor.__init__": 774
        },
        {
            "transformers.models.deformable_detr.image_processing_deformable_detr.DeformableDetrImageProcessor.from_dict": 828
        },
        {
            "transformers.models.deformable_detr.image_processing_deformable_detr.DeformableDetrImageProcessor.convert_coco_poly_to_mask": 878
        },
        {
            "transformers.models.deformable_detr.image_processing_deformable_detr.DeformableDetrImageProcessor.prepare_coco_detection": 883
        },
        {
            "transformers.models.deformable_detr.image_processing_deformable_detr.DeformableDetrImageProcessor.prepare_coco_panoptic": 888
        },
        {
            "transformers.models.deformable_detr.image_processing_deformable_detr.DeformableDetrImageProcessor.resize": 893
        },
        {
            "transformers.models.deformable_detr.image_processing_deformable_detr.DeformableDetrImageProcessor.preprocess": 1069
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/deformable_detr/feature_extraction_deformable_detr.py": [
        {
            "transformers.models.deformable_detr.feature_extraction_deformable_detr.DeformableDetrFeatureExtractor.__init__": 27
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/deformable_detr/configuration_deformable_detr.py": [
        {
            "transformers.models.deformable_detr.configuration_deformable_detr.DeformableDetrConfig.__init__": 152
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/beit/modeling_flax_beit.py": [
        {
            "transformers.models.beit.modeling_flax_beit.FlaxBeitPreTrainedModel.__init__": 601
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/beit/configuration_beit.py": [
        {
            "transformers.models.beit.configuration_beit.BeitConfig.__init__": 120
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/beit/modeling_beit.py": [
        {
            "transformers.models.beit.modeling_beit.BeitEncoder.custom_forward": 516
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/beit/image_processing_beit.py": [
        {
            "transformers.models.beit.image_processing_beit.BeitImageProcessor.__init__": 95
        },
        {
            "transformers.models.beit.image_processing_beit.BeitImageProcessor.from_dict": 144
        },
        {
            "transformers.models.beit.image_processing_beit.BeitImageProcessor.resize": 154
        },
        {
            "transformers.models.beit.image_processing_beit.BeitImageProcessor.center_crop": 182
        },
        {
            "transformers.models.beit.image_processing_beit.BeitImageProcessor.rescale": 204
        },
        {
            "transformers.models.beit.image_processing_beit.BeitImageProcessor.normalize": 224
        },
        {
            "transformers.models.beit.image_processing_beit.BeitImageProcessor.__call__": 359
        },
        {
            "transformers.models.beit.image_processing_beit.BeitImageProcessor.preprocess": 364
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/beit/feature_extraction_beit.py": [
        {
            "transformers.models.beit.feature_extraction_beit.BeitFeatureExtractor.__init__": 27
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/hubert/modeling_hubert.py": [
        {
            "transformers.models.hubert.modeling_hubert.HubertFeatureEncoder.custom_forward": 349
        },
        {
            "transformers.models.hubert.modeling_hubert.HubertEncoder.custom_forward": 700
        },
        {
            "transformers.models.hubert.modeling_hubert.HubertEncoderStableLayerNorm.custom_forward": 790
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/hubert/modeling_tf_hubert.py": [
        {
            "transformers.models.hubert.modeling_tf_hubert.input_values_processing": 51
        },
        {
            "transformers.models.hubert.modeling_tf_hubert.TFHubertGroupNorm.__init__": 290
        },
        {
            "transformers.models.hubert.modeling_tf_hubert.TFHubertWeightNormConv1D.__init__": 514
        },
        {
            "transformers.models.hubert.modeling_tf_hubert.TFHubertNoLayerNormConvLayer.__init__": 573
        },
        {
            "transformers.models.hubert.modeling_tf_hubert.TFHubertLayerNormConvLayer.__init__": 595
        },
        {
            "transformers.models.hubert.modeling_tf_hubert.TFHubertGroupNormConvLayer.__init__": 619
        },
        {
            "transformers.models.hubert.modeling_tf_hubert.TFHubertPositionalConvEmbedding.__init__": 643
        },
        {
            "transformers.models.hubert.modeling_tf_hubert.TFHubertSamePadLayer.__init__": 664
        },
        {
            "transformers.models.hubert.modeling_tf_hubert.TFHubertFeatureEncoder.__init__": 675
        },
        {
            "transformers.models.hubert.modeling_tf_hubert.TFHubertFeatureExtractor.__init__": 702
        },
        {
            "transformers.models.hubert.modeling_tf_hubert.TFHubertFeatureProjection.__init__": 713
        },
        {
            "transformers.models.hubert.modeling_tf_hubert.TFHubertAttention.__init__": 736
        },
        {
            "transformers.models.hubert.modeling_tf_hubert.TFHubertFeedForward.__init__": 888
        },
        {
            "transformers.models.hubert.modeling_tf_hubert.TFHubertEncoderLayer.__init__": 921
        },
        {
            "transformers.models.hubert.modeling_tf_hubert.TFHubertEncoderLayerStableLayerNorm.__init__": 965
        },
        {
            "transformers.models.hubert.modeling_tf_hubert.TFHubertEncoder.__init__": 1007
        },
        {
            "transformers.models.hubert.modeling_tf_hubert.TFHubertEncoderStableLayerNorm.__init__": 1073
        },
        {
            "transformers.models.hubert.modeling_tf_hubert.TFHubertMainLayer.__init__": 1143
        },
        {
            "transformers.models.hubert.modeling_tf_hubert.TFHubertMainLayer.call": 1220
        },
        {
            "transformers.models.hubert.modeling_tf_hubert.TFHubertPreTrainedModel.__init__": 1308
        },
        {
            "transformers.models.hubert.modeling_tf_hubert.TFHubertModel.__init__": 1433
        },
        {
            "transformers.models.hubert.modeling_tf_hubert.TFHubertForCTC.__init__": 1532
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/hubert/configuration_hubert.py": [
        {
            "transformers.models.hubert.configuration_hubert.HubertConfig.__init__": 159
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/switch_transformers/modeling_switch_transformers.py": [
        {
            "transformers.models.switch_transformers.modeling_switch_transformers.SwitchTransformersStack.custom_forward": 1070
        },
        {
            "transformers.models.switch_transformers.modeling_switch_transformers.SwitchTransformersForConditionalGeneration.prepare_inputs_for_generation": 1751
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/switch_transformers/configuration_switch_transformers.py": [
        {
            "transformers.models.switch_transformers.configuration_switch_transformers.SwitchTransformersConfig.__init__": 101
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/table_transformer/configuration_table_transformer.py": [
        {
            "transformers.models.table_transformer.configuration_table_transformer.TableTransformerConfig.__init__": 144
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/table_transformer/modeling_table_transformer.py": [
        {
            "transformers.models.table_transformer.modeling_table_transformer.TableTransformerDecoder.custom_forward": 1076
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/codegen/tokenization_codegen.py": [
        {
            "transformers.models.codegen.tokenization_codegen.CodeGenTokenizer.__init__": 152
        },
        {
            "transformers.models.codegen.tokenization_codegen.CodeGenTokenizer.prepare_for_tokenization": 312
        },
        {
            "transformers.models.codegen.tokenization_codegen.CodeGenTokenizer.decode": 318
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/codegen/modeling_codegen.py": [
        {
            "transformers.models.codegen.modeling_codegen.CodeGenPreTrainedModel.__init__": 336
        },
        {
            "transformers.models.codegen.modeling_codegen.CodeGenModel.custom_forward": 562
        },
        {
            "transformers.models.codegen.modeling_codegen.CodeGenForCausalLM.prepare_inputs_for_generation": 633
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/codegen/configuration_codegen.py": [
        {
            "transformers.models.codegen.configuration_codegen.CodeGenConfig.__init__": 109
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/codegen/tokenization_codegen_fast.py": [
        {
            "transformers.models.codegen.tokenization_codegen_fast.CodeGenTokenizerFast.__init__": 120
        },
        {
            "transformers.models.codegen.tokenization_codegen_fast.CodeGenTokenizerFast._batch_encode_plus": 161
        },
        {
            "transformers.models.codegen.tokenization_codegen_fast.CodeGenTokenizerFast._encode_plus": 170
        },
        {
            "transformers.models.codegen.tokenization_codegen_fast.CodeGenTokenizerFast.decode": 184
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/glpn/configuration_glpn.py": [
        {
            "transformers.models.glpn.configuration_glpn.GLPNConfig.__init__": 95
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/glpn/image_processing_glpn.py": [
        {
            "transformers.models.glpn.image_processing_glpn.GLPNImageProcessor.__init__": 54
        },
        {
            "transformers.models.glpn.image_processing_glpn.GLPNImageProcessor.resize": 68
        },
        {
            "transformers.models.glpn.image_processing_glpn.GLPNImageProcessor.rescale": 100
        },
        {
            "transformers.models.glpn.image_processing_glpn.GLPNImageProcessor.preprocess": 122
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/glpn/feature_extraction_glpn.py": [
        {
            "transformers.models.glpn.feature_extraction_glpn.GLPNFeatureExtractor.__init__": 27
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/lxmert/tokenization_lxmert.py": [
        {
            "transformers.models.lxmert.tokenization_lxmert.LxmertTokenizer.__init__": 114
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/lxmert/modeling_tf_lxmert.py": [
        {
            "transformers.models.lxmert.modeling_tf_lxmert.TFLxmertVisualFeatureEncoder.__init__": 153
        },
        {
            "transformers.models.lxmert.modeling_tf_lxmert.TFLxmertEmbeddings.__init__": 192
        },
        {
            "transformers.models.lxmert.modeling_tf_lxmert.TFLxmertAttention.__init__": 264
        },
        {
            "transformers.models.lxmert.modeling_tf_lxmert.TFLxmertIntermediate.__init__": 340
        },
        {
            "transformers.models.lxmert.modeling_tf_lxmert.TFLxmertOutput.__init__": 359
        },
        {
            "transformers.models.lxmert.modeling_tf_lxmert.TFLxmertAttentionOutput.__init__": 378
        },
        {
            "transformers.models.lxmert.modeling_tf_lxmert.TFLxmertSelfAttentionLayer.__init__": 396
        },
        {
            "transformers.models.lxmert.modeling_tf_lxmert.TFLxmertCrossAttentionLayer.__init__": 411
        },
        {
            "transformers.models.lxmert.modeling_tf_lxmert.TFLxmertLayer.__init__": 433
        },
        {
            "transformers.models.lxmert.modeling_tf_lxmert.TFLxmertXLayer.__init__": 449
        },
        {
            "transformers.models.lxmert.modeling_tf_lxmert.TFLxmertEncoder.__init__": 554
        },
        {
            "transformers.models.lxmert.modeling_tf_lxmert.TFLxmertMainLayer.__init__": 666
        },
        {
            "transformers.models.lxmert.modeling_tf_lxmert.TFLxmertModel.__init__": 945
        },
        {
            "transformers.models.lxmert.modeling_tf_lxmert.TFLxmertPooler.__init__": 1006
        },
        {
            "transformers.models.lxmert.modeling_tf_lxmert.TFLxmertPredictionHeadTransform.__init__": 1025
        },
        {
            "transformers.models.lxmert.modeling_tf_lxmert.TFLxmertLMPredictionHead.__init__": 1051
        },
        {
            "transformers.models.lxmert.modeling_tf_lxmert.TFLxmertMLMHead.__init__": 1095
        },
        {
            "transformers.models.lxmert.modeling_tf_lxmert.TFLxmertPreTrainingHeads.__init__": 1107
        },
        {
            "transformers.models.lxmert.modeling_tf_lxmert.TFLxmertVisualAnswerHead.__init__": 1124
        },
        {
            "transformers.models.lxmert.modeling_tf_lxmert.TFLxmertVisualObjHead.__init__": 1150
        },
        {
            "transformers.models.lxmert.modeling_tf_lxmert.TFLxmertForPreTraining.__init__": 1185
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/lxmert/tokenization_lxmert_fast.py": [
        {
            "transformers.models.lxmert.tokenization_lxmert_fast.LxmertTokenizerFast.__init__": 94
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/lxmert/modeling_lxmert.py": [
        {
            "transformers.models.lxmert.modeling_lxmert.LxmertForPreTraining.forward": 1155
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/lxmert/configuration_lxmert.py": [
        {
            "transformers.models.lxmert.configuration_lxmert.LxmertConfig.__init__": 118
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/flaubert/modeling_tf_flaubert.py": [
        {
            "transformers.models.flaubert.modeling_tf_flaubert.TFFlaubertModel.__init__": 245
        },
        {
            "transformers.models.flaubert.modeling_tf_flaubert.TFFlaubertMultiHeadAttention.__init__": 302
        },
        {
            "transformers.models.flaubert.modeling_tf_flaubert.TFFlaubertTransformerFFN.__init__": 393
        },
        {
            "transformers.models.flaubert.modeling_tf_flaubert.TFFlaubertMainLayer.__init__": 414
        },
        {
            "transformers.models.flaubert.modeling_tf_flaubert.TFFlaubertPredLayer.__init__": 698
        },
        {
            "transformers.models.flaubert.modeling_tf_flaubert.TFFlaubertWithLMHeadModel.__init__": 778
        },
        {
            "transformers.models.flaubert.modeling_tf_flaubert.TFFlaubertWithLMHeadModel.prepare_inputs_for_generation": 792
        },
        {
            "transformers.models.flaubert.modeling_tf_flaubert.TFFlaubertForSequenceClassification.__init__": 871
        },
        {
            "transformers.models.flaubert.modeling_tf_flaubert.TFFlaubertForQuestionAnsweringSimple.__init__": 957
        },
        {
            "transformers.models.flaubert.modeling_tf_flaubert.TFFlaubertForTokenClassification.__init__": 1058
        },
        {
            "transformers.models.flaubert.modeling_tf_flaubert.TFFlaubertForMultipleChoice.__init__": 1146
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/flaubert/modeling_flaubert.py": [
        {
            "transformers.models.flaubert.modeling_flaubert.FlaubertPreTrainedModel.__init__": 352
        },
        {
            "transformers.models.flaubert.modeling_flaubert.FlaubertWithLMHeadModel.prepare_inputs_for_generation": 674
        },
        {
            "transformers.models.flaubert.modeling_flaubert.FlaubertForMultipleChoice.__init__": 1215
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/flaubert/configuration_flaubert.py": [
        {
            "transformers.models.flaubert.configuration_flaubert.FlaubertConfig.__init__": 146
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/flaubert/tokenization_flaubert.py": [
        {
            "transformers.models.flaubert.tokenization_flaubert.FlaubertTokenizer.__init__": 223
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/unispeech_sat/modeling_unispeech_sat.py": [
        {
            "transformers.models.unispeech_sat.modeling_unispeech_sat.UniSpeechSatFeatureEncoder.custom_forward": 400
        },
        {
            "transformers.models.unispeech_sat.modeling_unispeech_sat.UniSpeechSatEncoder.custom_forward": 749
        },
        {
            "transformers.models.unispeech_sat.modeling_unispeech_sat.UniSpeechSatEncoderStableLayerNorm.custom_forward": 839
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/unispeech_sat/configuration_unispeech_sat.py": [
        {
            "transformers.models.unispeech_sat.configuration_unispeech_sat.UniSpeechSatConfig.__init__": 190
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/wav2vec2_with_lm/processing_wav2vec2_with_lm.py": [
        {
            "transformers.models.wav2vec2_with_lm.processing_wav2vec2_with_lm.Wav2Vec2ProcessorWithLM.from_pretrained": 113
        },
        {
            "transformers.models.wav2vec2_with_lm.processing_wav2vec2_with_lm.Wav2Vec2ProcessorWithLM.__call__": 214
        },
        {
            "transformers.models.wav2vec2_with_lm.processing_wav2vec2_with_lm.Wav2Vec2ProcessorWithLM.pad": 253
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/xlm_prophetnet/tokenization_xlm_prophetnet.py": [
        {
            "transformers.models.xlm_prophetnet.tokenization_xlm_prophetnet.XLMProphetNetTokenizer.__init__": 133
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/xlm_prophetnet/modeling_xlm_prophetnet.py": [
        {
            "transformers.models.xlm_prophetnet.modeling_xlm_prophetnet.XLMProphetNetEncoder.custom_forward": 1382
        },
        {
            "transformers.models.xlm_prophetnet.modeling_xlm_prophetnet.XLMProphetNetDecoder.custom_forward": 1623
        },
        {
            "transformers.models.xlm_prophetnet.modeling_xlm_prophetnet.XLMProphetNetForConditionalGeneration.prepare_inputs_for_generation": 2088
        },
        {
            "transformers.models.xlm_prophetnet.modeling_xlm_prophetnet.XLMProphetNetForCausalLM.prepare_inputs_for_generation": 2343
        },
        {
            "transformers.models.xlm_prophetnet.modeling_xlm_prophetnet.XLMProphetNetDecoderWrapper.forward": 2387
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/xlm_prophetnet/configuration_xlm_prophetnet.py": [
        {
            "transformers.models.xlm_prophetnet.configuration_xlm_prophetnet.XLMProphetNetConfig.__init__": 109
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/vit/modeling_tf_vit.py": [
        {
            "transformers.models.vit.modeling_tf_vit.TFViTEmbeddings.__init__": 60
        },
        {
            "transformers.models.vit.modeling_tf_vit.TFViTPatchEmbeddings.__init__": 151
        },
        {
            "transformers.models.vit.modeling_tf_vit.TFViTSelfAttention.__init__": 209
        },
        {
            "transformers.models.vit.modeling_tf_vit.TFViTSelfOutput.__init__": 289
        },
        {
            "transformers.models.vit.modeling_tf_vit.TFViTAttention.__init__": 305
        },
        {
            "transformers.models.vit.modeling_tf_vit.TFViTIntermediate.__init__": 333
        },
        {
            "transformers.models.vit.modeling_tf_vit.TFViTOutput.__init__": 353
        },
        {
            "transformers.models.vit.modeling_tf_vit.TFViTLayer.__init__": 372
        },
        {
            "transformers.models.vit.modeling_tf_vit.TFViTEncoder.__init__": 420
        },
        {
            "transformers.models.vit.modeling_tf_vit.TFViTMainLayer.__init__": 468
        },
        {
            "transformers.models.vit.modeling_tf_vit.TFViTModel.__init__": 664
        },
        {
            "transformers.models.vit.modeling_tf_vit.TFViTPooler.__init__": 714
        },
        {
            "transformers.models.vit.modeling_tf_vit.TFViTForImageClassification.__init__": 749
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/vit/modeling_vit.py": [
        {
            "transformers.models.vit.modeling_vit.ViTEncoder.custom_forward": 398
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/vit/image_processing_vit.py": [
        {
            "transformers.models.vit.image_processing_vit.ViTImageProcessor.__init__": 74
        },
        {
            "transformers.models.vit.image_processing_vit.ViTImageProcessor.resize": 98
        },
        {
            "transformers.models.vit.image_processing_vit.ViTImageProcessor.rescale": 132
        },
        {
            "transformers.models.vit.image_processing_vit.ViTImageProcessor.normalize": 154
        },
        {
            "transformers.models.vit.image_processing_vit.ViTImageProcessor.preprocess": 183
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/vit/configuration_vit.py": [
        {
            "transformers.models.vit.configuration_vit.ViTConfig.__init__": 93
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/vit/modeling_flax_vit.py": [
        {
            "transformers.models.vit.modeling_flax_vit.FlaxViTPreTrainedModel.__init__": 440
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/vit/feature_extraction_vit.py": [
        {
            "transformers.models.vit.feature_extraction_vit.ViTFeatureExtractor.__init__": 27
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/megatron_bert/configuration_megatron_bert.py": [
        {
            "transformers.models.megatron_bert.configuration_megatron_bert.MegatronBertConfig.__init__": 95
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/megatron_bert/modeling_megatron_bert.py": [
        {
            "transformers.models.megatron_bert.modeling_megatron_bert.MegatronBertEncoder.custom_forward": 554
        },
        {
            "transformers.models.megatron_bert.modeling_megatron_bert.MegatronBertForCausalLM.prepare_inputs_for_generation": 1248
        },
        {
            "transformers.models.megatron_bert.modeling_megatron_bert.MegatronBertForMaskedLM.prepare_inputs_for_generation": 1357
        },
        {
            "transformers.models.megatron_bert.modeling_megatron_bert.MegatronBertForNextSentencePrediction.forward": 1392
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/rembert/tokenization_rembert_fast.py": [
        {
            "transformers.models.rembert.tokenization_rembert_fast.RemBertTokenizerFast.__init__": 103
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/rembert/tokenization_rembert.py": [
        {
            "transformers.models.rembert.tokenization_rembert.RemBertTokenizer.__init__": 99
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/rembert/configuration_rembert.py": [
        {
            "transformers.models.rembert.configuration_rembert.RemBertConfig.__init__": 101
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/rembert/modeling_rembert.py": [
        {
            "transformers.models.rembert.modeling_rembert.RemBertEncoder.custom_forward": 547
        },
        {
            "transformers.models.rembert.modeling_rembert.RemBertForMaskedLM.prepare_inputs_for_generation": 999
        },
        {
            "transformers.models.rembert.modeling_rembert.RemBertForCausalLM.prepare_inputs_for_generation": 1141
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/rembert/modeling_tf_rembert.py": [
        {
            "transformers.models.rembert.modeling_tf_rembert.TFRemBertEmbeddings.__init__": 73
        },
        {
            "transformers.models.rembert.modeling_tf_rembert.TFRemBertSelfAttention.__init__": 158
        },
        {
            "transformers.models.rembert.modeling_tf_rembert.TFRemBertSelfOutput.__init__": 276
        },
        {
            "transformers.models.rembert.modeling_tf_rembert.TFRemBertAttention.__init__": 295
        },
        {
            "transformers.models.rembert.modeling_tf_rembert.TFRemBertIntermediate.__init__": 336
        },
        {
            "transformers.models.rembert.modeling_tf_rembert.TFRemBertOutput.__init__": 357
        },
        {
            "transformers.models.rembert.modeling_tf_rembert.TFRemBertLayer.__init__": 376
        },
        {
            "transformers.models.rembert.modeling_tf_rembert.TFRemBertEncoder.__init__": 462
        },
        {
            "transformers.models.rembert.modeling_tf_rembert.TFRemBertPooler.__init__": 539
        },
        {
            "transformers.models.rembert.modeling_tf_rembert.TFRemBertLMPredictionHead.__init__": 559
        },
        {
            "transformers.models.rembert.modeling_tf_rembert.TFRemBertMLMHead.__init__": 614
        },
        {
            "transformers.models.rembert.modeling_tf_rembert.TFRemBertMainLayer.__init__": 629
        },
        {
            "transformers.models.rembert.modeling_tf_rembert.TFRemBertModel.__init__": 945
        },
        {
            "transformers.models.rembert.modeling_tf_rembert.TFRemBertForMaskedLM.__init__": 1037
        },
        {
            "transformers.models.rembert.modeling_tf_rembert.TFRemBertForCausalLM.__init__": 1117
        },
        {
            "transformers.models.rembert.modeling_tf_rembert.TFRemBertForCausalLM.prepare_inputs_for_generation": 1130
        },
        {
            "transformers.models.rembert.modeling_tf_rembert.TFRemBertForSequenceClassification.__init__": 1250
        },
        {
            "transformers.models.rembert.modeling_tf_rembert.TFRemBertForMultipleChoice.__init__": 1333
        },
        {
            "transformers.models.rembert.modeling_tf_rembert.TFRemBertForTokenClassification.__init__": 1459
        },
        {
            "transformers.models.rembert.modeling_tf_rembert.TFRemBertForQuestionAnswering.__init__": 1538
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/roc_bert/tokenization_roc_bert.py": [
        {
            "transformers.models.roc_bert.tokenization_roc_bert.RoCBertTokenizer.__init__": 142
        },
        {
            "transformers.models.roc_bert.tokenization_roc_bert.RoCBertTokenizer._encode_plus": 227
        },
        {
            "transformers.models.roc_bert.tokenization_roc_bert.RoCBertTokenizer.prepare_for_model": 322
        },
        {
            "transformers.models.roc_bert.tokenization_roc_bert.RoCBertTokenizer._batch_encode_plus": 562
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/roc_bert/configuration_roc_bert.py": [
        {
            "transformers.models.roc_bert.configuration_roc_bert.RoCBertConfig.__init__": 114
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/roc_bert/modeling_roc_bert.py": [
        {
            "transformers.models.roc_bert.modeling_roc_bert.RoCBertEncoder.custom_forward": 646
        },
        {
            "transformers.models.roc_bert.modeling_roc_bert.RoCBertForPreTraining.forward": 1104
        },
        {
            "transformers.models.roc_bert.modeling_roc_bert.RoCBertForMaskedLM.prepare_inputs_for_generation": 1377
        },
        {
            "transformers.models.roc_bert.modeling_roc_bert.RoCBertForCausalLM.prepare_inputs_for_generation": 1547
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/nystromformer/modeling_nystromformer.py": [
        {
            "transformers.models.nystromformer.modeling_nystromformer.NystromformerEncoder.custom_forward": 373
        },
        {
            "transformers.models.nystromformer.modeling_nystromformer.NystromformerClassificationHead.forward": 748
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/nystromformer/configuration_nystromformer.py": [
        {
            "transformers.models.nystromformer.configuration_nystromformer.NystromformerConfig.__init__": 94
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/bloom/configuration_bloom.py": [
        {
            "transformers.models.bloom.configuration_bloom.BloomConfig.__init__": 115
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/bloom/tokenization_bloom_fast.py": [
        {
            "transformers.models.bloom.tokenization_bloom_fast.BloomTokenizerFast.__init__": 106
        },
        {
            "transformers.models.bloom.tokenization_bloom_fast.BloomTokenizerFast._batch_encode_plus": 137
        },
        {
            "transformers.models.bloom.tokenization_bloom_fast.BloomTokenizerFast._encode_plus": 147
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/bloom/modeling_bloom.py": [
        {
            "transformers.models.bloom.modeling_bloom.BloomPreTrainedModel.__init__": 485
        },
        {
            "transformers.models.bloom.modeling_bloom.BloomModel.forward": 678
        },
        {
            "transformers.models.bloom.modeling_bloom.BloomModel.custom_forward": 768
        },
        {
            "transformers.models.bloom.modeling_bloom.BloomForCausalLM.prepare_inputs_for_generation": 840
        },
        {
            "transformers.models.bloom.modeling_bloom.BloomForCausalLM.forward": 868
        },
        {
            "transformers.models.bloom.modeling_bloom.BloomForSequenceClassification.forward": 998
        },
        {
            "transformers.models.bloom.modeling_bloom.BloomForTokenClassification.forward": 1134
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/vilt/processing_vilt.py": [
        {
            "transformers.models.vilt.processing_vilt.ViltProcessor.__init__": 44
        },
        {
            "transformers.models.vilt.processing_vilt.ViltProcessor.__call__": 62
        },
        {
            "transformers.models.vilt.processing_vilt.ViltProcessor.batch_decode": 112
        },
        {
            "transformers.models.vilt.processing_vilt.ViltProcessor.decode": 119
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/vilt/configuration_vilt.py": [
        {
            "transformers.models.vilt.configuration_vilt.ViltConfig.__init__": 101
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/vilt/image_processing_vilt.py": [
        {
            "transformers.models.vilt.image_processing_vilt.ViltImageProcessor.__init__": 156
        },
        {
            "transformers.models.vilt.image_processing_vilt.ViltImageProcessor.from_dict": 189
        },
        {
            "transformers.models.vilt.image_processing_vilt.ViltImageProcessor.resize": 200
        },
        {
            "transformers.models.vilt.image_processing_vilt.ViltImageProcessor.rescale": 236
        },
        {
            "transformers.models.vilt.image_processing_vilt.ViltImageProcessor.normalize": 256
        },
        {
            "transformers.models.vilt.image_processing_vilt.ViltImageProcessor.preprocess": 372
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/vilt/feature_extraction_vilt.py": [
        {
            "transformers.models.vilt.feature_extraction_vilt.ViltFeatureExtractor.__init__": 27
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/vilt/modeling_vilt.py": [
        {
            "transformers.models.vilt.modeling_vilt.ViltEncoder.custom_forward": 543
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/gptj/modeling_gptj.py": [
        {
            "transformers.models.gptj.modeling_gptj.GPTJPreTrainedModel.__init__": 336
        },
        {
            "transformers.models.gptj.modeling_gptj.GPTJModel.custom_forward": 654
        },
        {
            "transformers.models.gptj.modeling_gptj.GPTJForCausalLM.prepare_inputs_for_generation": 755
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/gptj/modeling_flax_gptj.py": [
        {
            "transformers.models.gptj.modeling_flax_gptj.FlaxGPTJPreTrainedModel.__init__": 370
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/gptj/modeling_tf_gptj.py": [
        {
            "transformers.models.gptj.modeling_tf_gptj.TFGPTJAttention.__init__": 85
        },
        {
            "transformers.models.gptj.modeling_tf_gptj.TFGPTJMLP.__init__": 271
        },
        {
            "transformers.models.gptj.modeling_tf_gptj.TFGPTJBlock.__init__": 294
        },
        {
            "transformers.models.gptj.modeling_tf_gptj.TFGPTJMainLayer.__init__": 339
        },
        {
            "transformers.models.gptj.modeling_tf_gptj.TFGPTJModel.__init__": 659
        },
        {
            "transformers.models.gptj.modeling_tf_gptj.TFGPTJForCausalLM.__init__": 728
        },
        {
            "transformers.models.gptj.modeling_tf_gptj.TFGPTJForCausalLM.prepare_inputs_for_generation": 741
        },
        {
            "transformers.models.gptj.modeling_tf_gptj.TFGPTJForSequenceClassification.__init__": 858
        },
        {
            "transformers.models.gptj.modeling_tf_gptj.TFGPTJForQuestionAnswering.__init__": 983
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/gptj/configuration_gptj.py": [
        {
            "transformers.models.gptj.configuration_gptj.GPTJConfig.__init__": 98
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/xlnet/modeling_tf_xlnet.py": [
        {
            "transformers.models.xlnet.modeling_tf_xlnet.TFXLNetRelativeAttention.__init__": 68
        },
        {
            "transformers.models.xlnet.modeling_tf_xlnet.TFXLNetFeedForward.__init__": 331
        },
        {
            "transformers.models.xlnet.modeling_tf_xlnet.TFXLNetLayer.__init__": 358
        },
        {
            "transformers.models.xlnet.modeling_tf_xlnet.TFXLNetLMHead.__init__": 402
        },
        {
            "transformers.models.xlnet.modeling_tf_xlnet.TFXLNetMainLayer.__init__": 437
        },
        {
            "transformers.models.xlnet.modeling_tf_xlnet.TFXLNetModel.__init__": 1140
        },
        {
            "transformers.models.xlnet.modeling_tf_xlnet.TFXLNetLMHeadModel.__init__": 1204
        },
        {
            "transformers.models.xlnet.modeling_tf_xlnet.TFXLNetLMHeadModel.prepare_inputs_for_generation": 1218
        },
        {
            "transformers.models.xlnet.modeling_tf_xlnet.TFXLNetForSequenceClassification.__init__": 1371
        },
        {
            "transformers.models.xlnet.modeling_tf_xlnet.TFXLNetForMultipleChoice.__init__": 1467
        },
        {
            "transformers.models.xlnet.modeling_tf_xlnet.TFXLNetForTokenClassification.__init__": 1599
        },
        {
            "transformers.models.xlnet.modeling_tf_xlnet.TFXLNetForQuestionAnsweringSimple.__init__": 1686
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/xlnet/tokenization_xlnet_fast.py": [
        {
            "transformers.models.xlnet.tokenization_xlnet_fast.XLNetTokenizerFast.__init__": 130
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/xlnet/configuration_xlnet.py": [
        {
            "transformers.models.xlnet.configuration_xlnet.XLNetConfig.__init__": 150
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/xlnet/tokenization_xlnet.py": [
        {
            "transformers.models.xlnet.tokenization_xlnet.XLNetTokenizer.__init__": 133
        },
        {
            "transformers.models.xlnet.tokenization_xlnet.XLNetTokenizer._decode": 253
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/xlnet/modeling_xlnet.py": [
        {
            "transformers.models.xlnet.modeling_xlnet.XLNetModel.forward": 1066
        },
        {
            "transformers.models.xlnet.modeling_xlnet.XLNetLMHeadModel.prepare_inputs_for_generation": 1316
        },
        {
            "transformers.models.xlnet.modeling_xlnet.XLNetLMHeadModel.forward": 1360
        },
        {
            "transformers.models.xlnet.modeling_xlnet.XLNetForSequenceClassification.forward": 1521
        },
        {
            "transformers.models.xlnet.modeling_xlnet.XLNetForTokenClassification.forward": 1628
        },
        {
            "transformers.models.xlnet.modeling_xlnet.XLNetForMultipleChoice.forward": 1715
        },
        {
            "transformers.models.xlnet.modeling_xlnet.XLNetForQuestionAnsweringSimple.forward": 1818
        },
        {
            "transformers.models.xlnet.modeling_xlnet.XLNetForQuestionAnswering.forward": 1927
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/fsmt/modeling_fsmt.py": [
        {
            "transformers.models.fsmt.modeling_fsmt.FSMTForConditionalGeneration.prepare_inputs_for_generation": 1266
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/fsmt/configuration_fsmt.py": [
        {
            "transformers.models.fsmt.configuration_fsmt.FSMTConfig.__init__": 141
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/fsmt/tokenization_fsmt.py": [
        {
            "transformers.models.fsmt.tokenization_fsmt.FSMTTokenizer.__init__": 187
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/gpt_neo/configuration_gpt_neo.py": [
        {
            "transformers.models.gpt_neo.configuration_gpt_neo.GPTNeoConfig.__init__": 100
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/gpt_neo/modeling_flax_gpt_neo.py": [
        {
            "transformers.models.gpt_neo.modeling_flax_gpt_neo.FlaxGPTNeoPreTrainedModel.__init__": 350
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/gpt_neo/modeling_gpt_neo.py": [
        {
            "transformers.models.gpt_neo.modeling_gpt_neo.GPTNeoPreTrainedModel.__init__": 366
        },
        {
            "transformers.models.gpt_neo.modeling_gpt_neo.GPTNeoModel.custom_forward": 607
        },
        {
            "transformers.models.gpt_neo.modeling_gpt_neo.GPTNeoForCausalLM.prepare_inputs_for_generation": 684
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/owlvit/feature_extraction_owlvit.py": [
        {
            "transformers.models.owlvit.feature_extraction_owlvit.OwlViTFeatureExtractor.__init__": 27
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/owlvit/modeling_owlvit.py": [
        {
            "transformers.models.owlvit.modeling_owlvit.OwlViTEncoder.custom_forward": 752
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/owlvit/image_processing_owlvit.py": [
        {
            "transformers.models.owlvit.image_processing_owlvit.OwlViTImageProcessor.__init__": 121
        },
        {
            "transformers.models.owlvit.image_processing_owlvit.OwlViTImageProcessor.resize": 160
        },
        {
            "transformers.models.owlvit.image_processing_owlvit.OwlViTImageProcessor.center_crop": 177
        },
        {
            "transformers.models.owlvit.image_processing_owlvit.OwlViTImageProcessor.rescale": 193
        },
        {
            "transformers.models.owlvit.image_processing_owlvit.OwlViTImageProcessor.normalize": 205
        },
        {
            "transformers.models.owlvit.image_processing_owlvit.OwlViTImageProcessor.preprocess": 218
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/owlvit/configuration_owlvit.py": [
        {
            "transformers.models.owlvit.configuration_owlvit.OwlViTTextConfig.__init__": 97
        },
        {
            "transformers.models.owlvit.configuration_owlvit.OwlViTTextConfig.from_pretrained": 132
        },
        {
            "transformers.models.owlvit.configuration_owlvit.OwlViTVisionConfig.__init__": 205
        },
        {
            "transformers.models.owlvit.configuration_owlvit.OwlViTVisionConfig.from_pretrained": 239
        },
        {
            "transformers.models.owlvit.configuration_owlvit.OwlViTConfig.__init__": 283
        },
        {
            "transformers.models.owlvit.configuration_owlvit.OwlViTConfig.from_pretrained": 311
        },
        {
            "transformers.models.owlvit.configuration_owlvit.OwlViTConfig.from_text_vision_configs": 323
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/owlvit/processing_owlvit.py": [
        {
            "transformers.models.owlvit.processing_owlvit.OwlViTProcessor.__init__": 46
        },
        {
            "transformers.models.owlvit.processing_owlvit.OwlViTProcessor.__call__": 63
        },
        {
            "transformers.models.owlvit.processing_owlvit.OwlViTProcessor.post_process": 175
        },
        {
            "transformers.models.owlvit.processing_owlvit.OwlViTProcessor.post_process_object_detection": 182
        },
        {
            "transformers.models.owlvit.processing_owlvit.OwlViTProcessor.post_process_image_guided_detection": 189
        },
        {
            "transformers.models.owlvit.processing_owlvit.OwlViTProcessor.batch_decode": 196
        },
        {
            "transformers.models.owlvit.processing_owlvit.OwlViTProcessor.decode": 203
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/altclip/configuration_altclip.py": [
        {
            "transformers.models.altclip.configuration_altclip.AltCLIPTextConfig.__init__": 103
        },
        {
            "transformers.models.altclip.configuration_altclip.AltCLIPVisionConfig.__init__": 205
        },
        {
            "transformers.models.altclip.configuration_altclip.AltCLIPVisionConfig.from_pretrained": 241
        },
        {
            "transformers.models.altclip.configuration_altclip.AltCLIPConfig.__init__": 306
        },
        {
            "transformers.models.altclip.configuration_altclip.AltCLIPConfig.from_text_vision_configs": 335
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/altclip/processing_altclip.py": [
        {
            "transformers.models.altclip.processing_altclip.AltCLIPProcessor.__init__": 42
        },
        {
            "transformers.models.altclip.processing_altclip.AltCLIPProcessor.__call__": 59
        },
        {
            "transformers.models.altclip.processing_altclip.AltCLIPProcessor.batch_decode": 112
        },
        {
            "transformers.models.altclip.processing_altclip.AltCLIPProcessor.decode": 119
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/altclip/modeling_altclip.py": [
        {
            "transformers.models.altclip.modeling_altclip.AltRobertaEncoder.custom_forward": 648
        },
        {
            "transformers.models.altclip.modeling_altclip.AltCLIPEncoder.custom_forward": 962
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/mctct/modeling_mctct.py": [
        {
            "transformers.models.mctct.modeling_mctct.MCTCTEncoder.custom_forward": 628
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/mctct/feature_extraction_mctct.py": [
        {
            "transformers.models.mctct.feature_extraction_mctct.MCTCTFeatureExtractor.__init__": 79
        },
        {
            "transformers.models.mctct.feature_extraction_mctct.MCTCTFeatureExtractor.__call__": 240
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/mctct/processing_mctct.py": [
        {
            "transformers.models.mctct.processing_mctct.MCTCTProcessor.__call__": 45
        },
        {
            "transformers.models.mctct.processing_mctct.MCTCTProcessor.batch_decode": 83
        },
        {
            "transformers.models.mctct.processing_mctct.MCTCTProcessor.pad": 90
        },
        {
            "transformers.models.mctct.processing_mctct.MCTCTProcessor.decode": 120
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/mctct/configuration_mctct.py": [
        {
            "transformers.models.mctct.configuration_mctct.MCTCTConfig.__init__": 119
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/bartpho/tokenization_bartpho.py": [
        {
            "transformers.models.bartpho.tokenization_bartpho.BartphoTokenizer.__init__": 123
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/longformer/tokenization_longformer_fast.py": [
        {
            "transformers.models.longformer.tokenization_longformer_fast.LongformerTokenizerFast.__init__": 176
        },
        {
            "transformers.models.longformer.tokenization_longformer_fast.LongformerTokenizerFast._batch_encode_plus": 271
        },
        {
            "transformers.models.longformer.tokenization_longformer_fast.LongformerTokenizerFast._encode_plus": 280
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/longformer/modeling_tf_longformer.py": [
        {
            "transformers.models.longformer.modeling_tf_longformer.TFLongformerLMHead.__init__": 420
        },
        {
            "transformers.models.longformer.modeling_tf_longformer.TFLongformerEmbeddings.__init__": 474
        },
        {
            "transformers.models.longformer.modeling_tf_longformer.TFLongformerIntermediate.__init__": 581
        },
        {
            "transformers.models.longformer.modeling_tf_longformer.TFLongformerOutput.__init__": 602
        },
        {
            "transformers.models.longformer.modeling_tf_longformer.TFLongformerPooler.__init__": 621
        },
        {
            "transformers.models.longformer.modeling_tf_longformer.TFLongformerSelfOutput.__init__": 642
        },
        {
            "transformers.models.longformer.modeling_tf_longformer.TFLongformerSelfAttention.__init__": 660
        },
        {
            "transformers.models.longformer.modeling_tf_longformer.TFLongformerAttention.__init__": 1500
        },
        {
            "transformers.models.longformer.modeling_tf_longformer.TFLongformerLayer.__init__": 1530
        },
        {
            "transformers.models.longformer.modeling_tf_longformer.TFLongformerEncoder.__init__": 1560
        },
        {
            "transformers.models.longformer.modeling_tf_longformer.TFLongformerMainLayer.__init__": 1641
        },
        {
            "transformers.models.longformer.modeling_tf_longformer.TFLongformerModel.__init__": 2045
        },
        {
            "transformers.models.longformer.modeling_tf_longformer.TFLongformerForMaskedLM.__init__": 2105
        },
        {
            "transformers.models.longformer.modeling_tf_longformer.TFLongformerForQuestionAnswering.__init__": 2201
        },
        {
            "transformers.models.longformer.modeling_tf_longformer.TFLongformerClassificationHead.__init__": 2336
        },
        {
            "transformers.models.longformer.modeling_tf_longformer.TFLongformerForSequenceClassification.__init__": 2369
        },
        {
            "transformers.models.longformer.modeling_tf_longformer.TFLongformerForMultipleChoice.__init__": 2482
        },
        {
            "transformers.models.longformer.modeling_tf_longformer.TFLongformerForTokenClassification.__init__": 2618
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/longformer/configuration_longformer.py": [
        {
            "transformers.models.longformer.configuration_longformer.LongformerConfig.__init__": 117
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/longformer/modeling_longformer.py": [
        {
            "transformers.models.longformer.modeling_longformer.LongformerEncoder.custom_forward": 1312
        },
        {
            "transformers.models.longformer.modeling_longformer.LongformerLMHead.forward": 1399
        },
        {
            "transformers.models.longformer.modeling_longformer.LongformerClassificationHead.forward": 1999
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/longformer/tokenization_longformer.py": [
        {
            "transformers.models.longformer.tokenization_longformer.LongformerTokenizer.__init__": 197
        },
        {
            "transformers.models.longformer.tokenization_longformer.LongformerTokenizer.prepare_for_tokenization": 428
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/layoutlm/modeling_tf_layoutlm.py": [
        {
            "transformers.models.layoutlm.modeling_tf_layoutlm.TFLayoutLMEmbeddings.__init__": 62
        },
        {
            "transformers.models.layoutlm.modeling_tf_layoutlm.TFLayoutLMSelfAttention.__init__": 199
        },
        {
            "transformers.models.layoutlm.modeling_tf_layoutlm.TFLayoutLMSelfOutput.__init__": 317
        },
        {
            "transformers.models.layoutlm.modeling_tf_layoutlm.TFLayoutLMAttention.__init__": 336
        },
        {
            "transformers.models.layoutlm.modeling_tf_layoutlm.TFLayoutLMIntermediate.__init__": 377
        },
        {
            "transformers.models.layoutlm.modeling_tf_layoutlm.TFLayoutLMOutput.__init__": 398
        },
        {
            "transformers.models.layoutlm.modeling_tf_layoutlm.TFLayoutLMLayer.__init__": 417
        },
        {
            "transformers.models.layoutlm.modeling_tf_layoutlm.TFLayoutLMEncoder.__init__": 504
        },
        {
            "transformers.models.layoutlm.modeling_tf_layoutlm.TFLayoutLMPooler.__init__": 574
        },
        {
            "transformers.models.layoutlm.modeling_tf_layoutlm.TFLayoutLMPredictionHeadTransform.__init__": 595
        },
        {
            "transformers.models.layoutlm.modeling_tf_layoutlm.TFLayoutLMLMPredictionHead.__init__": 621
        },
        {
            "transformers.models.layoutlm.modeling_tf_layoutlm.TFLayoutLMMLMHead.__init__": 665
        },
        {
            "transformers.models.layoutlm.modeling_tf_layoutlm.TFLayoutLMMainLayer.__init__": 680
        },
        {
            "transformers.models.layoutlm.modeling_tf_layoutlm.TFLayoutLMModel.__init__": 920
        },
        {
            "transformers.models.layoutlm.modeling_tf_layoutlm.TFLayoutLMForMaskedLM.__init__": 1028
        },
        {
            "transformers.models.layoutlm.modeling_tf_layoutlm.TFLayoutLMForSequenceClassification.__init__": 1157
        },
        {
            "transformers.models.layoutlm.modeling_tf_layoutlm.TFLayoutLMForTokenClassification.__init__": 1287
        },
        {
            "transformers.models.layoutlm.modeling_tf_layoutlm.TFLayoutLMForQuestionAnswering.__init__": 1415
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/layoutlm/configuration_layoutlm.py": [
        {
            "transformers.models.layoutlm.configuration_layoutlm.LayoutLMConfig.__init__": 97
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/layoutlm/modeling_layoutlm.py": [
        {
            "transformers.models.layoutlm.modeling_layoutlm.LayoutLMEncoder.custom_forward": 489
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/layoutlm/tokenization_layoutlm.py": [
        {
            "transformers.models.layoutlm.tokenization_layoutlm.LayoutLMTokenizer.__init__": 122
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/layoutlm/tokenization_layoutlm_fast.py": [
        {
            "transformers.models.layoutlm.tokenization_layoutlm_fast.LayoutLMTokenizerFast.__init__": 108
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/ernie/modeling_ernie.py": [
        {
            "transformers.models.ernie.modeling_ernie.ErnieEncoder.custom_forward": 508
        },
        {
            "transformers.models.ernie.modeling_ernie.ErnieForCausalLM.prepare_inputs_for_generation": 1214
        },
        {
            "transformers.models.ernie.modeling_ernie.ErnieForMaskedLM.prepare_inputs_for_generation": 1338
        },
        {
            "transformers.models.ernie.modeling_ernie.ErnieForNextSentencePrediction.forward": 1372
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/ernie/configuration_ernie.py": [
        {
            "transformers.models.ernie.configuration_ernie.ErnieConfig.__init__": 114
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/conditional_detr/image_processing_conditional_detr.py": [
        {
            "transformers.models.conditional_detr.image_processing_conditional_detr.ConditionalDetrImageProcessor.__init__": 776
        },
        {
            "transformers.models.conditional_detr.image_processing_conditional_detr.ConditionalDetrImageProcessor.from_dict": 830
        },
        {
            "transformers.models.conditional_detr.image_processing_conditional_detr.ConditionalDetrImageProcessor.convert_coco_poly_to_mask": 880
        },
        {
            "transformers.models.conditional_detr.image_processing_conditional_detr.ConditionalDetrImageProcessor.prepare_coco_detection": 885
        },
        {
            "transformers.models.conditional_detr.image_processing_conditional_detr.ConditionalDetrImageProcessor.prepare_coco_panoptic": 890
        },
        {
            "transformers.models.conditional_detr.image_processing_conditional_detr.ConditionalDetrImageProcessor.resize": 895
        },
        {
            "transformers.models.conditional_detr.image_processing_conditional_detr.ConditionalDetrImageProcessor.preprocess": 1071
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/conditional_detr/configuration_conditional_detr.py": [
        {
            "transformers.models.conditional_detr.configuration_conditional_detr.ConditionalDetrConfig.__init__": 145
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/conditional_detr/feature_extraction_conditional_detr.py": [
        {
            "transformers.models.conditional_detr.feature_extraction_conditional_detr.ConditionalDetrFeatureExtractor.__init__": 27
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/conditional_detr/modeling_conditional_detr.py": [
        {
            "transformers.models.conditional_detr.modeling_conditional_detr.ConditionalDetrDecoder.custom_forward": 1395
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/phobert/tokenization_phobert.py": [
        {
            "transformers.models.phobert.tokenization_phobert.PhobertTokenizer.__init__": 121
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/wav2vec2/modeling_flax_wav2vec2.py": [
        {
            "transformers.models.wav2vec2.modeling_flax_wav2vec2.FlaxWav2Vec2PreTrainedModel.__init__": 859
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/wav2vec2/modeling_wav2vec2.py": [
        {
            "transformers.models.wav2vec2.modeling_wav2vec2.Wav2Vec2FeatureEncoder.custom_forward": 444
        },
        {
            "transformers.models.wav2vec2.modeling_wav2vec2.Wav2Vec2Encoder.custom_forward": 788
        },
        {
            "transformers.models.wav2vec2.modeling_wav2vec2.Wav2Vec2EncoderStableLayerNorm.custom_forward": 877
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/wav2vec2/processing_wav2vec2.py": [
        {
            "transformers.models.wav2vec2.processing_wav2vec2.Wav2Vec2Processor.from_pretrained": 49
        },
        {
            "transformers.models.wav2vec2.processing_wav2vec2.Wav2Vec2Processor.__call__": 67
        },
        {
            "transformers.models.wav2vec2.processing_wav2vec2.Wav2Vec2Processor.pad": 105
        },
        {
            "transformers.models.wav2vec2.processing_wav2vec2.Wav2Vec2Processor.batch_decode": 135
        },
        {
            "transformers.models.wav2vec2.processing_wav2vec2.Wav2Vec2Processor.decode": 142
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/wav2vec2/configuration_wav2vec2.py": [
        {
            "transformers.models.wav2vec2.configuration_wav2vec2.Wav2Vec2Config.__init__": 200
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/wav2vec2/feature_extraction_wav2vec2.py": [
        {
            "transformers.models.wav2vec2.feature_extraction_wav2vec2.Wav2Vec2FeatureExtractor.__init__": 67
        },
        {
            "transformers.models.wav2vec2.feature_extraction_wav2vec2.Wav2Vec2FeatureExtractor.__call__": 102
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/wav2vec2/modeling_tf_wav2vec2.py": [
        {
            "transformers.models.wav2vec2.modeling_tf_wav2vec2.input_values_processing": 94
        },
        {
            "transformers.models.wav2vec2.modeling_tf_wav2vec2.TFWav2Vec2GroupNorm.__init__": 329
        },
        {
            "transformers.models.wav2vec2.modeling_tf_wav2vec2.TFWav2Vec2WeightNormConv1D.__init__": 552
        },
        {
            "transformers.models.wav2vec2.modeling_tf_wav2vec2.TFWav2Vec2NoLayerNormConvLayer.__init__": 610
        },
        {
            "transformers.models.wav2vec2.modeling_tf_wav2vec2.TFWav2Vec2LayerNormConvLayer.__init__": 631
        },
        {
            "transformers.models.wav2vec2.modeling_tf_wav2vec2.TFWav2Vec2GroupNormConvLayer.__init__": 654
        },
        {
            "transformers.models.wav2vec2.modeling_tf_wav2vec2.TFWav2Vec2PositionalConvEmbedding.__init__": 679
        },
        {
            "transformers.models.wav2vec2.modeling_tf_wav2vec2.TFWav2Vec2SamePadLayer.__init__": 699
        },
        {
            "transformers.models.wav2vec2.modeling_tf_wav2vec2.TFWav2Vec2FeatureEncoder.__init__": 710
        },
        {
            "transformers.models.wav2vec2.modeling_tf_wav2vec2.TFWav2Vec2FeatureExtractor.__init__": 737
        },
        {
            "transformers.models.wav2vec2.modeling_tf_wav2vec2.TFWav2Vec2FeatureProjection.__init__": 748
        },
        {
            "transformers.models.wav2vec2.modeling_tf_wav2vec2.TFWav2Vec2Attention.__init__": 771
        },
        {
            "transformers.models.wav2vec2.modeling_tf_wav2vec2.TFWav2Vec2FeedForward.__init__": 922
        },
        {
            "transformers.models.wav2vec2.modeling_tf_wav2vec2.TFWav2Vec2EncoderLayer.__init__": 954
        },
        {
            "transformers.models.wav2vec2.modeling_tf_wav2vec2.TFWav2Vec2EncoderLayerStableLayerNorm.__init__": 997
        },
        {
            "transformers.models.wav2vec2.modeling_tf_wav2vec2.TFWav2Vec2Encoder.__init__": 1038
        },
        {
            "transformers.models.wav2vec2.modeling_tf_wav2vec2.TFWav2Vec2EncoderStableLayerNorm.__init__": 1103
        },
        {
            "transformers.models.wav2vec2.modeling_tf_wav2vec2.TFWav2Vec2MainLayer.__init__": 1173
        },
        {
            "transformers.models.wav2vec2.modeling_tf_wav2vec2.TFWav2Vec2MainLayer.call": 1250
        },
        {
            "transformers.models.wav2vec2.modeling_tf_wav2vec2.TFWav2Vec2PreTrainedModel.__init__": 1340
        },
        {
            "transformers.models.wav2vec2.modeling_tf_wav2vec2.TFWav2Vec2Model.__init__": 1465
        },
        {
            "transformers.models.wav2vec2.modeling_tf_wav2vec2.TFWav2Vec2ForCTC.__init__": 1568
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/wav2vec2/tokenization_wav2vec2.py": [
        {
            "transformers.models.wav2vec2.tokenization_wav2vec2.Wav2Vec2CTCTokenizer.__init__": 161
        },
        {
            "transformers.models.wav2vec2.tokenization_wav2vec2.Wav2Vec2CTCTokenizer._tokenize": 236
        },
        {
            "transformers.models.wav2vec2.tokenization_wav2vec2.Wav2Vec2CTCTokenizer.prepare_for_tokenization": 367
        },
        {
            "transformers.models.wav2vec2.tokenization_wav2vec2.Wav2Vec2CTCTokenizer.batch_decode": 420
        },
        {
            "transformers.models.wav2vec2.tokenization_wav2vec2.Wav2Vec2CTCTokenizer.decode": 490
        },
        {
            "transformers.models.wav2vec2.tokenization_wav2vec2.Wav2Vec2Tokenizer.__init__": 727
        },
        {
            "transformers.models.wav2vec2.tokenization_wav2vec2.Wav2Vec2Tokenizer.__call__": 798
        },
        {
            "transformers.models.wav2vec2.tokenization_wav2vec2.Wav2Vec2Tokenizer._decode": 886
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/bart/modeling_tf_bart.py": [
        {
            "transformers.models.bart.modeling_tf_bart.TFBartLearnedPositionalEmbedding.__init__": 124
        },
        {
            "transformers.models.bart.modeling_tf_bart.TFBartAttention.__init__": 149
        },
        {
            "transformers.models.bart.modeling_tf_bart.TFBartEncoderLayer.__init__": 300
        },
        {
            "transformers.models.bart.modeling_tf_bart.TFBartDecoderLayer.__init__": 356
        },
        {
            "transformers.models.bart.modeling_tf_bart.TFBartClassificationHead.__init__": 467
        },
        {
            "transformers.models.bart.modeling_tf_bart.TFBartEncoder.__init__": 682
        },
        {
            "transformers.models.bart.modeling_tf_bart.TFBartDecoder.__init__": 844
        },
        {
            "transformers.models.bart.modeling_tf_bart.TFBartMainLayer.__init__": 1069
        },
        {
            "transformers.models.bart.modeling_tf_bart.TFBartMainLayer.call": 1093
        },
        {
            "transformers.models.bart.modeling_tf_bart.TFBartModel.__init__": 1191
        },
        {
            "transformers.models.bart.modeling_tf_bart.TFBartModel.call": 1209
        },
        {
            "transformers.models.bart.modeling_tf_bart.BiasLayer.__init__": 1279
        },
        {
            "transformers.models.bart.modeling_tf_bart.TFBartForConditionalGeneration.__init__": 1298
        },
        {
            "transformers.models.bart.modeling_tf_bart.TFBartForConditionalGeneration.prepare_inputs_for_generation": 1434
        },
        {
            "transformers.models.bart.modeling_tf_bart.TFBartForSequenceClassification.__init__": 1495
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/bart/configuration_bart.py": [
        {
            "transformers.models.bart.configuration_bart.BartConfig.__init__": 114
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/bart/modeling_flax_bart.py": [
        {
            "transformers.models.bart.modeling_flax_bart.FlaxBartPreTrainedModel.__init__": 912
        },
        {
            "transformers.models.bart.modeling_flax_bart.FlaxBartPreTrainedModel._decoder_forward": 981
        },
        {
            "transformers.models.bart.modeling_flax_bart.FlaxBartPreTrainedModel._encoder_forward": 1047
        },
        {
            "transformers.models.bart.modeling_flax_bart.FlaxBartPreTrainedModel._decoder_forward": 1142
        },
        {
            "transformers.models.bart.modeling_flax_bart.FlaxBartForConditionalGeneration._decoder_forward": 1409
        },
        {
            "transformers.models.bart.modeling_flax_bart.FlaxBartForConditionalGeneration.prepare_inputs_for_generation": 1468
        },
        {
            "transformers.models.bart.modeling_flax_bart.FlaxBartDecoderPreTrainedModel.__init__": 1744
        },
        {
            "transformers.models.bart.modeling_flax_bart.FlaxBartDecoderWrapper.__call__": 1893
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/bart/tokenization_bart.py": [
        {
            "transformers.models.bart.tokenization_bart.BartTokenizer.__init__": 182
        },
        {
            "transformers.models.bart.tokenization_bart.BartTokenizer.prepare_for_tokenization": 413
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/bart/tokenization_bart_fast.py": [
        {
            "transformers.models.bart.tokenization_bart_fast.BartTokenizerFast.__init__": 154
        },
        {
            "transformers.models.bart.tokenization_bart_fast.BartTokenizerFast._batch_encode_plus": 250
        },
        {
            "transformers.models.bart.tokenization_bart_fast.BartTokenizerFast._encode_plus": 261
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/bart/modeling_bart.py": [
        {
            "transformers.models.bart.modeling_bart.BartEncoder.custom_forward": 844
        },
        {
            "transformers.models.bart.modeling_bart.BartDecoder.custom_forward": 1095
        },
        {
            "transformers.models.bart.modeling_bart.BartForConditionalGeneration.prepare_inputs_for_generation": 1416
        },
        {
            "transformers.models.bart.modeling_bart.BartForSequenceClassification.__init__": 1470
        },
        {
            "transformers.models.bart.modeling_bart.BartDecoderWrapper.forward": 1722
        },
        {
            "transformers.models.bart.modeling_bart.BartForCausalLM.prepare_inputs_for_generation": 1909
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/cpm/tokenization_cpm_fast.py": [
        {
            "transformers.models.cpm.tokenization_cpm_fast.CpmTokenizerFast.__init__": 41
        },
        {
            "transformers.models.cpm.tokenization_cpm_fast.CpmTokenizerFast._batch_encode_plus": 233
        },
        {
            "transformers.models.cpm.tokenization_cpm_fast.CpmTokenizerFast._decode": 240
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/cpm/tokenization_cpm.py": [
        {
            "transformers.models.cpm.tokenization_cpm.CpmTokenizer.__init__": 41
        },
        {
            "transformers.models.cpm.tokenization_cpm.CpmTokenizer._decode": 345
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/van/configuration_van.py": [
        {
            "transformers.models.van.configuration_van.VanConfig.__init__": 82
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/vision_encoder_decoder/modeling_flax_vision_encoder_decoder.py": [
        {
            "transformers.models.vision_encoder_decoder.modeling_flax_vision_encoder_decoder.FlaxVisionEncoderDecoderModel.__init__": 280
        },
        {
            "transformers.models.vision_encoder_decoder.modeling_flax_vision_encoder_decoder.FlaxVisionEncoderDecoderModel._decoder_forward": 374
        },
        {
            "transformers.models.vision_encoder_decoder.modeling_flax_vision_encoder_decoder.FlaxVisionEncoderDecoderModel._encoder_forward": 444
        },
        {
            "transformers.models.vision_encoder_decoder.modeling_flax_vision_encoder_decoder.FlaxVisionEncoderDecoderModel._decoder_forward": 553
        },
        {
            "transformers.models.vision_encoder_decoder.modeling_flax_vision_encoder_decoder.FlaxVisionEncoderDecoderModel.prepare_inputs_for_generation": 688
        },
        {
            "transformers.models.vision_encoder_decoder.modeling_flax_vision_encoder_decoder.FlaxVisionEncoderDecoderModel.from_encoder_decoder_pretrained": 725
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/vision_encoder_decoder/modeling_vision_encoder_decoder.py": [
        {
            "transformers.models.vision_encoder_decoder.modeling_vision_encoder_decoder.VisionEncoderDecoderModel.from_pretrained": 246
        },
        {
            "transformers.models.vision_encoder_decoder.modeling_vision_encoder_decoder.VisionEncoderDecoderModel.from_encoder_decoder_pretrained": 366
        },
        {
            "transformers.models.vision_encoder_decoder.modeling_vision_encoder_decoder.VisionEncoderDecoderModel.forward": 521
        },
        {
            "transformers.models.vision_encoder_decoder.modeling_vision_encoder_decoder.VisionEncoderDecoderModel.prepare_inputs_for_generation": 651
        },
        {
            "transformers.models.vision_encoder_decoder.modeling_vision_encoder_decoder.VisionEncoderDecoderModel.resize_token_embeddings": 666
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/vision_encoder_decoder/modeling_tf_vision_encoder_decoder.py": [
        {
            "transformers.models.vision_encoder_decoder.modeling_tf_vision_encoder_decoder.TFVisionEncoderDecoderModel.from_pretrained": 297
        },
        {
            "transformers.models.vision_encoder_decoder.modeling_tf_vision_encoder_decoder.TFVisionEncoderDecoderModel.from_encoder_decoder_pretrained": 366
        },
        {
            "transformers.models.vision_encoder_decoder.modeling_tf_vision_encoder_decoder.TFVisionEncoderDecoderModel.call": 536
        },
        {
            "transformers.models.vision_encoder_decoder.modeling_tf_vision_encoder_decoder.TFVisionEncoderDecoderModel.prepare_inputs_for_generation": 731
        },
        {
            "transformers.models.vision_encoder_decoder.modeling_tf_vision_encoder_decoder.TFVisionEncoderDecoderModel.resize_token_embeddings": 752
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/vision_encoder_decoder/configuration_vision_encoder_decoder.py": [
        {
            "transformers.models.vision_encoder_decoder.configuration_vision_encoder_decoder.VisionEncoderDecoderConfig.__init__": 83
        },
        {
            "transformers.models.vision_encoder_decoder.configuration_vision_encoder_decoder.VisionEncoderDecoderConfig.from_encoder_decoder_configs": 101
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/mask2former/modeling_mask2former.py": [
        {
            "transformers.models.mask2former.modeling_mask2former.sample_point": 266
        },
        {
            "transformers.models.mask2former.modeling_mask2former.Mask2FormerMaskedAttentionDecoder.custom_forward": 1870
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/mask2former/image_processing_mask2former.py": [
        {
            "transformers.models.mask2former.image_processing_mask2former.Mask2FormerImageProcessor.__init__": 381
        },
        {
            "transformers.models.mask2former.image_processing_mask2former.Mask2FormerImageProcessor.from_dict": 432
        },
        {
            "transformers.models.mask2former.image_processing_mask2former.Mask2FormerImageProcessor.resize": 462
        },
        {
            "transformers.models.mask2former.image_processing_mask2former.Mask2FormerImageProcessor.__call__": 541
        },
        {
            "transformers.models.mask2former.image_processing_mask2former.Mask2FormerImageProcessor.preprocess": 629
        },
        {
            "transformers.models.mask2former.image_processing_mask2former.Mask2FormerImageProcessor.encode_inputs": 784
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/models/mask2former/configuration_mask2former.py": [
        {
            "transformers.models.mask2former.configuration_mask2former.Mask2FormerConfig.__init__": 127
        },
        {
            "transformers.models.mask2former.configuration_mask2former.Mask2FormerConfig.from_backbone_config": 211
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/data/data_collator.py": [
        {
            "transformers.data.data_collator.DataCollatorForSOP.__init__": 1122
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/data/processors/glue.py": [
        {
            "transformers.data.processors.glue.MrpcProcessor.__init__": 172
        },
        {
            "transformers.data.processors.glue.MnliProcessor.__init__": 219
        },
        {
            "transformers.data.processors.glue.MnliMismatchedProcessor.__init__": 265
        },
        {
            "transformers.data.processors.glue.ColaProcessor.__init__": 281
        },
        {
            "transformers.data.processors.glue.Sst2Processor.__init__": 328
        },
        {
            "transformers.data.processors.glue.StsbProcessor.__init__": 374
        },
        {
            "transformers.data.processors.glue.QqpProcessor.__init__": 420
        },
        {
            "transformers.data.processors.glue.QnliProcessor.__init__": 472
        },
        {
            "transformers.data.processors.glue.RteProcessor.__init__": 518
        },
        {
            "transformers.data.processors.glue.WnliProcessor.__init__": 564
        }
    ],
    "/home/zhang/Packages/transformers/transformers4.26.1/data/processors/utils.py": [
        {
            "transformers.data.processors.utils.SingleSentenceClassificationProcessor.create_from_csv": 143
        },
        {
            "transformers.data.processors.utils.SingleSentenceClassificationProcessor.create_from_examples": 160
        }
    ]
}